{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "16d969d4-d3a4-4c46-b647-167236c78768",
   "metadata": {},
   "source": [
    "<h3 align=\"center\">Status : <span class=\"badge\"><b>En cours</b></span></h3>\n",
    "\n",
    "<h1 align=\"center\">RL GRPO</h1>\n",
    "\n",
    "---\n",
    "\n",
    "<h1 align=\"center\">Training a small Unimarc reasoner with RL</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "208a0dbc-baee-49c3-9ce6-2522e07c3be6",
   "metadata": {},
   "source": [
    "# Requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3fa9d1ef-0ab5-4522-b9c7-fc0f70ce3232",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filesystem      Size  Used Avail Use% Mounted on\n",
      "overlay         6.5T  4.8T  1.5T  78% /\n",
      "tmpfs            64M     0   64M   0% /dev\n",
      "tmpfs            10G     0   10G   0% /dev/shm\n",
      "/dev/sdm1       6.5T  4.8T  1.5T  78% /etc/hosts\n",
      "/dev/rbd26       98G  512K   98G   1% /home/onyxia/work\n",
      "/dev/sdf2       438G  5.7G  410G   2% /usr/bin/nvidia-smi\n",
      "tmpfs           122G   12K  122G   1% /run/secrets/kubernetes.io/serviceaccount\n",
      "tmpfs           504G     0  504G   0% /proc/acpi\n",
      "tmpfs           504G     0  504G   0% /sys/firmware\n",
      "tmpfs           504G     0  504G   0% /sys/devices/virtual/powercap\n"
     ]
    }
   ],
   "source": [
    "!df -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "25f023b3-02d5-49aa-bfad-e3918e6c6f18",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "!cd /home/onyxia/work & rm -r sft_lora_one_step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "281f8077-e3f2-4a3d-bd8a-b82808b0e168",
   "metadata": {},
   "outputs": [],
   "source": [
    "del model\n",
    "del peft_model\n",
    "del merged_model\n",
    "del tokenizer\n",
    "del trainer\n",
    "torch.cuda.empty_cache() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0992aaaa-ea41-4a21-a161-dbb055c716aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "del trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1ddac3ec-3e4e-48b8-9a69-4d0fe027dfad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch:\n",
      "PyTorch version is:2.7.0+cu126\n",
      "PyTorch is working with CUDA\n",
      "The GPU model is: NVIDIA A2\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(\"PyTorch:\")\n",
    "print(\"PyTorch version is:\" + torch.__version__)\n",
    "print(\"PyTorch is working with CUDA\" if torch.cuda.is_available() else \"Error! It is not working correctly\")\n",
    "print(\"The GPU model is: \"+ torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d502c402-8236-4ecb-9654-6e0d7cfa994d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in /usr/local/lib/python3.12/site-packages (25.1.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0516e17e-d358-45e2-8ad7-f16c62cd5378",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U --quiet datasets transformers trl huggingface_hub accelerate peft --use-deprecated=legacy-resolver\n",
    "#if A100 or H100 GPU: pip install flash-attn tf-keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ec980996-ca3c-4b66-8a88-42200f930e31",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'type': 'user',\n",
       " 'id': '63256c1fa3f07c8e168c0d47',\n",
       " 'name': 'Geraldine',\n",
       " 'fullname': 'Géraldine Geoffroy',\n",
       " 'email': 'grldn.geoffroy@gmail.com',\n",
       " 'emailVerified': True,\n",
       " 'canPay': False,\n",
       " 'periodEnd': 1748735999,\n",
       " 'isPro': False,\n",
       " 'avatarUrl': '/avatars/9cb069e5e90930e818ebe69300cd35d8.svg',\n",
       " 'orgs': [{'type': 'org',\n",
       "   'id': '665f255b175693a15893b7a1',\n",
       "   'name': 'discord-community',\n",
       "   'fullname': 'Hugging Face Discord Community',\n",
       "   'email': 'lunarflu@gmail.com',\n",
       "   'canPay': False,\n",
       "   'periodEnd': 1748735999,\n",
       "   'avatarUrl': 'https://cdn-avatars.huggingface.co/v1/production/uploads/6340651b388c3fa40f9a5bc0/j6Vb_hutYuKRcQgMaDTAt.png',\n",
       "   'roleInOrg': 'read',\n",
       "   'isEnterprise': False}],\n",
       " 'auth': {'type': 'access_token',\n",
       "  'accessToken': {'displayName': 'write_hf_token',\n",
       "   'role': 'write',\n",
       "   'createdAt': '2024-11-08T10:49:12.891Z'}}}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from huggingface_hub import login, whoami\n",
    "\n",
    "login(\n",
    "  token=\"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\" # with write permissions\n",
    ")\n",
    "whoami()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07e21012-2850-4403-a395-c70cdc15465e",
   "metadata": {},
   "source": [
    "# Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "add8b2b4-0c14-4582-98ff-30df58a4ed8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8a178c0d-8bea-43c5-b2b1-fec88e470af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"Qwen/Qwen3-0.6B\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    torch_dtype=\"auto\",\n",
    "    device_map=\"auto\",\n",
    "    #attn_implementation=\"flash_attention_2\"\n",
    ")\n",
    "#model.config.sliding_window = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d70772a8-b356-4b59-b05a-dc779e9dbb0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Qwen3Config {\n",
      "  \"_attn_implementation_autoset\": true,\n",
      "  \"architectures\": [\n",
      "    \"Qwen3ForCausalLM\"\n",
      "  ],\n",
      "  \"attention_bias\": false,\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 151643,\n",
      "  \"eos_token_id\": 151645,\n",
      "  \"head_dim\": 128,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 1024,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"max_position_embeddings\": 40960,\n",
      "  \"max_window_layers\": 28,\n",
      "  \"model_type\": \"qwen3\",\n",
      "  \"num_attention_heads\": 16,\n",
      "  \"num_hidden_layers\": 28,\n",
      "  \"num_key_value_heads\": 8,\n",
      "  \"rms_norm_eps\": 1e-06,\n",
      "  \"rope_scaling\": null,\n",
      "  \"rope_theta\": 1000000,\n",
      "  \"sliding_window\": null,\n",
      "  \"tie_word_embeddings\": true,\n",
      "  \"torch_dtype\": \"bfloat16\",\n",
      "  \"transformers_version\": \"4.51.3\",\n",
      "  \"use_cache\": true,\n",
      "  \"use_sliding_window\": false,\n",
      "  \"vocab_size\": 151936\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(model.config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6db1ceba-0d68-4622-8e50-3a37e482344b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Qwen3ForCausalLM(\n",
       "  (model): Qwen3Model(\n",
       "    (embed_tokens): Embedding(151936, 1024)\n",
       "    (layers): ModuleList(\n",
       "      (0-27): 28 x Qwen3DecoderLayer(\n",
       "        (self_attn): Qwen3Attention(\n",
       "          (q_proj): Linear(in_features=1024, out_features=2048, bias=False)\n",
       "          (k_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (v_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (o_proj): Linear(in_features=2048, out_features=1024, bias=False)\n",
       "          (q_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
       "          (k_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
       "        )\n",
       "        (mlp): Qwen3MLP(\n",
       "          (gate_proj): Linear(in_features=1024, out_features=3072, bias=False)\n",
       "          (up_proj): Linear(in_features=1024, out_features=3072, bias=False)\n",
       "          (down_proj): Linear(in_features=3072, out_features=1024, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): Qwen3RMSNorm((1024,), eps=1e-06)\n",
       "        (post_attention_layernorm): Qwen3RMSNorm((1024,), eps=1e-06)\n",
       "      )\n",
       "    )\n",
       "    (norm): Qwen3RMSNorm((1024,), eps=1e-06)\n",
       "    (rotary_emb): Qwen3RotaryEmbedding()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=1024, out_features=151936, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model.config.sliding_window = None\n",
    "device = \"cuda\" # for GPU usage or \"cpu\" for CPU usage\n",
    "model = model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bca1192b-9713-4f53-9340-c17d0273e6b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !Important\n",
    "tokenizer.padding_side = \"right\"\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70fdbedb-cdcf-471b-87d1-980842de7d49",
   "metadata": {},
   "source": [
    "## Inspect tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cea2c081-d317-4090-ab34-2c9fd5d6da83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "151669"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b093e0fa-0034-4024-8b51-b685c53de48c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**EOS**\n",
      "EOS token: <|im_end|>\n",
      "- EOS token id: 151645\n",
      "\n",
      "**PAD**\n",
      "PAD token: <|endoftext|>\n",
      "- PAD token id: 151643\n"
     ]
    }
   ],
   "source": [
    "print(f\"**EOS**\\nEOS token: {tokenizer.eos_token}\\n- EOS token id: {tokenizer.eos_token_id}\\n\\n**PAD**\\nPAD token: {tokenizer.pad_token}\\n- PAD token id: {tokenizer.pad_token_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8d2ce30d-56cb-471d-b2aa-2785766222f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[151667]], device='cuda:0'), 'attention_mask': tensor([[1]], device='cuda:0')}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer(\"<think>\", return_tensors=\"pt\").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ec381b03-cedc-47ff-8d58-5d05985f7b48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'</think>'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(151668)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d1097588-e692-4a37-9253-56eefc10537f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[ 1782, 12884,   374,  6303]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1]], device='cuda:0')}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer(\"the sky is blue\", return_tensors=\"pt\").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a232afe9-f43e-405d-b470-78fa8a0f26c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = tokenizer(\"the sky is blue\", return_tensors=\"pt\").to(device).input_ids[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b85a729e-cee3-4264-82dd-90e0e62e78a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'the sky is blue'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "03458069-d640-43d2-b800-f4c1882b7dd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current chat template: {%- if tools %}\n",
      "    {{- '<|im_start|>system\\n' }}\n",
      "    {%- if messages[0].role == 'system' %}\n",
      "        {{- messages[0].content + '\\n\\n' }}\n",
      "    {%- endif %}\n",
      "    {{- \"# Tools\\n\\nYou may call one or more functions to assist with the user query.\\n\\nYou are provided with function signatures within <tools></tools> XML tags:\\n<tools>\" }}\n",
      "    {%- for tool in tools %}\n",
      "        {{- \"\\n\" }}\n",
      "        {{- tool | tojson }}\n",
      "    {%- endfor %}\n",
      "    {{- \"\\n</tools>\\n\\nFor each function call, return a json object with function name and arguments within <tool_call></tool_call> XML tags:\\n<tool_call>\\n{\\\"name\\\": <function-name>, \\\"arguments\\\": <args-json-object>}\\n</tool_call><|im_end|>\\n\" }}\n",
      "{%- else %}\n",
      "    {%- if messages[0].role == 'system' %}\n",
      "        {{- '<|im_start|>system\\n' + messages[0].content + '<|im_end|>\\n' }}\n",
      "    {%- endif %}\n",
      "{%- endif %}\n",
      "{%- set ns = namespace(multi_step_tool=true, last_query_index=messages|length - 1) %}\n",
      "{%- for message in messages[::-1] %}\n",
      "    {%- set index = (messages|length - 1) - loop.index0 %}\n",
      "    {%- if ns.multi_step_tool and message.role == \"user\" and not(message.content.startswith('<tool_response>') and message.content.endswith('</tool_response>')) %}\n",
      "        {%- set ns.multi_step_tool = false %}\n",
      "        {%- set ns.last_query_index = index %}\n",
      "    {%- endif %}\n",
      "{%- endfor %}\n",
      "{%- for message in messages %}\n",
      "    {%- if (message.role == \"user\") or (message.role == \"system\" and not loop.first) %}\n",
      "        {{- '<|im_start|>' + message.role + '\\n' + message.content + '<|im_end|>' + '\\n' }}\n",
      "    {%- elif message.role == \"assistant\" %}\n",
      "        {%- set content = message.content %}\n",
      "        {%- set reasoning_content = '' %}\n",
      "        {%- if message.reasoning_content is defined and message.reasoning_content is not none %}\n",
      "            {%- set reasoning_content = message.reasoning_content %}\n",
      "        {%- else %}\n",
      "            {%- if '</think>' in message.content %}\n",
      "                {%- set content = message.content.split('</think>')[-1].lstrip('\\n') %}\n",
      "                {%- set reasoning_content = message.content.split('</think>')[0].rstrip('\\n').split('<think>')[-1].lstrip('\\n') %}\n",
      "            {%- endif %}\n",
      "        {%- endif %}\n",
      "        {%- if loop.index0 > ns.last_query_index %}\n",
      "            {%- if loop.last or (not loop.last and reasoning_content) %}\n",
      "                {{- '<|im_start|>' + message.role + '\\n<think>\\n' + reasoning_content.strip('\\n') + '\\n</think>\\n\\n' + content.lstrip('\\n') }}\n",
      "            {%- else %}\n",
      "                {{- '<|im_start|>' + message.role + '\\n' + content }}\n",
      "            {%- endif %}\n",
      "        {%- else %}\n",
      "            {{- '<|im_start|>' + message.role + '\\n' + content }}\n",
      "        {%- endif %}\n",
      "        {%- if message.tool_calls %}\n",
      "            {%- for tool_call in message.tool_calls %}\n",
      "                {%- if (loop.first and content) or (not loop.first) %}\n",
      "                    {{- '\\n' }}\n",
      "                {%- endif %}\n",
      "                {%- if tool_call.function %}\n",
      "                    {%- set tool_call = tool_call.function %}\n",
      "                {%- endif %}\n",
      "                {{- '<tool_call>\\n{\"name\": \"' }}\n",
      "                {{- tool_call.name }}\n",
      "                {{- '\", \"arguments\": ' }}\n",
      "                {%- if tool_call.arguments is string %}\n",
      "                    {{- tool_call.arguments }}\n",
      "                {%- else %}\n",
      "                    {{- tool_call.arguments | tojson }}\n",
      "                {%- endif %}\n",
      "                {{- '}\\n</tool_call>' }}\n",
      "            {%- endfor %}\n",
      "        {%- endif %}\n",
      "        {{- '<|im_end|>\\n' }}\n",
      "    {%- elif message.role == \"tool\" %}\n",
      "        {%- if loop.first or (messages[loop.index0 - 1].role != \"tool\") %}\n",
      "            {{- '<|im_start|>user' }}\n",
      "        {%- endif %}\n",
      "        {{- '\\n<tool_response>\\n' }}\n",
      "        {{- message.content }}\n",
      "        {{- '\\n</tool_response>' }}\n",
      "        {%- if loop.last or (messages[loop.index0 + 1].role != \"tool\") %}\n",
      "            {{- '<|im_end|>\\n' }}\n",
      "        {%- endif %}\n",
      "    {%- endif %}\n",
      "{%- endfor %}\n",
      "{%- if add_generation_prompt %}\n",
      "    {{- '<|im_start|>assistant\\n' }}\n",
      "    {%- if enable_thinking is defined and enable_thinking is false %}\n",
      "        {{- '<think>\\n\\n</think>\\n\\n' }}\n",
      "    {%- endif %}\n",
      "{%- endif %}\n"
     ]
    }
   ],
   "source": [
    "if hasattr(tokenizer, \"chat_template\"):\n",
    "    print(\"Current chat template:\", tokenizer.chat_template)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "650b9be4-19ca-40cc-97af-56bd0f6f570f",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6daf62b3-b325-42ed-8dee-f4e74c704f3c",
   "metadata": {},
   "source": [
    "### Without applying chat templating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "92e78fa0-e0d2-4382-b738-98663777d509",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"<|im_start|>system: You are a helpful assistant /no_think<|im_end|><|im_start|>user: complete this sentence 'the sky is blue and '<|im_end|><|im_start|>assistant: \"\n",
    "inputs = tokenizer(prompt, return_tensors=\"pt\").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8db10eed-0a4c-4ce6-866e-65574ec0b73a",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = model.generate(**inputs,\n",
    "                         max_new_tokens = 20,\n",
    "                         use_cache = True,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f2145d5d-c8cf-4019-802e-62d49ec09230",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|im_start|>system: You are a helpful assistant /no_think<|im_end|><|im_start|>user: complete this sentence 'the sky is blue and '<|im_end|><|im_start|>assistant: <think>\n",
      "\n",
      "<think>\n",
      "</think>\n",
      "\n",
      "the sky is blue and the sun is shining bright.<|im_end|>\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.decode(outputs[0], skip_special_tokens=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55a0c2d9-0160-41be-9d2e-e3bda819782e",
   "metadata": {},
   "source": [
    "### With applying chat templating"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b379d646-b3fe-4803-9519-1723ed53586e",
   "metadata": {},
   "source": [
    "#### No thinking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "1e6303e7-c98a-44ab-a0a9-6b545df643f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"\n",
    "You are a helpful assistant expert in Unimarc/XML bibliographic records.\n",
    "Your task is to generate a valid Unimarc XML record from given bibliographic metadata.\n",
    "\"\"\"\n",
    "\n",
    "user_prompt = \"\"\"\n",
    "Title: Electric vehicle tribology\n",
    "Subtitle: Challenges and opportunities for a sustainable transportation future\n",
    "Author: Leonardo I. Farfan-Cabrera, Ali Erdemir\n",
    "Publisher: Elsevier\n",
    "Year: 2024\n",
    "ISBN: 978-0-443-14074-7\n",
    "Language: English\n",
    "Collection/Series: Elsevier Series on Tribology and Surface Engineering\n",
    "Edition: Not specified\n",
    "Material description: 1 vol. (XI-313 p.), couv. ill. en coul., 23 cm\n",
    "Abstract/Notes: \"Electric vehicle tribology, challenges and opportunities for a sustainable transportation future\" provides practical, comprehensive guidance on a new and increasingly important area of tribology. Building skills from fundamentals to solution design, this book demonstrates the unique tribological techniques essential to the efficient electrification of transport systems. Led by professors with a combined three decades in industry and academia, and collecting insights from experts around the world, this book begins with the essential knowledge regarding both electric vehicles and tribology. After outlining the unique tribological needs of EVs, the book then breaks down the components and hardware required. It provides detailed protocols and methods for the testing and improvement of lubricants and materials as well as a dedicated section on modern lubrication specific to EVs. Throughout, it considers the critical question of sustainable tribology and the long-term sustainable options for lubrication and materials for electric vehicles.\n",
    "Source of the abstract/notes: 4e de couverture\n",
    "Table of contents: Not specified\n",
    "Keywords: Tribologie (technologie), Tribologie (Technologie)\n",
    "\"\"\"\n",
    "\n",
    "messages = [\n",
    "  {\"role\": \"system\", \"content\": system_prompt},\n",
    "  {\"role\": \"user\", \"content\": user_prompt},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6400bc7e-061f-4dc5-a465-d8be980a008f",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer.apply_chat_template(\n",
    "    messages,\n",
    "    return_dict=True,\n",
    "    tokenize = True,\n",
    "    add_generation_prompt = True, # Must add for generation\n",
    "    return_tensors = \"pt\",\n",
    "    enable_thinking=False\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "39395bd2-69eb-4689-8cb6-ffafb1de6e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = model.generate(\n",
    "    **inputs,\n",
    "    max_new_tokens = 32768,\n",
    "    use_cache = True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bf8b8c06-ca8e-46b2-aaf4-e5e9034d89e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_ids = outputs[0][len(inputs.input_ids[0]):].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2277029b-87e2-4d3b-8774-869a1b1feb00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thinking content: \n",
      "content: <unimarc:record>\n",
      "<unimarc:isbn>978-0-443-14074-7</unimarc:isbn>\n",
      "<unimarc:year>2024</unimarc:year>\n",
      "<unimarc:collection>Elsevier Series on Tribology and Surface Engineering</unimarc:collection>\n",
      "<unimarc:edition>Not specified</unimarc:edition>\n",
      "<unimarc:language>English</unimarc:language>\n",
      "<unimarc:publisher>Elsevier</unimarc:publisher>\n",
      "<unimarc:author>Leonardo I. Farfan-Cabrera, Ali Erdemir</unimarc:author>\n",
      "<unimarc:abstract>Electric vehicle tribology, challenges and opportunities for a sustainable transportation future provides practical, comprehensive guidance on a new and increasingly important area of tribology. Building skills from fundamentals to solution design, this book demonstrates the unique tribological techniques essential to the efficient electrification of transport systems. Led by professors with a combined three decades in industry and academia, and collecting insights from experts around the world, this book begins with the essential knowledge regarding both electric vehicles and tribology. After outlining the unique tribological needs of EVs, the book then breaks down the components and hardware required. It provides detailed protocols and methods for the testing and improvement of lubricants and materials as well as a dedicated section on modern lubrication specific to EVs. Throughout, it considers the critical question of sustainable tribology and the long-term sustainable options for lubrication and materials for electric vehicles.</unimarc:abstract>\n",
      "<unimarc:notes>4e de couverture</unimarc:notes>\n",
      "<unimarc:table-of-contents>Not specified</unimarc:table-of-contents>\n",
      "<unimarc:keywords>tribologie (technologie), tribologie (Technologie)</unimarc:keywords>\n",
      "</unimarc:record>\n"
     ]
    }
   ],
   "source": [
    "# parsing thinking content\n",
    "try:\n",
    "    # rindex finding 151668 (</think>)\n",
    "    index = len(output_ids) - output_ids[::-1].index(151668)\n",
    "except ValueError:\n",
    "    index = 0\n",
    "\n",
    "thinking_content = tokenizer.decode(output_ids[:index], skip_special_tokens=True).strip(\"\\n\")\n",
    "content = tokenizer.decode(output_ids[index:], skip_special_tokens=True).strip(\"\\n\")\n",
    "\n",
    "print(\"thinking content:\", thinking_content)\n",
    "print(\"content:\", content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "291fe1e1-552d-4768-b61a-11c7a3db482e",
   "metadata": {},
   "source": [
    "#### Thinking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "de048f76-03c7-413c-bb0e-05b714dcda1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"\n",
    "You are an expert in Unimarc/XML bibliographic records encoding.\n",
    "Here is bibliographic metadata: explain step-by-step how to transform metadata into this a compliant Unimarc/XML record.\n",
    "For example:\n",
    "- Title maps to 200$a\n",
    "- Subtitle to 200$e\n",
    "- ...\n",
    "Then generate Unimarc/XML from your reasoning\n",
    "\"\"\"\n",
    "\n",
    "user_prompt = \"\"\"\n",
    "Title: Electric vehicle tribology\n",
    "Subtitle: Challenges and opportunities for a sustainable transportation future\n",
    "Author: Leonardo I. Farfan-Cabrera, Ali Erdemir\n",
    "Publisher: Elsevier\n",
    "Year: 2024\n",
    "ISBN: 978-0-443-14074-7\n",
    "Language: English\n",
    "Collection/Series: Elsevier Series on Tribology and Surface Engineering\n",
    "Edition: Not specified\n",
    "Material description: 1 vol. (XI-313 p.), couv. ill. en coul., 23 cm\n",
    "Abstract/Notes: \"Electric vehicle tribology, challenges and opportunities for a sustainable transportation future\" provides practical, comprehensive guidance on a new and increasingly important area of tribology. Building skills from fundamentals to solution design, this book demonstrates the unique tribological techniques essential to the efficient electrification of transport systems. Led by professors with a combined three decades in industry and academia, and collecting insights from experts around the world, this book begins with the essential knowledge regarding both electric vehicles and tribology. After outlining the unique tribological needs of EVs, the book then breaks down the components and hardware required. It provides detailed protocols and methods for the testing and improvement of lubricants and materials as well as a dedicated section on modern lubrication specific to EVs. Throughout, it considers the critical question of sustainable tribology and the long-term sustainable options for lubrication and materials for electric vehicles.\n",
    "Source of the abstract/notes: 4e de couverture\n",
    "Table of contents: Not specified\n",
    "Keywords: Tribologie (technologie), Tribologie (Technologie)\n",
    "\"\"\"\n",
    "\n",
    "messages = [\n",
    "  {\"role\": \"system\", \"content\": system_prompt},\n",
    "  {\"role\": \"user\", \"content\": user_prompt},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "97d0dd62-9dac-4d82-9a7a-71ac6bb727e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer.apply_chat_template(\n",
    "    messages,\n",
    "    return_dict=True,\n",
    "    tokenize = True,\n",
    "    add_generation_prompt = True, # Must add for generation\n",
    "    return_tensors = \"pt\",\n",
    "    enable_thinking=True\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0604e9bb-95cb-4dba-92a8-98fefba1b62c",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = model.generate(\n",
    "    **inputs,\n",
    "    max_new_tokens = 32768,\n",
    "    use_cache = True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "770fcb0f-f46e-4fd0-994e-b0885fc1bbce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thinking content: <think>\n",
      "Okay, let's start by understanding the user's request. They want me to transform the provided bibliographic metadata into a compliant Unimarc/XML record. The example given was a structure where each field maps to specific numbers like 200$a, 200$e, etc. So, I need to follow that format step by step.\n",
      "\n",
      "First, I'll check the title. The title is \"Electric vehicle tribology\". The example uses 200$a, so I'll map that to the title. The subtitle is \"Challenges and opportunities for a sustainable transportation future\". The example uses 200$e, so that's the subtitle. \n",
      "\n",
      "Next, the authors are Leonardo I. Farfan-Cabrera and Ali Erdemir. The example uses 200$e for the authors, so I'll list them as such. The publisher is Elsevier, and the year is 2024. The ISBN is 978-0-443-14074-7, which maps to 200$e as well. \n",
      "\n",
      "The collection/series is \"Elsevier Series on Tribology and Surface Engineering\". The example uses 200$e again, so that's the series. The edition is \"Not specified\", so maybe leave it as is. The material description has 1 vol. (XI-313 p.), couv. ill. en coul., 23 cm. The abstract/notes mention sustainable tribology and EVs. The source of the abstract is 4e de couverture, which maps to 200$e. \n",
      "\n",
      "I need to make sure each field is mapped correctly. Let me double-check the example structure. The example uses 200$a for the title, 200$e for the subtitle, and so on. So, each key in the metadata should correspond to a 200$ number. \n",
      "\n",
      "Wait, the user's example uses 200$a for title, 200$e for subtitle, and so on. So, the key is to map each field to the corresponding 200$ code. Let me list out each part:\n",
      "\n",
      "- Title: 200$a\n",
      "- Subtitle: 200$e\n",
      "- Authors: 200$e\n",
      "- Publisher: 200$e\n",
      "- Year: 200$a\n",
      "- ISBN: 200$e\n",
      "- Collection/Series: 200$e\n",
      "- Edition: 200$e\n",
      "- Material description: 200$a (volume, pages, etc.)\n",
      "\n",
      "I need to ensure that each field is mapped correctly. Let me check again. The example uses 200$a for the title, which matches the first field. The subtitle is 200$e. Authors are 200$e. The publisher is 200$e. Year is 200$a. ISBN is 200$e. Collection/Series is 200$e. Edition is 200$e. Material description has volume, pages, etc., which would be 200$a. \n",
      "\n",
      "So, putting it all together, the Unimarc/XML record should have each key mapped to the corresponding 200$ number. I need to make sure there are no typos and that each part is correctly placed. Once all fields are mapped, the final XML should look like the example provided.\n",
      "</think>\n",
      "content: - Title maps to 200$a  \n",
      "- Subtitle maps to 200$e  \n",
      "- Authors map to 200$e  \n",
      "- Publisher maps to 200$e  \n",
      "- Year maps to 200$a  \n",
      "- ISBN maps to 200$e  \n",
      "- Collection/Series maps to 200$e  \n",
      "- Edition maps to 200$e  \n",
      "- Volume maps to 200$a  \n",
      "- Pages maps to 200$a  \n",
      "- Cover illustrations maps to 200$e  \n",
      "- Language maps to 200$e  \n",
      "- Abstract/Notes maps to 200$e  \n",
      "\n",
      "```xml\n",
      "<unimarc:record>\n",
      "  <unimarc:identifier>\n",
      "    <unimarc:identifierType>ISBN</unimarc:identifierType>\n",
      "    <unimarc:identifierValue>978-0-443-14074-7</unimarc:identifier>\n",
      "  </unimarc:identifier>\n",
      "  <unimarc:title>Electric vehicle tribology</unimarc:title>\n",
      "  <unimarc:subtitle>Challenges and opportunities for a sustainable transportation future</unimarc:subtitle>\n",
      "  <unimarc:author>Leonardo I. Farfan-Cabrera, Ali Erdemir</unimarc:author>\n",
      "  <unimarc:publisher>Elsevier</unimarc:publisher>\n",
      "  <unimarc:year>2024</unimarc:year>\n",
      "  <unimarc:collection>Elsevier Series on Tribology and Surface Engineering</unimarc:collection>\n",
      "  <unimarc:edition>Not specified</unimarc:edition>\n",
      "  <unimarc:material>1 vol. (XI-313 p.), couv. ill. en coul., 23 cm</unimarc:material>\n",
      "  <unimarc:abstract>...</unimarc:abstract>\n",
      "  <unimarc:notes>4e de couverture</unimarc:notes>\n",
      "</unimarc:record>\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "output_ids = outputs[0][len(inputs.input_ids[0]):].tolist()\n",
    "# parsing thinking content\n",
    "try:\n",
    "    # rindex finding 151668 (</think>)\n",
    "    index = len(output_ids) - output_ids[::-1].index(151668)\n",
    "except ValueError:\n",
    "    index = 0\n",
    "\n",
    "thinking_content = tokenizer.decode(output_ids[:index], skip_special_tokens=True).strip(\"\\n\")\n",
    "content = tokenizer.decode(output_ids[index:], skip_special_tokens=True).strip(\"\\n\")\n",
    "\n",
    "print(\"thinking content:\", thinking_content)\n",
    "print(\"content:\", content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52e940fb-b2f3-4340-8a86-55c0aacc2877",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(tokenizer.decode(outputs[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c037b7da-39f5-4576-80a3-7267775e0408",
   "metadata": {},
   "outputs": [],
   "source": [
    "#generated_ids = [\n",
    "#   output_ids[len(input_ids):] for input_ids, output_ids in zip(inputs.input_ids, outputs)\n",
    "#]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "766efb3a-dc8c-4278-b4be-1174ba8aa78f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c09f9a3-8e84-4392-a2c1-eacfe5d26b3d",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e481b67f-1e1f-4ec2-b573-a5a8c61ef24c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset, Dataset\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4ea14964-a96a-400b-a2ac-855241bc2ea4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 100%|██████████| 673/673 [00:00<00:00, 786.07 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['ppn', 'metadata', 'unimarc_record', 'reasoning'],\n",
       "    num_rows: 673\n",
       "})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = load_dataset(\"Geraldine/metadata-to-unimarc-traces\", split=\"train\")\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7ac3a96d-a170-44f7-a56d-9818ff24dd49",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.select(range(50))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30e138e2-5597-4c34-b889-e74ea23a379d",
   "metadata": {},
   "source": [
    "# One-step training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fb3eb03c-99b5-4551-aa2b-9bb73306ee84",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM, TrainingArguments\n",
    "from trl import SFTTrainer\n",
    "from peft import LoraConfig\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8dbe511f-d76b-4e52-a0dc-d1835f529e92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<|im_end|>'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65d50e36-36fc-469d-84fd-66a78be8d9e9",
   "metadata": {},
   "source": [
    "## Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f42fd549-efc6-4f90-9528-33986cf83222",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 673/673 [00:00<00:00, 4588.01 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['messages'],\n",
       "    num_rows: 673\n",
       "})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "system_message = \"\"\"\n",
    "You are an expert bibliographic cataloguer specialized in Unimarc/XML.\n",
    "Given bibliographic metadata, your task is to generate detailed reasoning about how these metadata should be mapped to Unimarc fields.\n",
    "Strictly follow the Unimarc standards.\"\"\"\n",
    "\n",
    "def create_conversation(row):\n",
    "  return {\n",
    "    \"messages\": [\n",
    "      {\"role\": \"system\", \"content\": system_message + \" /think\"},\n",
    "      {\"role\": \"user\", \"content\": f\"# Bibliographical metadata:\\n{row['metadata']}\"},\n",
    "      {\"role\": \"assistant\", \"content\": \"thinking content: <think> \" + row[\"reasoning\"] + \"</think>\\ncontent: <record><controlfield tag='001'>...</controlfield>...</record>\"} # to avoid infinite generation\n",
    "    ]\n",
    "  }\n",
    "\n",
    "dataset = dataset.map(create_conversation, remove_columns=dataset.features, batched=False)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ba6d5d8f-a3d5-4f25-83aa-0765a911d1c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 50/50 [00:00<00:00, 151.14 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['messages'],\n",
       "    num_rows: 50\n",
       "})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "system_message = \"\"\"\n",
    "You are a helpful assistant expert in Unimarc/XML bibliographic records\"\"\"\n",
    "\n",
    "def create_conversation(row):\n",
    "  return {\n",
    "    \"messages\": [\n",
    "      {\"role\": \"system\", \"content\": system_message + \" /think\"},\n",
    "      {\"role\": \"user\", \"content\": f\"# Bibliographical metadata:\\n{row['metadata']}\\n\\n# Unimarc/XML record:\\n{row['unimarc_record']}\"},\n",
    "      {\"role\": \"assistant\", \"content\": \"thinking content: <think> \" + row[\"reasoning\"] + \"</think>\\ncontent: <record><controlfield tag='001'>...</controlfield>...[UNIMARC/XML GOES HERE]...</record>\"} # to avoid infinite generation\n",
    "    ]\n",
    "  }\n",
    "\n",
    "dataset = dataset.map(create_conversation, remove_columns=dataset.features, batched=False)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e98e4986-4505-47bb-919c-ae8f588864ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [{'content': '\\nYou are a helpful assistant expert in Unimarc/XML bibliographic records /think',\n",
       "   'role': 'system'},\n",
       "  {'content': '# Bibliographical metadata:\\nTitle: Yoga senior  \\nSubtitle: la méthode de Gasquet  \\nAuthor: Dr Bernadette de Gasquet  \\nParticipation: avec la participation du Dr Marie Thirion  \\nAuthor details:  \\n- Bernadette de Gasquet (born 1946)  \\n- Marie Thirion (born 1944), pediatrician  \\n\\nPublisher: Robert Laffont  \\nPlace of publication: Paris  \\nYear: DL 2019 (Legal deposit 2019)  \\n\\nISBN: 978-2-221-24174-5  \\nOther identifier: 9782221241745 (EAN)  \\nOCLC number: 1107377985  \\n\\nLanguage: French (fre)  \\n\\nEdition: Not explicitly stated; appears first edition  \\n\\nMaterial Description:  \\n- 1 volume (250 pages)  \\n- Illustrations, color illustrated cover  \\n- Dimensions: 22 cm  \\n\\nCollection/Series: Réponses  \\n\\nNotes/Bibliographic references: Notes bibliogr.  \\n\\nAbstract/Notes:  \\nLa méthode de Gasquet enfin adaptée aux seniors ! Quelle activité physique pratiquer lorsque, à 50 ans, des fragilités corporelles et des douleurs apparaissent ? Comment prendre soin de soi, garder un corps fonctionnel et source de plaisir ? Spécialiste du périnée, professeure de yoga, reconnue et suivie par des médecins, des sages-femmes, des kinésithérapeutes et des coachs sportifs dans le monde entier, Bernadette de Gasquet adapte dans ce livre sa célèbre méthode aux seniors et propose un travail sur le renforcement musculaire, sans recherche de la performance, à travers des exercices simples. Travail corporel sans douleur et sans risque, discipline au service de l\\'être humain, le yoga peut être pratiqué à tout âge. En alternant tonification et détente, renforcements et étirements, en associant respiration et action sur les fonctions vitales, on peut garder un corps en pleine forme. Bernadette de Gasquet reprend ici les bases de l\\'activité physique – postures, respiration, abdominaux – en se concentrant sur les maux des seniors – douleurs articulaires, problèmes de circulation, de constipation, hypertension, troubles respiratoires, rhumatismes... – pour leur donner les clés d\\'une vie plus saine et du bien-être au quotidien. 200 photos, 15 schémas, des exercices filmés... Yoga senior vous propose de nombreux conseils pratiques et des exercices physiques adaptés pour rester en forme après 50 ans.  \\nSource of the abstract/notes: éditeur  \\n\\nTable of contents: Not provided  \\n\\nKeywords/Subject headings:  \\n- Hatha-yoga (RAMEAU)  \\n- Exercices physiques pour personnes âgées (RAMEAU)  \\n\\nClassification:  \\n- Dewey: 613.710 846  \\n- French national bibliography classification: 610  \\n- Réponses (Paris. 1967) [series] ISSN 0750-7747  \\n\\nCountry of publication: France (FR)  \\n\\nOther information:  \\n- Legal deposit and cataloging codes for French institutions included  \\n- Material type: text, printed book  \\n- Carrier type: volume (nga)\\n\\n# Unimarc/XML record:\\n<record><controlfield tag=\"005\">20210208123415.000</controlfield><leader> cam0 22        450 </leader><controlfield tag=\"001\">236807005</controlfield><controlfield tag=\"003\">http://www.sudoc.fr/236807005</controlfield><datafield tag=\"035\" ind1=\" \" ind2=\" \"><subfield code=\"a\">(OCoLC)1107377985</subfield></datafield><datafield tag=\"010\" ind1=\" \" ind2=\" \"><subfield code=\"a\">978-2-221-24174-5</subfield><subfield code=\"b\">br.</subfield></datafield><datafield tag=\"073\" ind1=\" \" ind2=\"1\"><subfield code=\"a\">9782221241745</subfield></datafield><datafield tag=\"035\" ind1=\" \" ind2=\" \"><subfield code=\"a\">FRBNF457384730000008</subfield><subfield code=\"z\">FRBNF45738473</subfield></datafield><datafield tag=\"100\" ind1=\" \" ind2=\" \"><subfield code=\"a\">20190703h20192019m  y0frey50      ba</subfield></datafield><datafield tag=\"101\" ind1=\"0\" ind2=\" \"><subfield code=\"a\">fre</subfield><subfield code=\"2\">639-2</subfield></datafield><datafield tag=\"105\" ind1=\" \" ind2=\" \"><subfield code=\"a\">a   ||||000yy</subfield></datafield><datafield tag=\"106\" ind1=\" \" ind2=\" \"><subfield code=\"a\">r</subfield></datafield><datafield tag=\"181\" ind1=\" \" ind2=\" \"><subfield code=\"6\">z01</subfield><subfield code=\"c\">txt</subfield><subfield code=\"2\">rdacontent</subfield></datafield><datafield tag=\"181\" ind1=\" \" ind2=\"1\"><subfield code=\"6\">z01</subfield><subfield code=\"a\">i#</subfield><subfield code=\"b\">xxxe##</subfield></datafield><datafield tag=\"182\" ind1=\" \" ind2=\" \"><subfield code=\"6\">z01</subfield><subfield code=\"c\">n</subfield><subfield code=\"2\">rdamedia</subfield></datafield><datafield tag=\"182\" ind1=\" \" ind2=\"1\"><subfield code=\"6\">z01</subfield><subfield code=\"a\">n</subfield></datafield><datafield tag=\"183\" ind1=\" \" ind2=\"1\"><subfield code=\"6\">z01</subfield><subfield code=\"a\">nga</subfield><subfield code=\"2\">RDAfrCarrier</subfield></datafield><datafield tag=\"102\" ind1=\" \" ind2=\" \"><subfield code=\"a\">FR</subfield></datafield><datafield tag=\"320\" ind1=\" \" ind2=\" \"><subfield code=\"a\">Notes bibliogr.</subfield></datafield><datafield tag=\"200\" ind1=\"1\" ind2=\" \"><subfield code=\"a\">Yoga senior</subfield><subfield code=\"e\">la méthode de Gasquet</subfield><subfield code=\"f\">Dr Bernadette de Gasquet</subfield><subfield code=\"f\">avec la participation du Dr Marie Thirion</subfield></datafield><datafield tag=\"700\" ind1=\" \" ind2=\"1\"><subfield code=\"3\">084278986</subfield><subfield code=\"a\">Gasquet</subfield><subfield code=\"b\">Bernadette de</subfield><subfield code=\"f\">1946-....</subfield><subfield code=\"4\">070</subfield></datafield><datafield tag=\"702\" ind1=\" \" ind2=\"1\"><subfield code=\"3\">028312635</subfield><subfield code=\"a\">Thirion</subfield><subfield code=\"b\">Marie</subfield><subfield code=\"f\">1944-....</subfield><subfield code=\"c\">pédiatre</subfield><subfield code=\"4\">205</subfield></datafield><datafield tag=\"801\" ind1=\" \" ind2=\"3\"><subfield code=\"a\">FR</subfield><subfield code=\"b\">Abes</subfield><subfield code=\"c\">20210208</subfield><subfield code=\"g\">AFNOR</subfield></datafield><datafield tag=\"214\" ind1=\" \" ind2=\"0\"><subfield code=\"a\">Paris</subfield><subfield code=\"c\">Robert Laffont</subfield><subfield code=\"d\">DL 2019</subfield></datafield><datafield tag=\"215\" ind1=\" \" ind2=\" \"><subfield code=\"a\">1 vol. (250 p.)</subfield><subfield code=\"c\">ill., couv. ill. en coul.</subfield><subfield code=\"d\">22 cm</subfield></datafield><datafield tag=\"225\" ind1=\"0\" ind2=\" \"><subfield code=\"a\">Réponses</subfield></datafield><datafield tag=\"410\" ind1=\" \" ind2=\"|\"><subfield code=\"0\">001026399</subfield><subfield code=\"t\">Réponses (Paris. 1967)</subfield><subfield code=\"x\">0750-7747</subfield></datafield><datafield tag=\"606\" ind1=\" \" ind2=\" \"><subfield code=\"3\">027347893</subfield><subfield code=\"a\">Hatha-yoga</subfield><subfield code=\"2\">rameau</subfield></datafield><datafield tag=\"606\" ind1=\" \" ind2=\" \"><subfield code=\"3\">027425541</subfield><subfield code=\"a\">Exercices physiques pour personnes âgées</subfield><subfield code=\"2\">rameau</subfield></datafield><datafield tag=\"676\" ind1=\" \" ind2=\" \"><subfield code=\"a\">613.710 846</subfield><subfield code=\"v\">23</subfield></datafield><datafield tag=\"686\" ind1=\" \" ind2=\" \"><subfield code=\"a\">610</subfield><subfield code=\"2\">Cadre de classement de la Bibliographie nationale française</subfield></datafield><datafield tag=\"801\" ind1=\" \" ind2=\"0\"><subfield code=\"a\">FR</subfield><subfield code=\"b\">FR-751131015</subfield><subfield code=\"c\">20190529</subfield><subfield code=\"g\">AFNOR</subfield><subfield code=\"2\">intermrc</subfield></datafield><datafield tag=\"330\" ind1=\" \" ind2=\" \"><subfield code=\"a\">La méthode de Gasquet enfin adaptée aux seniors ! Quelle activité physique pratiquer lorsque, à 50 ans, des fragilités corporelles et des douleurs apparaissent ? Comment prendre soin de soi, garder un corps fonctionnel et source de plaisir ? Spécialiste du périnée, professeure de yoga, reconnue et suivie par des médecins, des sages-femmes, des kinésithérapeutes et des coachs sportifs dans le monde entier, Bernadette de Gasquet adapte dans ce livre sa célèbre méthode aux seniors et propose un travail sur le renforcement musculaire, sans recherche de la performance, à travers des exercices simples. Travail corporel sans douleur et sans risque, discipline au service de l\\'être humain, le yoga peut être pratiqué à tout âge. En alternant tonification et détente, renforcements et étirements, en associant respiration et action sur les fonctions vitales, on peut garder un corps en pleine forme. Bernadette de Gasquet reprend ici les bases de l\\'activité physique – postures, respiration, abdominaux – en se concentrant sur les maux des seniors – douleurs articulaires, problèmes de circulation, de constipation, hypertension, troubles respiratoires, rhumatismes... – pour leur donner les clés d\\'une vie plus saine et du bien-être au quotidien. 200 photos, 15 schémas, des exercices filmés... Yoga senior vous propose de nombreux conseils pratiques et des exercices physiques adaptés pour rester en forme après 50 ans</subfield><subfield code=\"2\">éditeur</subfield></datafield></record>',\n",
       "   'role': 'user'},\n",
       "  {'content': 'thinking content: <think> To transform the provided bibliographical metadata into the given UNIMARC/XML record, proceed step-by-step, field by field, as follows:\\n\\n1. **Control fields** (these are often generated/managed by the cataloguing system):\\n\\n   - `<controlfield tag=\"001\">` — Record identifier: `236807005` (not present in metadata; assigned by system)\\n   - `<controlfield tag=\"003\">` — Control number identifier (URI source): `http://www.sudoc.fr/236807005`\\n   - `<controlfield tag=\"005\">` — Date and time of record processing: `20210208123415.000` (recording timestamp)\\n   - `<controlfield tag=\"035\">` — Various system identifiers:\\n     - `(OCoLC)1107377985` from OCLC number metadata\\n     - `FRBNF...` codes from French national bibliographic authority (not explicitly given but part of cataloguing)\\n   - `<controlfield tag=\"010\">` — International Standard Book Number with binding type: `978-2-221-24174-5` and a binding subfield `$b`: `br.` (broché = paperback)\\n   - `<controlfield tag=\"073\">` — EAN (European article number) from \"Other identifier\": `9782221241745`\\n\\n2. **Leader**\\n\\n   - Encodes record status, type, bibliographic level, encoding level, etc. (`cam0 22        450`) - typically system generated.\\n\\n3. **010 field** (ISBN with binding):\\n\\n   - Maps ISBN to `<datafield tag=\"010\"><subfield code=\"a\">978-2-221-24174-5</subfield><subfield code=\"b\">br.</subfield></datafield>`\\n   - Binding \"br.\" corresponds to paperback (derived or cataloguer\\'s addition).\\n\\n4. **073 field** (EAN):\\n\\n   - `<datafield tag=\"073\"><subfield code=\"a\">9782221241745</subfield></datafield>`  \\n   - From \"Other identifier\" (EAN in metadata).\\n\\n5. **035 field** (other system numbers):\\n\\n   - OCLC: `(OCoLC)1107377985`\\n   - Other French identifiers (cataloguing institution codes), e.g. `FRBNF...`  \\n   - These are authority/control numbers for integration between systems.\\n\\n6. **100 field** — Date and activity code (special code field for cataloguing date/level):\\n\\n   - `<datafield tag=\"100\"><subfield code=\"a\">20190703h20192019m  y0frey50      ba</subfield>`  \\n   - This is a coded field indicating cataloguing dates or activity; this comes from cataloguing process and legal deposit year.  \\n   - The year 2019 comes from \"DL 2019\" (Deposited Legal year 2019).\\n\\n7. **101 field** — Language of the item:\\n\\n   - `<datafield tag=\"101\" ind1=\"0\"><subfield code=\"a\">fre</subfield><subfield code=\"2\">639-2</subfield></datafield>`  \\n   - From metadata language \"French (fre)\".\\n\\n8. **105, 106 fields** — Related to material form and genre:\\n\\n   - `<datafield tag=\"105\"><subfield code=\"a\">a   ||||000yy</subfield></datafield>`  \\n   - `<datafield tag=\"106\"><subfield code=\"a\">r</subfield></datafield>`\\n   - \\'a\\' = text, \\'r\\' indicates genre/form type (e.g., normal printed book).  \\n   - These are based on \"Material type: text, printed book\" from metadata.\\n\\n9. **181, 182, 183 fields** — Content, Media, and Carrier types (RDA):\\n\\n   - `<datafield tag=\"181\"><subfield code=\"c\">txt</subfield><subfield code=\"2\">rdacontent</subfield></datafield>`: Content type = text.\\n   - `<datafield tag=\"182\"><subfield code=\"c\">n</subfield><subfield code=\"2\">rdamedia</subfield></datafield>`: Media type (unmediated).\\n   - `<datafield tag=\"183\"><subfield code=\"a\">nga</subfield><subfield code=\"2\">RDAfrCarrier</subfield></datafield>`: Carrier type = volume (nga).\\n   - These correspond to the metadata fields \"Material type: text, printed book\" and \"Carrier type: volume (nga)\".\\n\\n10. **102 field** — Place of publication country code:\\n\\n    - `<datafield tag=\"102\"><subfield code=\"a\">FR</subfield></datafield>`\\n    - From \"Country of publication: France (FR)\".\\n\\n11. **320 field** — Notes on bibliography:\\n\\n    - `<datafield tag=\"320\"><subfield code=\"a\">Notes bibliogr.</subfield></datafield>`\\n    - From metadata \"Notes bibliogr.\" under Notes/Bibliographic references.\\n\\n12. **200 field** — Title and statement of responsibility:\\n\\n    - `<datafield tag=\"200\" ind1=\"1\" ind2=\" \">`\\n      - `<subfield code=\"a\">Yoga senior</subfield>` -- maps Title\\n      - `<subfield code=\"e\">la méthode de Gasquet</subfield>` -- maps Subtitle\\n      - `<subfield code=\"f\">Dr Bernadette de Gasquet</subfield>` -- maps Author (statement of responsibility)\\n      - `<subfield code=\"f\">avec la participation du Dr Marie Thirion</subfield>` -- maps Participation statement\\n    - So:\\n      - 200$a = Title\\n      - 200$e = Subtitle\\n      - 200$f = Author(s) / participation statement\\n\\n13. **700 field** — Main personal author details:\\n\\n    - `<datafield tag=\"700\" ind1=\" \" ind2=\"1\">`\\n      - `<subfield code=\"3\">084278986</subfield>` — Local control number or authority key\\n      - `<subfield code=\"a\">Gasquet</subfield>` — family name\\n      - `<subfield code=\"b\">Bernadette de</subfield>` — given names\\n      - `<subfield code=\"f\">1946-....</subfield>` — dates of birth (metadata: born 1946)\\n      - `<subfield code=\"4\">070</subfield>` — relator code for author (UNIMARC relators, \\'070\\' = author)\\n    - From Author details metadata for Bernadette de Gasquet\\n    - Note: The names are split into family and given according to French conventions and authority data.\\n\\n14. **702 field** — Secondary personal contributor details (participant):\\n\\n    - `<datafield tag=\"702\" ind1=\" \" ind2=\"1\">`\\n      - `<subfield code=\"3\">028312635</subfield>` — local control number\\n      - `<subfield code=\"a\">Thirion</subfield>` — family name\\n      - `<subfield code=\"b\">Marie</subfield>` — given name\\n      - `<subfield code=\"f\">1944-....</subfield>` — birth year\\n      - `<subfield code=\"c\">pédiatre</subfield>` — profession (from metadata \"pediatrician\")\\n      - `<subfield code=\"4\">205</subfield>` — relator code for contributor function (\\'205\\' = collaborator)\\n    - Matches \"avec la participation du Dr Marie Thirion\" and author\\'s birth details + profession.\\n\\n15. **801 fields** — Cataloguing source and date(s):\\n\\n    - Two 801 fields with different subfields showing cataloguing institution, date, and processing. E.g.:\\n      - `<datafield tag=\"801\" ind1=\" \" ind2=\"3\">`\\n      - `<datafield tag=\"801\" ind1=\" \" ind2=\"0\">`\\n    - From cataloguing administrative metadata, not in source but typical.\\n\\n16. **214 field** — Imprint information (Publication):\\n\\n    - `<datafield tag=\"214\" ind1=\" \" ind2=\"0\">`\\n      - `<subfield code=\"a\">Paris</subfield>` — place of publication (metadata: Paris)\\n      - `<subfield code=\"c\">Robert Laffont</subfield>` — publisher\\n      - `<subfield code=\"d\">DL 2019</subfield>` — date, legal deposit year (DL 2019)\\n    - Maps directly from metadata imprint data.\\n\\n17. **215 field** — Physical description:\\n\\n    - `<datafield tag=\"215\" ind1=\" \" ind2=\" \">`\\n      - `<subfield code=\"a\">1 vol. (250 p.)</subfield>` — volume and pages\\n      - `<subfield code=\"c\">ill., couv. ill. en coul.</subfield>` — includes illustrations and cover in color (from \"Illustrations, color illustrated cover\")\\n      - `<subfield code=\"d\">22 cm</subfield>` — physical size\\n    - Direct mapping from metadata \"Material description\".\\n\\n18. **225 and 410 fields** — Series or Collection:\\n\\n    - `<datafield tag=\"225\" ind1=\"0\" ind2=\" \">`\\n      - `<subfield code=\"a\">Réponses</subfield>`\\n    - `<datafield tag=\"410\" ind1=\" \" ind2=\"|\">`\\n      - `<subfield code=\"0\">001026399</subfield>` — series identifier (from catalogue\\'s own authority files)\\n      - `<subfield code=\"t\">Réponses (Paris. 1967)</subfield>` — series title with place and founding year\\n      - `<subfield code=\"x\">0750-7747</subfield>` — ISSN for the series\\n    - From metadata \"Collection/Series: Réponses\" and ISSN 0750-7747\\n\\n19. **606 fields** — Subject headings:\\n\\n    - Two fields for RAMEAU subjects:\\n      - `<datafield tag=\"606\"><subfield code=\"3\">027347893</subfield><subfield code=\"a\">Hatha-yoga</subfield><subfield code=\"2\">rameau</subfield></datafield>`\\n      - `<datafield tag=\"606\"><subfield code=\"3\">027425541</subfield><subfield code=\"a\">Exercices physiques pour personnes âgées</subfield><subfield code=\"2\">rameau</subfield></datafield>`\\n    - Map from keywords/subject headings with authority source \"RAMEAU\".\\n\\n20. **676 and 686 fields** — Classification schemes:\\n\\n    - `<datafield tag=\"676\"><subfield code=\"a\">613.710 846</subfield><subfield code=\"v\">23</subfield></datafield>`\\n      - 613.710 is Dewey number, 846 possibly language or variant, 23 is DDC edition.\\n    - `<datafield tag=\"686\"><subfield code=\"a\">610</subfield><subfield code=\"2\">Cadre de classement de la Bibliographie nationale française</subfield></datafield>`\\n      - The French national bibliography classification number 610\\n\\n21. **330 field** — Summary / Abstract:\\n\\n    - `<datafield tag=\"330\"><subfield code=\"a\">[full abstract text]</subfield><subfield code=\"2\">éditeur</subfield></datafield>`\\n    - The long abstract text from metadata \"Abstract/Notes\" with the source \"éditeur\" (publisher).\\n\\n---\\n\\n### Summary Table of key mappings:\\n\\n| Metadata element                  | UNIMARC tag and subfield      | Note                                      |\\n|---------------------------------|-------------------------------|-------------------------------------------|\\n| Title                           | 200$a                         | Main title                               |\\n| Subtitle                        | 200$e                         | Subtitle                                 |\\n| Author (main)                   | 200$f, 700$a(b)(f)            | Statement of responsibility and author info with dates |\\n| Participant                    | 200$f, 702$a(b)(f)(c)         | Statement and contributor info with profession  |\\n| ISBN                           | 010$a                        | ISBN number                              |\\n| Binding                        | 010$b                        | Binding type (\\'br.\\' for paperback)       |\\n| EAN                            | 073$a                        | EAN other identifier                     |\\n| OCLC number                    | 035$a                        | System control number                     |\\n| Language                       | 101$a                        | lang code \\'fre\\'                          |\\n| Place of publication           | 214$a                        | Place of publication                     |\\n| Publisher                     | 214$c                        | Publisher                               |\\n| Date of publication (legal deposit) | 214$d                    | Date (DL 2019)                          |\\n| Physical description (volumes, pages) | 215$a                 | Number of volumes and pages              |\\n| Physical description (illustrations) | 215$c                  | Illustrations and cover details           |\\n| Physical description (dimensions) | 215$d                      | Size in cm                              |\\n| Series                        | 225$a                         | Series name                            |\\n| Series info (Series identifier, title, ISSN) | 410$0 410$t 410$x | Series authority and ISSN info          |\\n| Subjects (RAMEAU terms)        | 606$a and 606$2               | Subject headings with authority code    |\\n| Dewey / French classification | 676$a (DDC), 686$a (FNB classification) | Classification schemes                |\\n| Notes bibliogr.               | 320$a                        | Bibliographic notes                      |\\n| Abstract                      | 330$a and 330$2               | Abstract and its source (publisher)      |\\n| Material type and carrier info | 105, 106, 181, 182, 183       | Content, media, carrier codes             |\\n| Place of publication country   | 102$a                        | Country code                            |\\n| Authority and control numbers  | 035, 100 etc.                  | IDs and cataloguing system info          |\\n| Cataloguing data and source    | 801                           | Cataloguing institution, date            |\\n\\n---\\n\\n### Additional notes:\\n\\n- Some fields (controlfields 001, 003, 005, 035, 100, 801) are system-generated and come from cataloguing process and integration with national and international systems.\\n- Relator codes `$4` in 700/702 fields correspond to the role of the person (author or contributor), respectively 070 and 205.\\n- The authors\\' names are split by family name and given name parts according to authority records.\\n- Professional designation (pédiatre) is placed in 702$c.\\n- Binding type \"br.\" (broché) is deduced from material (typical for paperbacks).\\n- The \"DL 2019\" is copied literally into 214$d noting the legal deposit date.\\n- Language code is \"fre\" per ISO 639-2.\\n- Abstract is very long and fully included in 330$a with subfield $2 indicating its source.\\n- ISBN appears twice: as 010$a/b (ISBN + binding type) and 073$a (EAN without hyphens).\\n- The dimensions, volume count, number of pages, and illustration details are composed in 215.\\n- The series information includes both 225 (series title) and 410 (series authority control number, titles, ISSN).\\n- Subject headings use RAMEAU authority code in $2.\\n\\n---\\n\\nThis stepwise mapping explains how each piece of your metadata is encoded into UNIMARC XML fields and subfields as presented in the example record.</think>\\ncontent:<record><controlfield tag=\\'001\\'>...</controlfield>...[UNIMARC/XML GOES HERE]...</record>',\n",
       "   'role': 'assistant'}]}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "170e829f-b741-4e79-acbe-01b1eb2202ed",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ed30eb4c-caf2-4177-99b5-bdee8d1d9229",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting train dataset to ChatML: 100%|██████████| 50/50 [00:00<00:00, 1408.86 examples/s]\n",
      "Applying chat template to train dataset: 100%|██████████| 50/50 [00:00<00:00, 787.14 examples/s]\n",
      "Tokenizing train dataset: 100%|██████████| 50/50 [00:01<00:00, 39.96 examples/s]\n",
      "Truncating train dataset: 100%|██████████| 50/50 [00:00<00:00, 4708.57 examples/s]\n",
      "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
     ]
    }
   ],
   "source": [
    "# ---- 3. Define LoRA config ----\n",
    "peft_config = LoraConfig(\n",
    "    r=8,\n",
    "    lora_alpha=32,\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\",\n",
    "    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\"] # may vary based on model, check with `model.named_modules()` in previous cell\n",
    ")\n",
    "\n",
    "# ---- 4. Training args ----\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./sft_lora_one_step\",\n",
    "    per_device_train_batch_size=1,\n",
    "    gradient_accumulation_steps=4,\n",
    "    logging_steps=50,\n",
    "    save_strategy=\"epoch\",\n",
    "    num_train_epochs=20,\n",
    "    learning_rate=5e-5,\n",
    "    fp16=True,\n",
    "    report_to=\"none\"\n",
    ")\n",
    "\n",
    "# ---- 5. Launch training ----\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    train_dataset=dataset,\n",
    "    peft_config=peft_config,\n",
    "    args=training_args\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ee1c7479-b072-409f-962d-39be80434800",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='240' max='240' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [240/240 10:39, Epoch 18/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.955300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.522700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1.391300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1.314200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=240, training_loss=1.50365465482076, metrics={'train_runtime': 644.4279, 'train_samples_per_second': 1.552, 'train_steps_per_second': 0.372, 'total_flos': 2513580217860096.0, 'train_loss': 1.50365465482076})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b91e418b-0801-4a3f-8e20-87344b179ce8",
   "metadata": {},
   "source": [
    "## Save adapter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1d277086-7049-4f42-a0b6-e12ff456ee89",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04d565d9-6ff7-4ed4-9615-a16e338203e7",
   "metadata": {},
   "source": [
    "## Merging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "34dae021-660d-43e0-ae94-3626ab5949c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import PeftModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "31726b78-f7dd-4ff5-a6e5-1ff83d29c739",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/site-packages/peft/tuners/tuners_utils.py:167: UserWarning: Already found a `peft_config` attribute in the model. This will lead to having multiple adapters in the model. Make sure to know what you are doing!\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "peft_model = PeftModel.from_pretrained(model, \"./sft_lora_one_step\")\n",
    "merged_model = peft_model.merge_and_unload()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee7294b0-e14c-4977-860e-5b31fd528764",
   "metadata": {},
   "source": [
    "## Test inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "354bb327-42ac-42ac-829e-3a833c6476cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_model = merged_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8cc8e7af-40f7-40b3-92b6-8b0322e8330a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# simple test\n",
    "messages = [\n",
    "  {\"role\": \"system\", \"content\": \"You are a helpful assistant\"},\n",
    "  {\"role\": \"user\", \"content\": \"Give me a short introduction to large language model.\"},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "93db4a2b-d8da-4609-9c98-4ade1b7dd77a",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"\n",
    "You are an expert in Unimarc/XML bibliographic records encoding.\n",
    "Explains how to generate Unimarc records from the following metadata.\n",
    "Then generate the Unimarc/XML record\n",
    "\"\"\"\n",
    "\n",
    "user_prompt = \"\"\"\n",
    "Title: Electric vehicle tribology\n",
    "Subtitle: Challenges and opportunities for a sustainable transportation future\n",
    "Author: Leonardo I. Farfan-Cabrera, Ali Erdemir\n",
    "Publisher: Elsevier\n",
    "Year: 2024\n",
    "ISBN: 978-0-443-14074-7\n",
    "Language: English\n",
    "Collection/Series: Elsevier Series on Tribology and Surface Engineering\n",
    "Edition: Not specified\n",
    "Material description: 1 vol. (XI-313 p.), couv. ill. en coul., 23 cm\n",
    "Abstract/Notes: \"Electric vehicle tribology, challenges and opportunities for a sustainable transportation future\" provides practical, comprehensive guidance on a new and increasingly important area of tribology. Building skills from fundamentals to solution design, this book demonstrates the unique tribological techniques essential to the efficient electrification of transport systems. Led by professors with a combined three decades in industry and academia, and collecting insights from experts around the world, this book begins with the essential knowledge regarding both electric vehicles and tribology. After outlining the unique tribological needs of EVs, the book then breaks down the components and hardware required. It provides detailed protocols and methods for the testing and improvement of lubricants and materials as well as a dedicated section on modern lubrication specific to EVs. Throughout, it considers the critical question of sustainable tribology and the long-term sustainable options for lubrication and materials for electric vehicles.\n",
    "Source of the abstract/notes: 4e de couverture\n",
    "Table of contents: Not specified\n",
    "Keywords: Tribologie (technologie), Tribologie (Technologie)\n",
    "\"\"\"\n",
    "\n",
    "messages = [\n",
    "  {\"role\": \"system\", \"content\": system_prompt},\n",
    "  {\"role\": \"user\", \"content\": user_prompt},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "66bbd983-8d09-4e03-98fa-51a6d87c43ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer.apply_chat_template(\n",
    "    messages,\n",
    "    return_dict=True,\n",
    "    tokenize = True,\n",
    "    add_generation_prompt = True, # Must add for generation\n",
    "    return_tensors = \"pt\",\n",
    "    enable_thinking=True\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3f61a4da-4160-438b-8761-a441c149d8f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = merged_model.generate(\n",
    "    **inputs,\n",
    "    max_new_tokens = 32768,\n",
    "    use_cache = True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ff49048e-d2c7-484c-8278-5c0ce25ce50d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "system\n",
      "\n",
      "You are an expert in Unimarc/XML bibliographic records encoding.\n",
      "Explains how to generate Unimarc records from the following metadata.\n",
      "Then generate the Unimarc/XML record\n",
      "\n",
      "user\n",
      "\n",
      "Title: Electric vehicle tribology\n",
      "Subtitle: Challenges and opportunities for a sustainable transportation future\n",
      "Author: Leonardo I. Farfan-Cabrera, Ali Erdemir\n",
      "Publisher: Elsevier\n",
      "Year: 2024\n",
      "ISBN: 978-0-443-14074-7\n",
      "Language: English\n",
      "Collection/Series: Elsevier Series on Tribology and Surface Engineering\n",
      "Edition: Not specified\n",
      "Material description: 1 vol. (XI-313 p.), couv. ill. en coul., 23 cm\n",
      "Abstract/Notes: \"Electric vehicle tribology, challenges and opportunities for a sustainable transportation future\" provides practical, comprehensive guidance on a new and increasingly important area of tribology. Building skills from fundamentals to solution design, this book demonstrates the unique tribological techniques essential to the efficient electrification of transport systems. Led by professors with a combined three decades in industry and academia, and collecting insights from experts around the world, this book begins with the essential knowledge regarding both electric vehicles and tribology. After outlining the unique tribological needs of EVs, the book then breaks down the components and hardware required. It provides detailed protocols and methods for the testing and improvement of lubricants and materials as well as a dedicated section on modern lubrication specific to EVs. Throughout, it considers the critical question of sustainable tribology and the long-term sustainable options for lubrication and materials for electric vehicles.\n",
      "Source of the abstract/notes: 4e de couverture\n",
      "Table of contents: Not specified\n",
      "Keywords: Tribologie (technologie), Tribologie (Technologie)\n",
      "\n",
      "assistant\n",
      "<think>\n",
      "Okay, I need to generate the Unimarc/XML record from the provided metadata. Let me start by recalling the structure of the Unimarc record. The fields are usually titled as follows:\n",
      "\n",
      "- Title (title field)\n",
      "- Author (author field)\n",
      "- Publisher (publisher)\n",
      "- Year (year)\n",
      "- ISBN (isbn field)\n",
      "- Collection/Series (collection)\n",
      "- Material description (material description)\n",
      "- Abstract/Notes (abstract/notes)\n",
      "\n",
      "The user provided the title, author, publisher, year, ISBN, collection, material description, and keywords. Also, the source of the abstract/notes is mentioned as 4e de couverture, which is a note about the cover page.\n",
      "\n",
      "I need to check the exact numbering of the fields. The Unimarc record typically has 13 fields, but sometimes the order can be different. Let me confirm:\n",
      "\n",
      "- 1: Title (title)\n",
      "- 2: Author (author)\n",
      "- 3: Publisher (publisher)\n",
      "- 4: Year (year)\n",
      "- 5: ISBN (isbn)\n",
      "- 6: Collection/Series (collection)\n",
      "- 7: Material description (material)\n",
      "- 8: Abstract/Notes (abstract/notes)\n",
      "- 9: Keywords (keyword)\n",
      "- 10: Source of abstract/notes (source)\n",
      "- 11: Notes on the source (note)\n",
      "- 12: Notes on the source (another note)\n",
      "- 13: Notes on the source (third note)\n",
      "\n",
      "Wait, the user's provided abstract/notes are already part of the source field. So the 10th and 11th fields would be the source and note. But the user mentioned \"Source of the abstract/notes: 4e de couverture\" which is a note. So the 10th field is the source, and the 11th is the note. However, the original data has the source as the 4th field. So the structure is:\n",
      "\n",
      "1: Title\n",
      "2: Author\n",
      "3: Publisher\n",
      "4: Year\n",
      "5: ISBN\n",
      "6: Collection/Series\n",
      "7: Material description\n",
      "8: Abstract/Notes (source)\n",
      "9: Keywords\n",
      "10: Source of abstract/notes\n",
      "11: Notes on the source\n",
      "12: Notes on the source\n",
      "13: Notes on the source\n",
      "\n",
      "But the user's data shows that the source is already in the abstract/notes field. So maybe the 8th and 10th fields are the source and note. Let me check again.\n",
      "\n",
      "The original data provided by the user includes:\n",
      "\n",
      "- Source of abstract/notes: 4e de couverture\n",
      "- Notes: (not provided in the original data, just the 4e)\n",
      "\n",
      "So the Unimarc fields would be:\n",
      "\n",
      "1: Title: Electric vehicle tribology\n",
      "2: Author: Leonardo I. Farfan-Cabrera, Ali Erdemir\n",
      "3: Publisher: Elsevier\n",
      "4: Year: 2024\n",
      "5: ISBN: 978-0-443-14074-7\n",
      "6: Collection/Series: Elsevier Series on Tribology and Surface Engineering\n",
      "7: Material description: 1 vol. (XI-313 p.), couv. ill., 23 cm\n",
      "8: Abstract/Notes: 4e de couverture\n",
      "9: Keywords: Tribologie (technologie)\n",
      "10: Source of abstract/notes: 4e de couverture\n",
      "11: Notes on the source: couv. ill.\n",
      "12: Notes on the source: 23 cm\n",
      "13: Notes on the source: 4e de couverture\n",
      "\n",
      "Wait, but the original data doesn't have the 11th and 12th fields. The user only provided the 4th and 8th fields. Maybe there are more notes. The user's input includes:\n",
      "\n",
      "- \"Source of the abstract/notes: 4e de couverture\" (so 4e is the source)\n",
      "- \"Notes: Not specified\" (but the 4e is the source)\n",
      "\n",
      "So the 10th field is the source, and the 11th and 12th are the note fields. But the original data only includes 4e and couv. ill. So perhaps the 10th field is the source, and the 11th is the note. The user might have made a typo, but I'll follow the given data.\n",
      "\n",
      "Now, putting it all together into the Unimarc/XML format. The fields are as follows:\n",
      "\n",
      "- Title: Electric vehicle tribology\n",
      "- Author: Leonardo I. Farfan-Cabrera, Ali Erdemir\n",
      "- Publisher: Elsevier\n",
      "- Year: 2024\n",
      "- ISBN: 978-0-443-14074-7\n",
      "- Collection/Series: Elsevier Series on Tribology and Surface Engineering\n",
      "- Material description: 1 vol. (XI-313 p.), couv. ill., 23 cm\n",
      "- Abstract/Notes: 4e de couverture\n",
      "- Keywords: Tribologie (technologie)\n",
      "\n",
      "The source of the abstract/notes is in the 4th field, and the notes are in the 8th field.\n",
      "\n",
      "I think that's all. Now, I need to format this into the Unimarc record. Let me check the exact codes again. The Unimarc fields for the record would be as follows:\n",
      "\n",
      "1. Title: [Electric vehicle tribology]\n",
      "2. Author: [Leonardo I. Farfan-Cabrera, Ali Erdemir]\n",
      "3. Publisher: Elsevier\n",
      "4. Year: 2024\n",
      "5. ISBN: 978-0-443-14074-7\n",
      "6. Collection/Series: Elsevier Series on Tribology and Surface Engineering\n",
      "7. Material description: 1 vol. (XI-313 p.), couv. ill., 23 cm\n",
      "8. Abstract/Notes: 4e de couverture\n",
      "9. Keywords: Tribologie (technologie)\n",
      "10. Source of abstract/notes: 4e de couverture\n",
      "11. Notes on the source: couv. ill.\n",
      "12. Notes on the source: 23 cm\n",
      "13. Notes on the source: 4e de couverture\n",
      "\n",
      "Yes, that's correct. Now, I need to present this in the required Unimarc/XML format, making sure the numbers are correctly placed and the fields are properly labeled.\n",
      "</think>\n",
      "\n",
      "```xml\n",
      "<record><controlfield tag=\"005\">20250212153703.000</controlfield><datafield tag=\"035\" ind1=\" \" ind2=\" \"><subfield code=\"a\">(text)</subfield><subfield code=\"b\">Electric vehicle tribology</subfield><subfield code=\"b\">2024</subfield></datafield><datafield tag=\"033\" ind1=\" \" ind2=\" \"><subfield code=\"a\">978-0-443-14074-7</subfield><subfield code=\"b\">isbn</subfield></datafield><datafield tag=\"100\" ind1=\" \" ind2=\" \"><subfield code=\"a\">A</subfield><subfield code=\"2\">Leonardo I. Farfan-Cabrera</subfield><subfield code=\"2\">Ali Erdemir</subfield></datafield><datafield tag=\"101\" ind1=\"0\" ind2=\" \"><subfield code=\"a\">X</subfield><subfield code=\"2\">2024</subfield></datafield><datafield tag=\"101\" ind1=\"0\" ind2=\" \"><subfield code=\"a\">Y</subfield><subfield code=\"2\">4</subfield></datafield><datafield tag=\"105\" ind1=\" \" ind2=\" \"><subfield code=\"a\">4e</subfield><subfield code=\"2\">de couv.</subfield></datafield><datafield tag=\"106\" ind1=\" \" ind2=\" \"><subfield code=\"a\">23 cm</subfield></datafield><datafield tag=\"180\" ind1=\" \" ind2=\" \"><subfield code=\"a\">1</subfield><subfield code=\"2\">XI</subfield><subfield code=\"2\">313</subfield></datafield><datafield tag=\"181\" ind1=\" \" ind2=\" \"><subfield code=\"a\">313</subfield></datafield><datafield tag=\"181\" ind1=\" \" ind2=\" \"><subfield code=\"a\">couv</subfield></datafield><datafield tag=\"181\" ind1=\" \" ind2=\" \"><subfield code=\"a\">ill.</subfield></datafield><datafield tag=\"185\" ind1=\" \" ind2=\" \"><subfield code=\"a\">23 cm</subfield></datafield><datafield tag=\"185\" ind1=\" \" ind2=\" \"><subfield code=\"a\">23 cm</subfield></datafield><datafield tag=\"191\" ind1=\" \" ind2=\" \"><subfield code=\"a\">2</subfield><subfield code=\"2\">4</subfield></datafield><datafield tag=\"191\" ind1=\" \" ind2=\" \"><subfield code=\"a\">4e</subfield><subfield code=\"2\">de</subfield></datafield><datafield tag=\"191\" ind1=\" \" ind2=\" \"><subfield code=\"a\">23 cm</subfield></datafield><datafield tag=\"191\" ind1=\" \" ind2=\" \"><subfield code=\"a\">4e</subfield></datafield><datafield tag=\"200\" ind1=\" \" ind2=\" \"><subfield code=\"a\">R</subfield><subfield code=\"2\">2</subfield></datafield><datafield tag=\"205\" ind1=\" \" ind2=\" \"><subfield code=\"a\">4e</subfield></datafield><datafield tag=\"205\" ind1=\" \" ind2=\" \"><subfield code=\"a\">de</subfield></datafield><datafield tag=\"205\" ind1=\" \" ind2=\" \"><subfield code=\"a\">23 cm</subfield></datafield></record>\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.decode(outputs[0], skip_special_tokens=True))\n",
    "# or tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6b9fca92-0aa7-4715-a1bb-edfedce7cff1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thinking content: <think>\n",
      "Okay, I need to generate the Unimarc/XML record from the provided metadata. Let me start by recalling the structure of the Unimarc record. The fields are usually titled as follows:\n",
      "\n",
      "- Title (title field)\n",
      "- Author (author field)\n",
      "- Publisher (publisher)\n",
      "- Year (year)\n",
      "- ISBN (isbn field)\n",
      "- Collection/Series (collection)\n",
      "- Material description (material description)\n",
      "- Abstract/Notes (abstract/notes)\n",
      "\n",
      "The user provided the title, author, publisher, year, ISBN, collection, material description, and keywords. Also, the source of the abstract/notes is mentioned as 4e de couverture, which is a note about the cover page.\n",
      "\n",
      "I need to check the exact numbering of the fields. The Unimarc record typically has 13 fields, but sometimes the order can be different. Let me confirm:\n",
      "\n",
      "- 1: Title (title)\n",
      "- 2: Author (author)\n",
      "- 3: Publisher (publisher)\n",
      "- 4: Year (year)\n",
      "- 5: ISBN (isbn)\n",
      "- 6: Collection/Series (collection)\n",
      "- 7: Material description (material)\n",
      "- 8: Abstract/Notes (abstract/notes)\n",
      "- 9: Keywords (keyword)\n",
      "- 10: Source of abstract/notes (source)\n",
      "- 11: Notes on the source (note)\n",
      "- 12: Notes on the source (another note)\n",
      "- 13: Notes on the source (third note)\n",
      "\n",
      "Wait, the user's provided abstract/notes are already part of the source field. So the 10th and 11th fields would be the source and note. But the user mentioned \"Source of the abstract/notes: 4e de couverture\" which is a note. So the 10th field is the source, and the 11th is the note. However, the original data has the source as the 4th field. So the structure is:\n",
      "\n",
      "1: Title\n",
      "2: Author\n",
      "3: Publisher\n",
      "4: Year\n",
      "5: ISBN\n",
      "6: Collection/Series\n",
      "7: Material description\n",
      "8: Abstract/Notes (source)\n",
      "9: Keywords\n",
      "10: Source of abstract/notes\n",
      "11: Notes on the source\n",
      "12: Notes on the source\n",
      "13: Notes on the source\n",
      "\n",
      "But the user's data shows that the source is already in the abstract/notes field. So maybe the 8th and 10th fields are the source and note. Let me check again.\n",
      "\n",
      "The original data provided by the user includes:\n",
      "\n",
      "- Source of abstract/notes: 4e de couverture\n",
      "- Notes: (not provided in the original data, just the 4e)\n",
      "\n",
      "So the Unimarc fields would be:\n",
      "\n",
      "1: Title: Electric vehicle tribology\n",
      "2: Author: Leonardo I. Farfan-Cabrera, Ali Erdemir\n",
      "3: Publisher: Elsevier\n",
      "4: Year: 2024\n",
      "5: ISBN: 978-0-443-14074-7\n",
      "6: Collection/Series: Elsevier Series on Tribology and Surface Engineering\n",
      "7: Material description: 1 vol. (XI-313 p.), couv. ill., 23 cm\n",
      "8: Abstract/Notes: 4e de couverture\n",
      "9: Keywords: Tribologie (technologie)\n",
      "10: Source of abstract/notes: 4e de couverture\n",
      "11: Notes on the source: couv. ill.\n",
      "12: Notes on the source: 23 cm\n",
      "13: Notes on the source: 4e de couverture\n",
      "\n",
      "Wait, but the original data doesn't have the 11th and 12th fields. The user only provided the 4th and 8th fields. Maybe there are more notes. The user's input includes:\n",
      "\n",
      "- \"Source of the abstract/notes: 4e de couverture\" (so 4e is the source)\n",
      "- \"Notes: Not specified\" (but the 4e is the source)\n",
      "\n",
      "So the 10th field is the source, and the 11th and 12th are the note fields. But the original data only includes 4e and couv. ill. So perhaps the 10th field is the source, and the 11th is the note. The user might have made a typo, but I'll follow the given data.\n",
      "\n",
      "Now, putting it all together into the Unimarc/XML format. The fields are as follows:\n",
      "\n",
      "- Title: Electric vehicle tribology\n",
      "- Author: Leonardo I. Farfan-Cabrera, Ali Erdemir\n",
      "- Publisher: Elsevier\n",
      "- Year: 2024\n",
      "- ISBN: 978-0-443-14074-7\n",
      "- Collection/Series: Elsevier Series on Tribology and Surface Engineering\n",
      "- Material description: 1 vol. (XI-313 p.), couv. ill., 23 cm\n",
      "- Abstract/Notes: 4e de couverture\n",
      "- Keywords: Tribologie (technologie)\n",
      "\n",
      "The source of the abstract/notes is in the 4th field, and the notes are in the 8th field.\n",
      "\n",
      "I think that's all. Now, I need to format this into the Unimarc record. Let me check the exact codes again. The Unimarc fields for the record would be as follows:\n",
      "\n",
      "1. Title: [Electric vehicle tribology]\n",
      "2. Author: [Leonardo I. Farfan-Cabrera, Ali Erdemir]\n",
      "3. Publisher: Elsevier\n",
      "4. Year: 2024\n",
      "5. ISBN: 978-0-443-14074-7\n",
      "6. Collection/Series: Elsevier Series on Tribology and Surface Engineering\n",
      "7. Material description: 1 vol. (XI-313 p.), couv. ill., 23 cm\n",
      "8. Abstract/Notes: 4e de couverture\n",
      "9. Keywords: Tribologie (technologie)\n",
      "10. Source of abstract/notes: 4e de couverture\n",
      "11. Notes on the source: couv. ill.\n",
      "12. Notes on the source: 23 cm\n",
      "13. Notes on the source: 4e de couverture\n",
      "\n",
      "Yes, that's correct. Now, I need to present this in the required Unimarc/XML format, making sure the numbers are correctly placed and the fields are properly labeled.\n",
      "</think>\n",
      "content: ```xml\n",
      "<record><controlfield tag=\"005\">20250212153703.000</controlfield><datafield tag=\"035\" ind1=\" \" ind2=\" \"><subfield code=\"a\">(text)</subfield><subfield code=\"b\">Electric vehicle tribology</subfield><subfield code=\"b\">2024</subfield></datafield><datafield tag=\"033\" ind1=\" \" ind2=\" \"><subfield code=\"a\">978-0-443-14074-7</subfield><subfield code=\"b\">isbn</subfield></datafield><datafield tag=\"100\" ind1=\" \" ind2=\" \"><subfield code=\"a\">A</subfield><subfield code=\"2\">Leonardo I. Farfan-Cabrera</subfield><subfield code=\"2\">Ali Erdemir</subfield></datafield><datafield tag=\"101\" ind1=\"0\" ind2=\" \"><subfield code=\"a\">X</subfield><subfield code=\"2\">2024</subfield></datafield><datafield tag=\"101\" ind1=\"0\" ind2=\" \"><subfield code=\"a\">Y</subfield><subfield code=\"2\">4</subfield></datafield><datafield tag=\"105\" ind1=\" \" ind2=\" \"><subfield code=\"a\">4e</subfield><subfield code=\"2\">de couv.</subfield></datafield><datafield tag=\"106\" ind1=\" \" ind2=\" \"><subfield code=\"a\">23 cm</subfield></datafield><datafield tag=\"180\" ind1=\" \" ind2=\" \"><subfield code=\"a\">1</subfield><subfield code=\"2\">XI</subfield><subfield code=\"2\">313</subfield></datafield><datafield tag=\"181\" ind1=\" \" ind2=\" \"><subfield code=\"a\">313</subfield></datafield><datafield tag=\"181\" ind1=\" \" ind2=\" \"><subfield code=\"a\">couv</subfield></datafield><datafield tag=\"181\" ind1=\" \" ind2=\" \"><subfield code=\"a\">ill.</subfield></datafield><datafield tag=\"185\" ind1=\" \" ind2=\" \"><subfield code=\"a\">23 cm</subfield></datafield><datafield tag=\"185\" ind1=\" \" ind2=\" \"><subfield code=\"a\">23 cm</subfield></datafield><datafield tag=\"191\" ind1=\" \" ind2=\" \"><subfield code=\"a\">2</subfield><subfield code=\"2\">4</subfield></datafield><datafield tag=\"191\" ind1=\" \" ind2=\" \"><subfield code=\"a\">4e</subfield><subfield code=\"2\">de</subfield></datafield><datafield tag=\"191\" ind1=\" \" ind2=\" \"><subfield code=\"a\">23 cm</subfield></datafield><datafield tag=\"191\" ind1=\" \" ind2=\" \"><subfield code=\"a\">4e</subfield></datafield><datafield tag=\"200\" ind1=\" \" ind2=\" \"><subfield code=\"a\">R</subfield><subfield code=\"2\">2</subfield></datafield><datafield tag=\"205\" ind1=\" \" ind2=\" \"><subfield code=\"a\">4e</subfield></datafield><datafield tag=\"205\" ind1=\" \" ind2=\" \"><subfield code=\"a\">de</subfield></datafield><datafield tag=\"205\" ind1=\" \" ind2=\" \"><subfield code=\"a\">23 cm</subfield></datafield></record>\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "output_ids = outputs[0][len(inputs.input_ids[0]):].tolist()\n",
    "# parsing thinking content\n",
    "try:\n",
    "    # rindex finding 151668 (</think>)\n",
    "    index = len(output_ids) - output_ids[::-1].index(151668)\n",
    "except ValueError:\n",
    "    index = 0\n",
    "\n",
    "thinking_content = tokenizer.decode(output_ids[:index], skip_special_tokens=True).strip(\"\\n\")\n",
    "content = tokenizer.decode(output_ids[index:], skip_special_tokens=True).strip(\"\\n\")\n",
    "\n",
    "print(\"thinking content:\", thinking_content)\n",
    "print(\"content:\", content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e201b84b-dc33-453a-85ca-65494aa26331",
   "metadata": {},
   "source": [
    "## Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3627df69-0972-4325-96ec-d7c8ef7475f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./qwen3_unimarc_model/tokenizer_config.json',\n",
       " './qwen3_unimarc_model/special_tokens_map.json',\n",
       " './qwen3_unimarc_model/vocab.json',\n",
       " './qwen3_unimarc_model/merges.txt',\n",
       " './qwen3_unimarc_model/added_tokens.json',\n",
       " './qwen3_unimarc_model/tokenizer.json')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_model.save_pretrained(\"./qwen3_unimarc_model\")\n",
    "tokenizer.save_pretrained(\"./qwen3_unimarc_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f2218eb8-0745-478f-bfa9-b59933ab079e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "model.safetensors: 100%|██████████| 1.19G/1.19G [00:45<00:00, 25.9MB/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/Geraldine/Qwen3-0.6B-finetuned-unimarc-reasoning/commit/16f4538ea8fb96da752c14ae8b89ad447c005c06', commit_message='Upload Qwen3ForCausalLM', commit_description='', oid='16f4538ea8fb96da752c14ae8b89ad447c005c06', pr_url=None, repo_url=RepoUrl('https://huggingface.co/Geraldine/Qwen3-0.6B-finetuned-unimarc-reasoning', endpoint='https://huggingface.co', repo_type='model', repo_id='Geraldine/Qwen3-0.6B-finetuned-unimarc-reasoning'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_model.push_to_hub(f\"Geraldine/Qwen3-0.6B-finetuned-unimarc-reasoning\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9d40c86c-ee3c-4623-bce6-eb3532b7e755",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tokenizer.json: 100%|██████████| 11.4M/11.4M [00:00<00:00, 29.9MB/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/Geraldine/Qwen3-0.6B-finetuned-unimarc-reasoning/commit/ba3c695f452717db81ce7ff30851cf392a67f866', commit_message='Upload tokenizer', commit_description='', oid='ba3c695f452717db81ce7ff30851cf392a67f866', pr_url=None, repo_url=RepoUrl('https://huggingface.co/Geraldine/Qwen3-0.6B-finetuned-unimarc-reasoning', endpoint='https://huggingface.co', repo_type='model', repo_id='Geraldine/Qwen3-0.6B-finetuned-unimarc-reasoning'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.push_to_hub(f\"Geraldine/Qwen3-0.6B-finetuned-unimarc-reasoning\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0480fb14-b01c-42fb-a766-0babb82239a7",
   "metadata": {},
   "source": [
    "# Two-Step Training (Swappable LoRA Adapters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "33e6efce-6819-4a66-b9a2-903b8a3890ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM, TrainingArguments\n",
    "from trl import SFTTrainer\n",
    "from peft import LoraConfig\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a07e3324-afcc-4840-9461-32dca72ed9ad",
   "metadata": {},
   "source": [
    "## Train lora_trace Adapter (Text → Trace)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9b4b5dd-1d62-494b-875e-fd560f377ebb",
   "metadata": {},
   "source": [
    "### Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8bf7954f-a402-472f-ac64-6c230f3c0abc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 173/173 [00:00<00:00, 2180.10 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['messages'],\n",
       "    num_rows: 173\n",
       "})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "system_message = \"\"\"You are an expert assistant in cataloging and Unimarc/XML standards. \n",
    "Your task is to explain how to generate Unimarc/XML fields from bibliographic data using structured reasoning. \"\"\"\n",
    "def create_conversation(row):\n",
    "  return {\n",
    "    \"messages\": [\n",
    "      {\"role\": \"system\", \"content\": system_message + \" /think\"},\n",
    "      {\"role\": \"user\", \"content\": f\"# Bibliographical metadata:\\n{row['metadata']}\\n\\n# Unimarc/XML record:\\n{row['unimarc_record']}\"},\n",
    "      {\"role\": \"assistant\", \"content\": row[\"reasoning\"]} # to avoid infinite generation\n",
    "    ]\n",
    "  }\n",
    "\n",
    "dataset = dataset.map(create_conversation, remove_columns=dataset.features, batched=False)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5d52d6ac-6dda-4d82-abf4-79d0dfc2676a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [{'content': 'You are an expert assistant in cataloging and Unimarc/XML standards. \\nYour task is to explain how to generate Unimarc/XML fields from bibliographic data using structured reasoning.  /think',\n",
       "   'role': 'system'},\n",
       "  {'content': '# Bibliographical metadata:\\nTitle: Yoga senior  \\nSubtitle: la méthode de Gasquet  \\nAuthor: Dr Bernadette de Gasquet  \\nParticipation: avec la participation du Dr Marie Thirion  \\nAuthor details:  \\n- Bernadette de Gasquet (born 1946)  \\n- Marie Thirion (born 1944), pediatrician  \\n\\nPublisher: Robert Laffont  \\nPlace of publication: Paris  \\nYear: DL 2019 (Legal deposit 2019)  \\n\\nISBN: 978-2-221-24174-5  \\nOther identifier: 9782221241745 (EAN)  \\nOCLC number: 1107377985  \\n\\nLanguage: French (fre)  \\n\\nEdition: Not explicitly stated; appears first edition  \\n\\nMaterial Description:  \\n- 1 volume (250 pages)  \\n- Illustrations, color illustrated cover  \\n- Dimensions: 22 cm  \\n\\nCollection/Series: Réponses  \\n\\nNotes/Bibliographic references: Notes bibliogr.  \\n\\nAbstract/Notes:  \\nLa méthode de Gasquet enfin adaptée aux seniors ! Quelle activité physique pratiquer lorsque, à 50 ans, des fragilités corporelles et des douleurs apparaissent ? Comment prendre soin de soi, garder un corps fonctionnel et source de plaisir ? Spécialiste du périnée, professeure de yoga, reconnue et suivie par des médecins, des sages-femmes, des kinésithérapeutes et des coachs sportifs dans le monde entier, Bernadette de Gasquet adapte dans ce livre sa célèbre méthode aux seniors et propose un travail sur le renforcement musculaire, sans recherche de la performance, à travers des exercices simples. Travail corporel sans douleur et sans risque, discipline au service de l\\'être humain, le yoga peut être pratiqué à tout âge. En alternant tonification et détente, renforcements et étirements, en associant respiration et action sur les fonctions vitales, on peut garder un corps en pleine forme. Bernadette de Gasquet reprend ici les bases de l\\'activité physique – postures, respiration, abdominaux – en se concentrant sur les maux des seniors – douleurs articulaires, problèmes de circulation, de constipation, hypertension, troubles respiratoires, rhumatismes... – pour leur donner les clés d\\'une vie plus saine et du bien-être au quotidien. 200 photos, 15 schémas, des exercices filmés... Yoga senior vous propose de nombreux conseils pratiques et des exercices physiques adaptés pour rester en forme après 50 ans.  \\nSource of the abstract/notes: éditeur  \\n\\nTable of contents: Not provided  \\n\\nKeywords/Subject headings:  \\n- Hatha-yoga (RAMEAU)  \\n- Exercices physiques pour personnes âgées (RAMEAU)  \\n\\nClassification:  \\n- Dewey: 613.710 846  \\n- French national bibliography classification: 610  \\n- Réponses (Paris. 1967) [series] ISSN 0750-7747  \\n\\nCountry of publication: France (FR)  \\n\\nOther information:  \\n- Legal deposit and cataloging codes for French institutions included  \\n- Material type: text, printed book  \\n- Carrier type: volume (nga)\\n\\n# Unimarc/XML record:\\n<record><controlfield tag=\"005\">20210208123415.000</controlfield><leader> cam0 22        450 </leader><controlfield tag=\"001\">236807005</controlfield><controlfield tag=\"003\">http://www.sudoc.fr/236807005</controlfield><datafield tag=\"035\" ind1=\" \" ind2=\" \"><subfield code=\"a\">(OCoLC)1107377985</subfield></datafield><datafield tag=\"010\" ind1=\" \" ind2=\" \"><subfield code=\"a\">978-2-221-24174-5</subfield><subfield code=\"b\">br.</subfield></datafield><datafield tag=\"073\" ind1=\" \" ind2=\"1\"><subfield code=\"a\">9782221241745</subfield></datafield><datafield tag=\"035\" ind1=\" \" ind2=\" \"><subfield code=\"a\">FRBNF457384730000008</subfield><subfield code=\"z\">FRBNF45738473</subfield></datafield><datafield tag=\"100\" ind1=\" \" ind2=\" \"><subfield code=\"a\">20190703h20192019m  y0frey50      ba</subfield></datafield><datafield tag=\"101\" ind1=\"0\" ind2=\" \"><subfield code=\"a\">fre</subfield><subfield code=\"2\">639-2</subfield></datafield><datafield tag=\"105\" ind1=\" \" ind2=\" \"><subfield code=\"a\">a   ||||000yy</subfield></datafield><datafield tag=\"106\" ind1=\" \" ind2=\" \"><subfield code=\"a\">r</subfield></datafield><datafield tag=\"181\" ind1=\" \" ind2=\" \"><subfield code=\"6\">z01</subfield><subfield code=\"c\">txt</subfield><subfield code=\"2\">rdacontent</subfield></datafield><datafield tag=\"181\" ind1=\" \" ind2=\"1\"><subfield code=\"6\">z01</subfield><subfield code=\"a\">i#</subfield><subfield code=\"b\">xxxe##</subfield></datafield><datafield tag=\"182\" ind1=\" \" ind2=\" \"><subfield code=\"6\">z01</subfield><subfield code=\"c\">n</subfield><subfield code=\"2\">rdamedia</subfield></datafield><datafield tag=\"182\" ind1=\" \" ind2=\"1\"><subfield code=\"6\">z01</subfield><subfield code=\"a\">n</subfield></datafield><datafield tag=\"183\" ind1=\" \" ind2=\"1\"><subfield code=\"6\">z01</subfield><subfield code=\"a\">nga</subfield><subfield code=\"2\">RDAfrCarrier</subfield></datafield><datafield tag=\"102\" ind1=\" \" ind2=\" \"><subfield code=\"a\">FR</subfield></datafield><datafield tag=\"320\" ind1=\" \" ind2=\" \"><subfield code=\"a\">Notes bibliogr.</subfield></datafield><datafield tag=\"200\" ind1=\"1\" ind2=\" \"><subfield code=\"a\">Yoga senior</subfield><subfield code=\"e\">la méthode de Gasquet</subfield><subfield code=\"f\">Dr Bernadette de Gasquet</subfield><subfield code=\"f\">avec la participation du Dr Marie Thirion</subfield></datafield><datafield tag=\"700\" ind1=\" \" ind2=\"1\"><subfield code=\"3\">084278986</subfield><subfield code=\"a\">Gasquet</subfield><subfield code=\"b\">Bernadette de</subfield><subfield code=\"f\">1946-....</subfield><subfield code=\"4\">070</subfield></datafield><datafield tag=\"702\" ind1=\" \" ind2=\"1\"><subfield code=\"3\">028312635</subfield><subfield code=\"a\">Thirion</subfield><subfield code=\"b\">Marie</subfield><subfield code=\"f\">1944-....</subfield><subfield code=\"c\">pédiatre</subfield><subfield code=\"4\">205</subfield></datafield><datafield tag=\"801\" ind1=\" \" ind2=\"3\"><subfield code=\"a\">FR</subfield><subfield code=\"b\">Abes</subfield><subfield code=\"c\">20210208</subfield><subfield code=\"g\">AFNOR</subfield></datafield><datafield tag=\"214\" ind1=\" \" ind2=\"0\"><subfield code=\"a\">Paris</subfield><subfield code=\"c\">Robert Laffont</subfield><subfield code=\"d\">DL 2019</subfield></datafield><datafield tag=\"215\" ind1=\" \" ind2=\" \"><subfield code=\"a\">1 vol. (250 p.)</subfield><subfield code=\"c\">ill., couv. ill. en coul.</subfield><subfield code=\"d\">22 cm</subfield></datafield><datafield tag=\"225\" ind1=\"0\" ind2=\" \"><subfield code=\"a\">Réponses</subfield></datafield><datafield tag=\"410\" ind1=\" \" ind2=\"|\"><subfield code=\"0\">001026399</subfield><subfield code=\"t\">Réponses (Paris. 1967)</subfield><subfield code=\"x\">0750-7747</subfield></datafield><datafield tag=\"606\" ind1=\" \" ind2=\" \"><subfield code=\"3\">027347893</subfield><subfield code=\"a\">Hatha-yoga</subfield><subfield code=\"2\">rameau</subfield></datafield><datafield tag=\"606\" ind1=\" \" ind2=\" \"><subfield code=\"3\">027425541</subfield><subfield code=\"a\">Exercices physiques pour personnes âgées</subfield><subfield code=\"2\">rameau</subfield></datafield><datafield tag=\"676\" ind1=\" \" ind2=\" \"><subfield code=\"a\">613.710 846</subfield><subfield code=\"v\">23</subfield></datafield><datafield tag=\"686\" ind1=\" \" ind2=\" \"><subfield code=\"a\">610</subfield><subfield code=\"2\">Cadre de classement de la Bibliographie nationale française</subfield></datafield><datafield tag=\"801\" ind1=\" \" ind2=\"0\"><subfield code=\"a\">FR</subfield><subfield code=\"b\">FR-751131015</subfield><subfield code=\"c\">20190529</subfield><subfield code=\"g\">AFNOR</subfield><subfield code=\"2\">intermrc</subfield></datafield><datafield tag=\"330\" ind1=\" \" ind2=\" \"><subfield code=\"a\">La méthode de Gasquet enfin adaptée aux seniors ! Quelle activité physique pratiquer lorsque, à 50 ans, des fragilités corporelles et des douleurs apparaissent ? Comment prendre soin de soi, garder un corps fonctionnel et source de plaisir ? Spécialiste du périnée, professeure de yoga, reconnue et suivie par des médecins, des sages-femmes, des kinésithérapeutes et des coachs sportifs dans le monde entier, Bernadette de Gasquet adapte dans ce livre sa célèbre méthode aux seniors et propose un travail sur le renforcement musculaire, sans recherche de la performance, à travers des exercices simples. Travail corporel sans douleur et sans risque, discipline au service de l\\'être humain, le yoga peut être pratiqué à tout âge. En alternant tonification et détente, renforcements et étirements, en associant respiration et action sur les fonctions vitales, on peut garder un corps en pleine forme. Bernadette de Gasquet reprend ici les bases de l\\'activité physique – postures, respiration, abdominaux – en se concentrant sur les maux des seniors – douleurs articulaires, problèmes de circulation, de constipation, hypertension, troubles respiratoires, rhumatismes... – pour leur donner les clés d\\'une vie plus saine et du bien-être au quotidien. 200 photos, 15 schémas, des exercices filmés... Yoga senior vous propose de nombreux conseils pratiques et des exercices physiques adaptés pour rester en forme après 50 ans</subfield><subfield code=\"2\">éditeur</subfield></datafield></record>',\n",
       "   'role': 'user'},\n",
       "  {'content': 'To transform the provided bibliographical metadata into the given UNIMARC/XML record, proceed step-by-step, field by field, as follows:\\n\\n1. **Control fields** (these are often generated/managed by the cataloguing system):\\n\\n   - `<controlfield tag=\"001\">` — Record identifier: `236807005` (not present in metadata; assigned by system)\\n   - `<controlfield tag=\"003\">` — Control number identifier (URI source): `http://www.sudoc.fr/236807005`\\n   - `<controlfield tag=\"005\">` — Date and time of record processing: `20210208123415.000` (recording timestamp)\\n   - `<controlfield tag=\"035\">` — Various system identifiers:\\n     - `(OCoLC)1107377985` from OCLC number metadata\\n     - `FRBNF...` codes from French national bibliographic authority (not explicitly given but part of cataloguing)\\n   - `<controlfield tag=\"010\">` — International Standard Book Number with binding type: `978-2-221-24174-5` and a binding subfield `$b`: `br.` (broché = paperback)\\n   - `<controlfield tag=\"073\">` — EAN (European article number) from \"Other identifier\": `9782221241745`\\n\\n2. **Leader**\\n\\n   - Encodes record status, type, bibliographic level, encoding level, etc. (`cam0 22        450`) - typically system generated.\\n\\n3. **010 field** (ISBN with binding):\\n\\n   - Maps ISBN to `<datafield tag=\"010\"><subfield code=\"a\">978-2-221-24174-5</subfield><subfield code=\"b\">br.</subfield></datafield>`\\n   - Binding \"br.\" corresponds to paperback (derived or cataloguer\\'s addition).\\n\\n4. **073 field** (EAN):\\n\\n   - `<datafield tag=\"073\"><subfield code=\"a\">9782221241745</subfield></datafield>`  \\n   - From \"Other identifier\" (EAN in metadata).\\n\\n5. **035 field** (other system numbers):\\n\\n   - OCLC: `(OCoLC)1107377985`\\n   - Other French identifiers (cataloguing institution codes), e.g. `FRBNF...`  \\n   - These are authority/control numbers for integration between systems.\\n\\n6. **100 field** — Date and activity code (special code field for cataloguing date/level):\\n\\n   - `<datafield tag=\"100\"><subfield code=\"a\">20190703h20192019m  y0frey50      ba</subfield>`  \\n   - This is a coded field indicating cataloguing dates or activity; this comes from cataloguing process and legal deposit year.  \\n   - The year 2019 comes from \"DL 2019\" (Deposited Legal year 2019).\\n\\n7. **101 field** — Language of the item:\\n\\n   - `<datafield tag=\"101\" ind1=\"0\"><subfield code=\"a\">fre</subfield><subfield code=\"2\">639-2</subfield></datafield>`  \\n   - From metadata language \"French (fre)\".\\n\\n8. **105, 106 fields** — Related to material form and genre:\\n\\n   - `<datafield tag=\"105\"><subfield code=\"a\">a   ||||000yy</subfield></datafield>`  \\n   - `<datafield tag=\"106\"><subfield code=\"a\">r</subfield></datafield>`\\n   - \\'a\\' = text, \\'r\\' indicates genre/form type (e.g., normal printed book).  \\n   - These are based on \"Material type: text, printed book\" from metadata.\\n\\n9. **181, 182, 183 fields** — Content, Media, and Carrier types (RDA):\\n\\n   - `<datafield tag=\"181\"><subfield code=\"c\">txt</subfield><subfield code=\"2\">rdacontent</subfield></datafield>`: Content type = text.\\n   - `<datafield tag=\"182\"><subfield code=\"c\">n</subfield><subfield code=\"2\">rdamedia</subfield></datafield>`: Media type (unmediated).\\n   - `<datafield tag=\"183\"><subfield code=\"a\">nga</subfield><subfield code=\"2\">RDAfrCarrier</subfield></datafield>`: Carrier type = volume (nga).\\n   - These correspond to the metadata fields \"Material type: text, printed book\" and \"Carrier type: volume (nga)\".\\n\\n10. **102 field** — Place of publication country code:\\n\\n    - `<datafield tag=\"102\"><subfield code=\"a\">FR</subfield></datafield>`\\n    - From \"Country of publication: France (FR)\".\\n\\n11. **320 field** — Notes on bibliography:\\n\\n    - `<datafield tag=\"320\"><subfield code=\"a\">Notes bibliogr.</subfield></datafield>`\\n    - From metadata \"Notes bibliogr.\" under Notes/Bibliographic references.\\n\\n12. **200 field** — Title and statement of responsibility:\\n\\n    - `<datafield tag=\"200\" ind1=\"1\" ind2=\" \">`\\n      - `<subfield code=\"a\">Yoga senior</subfield>` -- maps Title\\n      - `<subfield code=\"e\">la méthode de Gasquet</subfield>` -- maps Subtitle\\n      - `<subfield code=\"f\">Dr Bernadette de Gasquet</subfield>` -- maps Author (statement of responsibility)\\n      - `<subfield code=\"f\">avec la participation du Dr Marie Thirion</subfield>` -- maps Participation statement\\n    - So:\\n      - 200$a = Title\\n      - 200$e = Subtitle\\n      - 200$f = Author(s) / participation statement\\n\\n13. **700 field** — Main personal author details:\\n\\n    - `<datafield tag=\"700\" ind1=\" \" ind2=\"1\">`\\n      - `<subfield code=\"3\">084278986</subfield>` — Local control number or authority key\\n      - `<subfield code=\"a\">Gasquet</subfield>` — family name\\n      - `<subfield code=\"b\">Bernadette de</subfield>` — given names\\n      - `<subfield code=\"f\">1946-....</subfield>` — dates of birth (metadata: born 1946)\\n      - `<subfield code=\"4\">070</subfield>` — relator code for author (UNIMARC relators, \\'070\\' = author)\\n    - From Author details metadata for Bernadette de Gasquet\\n    - Note: The names are split into family and given according to French conventions and authority data.\\n\\n14. **702 field** — Secondary personal contributor details (participant):\\n\\n    - `<datafield tag=\"702\" ind1=\" \" ind2=\"1\">`\\n      - `<subfield code=\"3\">028312635</subfield>` — local control number\\n      - `<subfield code=\"a\">Thirion</subfield>` — family name\\n      - `<subfield code=\"b\">Marie</subfield>` — given name\\n      - `<subfield code=\"f\">1944-....</subfield>` — birth year\\n      - `<subfield code=\"c\">pédiatre</subfield>` — profession (from metadata \"pediatrician\")\\n      - `<subfield code=\"4\">205</subfield>` — relator code for contributor function (\\'205\\' = collaborator)\\n    - Matches \"avec la participation du Dr Marie Thirion\" and author\\'s birth details + profession.\\n\\n15. **801 fields** — Cataloguing source and date(s):\\n\\n    - Two 801 fields with different subfields showing cataloguing institution, date, and processing. E.g.:\\n      - `<datafield tag=\"801\" ind1=\" \" ind2=\"3\">`\\n      - `<datafield tag=\"801\" ind1=\" \" ind2=\"0\">`\\n    - From cataloguing administrative metadata, not in source but typical.\\n\\n16. **214 field** — Imprint information (Publication):\\n\\n    - `<datafield tag=\"214\" ind1=\" \" ind2=\"0\">`\\n      - `<subfield code=\"a\">Paris</subfield>` — place of publication (metadata: Paris)\\n      - `<subfield code=\"c\">Robert Laffont</subfield>` — publisher\\n      - `<subfield code=\"d\">DL 2019</subfield>` — date, legal deposit year (DL 2019)\\n    - Maps directly from metadata imprint data.\\n\\n17. **215 field** — Physical description:\\n\\n    - `<datafield tag=\"215\" ind1=\" \" ind2=\" \">`\\n      - `<subfield code=\"a\">1 vol. (250 p.)</subfield>` — volume and pages\\n      - `<subfield code=\"c\">ill., couv. ill. en coul.</subfield>` — includes illustrations and cover in color (from \"Illustrations, color illustrated cover\")\\n      - `<subfield code=\"d\">22 cm</subfield>` — physical size\\n    - Direct mapping from metadata \"Material description\".\\n\\n18. **225 and 410 fields** — Series or Collection:\\n\\n    - `<datafield tag=\"225\" ind1=\"0\" ind2=\" \">`\\n      - `<subfield code=\"a\">Réponses</subfield>`\\n    - `<datafield tag=\"410\" ind1=\" \" ind2=\"|\">`\\n      - `<subfield code=\"0\">001026399</subfield>` — series identifier (from catalogue\\'s own authority files)\\n      - `<subfield code=\"t\">Réponses (Paris. 1967)</subfield>` — series title with place and founding year\\n      - `<subfield code=\"x\">0750-7747</subfield>` — ISSN for the series\\n    - From metadata \"Collection/Series: Réponses\" and ISSN 0750-7747\\n\\n19. **606 fields** — Subject headings:\\n\\n    - Two fields for RAMEAU subjects:\\n      - `<datafield tag=\"606\"><subfield code=\"3\">027347893</subfield><subfield code=\"a\">Hatha-yoga</subfield><subfield code=\"2\">rameau</subfield></datafield>`\\n      - `<datafield tag=\"606\"><subfield code=\"3\">027425541</subfield><subfield code=\"a\">Exercices physiques pour personnes âgées</subfield><subfield code=\"2\">rameau</subfield></datafield>`\\n    - Map from keywords/subject headings with authority source \"RAMEAU\".\\n\\n20. **676 and 686 fields** — Classification schemes:\\n\\n    - `<datafield tag=\"676\"><subfield code=\"a\">613.710 846</subfield><subfield code=\"v\">23</subfield></datafield>`\\n      - 613.710 is Dewey number, 846 possibly language or variant, 23 is DDC edition.\\n    - `<datafield tag=\"686\"><subfield code=\"a\">610</subfield><subfield code=\"2\">Cadre de classement de la Bibliographie nationale française</subfield></datafield>`\\n      - The French national bibliography classification number 610\\n\\n21. **330 field** — Summary / Abstract:\\n\\n    - `<datafield tag=\"330\"><subfield code=\"a\">[full abstract text]</subfield><subfield code=\"2\">éditeur</subfield></datafield>`\\n    - The long abstract text from metadata \"Abstract/Notes\" with the source \"éditeur\" (publisher).\\n\\n---\\n\\n### Summary Table of key mappings:\\n\\n| Metadata element                  | UNIMARC tag and subfield      | Note                                      |\\n|---------------------------------|-------------------------------|-------------------------------------------|\\n| Title                           | 200$a                         | Main title                               |\\n| Subtitle                        | 200$e                         | Subtitle                                 |\\n| Author (main)                   | 200$f, 700$a(b)(f)            | Statement of responsibility and author info with dates |\\n| Participant                    | 200$f, 702$a(b)(f)(c)         | Statement and contributor info with profession  |\\n| ISBN                           | 010$a                        | ISBN number                              |\\n| Binding                        | 010$b                        | Binding type (\\'br.\\' for paperback)       |\\n| EAN                            | 073$a                        | EAN other identifier                     |\\n| OCLC number                    | 035$a                        | System control number                     |\\n| Language                       | 101$a                        | lang code \\'fre\\'                          |\\n| Place of publication           | 214$a                        | Place of publication                     |\\n| Publisher                     | 214$c                        | Publisher                               |\\n| Date of publication (legal deposit) | 214$d                    | Date (DL 2019)                          |\\n| Physical description (volumes, pages) | 215$a                 | Number of volumes and pages              |\\n| Physical description (illustrations) | 215$c                  | Illustrations and cover details           |\\n| Physical description (dimensions) | 215$d                      | Size in cm                              |\\n| Series                        | 225$a                         | Series name                            |\\n| Series info (Series identifier, title, ISSN) | 410$0 410$t 410$x | Series authority and ISSN info          |\\n| Subjects (RAMEAU terms)        | 606$a and 606$2               | Subject headings with authority code    |\\n| Dewey / French classification | 676$a (DDC), 686$a (FNB classification) | Classification schemes                |\\n| Notes bibliogr.               | 320$a                        | Bibliographic notes                      |\\n| Abstract                      | 330$a and 330$2               | Abstract and its source (publisher)      |\\n| Material type and carrier info | 105, 106, 181, 182, 183       | Content, media, carrier codes             |\\n| Place of publication country   | 102$a                        | Country code                            |\\n| Authority and control numbers  | 035, 100 etc.                  | IDs and cataloguing system info          |\\n| Cataloguing data and source    | 801                           | Cataloguing institution, date            |\\n\\n---\\n\\n### Additional notes:\\n\\n- Some fields (controlfields 001, 003, 005, 035, 100, 801) are system-generated and come from cataloguing process and integration with national and international systems.\\n- Relator codes `$4` in 700/702 fields correspond to the role of the person (author or contributor), respectively 070 and 205.\\n- The authors\\' names are split by family name and given name parts according to authority records.\\n- Professional designation (pédiatre) is placed in 702$c.\\n- Binding type \"br.\" (broché) is deduced from material (typical for paperbacks).\\n- The \"DL 2019\" is copied literally into 214$d noting the legal deposit date.\\n- Language code is \"fre\" per ISO 639-2.\\n- Abstract is very long and fully included in 330$a with subfield $2 indicating its source.\\n- ISBN appears twice: as 010$a/b (ISBN + binding type) and 073$a (EAN without hyphens).\\n- The dimensions, volume count, number of pages, and illustration details are composed in 215.\\n- The series information includes both 225 (series title) and 410 (series authority control number, titles, ISSN).\\n- Subject headings use RAMEAU authority code in $2.\\n\\n---\\n\\nThis stepwise mapping explains how each piece of your metadata is encoded into UNIMARC XML fields and subfields as presented in the example record.',\n",
       "   'role': 'assistant'}]}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bdc9105-ed3a-442a-bfbe-859981519aa2",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "3d9f8c4f-6cad-4c58-a362-cbbfae50760c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting train dataset to ChatML: 100%|██████████| 173/173 [00:00<00:00, 3676.68 examples/s]\n",
      "Applying chat template to train dataset: 100%|██████████| 173/173 [00:00<00:00, 1979.72 examples/s]\n",
      "Tokenizing train dataset: 100%|██████████| 173/173 [00:03<00:00, 53.17 examples/s]\n",
      "Truncating train dataset: 100%|██████████| 173/173 [00:00<00:00, 17814.80 examples/s]\n",
      "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
     ]
    }
   ],
   "source": [
    "# ---- 3. Define LoRA config ----\n",
    "peft_config = LoraConfig(\n",
    "    r=8,\n",
    "    lora_alpha=32,\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\",\n",
    "    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\"] # may vary based on model, check with `model.named_modules()` in previous cell\n",
    ")\n",
    "\n",
    "# ---- 4. Training args ----\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./sft_lora_trace\",\n",
    "    per_device_train_batch_size=1,\n",
    "    gradient_accumulation_steps=4,\n",
    "    logging_steps=10,\n",
    "    save_strategy=\"epoch\",\n",
    "    num_train_epochs=30,\n",
    "    learning_rate=5e-5,\n",
    "    fp16=True,\n",
    "    report_to=\"none\"\n",
    ")\n",
    "\n",
    "# ---- 5. Launch training ----\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    train_dataset=dataset,\n",
    "    peft_config=peft_config,\n",
    "    args=training_args\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "c968e1ef-8dce-4f93-be34-9caaab1803de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1290' max='1290' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1290/1290 57:30, Epoch 29/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>2.257600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>2.059800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>2.010000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1.870200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.759400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>1.615700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>1.523400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>1.586800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>1.428100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.453600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>1.509700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>1.441500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>1.351200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>1.359300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1.312100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>1.324500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>1.464200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>1.283000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>1.271900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1.283900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>1.392300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>1.359500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>1.361600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>1.308300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>1.249800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>1.199000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>1.327700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>1.180700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>1.279800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>1.268500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>1.304300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>1.231700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>1.255600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>1.242600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>1.202700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>1.304100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>370</td>\n",
       "      <td>1.201600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>1.221500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>390</td>\n",
       "      <td>1.232600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>1.119500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>410</td>\n",
       "      <td>1.153700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>1.181500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>430</td>\n",
       "      <td>1.322700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>440</td>\n",
       "      <td>1.162500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>1.141600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>460</td>\n",
       "      <td>1.236100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>470</td>\n",
       "      <td>1.167800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>1.159100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>490</td>\n",
       "      <td>1.283100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>1.213700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>510</td>\n",
       "      <td>1.159800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>520</td>\n",
       "      <td>1.135300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>530</td>\n",
       "      <td>1.110400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>1.177100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>1.147400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>560</td>\n",
       "      <td>1.222600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>570</td>\n",
       "      <td>1.091700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>580</td>\n",
       "      <td>1.144200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>590</td>\n",
       "      <td>1.093900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>1.228600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>610</td>\n",
       "      <td>1.187900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>620</td>\n",
       "      <td>1.119300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>630</td>\n",
       "      <td>1.109900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>640</td>\n",
       "      <td>1.178100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>1.154000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>660</td>\n",
       "      <td>1.053100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>670</td>\n",
       "      <td>1.179600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>680</td>\n",
       "      <td>1.053900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>690</td>\n",
       "      <td>1.059700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>1.151000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>710</td>\n",
       "      <td>1.176000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>720</td>\n",
       "      <td>1.063900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>730</td>\n",
       "      <td>1.103400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>740</td>\n",
       "      <td>1.121000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>1.075800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>760</td>\n",
       "      <td>1.101700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>770</td>\n",
       "      <td>1.102900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>780</td>\n",
       "      <td>1.057400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>790</td>\n",
       "      <td>1.125400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>1.093300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>810</td>\n",
       "      <td>1.073900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>820</td>\n",
       "      <td>1.081300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>830</td>\n",
       "      <td>1.075900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>840</td>\n",
       "      <td>1.128900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>1.124900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>860</td>\n",
       "      <td>1.132900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>870</td>\n",
       "      <td>1.001500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>880</td>\n",
       "      <td>1.090600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>890</td>\n",
       "      <td>0.989100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>1.139000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>910</td>\n",
       "      <td>1.069500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>920</td>\n",
       "      <td>1.108100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>930</td>\n",
       "      <td>1.036000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>940</td>\n",
       "      <td>1.023000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>1.036800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>960</td>\n",
       "      <td>1.023600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>970</td>\n",
       "      <td>1.124700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>980</td>\n",
       "      <td>1.095100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>990</td>\n",
       "      <td>1.044700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>1.032800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1010</td>\n",
       "      <td>1.033600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1020</td>\n",
       "      <td>1.104400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1030</td>\n",
       "      <td>0.997200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1040</td>\n",
       "      <td>1.049900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1050</td>\n",
       "      <td>1.105300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1060</td>\n",
       "      <td>1.065900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1070</td>\n",
       "      <td>0.965400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1080</td>\n",
       "      <td>1.069100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1090</td>\n",
       "      <td>1.042000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>1.084800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1110</td>\n",
       "      <td>1.105200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1120</td>\n",
       "      <td>1.036000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1130</td>\n",
       "      <td>1.004100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1140</td>\n",
       "      <td>0.986500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1150</td>\n",
       "      <td>1.054000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1160</td>\n",
       "      <td>1.049300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1170</td>\n",
       "      <td>1.010700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1180</td>\n",
       "      <td>1.000900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1190</td>\n",
       "      <td>1.068700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.994600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1210</td>\n",
       "      <td>1.056900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1220</td>\n",
       "      <td>1.037600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1230</td>\n",
       "      <td>1.025000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1240</td>\n",
       "      <td>1.017200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1250</td>\n",
       "      <td>1.035100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1260</td>\n",
       "      <td>1.023400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1270</td>\n",
       "      <td>0.994800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1280</td>\n",
       "      <td>1.105000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1290</td>\n",
       "      <td>1.009000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1290, training_loss=1.192039508228154, metrics={'train_runtime': 3453.4002, 'train_samples_per_second': 1.503, 'train_steps_per_second': 0.374, 'total_flos': 1.3800208274030592e+16, 'train_loss': 1.192039508228154})"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0f61e68-0def-4bbf-a87e-f3a8e742ee7e",
   "metadata": {},
   "source": [
    "### Save adapter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "91449f14-9eb8-41d2-9e61-b00671db2275",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9716e5b-3d69-4953-b777-96d315e1f992",
   "metadata": {},
   "source": [
    "### Test inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "cda389b5-0fed-4645-bfc5-2edc046a02f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import PeftModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "1c61d94f-34b0-4930-b7a8-8af92fbf7190",
   "metadata": {},
   "outputs": [],
   "source": [
    "peft_model_id = \"./sft_lora_trace\"\n",
    "tr_model_id = \"Qwen/Qwen3-0.6B\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "3e59cb04-56b6-4e7a-98b4-d05bb94877d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(tr_model_id, trust_remote_code=True, torch_dtype=torch.float16,\n",
    "     low_cpu_mem_usage=True,)\n",
    "model = PeftModel.from_pretrained(model, peft_model_id)\n",
    "merged_model = model.merge_and_unload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "00f0ef26-7d19-4a60-8048-0715a1cc0e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_model = merged_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "709e1910-a0dd-46b2-98c2-83b92375b804",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"\n",
    "You are a helpful assistant expert in Unimarc/XML bibliographic records.\n",
    "\"\"\"\n",
    "\n",
    "user_prompt = \"\"\"\n",
    "# Bibliographical metadata\n",
    "Title: Traverser\n",
    "Subtitle: = Crossings\n",
    "Author: Marie Liénard-Yeterian, Valérie Simon\n",
    "Author (authorized access point): Liénard-Yeterian, Marie; Simon, Valérie\n",
    "Language of text: French (fre), with English (eng) parallel title and content indicated\n",
    "Title in English: Crossings\n",
    "Country of publication: France (FR)\n",
    "Publisher: Skepsi Editions La Pensée\n",
    "Place of publication: [Caen]\n",
    "Date of publication: DL 2024 (date of legal deposit 2024)\n",
    "Physical description: 1 volume (86 pages)\n",
    "Illustrations: Photographic illustrations in color, both within and outside the text\n",
    "Dimensions: 24 cm\n",
    "ISBN: 978-29-595-9903-3\n",
    "Source of control number: http://www.sudoc.fr/283499370\n",
    "Abstract/Notes: It is a dialogue between images and words based on photographs and texts in two languages (French and English) distinct in their sense and dynamism, to explore the idea of crossing. The absence of punctuation allows the reader to let their own reactions emerge. The reader as the third author.\n",
    "Subject headings / Keywords:\n",
    "- Poésie autobiographique (Autobiographical poetry) [RAMEAU]\n",
    "- Livres de photographies (Photography books) [RAMEAU]\n",
    "\n",
    "Additional codes:\n",
    "- RDA content types: text, still image\n",
    "- RDA media type: n (unmediated)\n",
    "- RDA carrier type: nga (volume)\n",
    "Country code: FR\n",
    "Data format and encoding level: Unimarc XML with RDA elements\n",
    "\"\"\"\n",
    "\n",
    "messages = [\n",
    "  {\"role\": \"system\", \"content\": system_prompt + \" /think\"},\n",
    "  {\"role\": \"user\", \"content\": user_prompt},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "182d2853-81a2-4b88-a72e-0c2b0005377c",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer.apply_chat_template(\n",
    "    messages,\n",
    "    return_dict=True,\n",
    "    tokenize = True,\n",
    "    add_generation_prompt = True, # Must add for generation\n",
    "    return_tensors = \"pt\",\n",
    "    enable_thinking=True\n",
    ").to(device)\n",
    "\n",
    "outputs = merged_model.generate(\n",
    "    **inputs,\n",
    "    max_new_tokens = 32768,\n",
    "    use_cache = True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "26aac89e-2efd-42dc-a2fa-2071512245cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thinking content: \n",
      "content: ## Bibliographical metadata:\n",
      "\n",
      "### Title: Traverser  \n",
      "**Subtitle: = Crossings**  \n",
      "**Author: Marie Liénard-Yeterian, Valérie Simon**  \n",
      "**Author (authorized access point):** Liénard-Yeterian, Marie; Simon, Valérie  \n",
      "\n",
      "### Author details:  \n",
      "- Liénard-Yeterian, Marie  \n",
      "- Simon, Valérie  \n",
      "\n",
      "### Language:  \n",
      "- French (fre)  \n",
      "- English (eng) parallel title and content  \n",
      "\n",
      "### Country of publication: France (FR)  \n",
      "- Publication place: Caen  \n",
      "- Publication date: 2024 (DL 2024)  \n",
      "\n",
      "### Publisher:  \n",
      "- Skepsi Editions La Pensée  \n",
      "- Place of publication: [Caen]  \n",
      "- Date of legal deposit: 2024 (physical description: 1 volume (86 pages), illustrated with photomontages and text in color)  \n",
      "\n",
      "### Physical description:  \n",
      "- 24 cm height  \n",
      "- Photographs and text in color, as well as inside the text (photographic and textual illustrations)  \n",
      "- Media type: still image (photographic) and text (non-mediating text)  \n",
      "- Carrier type: volume (nga)  \n",
      "\n",
      "### ISBN: 9782959599033  \n",
      "\n",
      "### Source of control number: [SUDOC] 283499370  \n",
      "\n",
      "### Abstract/Notes:  \n",
      "- This book presents a dialogue between photographs and texts in two languages, \"Crossings\" and \"Traverser,\" to explore the idea of crossing.  \n",
      "- The absence of punctuation allows the reader to let their own reactions emerge.  \n",
      "- The reader is considered the third author.  \n",
      "\n",
      "### Subject headings and keywords:  \n",
      "- Poésie autobiographique (Autobiographical poetry) [RAMEAU]  \n",
      "- Livres de photographies (Photography books) [RAMEAU]  \n",
      "\n",
      "### Control number:  \n",
      "- Roland de Montreuil, France (283499370)  \n",
      "\n",
      "### Country code: FR  \n",
      "- Data format and encoding level: Unimarc/XML with RDA elements  \n",
      "\n",
      "---  \n",
      "This bibliographic record includes author information, title details, publication details, and subject headings. The record is structured in Unimarc/XML format.\n"
     ]
    }
   ],
   "source": [
    "output_ids = outputs[0][len(inputs.input_ids[0]):].tolist()\n",
    "# parsing thinking content\n",
    "try:\n",
    "    # rindex finding 151668 (</think>)\n",
    "    index = len(output_ids) - output_ids[::-1].index(151668)\n",
    "except ValueError:\n",
    "    index = 0\n",
    "\n",
    "thinking_content = tokenizer.decode(output_ids[:index], skip_special_tokens=True).strip(\"\\n\")\n",
    "content = tokenizer.decode(output_ids[index:], skip_special_tokens=True).strip(\"\\n\")\n",
    "\n",
    "print(\"thinking content:\", thinking_content)\n",
    "print(\"content:\", content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6ec8952-08f7-4327-8ed6-552759feb060",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load lora_trace adapter\n",
    "#model_trace = PeftModel.from_pretrained(model, \"./sft_lora_trace\")\n",
    "#model_trace.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41d92ed4-502e-43ea-a174-8be035f6dfce",
   "metadata": {},
   "source": [
    "## Train lora_output Adapter (Trace → XML)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e695b42e-5466-49c0-9ed0-2512854e58cf",
   "metadata": {},
   "source": [
    "### Reload model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "08af63d6-45b6-41c5-af3f-c1c255141a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "del model\n",
    "del tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "951034ba-8886-437e-bf73-7f6c05812633",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"Qwen/Qwen3-0.6B\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    torch_dtype=\"auto\",\n",
    "    device_map=\"auto\",\n",
    "    #attn_implementation=\"flash_attention_2\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "79ae9183-e18f-4293-b37a-ab209ed9a3fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Qwen3ForCausalLM(\n",
       "  (model): Qwen3Model(\n",
       "    (embed_tokens): Embedding(151936, 1024)\n",
       "    (layers): ModuleList(\n",
       "      (0-27): 28 x Qwen3DecoderLayer(\n",
       "        (self_attn): Qwen3Attention(\n",
       "          (q_proj): Linear(in_features=1024, out_features=2048, bias=False)\n",
       "          (k_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (v_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (o_proj): Linear(in_features=2048, out_features=1024, bias=False)\n",
       "          (q_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
       "          (k_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
       "        )\n",
       "        (mlp): Qwen3MLP(\n",
       "          (gate_proj): Linear(in_features=1024, out_features=3072, bias=False)\n",
       "          (up_proj): Linear(in_features=1024, out_features=3072, bias=False)\n",
       "          (down_proj): Linear(in_features=3072, out_features=1024, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): Qwen3RMSNorm((1024,), eps=1e-06)\n",
       "        (post_attention_layernorm): Qwen3RMSNorm((1024,), eps=1e-06)\n",
       "      )\n",
       "    )\n",
       "    (norm): Qwen3RMSNorm((1024,), eps=1e-06)\n",
       "    (rotary_emb): Qwen3RotaryEmbedding()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=1024, out_features=151936, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"cuda\" # for GPU usage or \"cpu\" for CPU usage\n",
    "model = model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "d28eaac4-55e5-4868-9dff-20866af6532d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !Important\n",
    "tokenizer.padding_side = \"right\"\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4d914a0-e23a-4e27-afd5-06a28ba68f90",
   "metadata": {},
   "source": [
    "### Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2de6716a-7f29-421c-b935-53d957035037",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"Geraldine/metadata-to-unimarc-traces\", split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e7564d51-016c-4e76-ad92-8aad2803f27d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 173/173 [00:00<00:00, 3746.52 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['messages'],\n",
       "    num_rows: 173\n",
       "})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "system_message = \"\"\"You are an expert assistant in cataloging and Unimarc/XML standards. \n",
    "Given detailed reasoning about how bibliographic metadata should be mapped to Unimarc fields, \n",
    "your task is to generate the corresponding Unimarc/XML bibliographic record, strictly following the Unimarc standards.\"\"\"\n",
    "def create_conversation(row):\n",
    "  return {\n",
    "    \"messages\": [\n",
    "      {\"role\": \"system\", \"content\": system_message + \" /think\"},\n",
    "      {\"role\": \"user\", \"content\": row[\"reasoning\"]},\n",
    "      {\"role\": \"assistant\", \"content\": row['unimarc_record'] + tokenizer.eos_token} # to avoid infinite generation\n",
    "    ]\n",
    "  }\n",
    "\n",
    "dataset = dataset.map(create_conversation, remove_columns=dataset.features, batched=False)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d3c6174e-5969-41e3-9f7a-36f52fd7904e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [{'content': 'You are an expert assistant in cataloging and Unimarc/XML standards. \\nGiven detailed reasoning about how bibliographic metadata should be mapped to Unimarc fields, \\nyour task is to generate the corresponding Unimarc/XML bibliographic record, strictly following the Unimarc standards. /think',\n",
       "   'role': 'system'},\n",
       "  {'content': 'To transform the provided bibliographical metadata into the given UNIMARC/XML record, proceed step-by-step, field by field, as follows:\\n\\n1. **Control fields** (these are often generated/managed by the cataloguing system):\\n\\n   - `<controlfield tag=\"001\">` — Record identifier: `236807005` (not present in metadata; assigned by system)\\n   - `<controlfield tag=\"003\">` — Control number identifier (URI source): `http://www.sudoc.fr/236807005`\\n   - `<controlfield tag=\"005\">` — Date and time of record processing: `20210208123415.000` (recording timestamp)\\n   - `<controlfield tag=\"035\">` — Various system identifiers:\\n     - `(OCoLC)1107377985` from OCLC number metadata\\n     - `FRBNF...` codes from French national bibliographic authority (not explicitly given but part of cataloguing)\\n   - `<controlfield tag=\"010\">` — International Standard Book Number with binding type: `978-2-221-24174-5` and a binding subfield `$b`: `br.` (broché = paperback)\\n   - `<controlfield tag=\"073\">` — EAN (European article number) from \"Other identifier\": `9782221241745`\\n\\n2. **Leader**\\n\\n   - Encodes record status, type, bibliographic level, encoding level, etc. (`cam0 22        450`) - typically system generated.\\n\\n3. **010 field** (ISBN with binding):\\n\\n   - Maps ISBN to `<datafield tag=\"010\"><subfield code=\"a\">978-2-221-24174-5</subfield><subfield code=\"b\">br.</subfield></datafield>`\\n   - Binding \"br.\" corresponds to paperback (derived or cataloguer\\'s addition).\\n\\n4. **073 field** (EAN):\\n\\n   - `<datafield tag=\"073\"><subfield code=\"a\">9782221241745</subfield></datafield>`  \\n   - From \"Other identifier\" (EAN in metadata).\\n\\n5. **035 field** (other system numbers):\\n\\n   - OCLC: `(OCoLC)1107377985`\\n   - Other French identifiers (cataloguing institution codes), e.g. `FRBNF...`  \\n   - These are authority/control numbers for integration between systems.\\n\\n6. **100 field** — Date and activity code (special code field for cataloguing date/level):\\n\\n   - `<datafield tag=\"100\"><subfield code=\"a\">20190703h20192019m  y0frey50      ba</subfield>`  \\n   - This is a coded field indicating cataloguing dates or activity; this comes from cataloguing process and legal deposit year.  \\n   - The year 2019 comes from \"DL 2019\" (Deposited Legal year 2019).\\n\\n7. **101 field** — Language of the item:\\n\\n   - `<datafield tag=\"101\" ind1=\"0\"><subfield code=\"a\">fre</subfield><subfield code=\"2\">639-2</subfield></datafield>`  \\n   - From metadata language \"French (fre)\".\\n\\n8. **105, 106 fields** — Related to material form and genre:\\n\\n   - `<datafield tag=\"105\"><subfield code=\"a\">a   ||||000yy</subfield></datafield>`  \\n   - `<datafield tag=\"106\"><subfield code=\"a\">r</subfield></datafield>`\\n   - \\'a\\' = text, \\'r\\' indicates genre/form type (e.g., normal printed book).  \\n   - These are based on \"Material type: text, printed book\" from metadata.\\n\\n9. **181, 182, 183 fields** — Content, Media, and Carrier types (RDA):\\n\\n   - `<datafield tag=\"181\"><subfield code=\"c\">txt</subfield><subfield code=\"2\">rdacontent</subfield></datafield>`: Content type = text.\\n   - `<datafield tag=\"182\"><subfield code=\"c\">n</subfield><subfield code=\"2\">rdamedia</subfield></datafield>`: Media type (unmediated).\\n   - `<datafield tag=\"183\"><subfield code=\"a\">nga</subfield><subfield code=\"2\">RDAfrCarrier</subfield></datafield>`: Carrier type = volume (nga).\\n   - These correspond to the metadata fields \"Material type: text, printed book\" and \"Carrier type: volume (nga)\".\\n\\n10. **102 field** — Place of publication country code:\\n\\n    - `<datafield tag=\"102\"><subfield code=\"a\">FR</subfield></datafield>`\\n    - From \"Country of publication: France (FR)\".\\n\\n11. **320 field** — Notes on bibliography:\\n\\n    - `<datafield tag=\"320\"><subfield code=\"a\">Notes bibliogr.</subfield></datafield>`\\n    - From metadata \"Notes bibliogr.\" under Notes/Bibliographic references.\\n\\n12. **200 field** — Title and statement of responsibility:\\n\\n    - `<datafield tag=\"200\" ind1=\"1\" ind2=\" \">`\\n      - `<subfield code=\"a\">Yoga senior</subfield>` -- maps Title\\n      - `<subfield code=\"e\">la méthode de Gasquet</subfield>` -- maps Subtitle\\n      - `<subfield code=\"f\">Dr Bernadette de Gasquet</subfield>` -- maps Author (statement of responsibility)\\n      - `<subfield code=\"f\">avec la participation du Dr Marie Thirion</subfield>` -- maps Participation statement\\n    - So:\\n      - 200$a = Title\\n      - 200$e = Subtitle\\n      - 200$f = Author(s) / participation statement\\n\\n13. **700 field** — Main personal author details:\\n\\n    - `<datafield tag=\"700\" ind1=\" \" ind2=\"1\">`\\n      - `<subfield code=\"3\">084278986</subfield>` — Local control number or authority key\\n      - `<subfield code=\"a\">Gasquet</subfield>` — family name\\n      - `<subfield code=\"b\">Bernadette de</subfield>` — given names\\n      - `<subfield code=\"f\">1946-....</subfield>` — dates of birth (metadata: born 1946)\\n      - `<subfield code=\"4\">070</subfield>` — relator code for author (UNIMARC relators, \\'070\\' = author)\\n    - From Author details metadata for Bernadette de Gasquet\\n    - Note: The names are split into family and given according to French conventions and authority data.\\n\\n14. **702 field** — Secondary personal contributor details (participant):\\n\\n    - `<datafield tag=\"702\" ind1=\" \" ind2=\"1\">`\\n      - `<subfield code=\"3\">028312635</subfield>` — local control number\\n      - `<subfield code=\"a\">Thirion</subfield>` — family name\\n      - `<subfield code=\"b\">Marie</subfield>` — given name\\n      - `<subfield code=\"f\">1944-....</subfield>` — birth year\\n      - `<subfield code=\"c\">pédiatre</subfield>` — profession (from metadata \"pediatrician\")\\n      - `<subfield code=\"4\">205</subfield>` — relator code for contributor function (\\'205\\' = collaborator)\\n    - Matches \"avec la participation du Dr Marie Thirion\" and author\\'s birth details + profession.\\n\\n15. **801 fields** — Cataloguing source and date(s):\\n\\n    - Two 801 fields with different subfields showing cataloguing institution, date, and processing. E.g.:\\n      - `<datafield tag=\"801\" ind1=\" \" ind2=\"3\">`\\n      - `<datafield tag=\"801\" ind1=\" \" ind2=\"0\">`\\n    - From cataloguing administrative metadata, not in source but typical.\\n\\n16. **214 field** — Imprint information (Publication):\\n\\n    - `<datafield tag=\"214\" ind1=\" \" ind2=\"0\">`\\n      - `<subfield code=\"a\">Paris</subfield>` — place of publication (metadata: Paris)\\n      - `<subfield code=\"c\">Robert Laffont</subfield>` — publisher\\n      - `<subfield code=\"d\">DL 2019</subfield>` — date, legal deposit year (DL 2019)\\n    - Maps directly from metadata imprint data.\\n\\n17. **215 field** — Physical description:\\n\\n    - `<datafield tag=\"215\" ind1=\" \" ind2=\" \">`\\n      - `<subfield code=\"a\">1 vol. (250 p.)</subfield>` — volume and pages\\n      - `<subfield code=\"c\">ill., couv. ill. en coul.</subfield>` — includes illustrations and cover in color (from \"Illustrations, color illustrated cover\")\\n      - `<subfield code=\"d\">22 cm</subfield>` — physical size\\n    - Direct mapping from metadata \"Material description\".\\n\\n18. **225 and 410 fields** — Series or Collection:\\n\\n    - `<datafield tag=\"225\" ind1=\"0\" ind2=\" \">`\\n      - `<subfield code=\"a\">Réponses</subfield>`\\n    - `<datafield tag=\"410\" ind1=\" \" ind2=\"|\">`\\n      - `<subfield code=\"0\">001026399</subfield>` — series identifier (from catalogue\\'s own authority files)\\n      - `<subfield code=\"t\">Réponses (Paris. 1967)</subfield>` — series title with place and founding year\\n      - `<subfield code=\"x\">0750-7747</subfield>` — ISSN for the series\\n    - From metadata \"Collection/Series: Réponses\" and ISSN 0750-7747\\n\\n19. **606 fields** — Subject headings:\\n\\n    - Two fields for RAMEAU subjects:\\n      - `<datafield tag=\"606\"><subfield code=\"3\">027347893</subfield><subfield code=\"a\">Hatha-yoga</subfield><subfield code=\"2\">rameau</subfield></datafield>`\\n      - `<datafield tag=\"606\"><subfield code=\"3\">027425541</subfield><subfield code=\"a\">Exercices physiques pour personnes âgées</subfield><subfield code=\"2\">rameau</subfield></datafield>`\\n    - Map from keywords/subject headings with authority source \"RAMEAU\".\\n\\n20. **676 and 686 fields** — Classification schemes:\\n\\n    - `<datafield tag=\"676\"><subfield code=\"a\">613.710 846</subfield><subfield code=\"v\">23</subfield></datafield>`\\n      - 613.710 is Dewey number, 846 possibly language or variant, 23 is DDC edition.\\n    - `<datafield tag=\"686\"><subfield code=\"a\">610</subfield><subfield code=\"2\">Cadre de classement de la Bibliographie nationale française</subfield></datafield>`\\n      - The French national bibliography classification number 610\\n\\n21. **330 field** — Summary / Abstract:\\n\\n    - `<datafield tag=\"330\"><subfield code=\"a\">[full abstract text]</subfield><subfield code=\"2\">éditeur</subfield></datafield>`\\n    - The long abstract text from metadata \"Abstract/Notes\" with the source \"éditeur\" (publisher).\\n\\n---\\n\\n### Summary Table of key mappings:\\n\\n| Metadata element                  | UNIMARC tag and subfield      | Note                                      |\\n|---------------------------------|-------------------------------|-------------------------------------------|\\n| Title                           | 200$a                         | Main title                               |\\n| Subtitle                        | 200$e                         | Subtitle                                 |\\n| Author (main)                   | 200$f, 700$a(b)(f)            | Statement of responsibility and author info with dates |\\n| Participant                    | 200$f, 702$a(b)(f)(c)         | Statement and contributor info with profession  |\\n| ISBN                           | 010$a                        | ISBN number                              |\\n| Binding                        | 010$b                        | Binding type (\\'br.\\' for paperback)       |\\n| EAN                            | 073$a                        | EAN other identifier                     |\\n| OCLC number                    | 035$a                        | System control number                     |\\n| Language                       | 101$a                        | lang code \\'fre\\'                          |\\n| Place of publication           | 214$a                        | Place of publication                     |\\n| Publisher                     | 214$c                        | Publisher                               |\\n| Date of publication (legal deposit) | 214$d                    | Date (DL 2019)                          |\\n| Physical description (volumes, pages) | 215$a                 | Number of volumes and pages              |\\n| Physical description (illustrations) | 215$c                  | Illustrations and cover details           |\\n| Physical description (dimensions) | 215$d                      | Size in cm                              |\\n| Series                        | 225$a                         | Series name                            |\\n| Series info (Series identifier, title, ISSN) | 410$0 410$t 410$x | Series authority and ISSN info          |\\n| Subjects (RAMEAU terms)        | 606$a and 606$2               | Subject headings with authority code    |\\n| Dewey / French classification | 676$a (DDC), 686$a (FNB classification) | Classification schemes                |\\n| Notes bibliogr.               | 320$a                        | Bibliographic notes                      |\\n| Abstract                      | 330$a and 330$2               | Abstract and its source (publisher)      |\\n| Material type and carrier info | 105, 106, 181, 182, 183       | Content, media, carrier codes             |\\n| Place of publication country   | 102$a                        | Country code                            |\\n| Authority and control numbers  | 035, 100 etc.                  | IDs and cataloguing system info          |\\n| Cataloguing data and source    | 801                           | Cataloguing institution, date            |\\n\\n---\\n\\n### Additional notes:\\n\\n- Some fields (controlfields 001, 003, 005, 035, 100, 801) are system-generated and come from cataloguing process and integration with national and international systems.\\n- Relator codes `$4` in 700/702 fields correspond to the role of the person (author or contributor), respectively 070 and 205.\\n- The authors\\' names are split by family name and given name parts according to authority records.\\n- Professional designation (pédiatre) is placed in 702$c.\\n- Binding type \"br.\" (broché) is deduced from material (typical for paperbacks).\\n- The \"DL 2019\" is copied literally into 214$d noting the legal deposit date.\\n- Language code is \"fre\" per ISO 639-2.\\n- Abstract is very long and fully included in 330$a with subfield $2 indicating its source.\\n- ISBN appears twice: as 010$a/b (ISBN + binding type) and 073$a (EAN without hyphens).\\n- The dimensions, volume count, number of pages, and illustration details are composed in 215.\\n- The series information includes both 225 (series title) and 410 (series authority control number, titles, ISSN).\\n- Subject headings use RAMEAU authority code in $2.\\n\\n---\\n\\nThis stepwise mapping explains how each piece of your metadata is encoded into UNIMARC XML fields and subfields as presented in the example record.',\n",
       "   'role': 'user'},\n",
       "  {'content': '<record><controlfield tag=\"005\">20210208123415.000</controlfield><leader> cam0 22        450 </leader><controlfield tag=\"001\">236807005</controlfield><controlfield tag=\"003\">http://www.sudoc.fr/236807005</controlfield><datafield tag=\"035\" ind1=\" \" ind2=\" \"><subfield code=\"a\">(OCoLC)1107377985</subfield></datafield><datafield tag=\"010\" ind1=\" \" ind2=\" \"><subfield code=\"a\">978-2-221-24174-5</subfield><subfield code=\"b\">br.</subfield></datafield><datafield tag=\"073\" ind1=\" \" ind2=\"1\"><subfield code=\"a\">9782221241745</subfield></datafield><datafield tag=\"035\" ind1=\" \" ind2=\" \"><subfield code=\"a\">FRBNF457384730000008</subfield><subfield code=\"z\">FRBNF45738473</subfield></datafield><datafield tag=\"100\" ind1=\" \" ind2=\" \"><subfield code=\"a\">20190703h20192019m  y0frey50      ba</subfield></datafield><datafield tag=\"101\" ind1=\"0\" ind2=\" \"><subfield code=\"a\">fre</subfield><subfield code=\"2\">639-2</subfield></datafield><datafield tag=\"105\" ind1=\" \" ind2=\" \"><subfield code=\"a\">a   ||||000yy</subfield></datafield><datafield tag=\"106\" ind1=\" \" ind2=\" \"><subfield code=\"a\">r</subfield></datafield><datafield tag=\"181\" ind1=\" \" ind2=\" \"><subfield code=\"6\">z01</subfield><subfield code=\"c\">txt</subfield><subfield code=\"2\">rdacontent</subfield></datafield><datafield tag=\"181\" ind1=\" \" ind2=\"1\"><subfield code=\"6\">z01</subfield><subfield code=\"a\">i#</subfield><subfield code=\"b\">xxxe##</subfield></datafield><datafield tag=\"182\" ind1=\" \" ind2=\" \"><subfield code=\"6\">z01</subfield><subfield code=\"c\">n</subfield><subfield code=\"2\">rdamedia</subfield></datafield><datafield tag=\"182\" ind1=\" \" ind2=\"1\"><subfield code=\"6\">z01</subfield><subfield code=\"a\">n</subfield></datafield><datafield tag=\"183\" ind1=\" \" ind2=\"1\"><subfield code=\"6\">z01</subfield><subfield code=\"a\">nga</subfield><subfield code=\"2\">RDAfrCarrier</subfield></datafield><datafield tag=\"102\" ind1=\" \" ind2=\" \"><subfield code=\"a\">FR</subfield></datafield><datafield tag=\"320\" ind1=\" \" ind2=\" \"><subfield code=\"a\">Notes bibliogr.</subfield></datafield><datafield tag=\"200\" ind1=\"1\" ind2=\" \"><subfield code=\"a\">Yoga senior</subfield><subfield code=\"e\">la méthode de Gasquet</subfield><subfield code=\"f\">Dr Bernadette de Gasquet</subfield><subfield code=\"f\">avec la participation du Dr Marie Thirion</subfield></datafield><datafield tag=\"700\" ind1=\" \" ind2=\"1\"><subfield code=\"3\">084278986</subfield><subfield code=\"a\">Gasquet</subfield><subfield code=\"b\">Bernadette de</subfield><subfield code=\"f\">1946-....</subfield><subfield code=\"4\">070</subfield></datafield><datafield tag=\"702\" ind1=\" \" ind2=\"1\"><subfield code=\"3\">028312635</subfield><subfield code=\"a\">Thirion</subfield><subfield code=\"b\">Marie</subfield><subfield code=\"f\">1944-....</subfield><subfield code=\"c\">pédiatre</subfield><subfield code=\"4\">205</subfield></datafield><datafield tag=\"801\" ind1=\" \" ind2=\"3\"><subfield code=\"a\">FR</subfield><subfield code=\"b\">Abes</subfield><subfield code=\"c\">20210208</subfield><subfield code=\"g\">AFNOR</subfield></datafield><datafield tag=\"214\" ind1=\" \" ind2=\"0\"><subfield code=\"a\">Paris</subfield><subfield code=\"c\">Robert Laffont</subfield><subfield code=\"d\">DL 2019</subfield></datafield><datafield tag=\"215\" ind1=\" \" ind2=\" \"><subfield code=\"a\">1 vol. (250 p.)</subfield><subfield code=\"c\">ill., couv. ill. en coul.</subfield><subfield code=\"d\">22 cm</subfield></datafield><datafield tag=\"225\" ind1=\"0\" ind2=\" \"><subfield code=\"a\">Réponses</subfield></datafield><datafield tag=\"410\" ind1=\" \" ind2=\"|\"><subfield code=\"0\">001026399</subfield><subfield code=\"t\">Réponses (Paris. 1967)</subfield><subfield code=\"x\">0750-7747</subfield></datafield><datafield tag=\"606\" ind1=\" \" ind2=\" \"><subfield code=\"3\">027347893</subfield><subfield code=\"a\">Hatha-yoga</subfield><subfield code=\"2\">rameau</subfield></datafield><datafield tag=\"606\" ind1=\" \" ind2=\" \"><subfield code=\"3\">027425541</subfield><subfield code=\"a\">Exercices physiques pour personnes âgées</subfield><subfield code=\"2\">rameau</subfield></datafield><datafield tag=\"676\" ind1=\" \" ind2=\" \"><subfield code=\"a\">613.710 846</subfield><subfield code=\"v\">23</subfield></datafield><datafield tag=\"686\" ind1=\" \" ind2=\" \"><subfield code=\"a\">610</subfield><subfield code=\"2\">Cadre de classement de la Bibliographie nationale française</subfield></datafield><datafield tag=\"801\" ind1=\" \" ind2=\"0\"><subfield code=\"a\">FR</subfield><subfield code=\"b\">FR-751131015</subfield><subfield code=\"c\">20190529</subfield><subfield code=\"g\">AFNOR</subfield><subfield code=\"2\">intermrc</subfield></datafield><datafield tag=\"330\" ind1=\" \" ind2=\" \"><subfield code=\"a\">La méthode de Gasquet enfin adaptée aux seniors ! Quelle activité physique pratiquer lorsque, à 50 ans, des fragilités corporelles et des douleurs apparaissent ? Comment prendre soin de soi, garder un corps fonctionnel et source de plaisir ? Spécialiste du périnée, professeure de yoga, reconnue et suivie par des médecins, des sages-femmes, des kinésithérapeutes et des coachs sportifs dans le monde entier, Bernadette de Gasquet adapte dans ce livre sa célèbre méthode aux seniors et propose un travail sur le renforcement musculaire, sans recherche de la performance, à travers des exercices simples. Travail corporel sans douleur et sans risque, discipline au service de l\\'être humain, le yoga peut être pratiqué à tout âge. En alternant tonification et détente, renforcements et étirements, en associant respiration et action sur les fonctions vitales, on peut garder un corps en pleine forme. Bernadette de Gasquet reprend ici les bases de l\\'activité physique – postures, respiration, abdominaux – en se concentrant sur les maux des seniors – douleurs articulaires, problèmes de circulation, de constipation, hypertension, troubles respiratoires, rhumatismes... – pour leur donner les clés d\\'une vie plus saine et du bien-être au quotidien. 200 photos, 15 schémas, des exercices filmés... Yoga senior vous propose de nombreux conseils pratiques et des exercices physiques adaptés pour rester en forme après 50 ans</subfield><subfield code=\"2\">éditeur</subfield></datafield></record><|im_end|>',\n",
       "   'role': 'assistant'}]}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "470ff6c9-89c2-4ffc-87f9-c5a5d7cafdd9",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d1a95351-3edf-44d9-9352-1c917fb60f23",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting train dataset to ChatML: 100%|██████████| 173/173 [00:00<00:00, 4952.93 examples/s]\n",
      "Applying chat template to train dataset: 100%|██████████| 173/173 [00:00<00:00, 1766.54 examples/s]\n",
      "Tokenizing train dataset: 100%|██████████| 173/173 [00:02<00:00, 59.88 examples/s]\n",
      "Truncating train dataset: 100%|██████████| 173/173 [00:00<00:00, 12157.81 examples/s]\n",
      "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
     ]
    }
   ],
   "source": [
    "# ---- 3. Define LoRA config ----\n",
    "peft_config = LoraConfig(\n",
    "    r=8,\n",
    "    lora_alpha=32,\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\",\n",
    "    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\"] # may vary based on model, check with `model.named_modules()` in previous cell\n",
    ")\n",
    "\n",
    "# ---- 4. Training args ----\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./sft_lora_unimarc_output\",\n",
    "    per_device_train_batch_size=1,\n",
    "    gradient_accumulation_steps=4,\n",
    "    logging_steps=10,\n",
    "    save_strategy=\"epoch\",\n",
    "    num_train_epochs=30,\n",
    "    learning_rate=5e-5,\n",
    "    fp16=True,\n",
    "    report_to=\"none\"\n",
    ")\n",
    "\n",
    "# ---- 5. Launch training ----\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    train_dataset=dataset,\n",
    "    peft_config=peft_config,\n",
    "    args=training_args\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3bb2add3-b304-4e7b-a368-a5550c3b3749",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1290' max='1290' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1290/1290 56:52, Epoch 29/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>2.000300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1.849600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1.748500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1.629000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.527200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>1.409600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>1.418000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>1.322800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>1.267500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.218000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>1.247400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>1.243700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>1.250800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>1.200200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1.163300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>1.171300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>1.145500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>1.080300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>1.086300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1.051000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>1.126600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>1.146100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>1.059600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>1.096200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>1.070800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.981900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>0.992000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.958800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>0.973700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>1.068000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>0.970900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.988000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>0.953400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>0.921500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>1.007800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>1.011200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>370</td>\n",
       "      <td>0.982400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>0.862100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>390</td>\n",
       "      <td>0.956800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.885200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>410</td>\n",
       "      <td>0.896400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>0.919500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>430</td>\n",
       "      <td>0.940200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>440</td>\n",
       "      <td>0.923300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.889900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>460</td>\n",
       "      <td>0.892100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>470</td>\n",
       "      <td>0.928400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>0.862200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>490</td>\n",
       "      <td>0.858300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.880000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>510</td>\n",
       "      <td>0.908400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>520</td>\n",
       "      <td>0.831600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>530</td>\n",
       "      <td>0.945500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>0.818700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.875700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>560</td>\n",
       "      <td>0.855600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>570</td>\n",
       "      <td>0.852100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>580</td>\n",
       "      <td>0.870300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>590</td>\n",
       "      <td>0.850900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.845600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>610</td>\n",
       "      <td>0.866700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>620</td>\n",
       "      <td>0.819700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>630</td>\n",
       "      <td>0.859000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>640</td>\n",
       "      <td>0.819200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>0.781800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>660</td>\n",
       "      <td>0.863300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>670</td>\n",
       "      <td>0.848700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>680</td>\n",
       "      <td>0.792800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>690</td>\n",
       "      <td>0.848300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.791400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>710</td>\n",
       "      <td>0.775500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>720</td>\n",
       "      <td>0.739000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>730</td>\n",
       "      <td>0.855300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>740</td>\n",
       "      <td>0.797900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>0.818100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>760</td>\n",
       "      <td>0.783000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>770</td>\n",
       "      <td>0.803100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>780</td>\n",
       "      <td>0.783800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>790</td>\n",
       "      <td>0.802300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.768100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>810</td>\n",
       "      <td>0.758600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>820</td>\n",
       "      <td>0.798100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>830</td>\n",
       "      <td>0.778100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>840</td>\n",
       "      <td>0.749500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>0.794300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>860</td>\n",
       "      <td>0.779200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>870</td>\n",
       "      <td>0.773100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>880</td>\n",
       "      <td>0.760300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>890</td>\n",
       "      <td>0.734800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.757800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>910</td>\n",
       "      <td>0.767700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>920</td>\n",
       "      <td>0.760500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>930</td>\n",
       "      <td>0.852700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>940</td>\n",
       "      <td>0.740700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>0.704000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>960</td>\n",
       "      <td>0.736700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>970</td>\n",
       "      <td>0.782100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>980</td>\n",
       "      <td>0.727300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>990</td>\n",
       "      <td>0.729700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.730400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1010</td>\n",
       "      <td>0.795300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1020</td>\n",
       "      <td>0.788000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1030</td>\n",
       "      <td>0.669500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1040</td>\n",
       "      <td>0.723300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1050</td>\n",
       "      <td>0.773200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1060</td>\n",
       "      <td>0.733200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1070</td>\n",
       "      <td>0.693400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1080</td>\n",
       "      <td>0.754200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1090</td>\n",
       "      <td>0.731400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.738100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1110</td>\n",
       "      <td>0.731600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1120</td>\n",
       "      <td>0.731300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1130</td>\n",
       "      <td>0.721900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1140</td>\n",
       "      <td>0.712700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1150</td>\n",
       "      <td>0.788900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1160</td>\n",
       "      <td>0.701100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1170</td>\n",
       "      <td>0.734800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1180</td>\n",
       "      <td>0.727700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1190</td>\n",
       "      <td>0.677900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.728100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1210</td>\n",
       "      <td>0.706600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1220</td>\n",
       "      <td>0.748700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1230</td>\n",
       "      <td>0.711800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1240</td>\n",
       "      <td>0.752400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1250</td>\n",
       "      <td>0.694600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1260</td>\n",
       "      <td>0.684000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1270</td>\n",
       "      <td>0.736700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1280</td>\n",
       "      <td>0.698200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1290</td>\n",
       "      <td>0.661800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1290, training_loss=0.9083033358403879, metrics={'train_runtime': 3415.5117, 'train_samples_per_second': 1.52, 'train_steps_per_second': 0.378, 'total_flos': 1.3800208274030592e+16, 'train_loss': 0.9083033358403879})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8c3fec2-3f4c-4943-a4c8-ebf5748b5ee7",
   "metadata": {},
   "source": [
    "### Save adapter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f2560c8c-7690-4997-853c-05267c844b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b39139f-faae-4f06-aab2-95e9dd960465",
   "metadata": {},
   "source": [
    "### Test inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c9015c0f-00e7-4db5-ad72-074d799928da",
   "metadata": {},
   "outputs": [],
   "source": [
    "peft_model_id = \"./sft_lora_unimarc_output\"\n",
    "tr_model_id = \"Qwen/Qwen3-0.6B\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "087cb0b1-05a5-4809-8661-47e729b94f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(tr_model_id, trust_remote_code=True, torch_dtype=torch.float16,\n",
    "     low_cpu_mem_usage=True,)\n",
    "model = PeftModel.from_pretrained(model, peft_model_id)\n",
    "merged_model = model.merge_and_unload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "59e473ea-7d21-4321-bd3c-ab4f3ca2e8e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_model = merged_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "07c1c517-7cec-4245-a6e8-4b34ec9cd553",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"\n",
    "You are a helpful assistant expert in Unimarc/XML bibliographic records.\n",
    "Used the given structured reasoning to generate Unimarc/XML record.\n",
    "\"\"\"\n",
    "\n",
    "user_prompt = \"\"\"\n",
    "Here's a step-by-step explanation of how the bibliographic metadata maps into the given UNIMARC/XML record:\n",
    "\n",
    "---\n",
    "\n",
    "### Main Title and Subtitle\n",
    "- **Title**: \"Les Jeux olympiques de 1892 à 2024\"  \n",
    "  → `datafield tag=\"200\" ind1=\"1\" ind2=\" \"` subfield `$a`\n",
    "\n",
    "- **Subtitle**: \"une aventure mondiale\"  \n",
    "  → `datafield tag=\"200\" ind1=\"1\" ind2=\" \"` subfield `$e`\n",
    "\n",
    "### Author (Main Entry - Personal Name)\n",
    "- Author: Patrick Clastres  \n",
    "  → `datafield tag=\"200\"` subfield `$f` contains author name \"Patrick Clastres\" (statement of responsibility)\n",
    "\n",
    "- Additional author info: \"Clastres, Patrick (19..-....)\"  \n",
    "  → `datafield tag=\"700\" ind1=\" \" ind2=\"1\"`  \n",
    "    - `$a` = Family Name \"Clastres\"  \n",
    "    - `$b` = Given Name \"Patrick\"  \n",
    "    - `$f` = Dates \"19..-....\"  \n",
    "    - `$4` = Code \"070\" (UNIMARC relator code for author or principal)  \n",
    "    - `$3` = \"080640443\" (possibly a local control number or authority ID)\n",
    "\n",
    "### ISBN, Physical Description and Related Information\n",
    "- ISBN: \"978-2-7535-9645-0 (br.)\"  \n",
    "  → `datafield tag=\"010\"` with subfields:  \n",
    "    - `$a` = ISBN \"978-2-7535-9645-0\"  \n",
    "    - `$b` = Specific edition/type \"br.\" (broché = paperback)  \n",
    "  → `datafield tag=\"073\"` (EAN barcode probably) with subfield `$a` = \"9782753596450\"\n",
    "\n",
    "### Place of Publication, Publisher, and Date\n",
    "- Place: \"Rennes\"  \n",
    "  → `datafield tag=\"214\" ind1=\" \" ind2=\"0\"` subfield `$a`\n",
    "\n",
    "- Publisher: \"Presses universitaires de Rennes\"  \n",
    "  → `datafield tag=\"214\"` subfield `$c`\n",
    "\n",
    "- Date: \"2025 (DL 2025)\"  \n",
    "  → `datafield tag=\"214\"` subfield `$d`\n",
    "\n",
    "### Language and Relevant Codes\n",
    "- Language: French (fre)  \n",
    "  → `datafield tag=\"101\"` subfield `$a` = \"fre\"  \n",
    "  → Also `$2` = \"639-2\" (ISO 639-2)\n",
    "\n",
    "- Country of publication: France (FR)  \n",
    "  → `datafield tag=\"102\"` subfield `$a`\n",
    "\n",
    "### Material Description\n",
    "- \"1 volume (463 pages); color illustrated cover; 24 cm\"  \n",
    "  → `datafield tag=\"215\"`  \n",
    "    - `$a` = \"1 vol. (463 p.)\"  \n",
    "    - `$c` = \"couv. ill. en coul.\" (color illustrated cover)  \n",
    "    - `$d` = \"24 cm\" (physical size)\n",
    "\n",
    "### Collection/Series and ISSN\n",
    "- Collection: Collection \"Histoire\"  \n",
    "  → `datafield tag=\"225\"` subfield `$a`\n",
    "\n",
    "- Series: \"Histoire (Rennes)\" with ISSN 1255-2364  \n",
    "  → `datafield tag=\"410\" ind1=\" \" ind2=\"|\"`  \n",
    "    - `$0` = \"003326195\" (authority or control number for the series)  \n",
    "    - `$t` = \"Histoire (Rennes)\" (series title)  \n",
    "    - `$x` = \"1255-2364\" (ISSN)\n",
    "\n",
    "### Keywords / Subject Headings\n",
    "- Keywords: Olympisme, Jeux olympiques, Histoire  \n",
    "  → `datafield tag=\"606\"` (subject headings from RAMEAU)  \n",
    "    For \"Olympisme\" and \"Jeux olympiques\":  \n",
    "    - `$a` = topical heading: e.g., \"Olympisme\" or \"Jeux olympiques\"  \n",
    "    - `$x` = subdivision: \"Histoire\"  \n",
    "    - `$2` = source of subject headings: \"rameau\"  \n",
    "    - `$3` = local identifier for the subject heading\n",
    "\n",
    "### Classification\n",
    "- Classification number: 796(23a)  \n",
    "  → `datafield tag=\"676\"`  \n",
    "    - `$a` = \"796\" (main class)  \n",
    "    - `$v` = \"23a\" (likely subclass or notation for Olympic Games)\n",
    "\n",
    "### Abstract/Notes\n",
    "- Abstract text (from back cover)  \n",
    "  → `datafield tag=\"330\"`  \n",
    "    - `$a` = the full abstract text  \n",
    "    - `$2` = source of abstract \"4e de couverture\"\n",
    "\n",
    "### Bibliographic References\n",
    "- \"Bibliogr. p. 419-424; includes index\"  \n",
    "  → `datafield tag=\"320\"` subfield `$a`\n",
    "\n",
    "### Control and Identification Fields\n",
    "- Control number (SUDOC): 284189537  \n",
    "  → `controlfield tag=\"001\"`\n",
    "\n",
    "- SUDOC URL as source  \n",
    "  → `controlfield tag=\"003\"` = \"http://www.sudoc.fr/284189537\"\n",
    "\n",
    "- Additional identifier (OCLC number)  \n",
    "  → `datafield tag=\"035\"` subfield `$a` = \"(OCoLC)1513823097\"\n",
    "\n",
    "### Administrative Data\n",
    "- Leader and control fields set for date/time and encoding specifics\n",
    "\n",
    "- `datafield tag=\"801\"` indicating cataloging source  \n",
    "  - `$a` = country code \"FR\"  \n",
    "  - `$b` = agency \"Abes\"  \n",
    "  - `$c` = date of cataloging \"20250424\"  \n",
    "  - `$g` = additional agency \"AFNOR\"\n",
    "\n",
    "---\n",
    "\n",
    "### Summary Table of mappings:\n",
    "\n",
    "| Metadata element                  | UNIMARC Tag | Subfields/Notes                             |\n",
    "|---------------------------------|-------------|--------------------------------------------|\n",
    "| Title                           | 200         | $a                                          |\n",
    "| Subtitle                        | 200         | $e                                          |\n",
    "| Author (statement of resp.)     | 200         | $f                                          |\n",
    "| Author (authorized form)        | 700         | $a family, $b given, $f dates, $4 relator  |\n",
    "| ISBN                           | 010         | $a ISBN, $b edition/type                    |\n",
    "| ISBN Barcode                   | 073         | $a EAN code                                 |\n",
    "| Place of publication           | 214         | $a                                          |\n",
    "| Publisher                     | 214         | $c                                          |\n",
    "| Date of publication           | 214         | $d                                          |\n",
    "| Language                      | 101         | $a iso639-2 code, $2 authority              |\n",
    "| Country                      | 102         | $a                                          |\n",
    "| Physical description          | 215         | $a extent, $c cover, $d size                 |\n",
    "| Collection/Series             | 225         | $a                                          |\n",
    "| Series title and ISSN         | 410         | $0 control number, $t title, $x ISSN        |\n",
    "| Subject headings (RAMEAU)      | 606         | $a topical, $x subdivision, $2 source, $3 ID|\n",
    "| Classification                | 676         | $a main class, $v subdivision                |\n",
    "| Abstract/Notes                | 330         | $a text, $2 source                           |\n",
    "| Bibliographic references       | 320         | $a                                          |\n",
    "| Control number (internal)       | 001         |                                              |\n",
    "| Source URL                    | 003         |                                              |\n",
    "| Identifier (OCLC)              | 035         | $a                                          |\n",
    "| Cataloging agency & date         | 801         | $a country, $b agency, $c date, $g agency   |\n",
    "\n",
    "---\n",
    "\n",
    "This is how the provided metadata has been structured and encoded into UNIMARC in the XML representation. Each data element corresponds to a standard UNIMARC field and subfield, respecting cataloging rules and controlled vocabularies.\n",
    "\"\"\"\n",
    "\n",
    "messages = [\n",
    "  {\"role\": \"system\", \"content\": system_prompt + \" /think\"},\n",
    "  {\"role\": \"user\", \"content\": user_prompt},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b11ac3aa-3983-4e01-8d4e-153cdd95ef60",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer.apply_chat_template(\n",
    "    messages,\n",
    "    return_dict=True,\n",
    "    tokenize = True,\n",
    "    add_generation_prompt = True, # Must add for generation\n",
    "    return_tensors = \"pt\",\n",
    "    enable_thinking=False\n",
    ").to(device)\n",
    "\n",
    "outputs = merged_model.generate(\n",
    "    **inputs,\n",
    "    max_new_tokens = 32768,\n",
    "    use_cache = True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "85b5aac4-7aa2-481b-a5e7-c66ed0b13c56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thinking content: \n",
      "content: Here is the corresponding UNIMARC bibliographic record, mapped from the provided metadata:\n",
      "\n",
      "```xml\n",
      "<Datafield tag=\"200\" ind1=\"1\" ind2=\" \">\n",
      "  <subfield code=\"a\">Les Jeux olympiques de 1892 à 2024</subfield>\n",
      "  <subfield code=\"e\">une aventure mondiale</subfield>\n",
      "</Datafield>\n",
      "\n",
      "<Datafield tag=\"101\" ind1=\" \");\n",
      "  <subfield code=\"a\">fre</subfield>\n",
      "  <subfield code=\"2\">639-2</subfield>\n",
      "</Datafield>\n",
      "\n",
      "<Datafield tag=\"102\" ind1=\" \");\n",
      "  <subfield code=\"a\">FR</subfield>\n",
      "</Datafield>\n",
      "\n",
      "<Datafield tag=\"102\" ind1=\"0\">\n",
      "  <subfield code=\"a\">RFR</subfield>\n",
      "</Datafield>\n",
      "\n",
      "<Datafield tag=\"320\" ind1=\"1\" ind2=\" \">\n",
      "  <subfield code=\"a\">Bibliogr. p. 419-424; includes index</subfield>\n",
      "</Datafield>\n",
      "\n",
      "<Datafield tag=\"410\" ind1=\" \">\n",
      "  <subfield code=\"0\">006751902</subfield>\n",
      "  <subfield code=\"t\">Histoire (Rennes)</subfield>\n",
      "  <subfield code=\"x\">1255-2364</subfield>\n",
      "</Datafield>\n",
      "```\n",
      "\n",
      "---\n",
      "\n",
      "### Key elements mapping:\n",
      "\n",
      "- **Title and Subtitle** → `200$a` and `200$e`\n",
      "- **Language** → `101$a` and `102$a` (French and FR)\n",
      "- **Publisher and Place of Publication** → `214$c`, `214$a`\n",
      "- **Date of Publication** → `214$d`\n",
      "- **Edition and Other Details** → `010$a` (ISBN + edition + price), `073$a` (EAN barcode)\n",
      "- **Country of Publication** → `102$a` (FR)\n",
      "- **Series, Collection, and ISSN** → `225$t`, `410$t`, `410$0`\n",
      "- **Subject Headings** → `606$a` (subjects) and `606$x` (subdivisions)\n",
      "- **Classification and Code** → `676$a` (main class), `676$v` (subclass)\n",
      "- **Abstract and Notes** → `330$a` (full abstract), `320$a` (index info)\n",
      "- **Control Numbers and Authorities** → `001`, `035$a` (internal control number), `801$a` (country, agency, date)\n",
      "- **Language Code and Authority** → `102$a` (ISO 639-2)\n",
      "\n",
      "---\n",
      "\n",
      "### Notes on Record Construction:\n",
      "\n",
      "- The record uses an authority ID (`006751902`) for internal cataloging.\n",
      "- The series name \"Histoire (Rennes)\" is included in `410$t` as a classification.\n",
      "- Subject headings and classification codes are derived from RAMEAU standards.\n",
      "- The language and country are encoded in `101` and `102`.\n",
      "- The control number is encoded in `035` as a source of the catalog.\n",
      "\n",
      "This record is typically generated by an XML cataloger based on:\n",
      "- Title, subtitle\n",
      "- Author statement\n",
      "- ISBN and related info\n",
      "- Series name, ISSN, and place of publication\n",
      "- Language, country of publication\n",
      "- Subject heading and classification codes\n",
      "- Control numbers and authority info\n",
      "- Bibliographic info (index, bibliography notes)\n",
      "\n",
      "Let me know if you want to see how the cataloger would process this particular record from the given bibliographical elements.\n"
     ]
    }
   ],
   "source": [
    "output_ids = outputs[0][len(inputs.input_ids[0]):].tolist()\n",
    "# parsing thinking content\n",
    "try:\n",
    "    # rindex finding 151668 (</think>)\n",
    "    index = len(output_ids) - output_ids[::-1].index(151668)\n",
    "except ValueError:\n",
    "    index = 0\n",
    "\n",
    "thinking_content = tokenizer.decode(output_ids[:index], skip_special_tokens=True).strip(\"\\n\")\n",
    "content = tokenizer.decode(output_ids[index:], skip_special_tokens=True).strip(\"\\n\")\n",
    "\n",
    "print(\"thinking content:\", thinking_content)\n",
    "print(\"content:\", content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bccae09-0f53-47c8-86d5-f3db1f038c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load lora_trace adapter\n",
    "#model_trace = PeftModel.from_pretrained(model, \"./sft_lora_unimarc_output\")\n",
    "#model_trace.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51c22d00-10b7-440e-949d-b0b540cc18e1",
   "metadata": {},
   "source": [
    "##  Merge the Two LoRA Adapters into One Adapter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "4212e953-fc9e-4a7a-b76f-8a78d9c9b921",
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import PeftModel, PeftConfig, get_peft_model, LoraConfig\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bd39bad-6a62-448a-96a6-927557f8ac95",
   "metadata": {},
   "source": [
    "### Reload first model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "192138b1-09d3-4e72-a803-81515bb896db",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"Qwen/Qwen3-0.6B\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    torch_dtype=\"auto\",\n",
    "    device_map=\"auto\",\n",
    "    #attn_implementation=\"flash_attention_2\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "ec4efa56-9a94-4df1-b362-8fe99dd769b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Qwen3ForCausalLM(\n",
       "  (model): Qwen3Model(\n",
       "    (embed_tokens): Embedding(151936, 1024)\n",
       "    (layers): ModuleList(\n",
       "      (0-27): 28 x Qwen3DecoderLayer(\n",
       "        (self_attn): Qwen3Attention(\n",
       "          (q_proj): Linear(in_features=1024, out_features=2048, bias=False)\n",
       "          (k_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (v_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (o_proj): Linear(in_features=2048, out_features=1024, bias=False)\n",
       "          (q_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
       "          (k_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
       "        )\n",
       "        (mlp): Qwen3MLP(\n",
       "          (gate_proj): Linear(in_features=1024, out_features=3072, bias=False)\n",
       "          (up_proj): Linear(in_features=1024, out_features=3072, bias=False)\n",
       "          (down_proj): Linear(in_features=3072, out_features=1024, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): Qwen3RMSNorm((1024,), eps=1e-06)\n",
       "        (post_attention_layernorm): Qwen3RMSNorm((1024,), eps=1e-06)\n",
       "      )\n",
       "    )\n",
       "    (norm): Qwen3RMSNorm((1024,), eps=1e-06)\n",
       "    (rotary_emb): Qwen3RotaryEmbedding()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=1024, out_features=151936, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"cuda\" # for GPU usage or \"cpu\" for CPU usage\n",
    "model = model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "810ca108-f513-4344-84ed-d1cbf34bdcc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !Important\n",
    "tokenizer.padding_side = \"right\"\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "b27c6b01-dc17-4e29-a0b6-f875861d1dec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thinking content: <think>\n",
      "Okay, the user asked for a short introduction to a large language model. Let me start by recalling what I know about LLMs. They are big language models, right? So I should mention their ability to understand and generate text, which is their main function.\n",
      "\n",
      "I need to keep it concise. Maybe start with \"Large language models (LLMs)\" and then explain their capabilities. Since they can understand and generate text, that's a key point. Also, their use cases like writing, answering questions, etc. \n",
      "\n",
      "Wait, should I mention something about training data? Oh yes, LLMs are trained on vast amounts of text, which allows them to learn from a wide range of information. That adds value. \n",
      "\n",
      "I should make sure the introduction flows well and covers the main points without getting too technical. Let me check if there's anything else I need to include. Maybe mention how they are used in various applications, like customer service or creative writing. \n",
      "\n",
      "No, the user just wants a short intro. Keep it to a couple of sentences. Alright, time to put it all together.\n",
      "</think>\n",
      "content: A large language model (LLM) is a type of artificial intelligence designed to understand and generate human language. They can comprehend text, answer questions, and create creative content by learning from vast amounts of data. LLMs are used in various applications, from writing to customer service, enabling them to process and respond to complex queries effectively.\n"
     ]
    }
   ],
   "source": [
    "# Little test\n",
    "messages = [\n",
    "  {\"role\": \"system\", \"content\": \"You are a helpful assistant\"},\n",
    "  {\"role\": \"user\", \"content\": \"Give me a short introduction to large language model.\"},\n",
    "]\n",
    "\n",
    "inputs = tokenizer.apply_chat_template(\n",
    "    messages,\n",
    "    return_dict=True,\n",
    "    tokenize = True,\n",
    "    add_generation_prompt = True, # Must add for generation\n",
    "    return_tensors = \"pt\",\n",
    "    enable_thinking=True\n",
    ").to(device)\n",
    "\n",
    "outputs = model.generate(\n",
    "    **inputs,\n",
    "    max_new_tokens = 32768,\n",
    "    use_cache = True,\n",
    ")\n",
    "\n",
    "output_ids = outputs[0][len(inputs.input_ids[0]):].tolist()\n",
    "# parsing thinking content\n",
    "try:\n",
    "    # rindex finding 151668 (</think>)\n",
    "    index = len(output_ids) - output_ids[::-1].index(151668)\n",
    "except ValueError:\n",
    "    index = 0\n",
    "\n",
    "thinking_content = tokenizer.decode(output_ids[:index], skip_special_tokens=True).strip(\"\\n\")\n",
    "content = tokenizer.decode(output_ids[index:], skip_special_tokens=True).strip(\"\\n\")\n",
    "\n",
    "print(\"thinking content:\", thinking_content)\n",
    "print(\"content:\", content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc32b6a2-dffb-489b-bf51-0081cbdb92be",
   "metadata": {},
   "source": [
    "### Merging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "529ad193-e3d1-4eb0-8880-7b6cbdc209c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the first adapter\n",
    "model = PeftModel.from_pretrained(base_model, \"./sft_lora_trace\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "2869dbc1-f070-4311-9814-89963eb81ebf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the second adapter (into the same PeftModel)\n",
    "model.load_adapter(\"./sft_lora_unimarc_output\", adapter_name=\"adapter2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "d2e4683e-482c-4bfb-8f70-3fe0cc2e52fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_model = model.merge_and_unload()  # This returns a base model with merged LoRA weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "e1aa6bd3-32b4-49ba-b50d-20c2944c9d60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Qwen3Config {\n",
      "  \"architectures\": [\n",
      "    \"Qwen3ForCausalLM\"\n",
      "  ],\n",
      "  \"attention_bias\": false,\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 151643,\n",
      "  \"eos_token_id\": 151645,\n",
      "  \"head_dim\": 128,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 1024,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"max_position_embeddings\": 40960,\n",
      "  \"max_window_layers\": 28,\n",
      "  \"model_type\": \"qwen3\",\n",
      "  \"num_attention_heads\": 16,\n",
      "  \"num_hidden_layers\": 28,\n",
      "  \"num_key_value_heads\": 8,\n",
      "  \"rms_norm_eps\": 1e-06,\n",
      "  \"rope_scaling\": null,\n",
      "  \"rope_theta\": 1000000,\n",
      "  \"sliding_window\": null,\n",
      "  \"tie_word_embeddings\": true,\n",
      "  \"torch_dtype\": \"bfloat16\",\n",
      "  \"transformers_version\": \"4.51.3\",\n",
      "  \"use_cache\": true,\n",
      "  \"use_sliding_window\": false,\n",
      "  \"vocab_size\": 151936\n",
      "}\n",
      "\n",
      "model\n",
      "<class 'transformers.models.qwen3.modeling_qwen3.Qwen3ForCausalLM'>\n"
     ]
    }
   ],
   "source": [
    "print(merged_model.config)\n",
    "print(merged_model.base_model_prefix)\n",
    "print(merged_model.__class__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31ef70d4-4a97-4c76-a85e-5201df24d323",
   "metadata": {},
   "source": [
    "### Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "3b05b047-80dd-48ba-b901-44b4574144f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./final_qwen3_unimarc_model/tokenizer_config.json',\n",
       " './final_qwen3_unimarc_model/special_tokens_map.json',\n",
       " './final_qwen3_unimarc_model/vocab.json',\n",
       " './final_qwen3_unimarc_model/merges.txt',\n",
       " './final_qwen3_unimarc_model/added_tokens.json',\n",
       " './final_qwen3_unimarc_model/tokenizer.json')"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the fully merged model (final model: Metadata → XML directly)\n",
    "merged_model.save_pretrained(\"./final_qwen3_unimarc_model\")\n",
    "tokenizer.save_pretrained(\"./final_qwen3_unimarc_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "a2ef651c-7d89-4939-b164-5054d124965b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "model.safetensors: 100%|██████████| 1.19G/1.19G [00:40<00:00, 29.2MB/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/Geraldine/Qwen3-0.6B-finetuned-unimarc-reasoning/commit/3b995572149c1ea0f73beb9f2eaae54d08b2401b', commit_message='Upload Qwen3ForCausalLM', commit_description='', oid='3b995572149c1ea0f73beb9f2eaae54d08b2401b', pr_url=None, repo_url=RepoUrl('https://huggingface.co/Geraldine/Qwen3-0.6B-finetuned-unimarc-reasoning', endpoint='https://huggingface.co', repo_type='model', repo_id='Geraldine/Qwen3-0.6B-finetuned-unimarc-reasoning'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_model.push_to_hub(f\"Geraldine/Qwen3-0.6B-finetuned-unimarc-reasoning\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "7e1e03bd-e4bb-44a1-9577-f834d5c1dc9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tokenizer.json: 100%|██████████| 11.4M/11.4M [00:00<00:00, 12.3MB/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/Geraldine/Qwen3-0.6B-finetuned-unimarc-reasoning/commit/7e2cef8370c43dec36a3bf4e4ac49d0f9eed6db2', commit_message='Upload tokenizer', commit_description='', oid='7e2cef8370c43dec36a3bf4e4ac49d0f9eed6db2', pr_url=None, repo_url=RepoUrl('https://huggingface.co/Geraldine/Qwen3-0.6B-finetuned-unimarc-reasoning', endpoint='https://huggingface.co', repo_type='model', repo_id='Geraldine/Qwen3-0.6B-finetuned-unimarc-reasoning'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.push_to_hub(f\"Geraldine/Qwen3-0.6B-finetuned-unimarc-reasoning\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72372564-0a26-49ab-8293-3c11c88fa9aa",
   "metadata": {},
   "source": [
    "## Test inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "c75be792-f7ba-437d-a5bf-84607e7d32c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_model = merged_model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1fdbf59-f6a6-4d5c-80cf-a389a7a38474",
   "metadata": {},
   "source": [
    "or"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b405cd22-c3be-42f5-86ca-f2fa3148576f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"Geraldine/Qwen3-0.6B-finetuned-unimarc-reasoning\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "merged_model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    torch_dtype=\"auto\",\n",
    "    device_map=\"auto\",\n",
    "    #attn_implementation=\"flash_attention_2\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e68cd63a-04c0-4b8f-8567-47b29da93114",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" # for GPU usage or \"cpu\" for CPU usage\n",
    "merged_model = merged_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a4388a87-20a5-430a-bae1-aa4ec9847e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.padding_side = \"right\"\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "578e75aa-28a3-466c-b44b-00bafe956aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# simple test\n",
    "messages = [\n",
    "  {\"role\": \"system\", \"content\": \"You are a helpful assistant\"},\n",
    "  {\"role\": \"user\", \"content\": \"Give me a short introduction to large language model.\"},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1a4882ae-6ea1-4154-803d-efcc71abc1f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"\n",
    "You are an expert in Unimarc/XML generation from bibliographic metadata.\n",
    "\"\"\"\n",
    "\n",
    "user_prompt = \"\"\"\n",
    "Here are the metadata:\n",
    "# Bibliographical metadata\n",
    "Title: Technopolitique\n",
    "Subtitle: Comment la technologie fait de nous des soldats\n",
    "Author: Asma Mhalla\n",
    "Publisher: Éditions du Seuil\n",
    "Year: 2024\n",
    "ISBN: 978-2-0215-4854-9\n",
    "Language: French\n",
    "Collection/Series: N/A\n",
    "Edition: N/A\n",
    "Material description: 1 volume (275 pages), couverture illustrée, 21 cm\n",
    "Abstract/Notes: Intelligence artificielle, réseaux sociaux, implants cérébraux, satellites, métavers… Le choc technologique sera l’un des enjeux clés du XXIe siècle et les géants américains, les « BigTech », sont à l’avant-garde. Entités hybrides, ils remodèlent la morphologie des États, redéfinissent les jeux de pouvoir et de puissance entre nations, interviennent dans la guerre, tracent les nouvelles frontières de la souveraineté. S’ils sont au cœur de la fabrique de la puissance étatsunienne face à la Chine, ils sont également des agents perturbateurs de la démocratie. De ces liens ambivalents entre BigTech et « BigState » est né un nouveau Léviathan à deux têtes, animé par un désir de puissance hors limites. Mais qui gouverne ces nouveaux acteurs privés de la prolifération technologique ? A cette vertigineuse question, nous n’avons d’autre choix que d’opposer l’innovation politique ! S’attaquant à tous les faux débats qui nous font manquer l’essentiel, Asma Mhalla ose ainsi une thèse forte et perturbante : les technologies de l’hypervitesse, à la fois civiles et militaires, font de chacun d’entre nous, qu’on le veuille ou non, des soldats. Nos cerveaux sont devenus l’ultime champ de bataille. Il est urgent de le penser car ce n’est rien de moins que le nouvel ordre mondial qui est en jeu, mais aussi la démocratie.\n",
    "Source of the abstract/notes: 4e de couverture\n",
    "Table of contents:\n",
    "- Introduction\n",
    "- Chapitre 1. Le siècle de la Technologie Totale\n",
    "- Chapitre 2. Le Triptyque des Bigtech\n",
    "- Chapitre 3. L'intelligence artificielle au cœur des batailles culturelles et idéologiques de la vallée\n",
    "- Chapitre 4. Aux confins des réseaux sociaux\n",
    "- Chapitre 5. De la guerre cognitive en démocratie\n",
    "- Chapitre 6. Puissance n'est pas (toujours) pouvoir\n",
    "- Chapitre 7. La militarisation du monde\n",
    "- Chapitre 8. Le spectre de l'hyperguerre\n",
    "- Chapitre 9. Naissance du complexe techno-militaire américain ?\n",
    "- Chapitre 10. La doctrine de l'information totale\n",
    "- Chapitre 11. Odyssée vers le futur\n",
    "- Conclusion. Entrer dans le nouveau siècle politique\n",
    "Keywords: Société numérique, Technologies de l'information et de la communication, Humanité, Science politique, Relations internationales, Société, Effets des innovations technologiques\n",
    "\"\"\"\n",
    "\n",
    "messages = [\n",
    "  {\"role\": \"system\", \"content\": system_prompt},\n",
    "  {\"role\": \"user\", \"content\": user_prompt},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b381a46b-e8d4-4614-984b-d27fb951f93f",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer.apply_chat_template(\n",
    "    messages,\n",
    "    return_dict=True,\n",
    "    tokenize = True,\n",
    "    add_generation_prompt = True, # Must add for generation\n",
    "    return_tensors = \"pt\",\n",
    "    enable_thinking=True\n",
    ").to(device)\n",
    "\n",
    "outputs = merged_model.generate(\n",
    "    **inputs,\n",
    "    max_new_tokens = 32768,\n",
    "    use_cache = True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "845743fc-e35f-4b16-b425-1d5f35b82059",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thinking content: <think>\n",
      "Okay, let's look at the bibliographic metadata for the book \"Technopolitique\" by Asma Mhalla. The user wants the 2024 Unimarc/XML representation of this book's metadata.\n",
      "\n",
      "First, the author is Asma Mhalla, and the publication is Éditions du Seuil, 2024. The ISBN is 978-2-0215-4854-9. The language is French. The collection is not specified, but the main subject field includes \"Société numérique\", \"Technologies de l'information et de la communication\", \"Humanité\", and \"Science politique\". The subject headings also mention international relations, social sciences, and technological effects.\n",
      "\n",
      "The physical description indicates one volume of 275 pages with an illustrated cover. The abstract/notes is a full text summary from the back cover. The edition is not specified further. \n",
      "\n",
      "No other authors or contributors are present. The format and content fields are all present, and the data is correctly structured according to the Unimarc XML standards. The subject headings are in the correct RAMEAU language code. The metadata is comprehensive and correctly captures all relevant information related to the book. No errors or missing fields are present. This confirms that the book is a well-documented and informative work on technological influence on politics and society.\n",
      "</think>\n",
      "content: <file><ref><title>Technopolitique</title><author>Asma Mhalla</author><publisher>Éditions du Seuil</publisher><year>2024</year><isbn>978-2-0215-4854-9</language>fre</language><physical_description>1 volume (275 pages), couverture illustrée</physical_description><subjects><symbol>RAMEAU</symbol> Société numérique, Technologies de l'information et de la communication, Humanité, Science politique, Relations internationales, Société, Effets des innovations technologiques</subjects><collection>Non spécifié</collection><date>2024</date></file>\n"
     ]
    }
   ],
   "source": [
    "output_ids = outputs[0][len(inputs.input_ids[0]):].tolist()\n",
    "# parsing thinking content\n",
    "try:\n",
    "    # rindex finding 151668 (</think>)\n",
    "    index = len(output_ids) - output_ids[::-1].index(151668)\n",
    "except ValueError:\n",
    "    index = 0\n",
    "\n",
    "thinking_content = tokenizer.decode(output_ids[:index], skip_special_tokens=True).strip(\"\\n\")\n",
    "content = tokenizer.decode(output_ids[index:], skip_special_tokens=True).strip(\"\\n\")\n",
    "\n",
    "print(\"thinking content:\", thinking_content)\n",
    "print(\"content:\", content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d8020ee-4889-4a3c-a278-606944f25880",
   "metadata": {},
   "source": [
    "# Reward functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f6c955c-550b-412b-9723-6f7729a04cef",
   "metadata": {},
   "source": [
    "## utils functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7d53cc64-58bc-457a-8aa8-4729e5934045",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "import re\n",
    "\n",
    "def extract_hash_answer(text: str) -> str | None:\n",
    "    # Use model response structure to find the XML part\n",
    "    if \"</think>\" not in text:\n",
    "        return text\n",
    "    return text.split(\"</think>\")[1].strip()\n",
    "\n",
    "def extract_xml(text: str) -> str | None:\n",
    "    # Use regular expression to find the XML part enclosed in ```xml...```\n",
    "    xml_match = re.search(r'```xml(.*?)```', response, re.DOTALL)\n",
    "    if xml_match:\n",
    "        return xml_match.group(1).strip()\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def extract_field_values(xml_str):\n",
    "    root = ET.fromstring(xml_str)\n",
    "    fields = {}\n",
    "    for df in root.findall(\".//datafield\"):\n",
    "        tag = df.get(\"tag\")\n",
    "        subfields = [sf.text for sf in df.findall(\"subfield\")]\n",
    "        fields[tag] = \" \".join(subfields)\n",
    "    return fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2f9a80c6-e6a3-454f-b411-265079c766d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<think>\n",
      "Okay, I need to generate the Unimarc/XML record from the provided metadata. Let me start by recalling the structure of the Unimarc record. The fields are usually titled as follows:\n",
      "\n",
      "- Title (title field)\n",
      "- Author (author field)\n",
      "- Publisher (publisher)\n",
      "- Year (year)\n",
      "- ISBN (isbn field)\n",
      "- Collection/Series (collection)\n",
      "- Material description (material description)\n",
      "- Abstract/Notes (abstract/notes)\n",
      "\n",
      "The user provided the title, author, publisher, year, ISBN, collection, material description, and keywords. Also, the source of the abstract/notes is mentioned as 4e de couverture, which is a note about the cover page.\n",
      "\n",
      "I need to check the exact numbering of the fields. The Unimarc record typically has 13 fields, but sometimes the order can be different. Let me confirm:\n",
      "\n",
      "- 1: Title (title)\n",
      "- 2: Author (author)\n",
      "- 3: Publisher (publisher)\n",
      "- 4: Year (year)\n",
      "- 5: ISBN (isbn)\n",
      "- 6: Collection/Series (collection)\n",
      "- 7: Material description (material)\n",
      "- 8: Abstract/Notes (abstract/notes)\n",
      "- 9: Keywords (keyword)\n",
      "- 10: Source of abstract/notes (source)\n",
      "- 11: Notes on the source (note)\n",
      "- 12: Notes on the source (another note)\n",
      "- 13: Notes on the source (third note)\n",
      "\n",
      "Wait, the user's provided abstract/notes are already part of the source field. So the 10th and 11th fields would be the source and note. But the user mentioned \"Source of the abstract/notes: 4e de couverture\" which is a note. So the 10th field is the source, and the 11th is the note. However, the original data has the source as the 4th field. So the structure is:\n",
      "\n",
      "1: Title\n",
      "2: Author\n",
      "3: Publisher\n",
      "4: Year\n",
      "5: ISBN\n",
      "6: Collection/Series\n",
      "7: Material description\n",
      "8: Abstract/Notes (source)\n",
      "9: Keywords\n",
      "10: Source of abstract/notes\n",
      "11: Notes on the source\n",
      "12: Notes on the source\n",
      "13: Notes on the source\n",
      "\n",
      "But the user's data shows that the source is already in the abstract/notes field. So maybe the 8th and 10th fields are the source and note. Let me check again.\n",
      "\n",
      "The original data provided by the user includes:\n",
      "\n",
      "- Source of abstract/notes: 4e de couverture\n",
      "- Notes: (not provided in the original data, just the 4e)\n",
      "\n",
      "So the Unimarc fields would be:\n",
      "\n",
      "1: Title: Electric vehicle tribology\n",
      "2: Author: Leonardo I. Farfan-Cabrera, Ali Erdemir\n",
      "3: Publisher: Elsevier\n",
      "4: Year: 2024\n",
      "5: ISBN: 978-0-443-14074-7\n",
      "6: Collection/Series: Elsevier Series on Tribology and Surface Engineering\n",
      "7: Material description: 1 vol. (XI-313 p.), couv. ill., 23 cm\n",
      "8: Abstract/Notes: 4e de couverture\n",
      "9: Keywords: Tribologie (technologie)\n",
      "10: Source of abstract/notes: 4e de couverture\n",
      "11: Notes on the source: couv. ill.\n",
      "12: Notes on the source: 23 cm\n",
      "13: Notes on the source: 4e de couverture\n",
      "\n",
      "Wait, but the original data doesn't have the 11th and 12th fields. The user only provided the 4th and 8th fields. Maybe there are more notes. The user's input includes:\n",
      "\n",
      "- \"Source of the abstract/notes: 4e de couverture\" (so 4e is the source)\n",
      "- \"Notes: Not specified\" (but the 4e is the source)\n",
      "\n",
      "So the 10th field is the source, and the 11th and 12th are the note fields. But the original data only includes 4e and couv. ill. So perhaps the 10th field is the source, and the 11th is the note. The user might have made a typo, but I'll follow the given data.\n",
      "\n",
      "Now, putting it all together into the Unimarc/XML format. The fields are as follows:\n",
      "\n",
      "- Title: Electric vehicle tribology\n",
      "- Author: Leonardo I. Farfan-Cabrera, Ali Erdemir\n",
      "- Publisher: Elsevier\n",
      "- Year: 2024\n",
      "- ISBN: 978-0-443-14074-7\n",
      "- Collection/Series: Elsevier Series on Tribology and Surface Engineering\n",
      "- Material description: 1 vol. (XI-313 p.), couv. ill., 23 cm\n",
      "- Abstract/Notes: 4e de couverture\n",
      "- Keywords: Tribologie (technologie)\n",
      "\n",
      "The source of the abstract/notes is in the 4th field, and the notes are in the 8th field.\n",
      "\n",
      "I think that's all. Now, I need to format this into the Unimarc record. Let me check the exact codes again. The Unimarc fields for the record would be as follows:\n",
      "\n",
      "1. Title: [Electric vehicle tribology]\n",
      "2. Author: [Leonardo I. Farfan-Cabrera, Ali Erdemir]\n",
      "3. Publisher: Elsevier\n",
      "4. Year: 2024\n",
      "5. ISBN: 978-0-443-14074-7\n",
      "6. Collection/Series: Elsevier Series on Tribology and Surface Engineering\n",
      "7. Material description: 1 vol. (XI-313 p.), couv. ill., 23 cm\n",
      "8. Abstract/Notes: 4e de couverture\n",
      "9. Keywords: Tribologie (technologie)\n",
      "10. Source of abstract/notes: 4e de couverture\n",
      "11. Notes on the source: couv. ill.\n",
      "12. Notes on the source: 23 cm\n",
      "13. Notes on the source: 4e de couverture\n",
      "\n",
      "Yes, that's correct. Now, I need to present this in the required Unimarc/XML format, making sure the numbers are correctly placed and the fields are properly labeled.\n",
      "</think>\n",
      "\n",
      "```xml\n",
      "<record><controlfield tag=\"005\">20250212153703.000</controlfield><datafield tag=\"035\" ind1=\" \" ind2=\" \"><subfield code=\"a\">(text)</subfield><subfield code=\"b\">Electric vehicle tribology</subfield><subfield code=\"b\">2024</subfield></datafield><datafield tag=\"033\" ind1=\" \" ind2=\" \"><subfield code=\"a\">978-0-443-14074-7</subfield><subfield code=\"b\">isbn</subfield></datafield><datafield tag=\"100\" ind1=\" \" ind2=\" \"><subfield code=\"a\">A</subfield><subfield code=\"2\">Leonardo I. Farfan-Cabrera</subfield><subfield code=\"2\">Ali Erdemir</subfield></datafield><datafield tag=\"101\" ind1=\"0\" ind2=\" \"><subfield code=\"a\">X</subfield><subfield code=\"2\">2024</subfield></datafield><datafield tag=\"101\" ind1=\"0\" ind2=\" \"><subfield code=\"a\">Y</subfield><subfield code=\"2\">4</subfield></datafield><datafield tag=\"105\" ind1=\" \" ind2=\" \"><subfield code=\"a\">4e</subfield><subfield code=\"2\">de couv.</subfield></datafield><datafield tag=\"106\" ind1=\" \" ind2=\" \"><subfield code=\"a\">23 cm</subfield></datafield><datafield tag=\"180\" ind1=\" \" ind2=\" \"><subfield code=\"a\">1</subfield><subfield code=\"2\">XI</subfield><subfield code=\"2\">313</subfield></datafield><datafield tag=\"181\" ind1=\" \" ind2=\" \"><subfield code=\"a\">313</subfield></datafield><datafield tag=\"181\" ind1=\" \" ind2=\" \"><subfield code=\"a\">couv</subfield></datafield><datafield tag=\"181\" ind1=\" \" ind2=\" \"><subfield code=\"a\">ill.</subfield></datafield><datafield tag=\"185\" ind1=\" \" ind2=\" \"><subfield code=\"a\">23 cm</subfield></datafield><datafield tag=\"185\" ind1=\" \" ind2=\" \"><subfield code=\"a\">23 cm</subfield></datafield><datafield tag=\"191\" ind1=\" \" ind2=\" \"><subfield code=\"a\">2</subfield><subfield code=\"2\">4</subfield></datafield><datafield tag=\"191\" ind1=\" \" ind2=\" \"><subfield code=\"a\">4e</subfield><subfield code=\"2\">de</subfield></datafield><datafield tag=\"191\" ind1=\" \" ind2=\" \"><subfield code=\"a\">23 cm</subfield></datafield><datafield tag=\"191\" ind1=\" \" ind2=\" \"><subfield code=\"a\">4e</subfield></datafield><datafield tag=\"200\" ind1=\" \" ind2=\" \"><subfield code=\"a\">R</subfield><subfield code=\"2\">2</subfield></datafield><datafield tag=\"205\" ind1=\" \" ind2=\" \"><subfield code=\"a\">4e</subfield></datafield><datafield tag=\"205\" ind1=\" \" ind2=\" \"><subfield code=\"a\">de</subfield></datafield><datafield tag=\"205\" ind1=\" \" ind2=\" \"><subfield code=\"a\">23 cm</subfield></datafield></record>\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "# Example avec le résultat du test d'inférence sur le merged_model\n",
    "response = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5f9cf5c4-2f15-46c4-b8f1-ae2a497b8e82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```xml\n",
      "<record><controlfield tag=\"005\">20250212153703.000</controlfield><datafield tag=\"035\" ind1=\" \" ind2=\" \"><subfield code=\"a\">(text)</subfield><subfield code=\"b\">Electric vehicle tribology</subfield><subfield code=\"b\">2024</subfield></datafield><datafield tag=\"033\" ind1=\" \" ind2=\" \"><subfield code=\"a\">978-0-443-14074-7</subfield><subfield code=\"b\">isbn</subfield></datafield><datafield tag=\"100\" ind1=\" \" ind2=\" \"><subfield code=\"a\">A</subfield><subfield code=\"2\">Leonardo I. Farfan-Cabrera</subfield><subfield code=\"2\">Ali Erdemir</subfield></datafield><datafield tag=\"101\" ind1=\"0\" ind2=\" \"><subfield code=\"a\">X</subfield><subfield code=\"2\">2024</subfield></datafield><datafield tag=\"101\" ind1=\"0\" ind2=\" \"><subfield code=\"a\">Y</subfield><subfield code=\"2\">4</subfield></datafield><datafield tag=\"105\" ind1=\" \" ind2=\" \"><subfield code=\"a\">4e</subfield><subfield code=\"2\">de couv.</subfield></datafield><datafield tag=\"106\" ind1=\" \" ind2=\" \"><subfield code=\"a\">23 cm</subfield></datafield><datafield tag=\"180\" ind1=\" \" ind2=\" \"><subfield code=\"a\">1</subfield><subfield code=\"2\">XI</subfield><subfield code=\"2\">313</subfield></datafield><datafield tag=\"181\" ind1=\" \" ind2=\" \"><subfield code=\"a\">313</subfield></datafield><datafield tag=\"181\" ind1=\" \" ind2=\" \"><subfield code=\"a\">couv</subfield></datafield><datafield tag=\"181\" ind1=\" \" ind2=\" \"><subfield code=\"a\">ill.</subfield></datafield><datafield tag=\"185\" ind1=\" \" ind2=\" \"><subfield code=\"a\">23 cm</subfield></datafield><datafield tag=\"185\" ind1=\" \" ind2=\" \"><subfield code=\"a\">23 cm</subfield></datafield><datafield tag=\"191\" ind1=\" \" ind2=\" \"><subfield code=\"a\">2</subfield><subfield code=\"2\">4</subfield></datafield><datafield tag=\"191\" ind1=\" \" ind2=\" \"><subfield code=\"a\">4e</subfield><subfield code=\"2\">de</subfield></datafield><datafield tag=\"191\" ind1=\" \" ind2=\" \"><subfield code=\"a\">23 cm</subfield></datafield><datafield tag=\"191\" ind1=\" \" ind2=\" \"><subfield code=\"a\">4e</subfield></datafield><datafield tag=\"200\" ind1=\" \" ind2=\" \"><subfield code=\"a\">R</subfield><subfield code=\"2\">2</subfield></datafield><datafield tag=\"205\" ind1=\" \" ind2=\" \"><subfield code=\"a\">4e</subfield></datafield><datafield tag=\"205\" ind1=\" \" ind2=\" \"><subfield code=\"a\">de</subfield></datafield><datafield tag=\"205\" ind1=\" \" ind2=\" \"><subfield code=\"a\">23 cm</subfield></datafield></record>\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "print(extract_hash_answer(text=response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ff7bf179-7fa4-48c0-8c78-b06dcf90e38b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<record><controlfield tag=\"005\">20250212153703.000</controlfield><datafield tag=\"035\" ind1=\" \" ind2=\" \"><subfield code=\"a\">(text)</subfield><subfield code=\"b\">Electric vehicle tribology</subfield><subfield code=\"b\">2024</subfield></datafield><datafield tag=\"033\" ind1=\" \" ind2=\" \"><subfield code=\"a\">978-0-443-14074-7</subfield><subfield code=\"b\">isbn</subfield></datafield><datafield tag=\"100\" ind1=\" \" ind2=\" \"><subfield code=\"a\">A</subfield><subfield code=\"2\">Leonardo I. Farfan-Cabrera</subfield><subfield code=\"2\">Ali Erdemir</subfield></datafield><datafield tag=\"101\" ind1=\"0\" ind2=\" \"><subfield code=\"a\">X</subfield><subfield code=\"2\">2024</subfield></datafield><datafield tag=\"101\" ind1=\"0\" ind2=\" \"><subfield code=\"a\">Y</subfield><subfield code=\"2\">4</subfield></datafield><datafield tag=\"105\" ind1=\" \" ind2=\" \"><subfield code=\"a\">4e</subfield><subfield code=\"2\">de couv.</subfield></datafield><datafield tag=\"106\" ind1=\" \" ind2=\" \"><subfield code=\"a\">23 cm</subfield></datafield><datafield tag=\"180\" ind1=\" \" ind2=\" \"><subfield code=\"a\">1</subfield><subfield code=\"2\">XI</subfield><subfield code=\"2\">313</subfield></datafield><datafield tag=\"181\" ind1=\" \" ind2=\" \"><subfield code=\"a\">313</subfield></datafield><datafield tag=\"181\" ind1=\" \" ind2=\" \"><subfield code=\"a\">couv</subfield></datafield><datafield tag=\"181\" ind1=\" \" ind2=\" \"><subfield code=\"a\">ill.</subfield></datafield><datafield tag=\"185\" ind1=\" \" ind2=\" \"><subfield code=\"a\">23 cm</subfield></datafield><datafield tag=\"185\" ind1=\" \" ind2=\" \"><subfield code=\"a\">23 cm</subfield></datafield><datafield tag=\"191\" ind1=\" \" ind2=\" \"><subfield code=\"a\">2</subfield><subfield code=\"2\">4</subfield></datafield><datafield tag=\"191\" ind1=\" \" ind2=\" \"><subfield code=\"a\">4e</subfield><subfield code=\"2\">de</subfield></datafield><datafield tag=\"191\" ind1=\" \" ind2=\" \"><subfield code=\"a\">23 cm</subfield></datafield><datafield tag=\"191\" ind1=\" \" ind2=\" \"><subfield code=\"a\">4e</subfield></datafield><datafield tag=\"200\" ind1=\" \" ind2=\" \"><subfield code=\"a\">R</subfield><subfield code=\"2\">2</subfield></datafield><datafield tag=\"205\" ind1=\" \" ind2=\" \"><subfield code=\"a\">4e</subfield></datafield><datafield tag=\"205\" ind1=\" \" ind2=\" \"><subfield code=\"a\">de</subfield></datafield><datafield tag=\"205\" ind1=\" \" ind2=\" \"><subfield code=\"a\">23 cm</subfield></datafield></record>\n"
     ]
    }
   ],
   "source": [
    "print(extract_xml(text=response))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5e0c0ec-44c7-4f19-8055-f760b4627cf0",
   "metadata": {},
   "source": [
    "## Format-based reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2bcd0252-36d8-4281-8ad3-b7081cf1b1d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_reward(xml_output: str) -> float:\n",
    "    try:\n",
    "        root = ET.fromstring(xml_output)\n",
    "    except ET.ParseError:\n",
    "        return 0.0  # Not even valid XML\n",
    "\n",
    "    required_tags = [\"leader\", \"controlfield\", \"datafield\"]\n",
    "    has_required_tags = all(root.find(f\".//{tag}\") is not None for tag in required_tags)\n",
    "\n",
    "    if not has_required_tags:\n",
    "        return 0.3  # Barely structured but not fully compliant\n",
    "\n",
    "    # Optionally: integrate XSD/Schematron validation here\n",
    "    return 1.0  # Well-formed and conforms to expected structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0e9a09fc-3630-42bc-a6dc-2776b54e7239",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3\n"
     ]
    }
   ],
   "source": [
    "xml_answer = extract_xml(text=response)\n",
    "print(format_reward(xml_output=xml_answer))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6a96315-00f0-4ca5-b286-710546be8425",
   "metadata": {},
   "source": [
    "## Accuracy-based reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c94bbef0-8539-47c6-96ac-2df18b8a54d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "xml_answer = extract_xml(text=response)\n",
    "xml_target = \"\"\"<record><controlfield tag=\"005\">20240731164753.000</controlfield><leader> cam0 22 450 </leader><controlfield tag=\"001\">276421795</controlfield><controlfield tag=\"003\">http://www.sudoc.fr/276421795</controlfield><datafield tag=\"035\" ind1=\" \" ind2=\" \"><subfield code=\"a\">(OCoLC)1426782189</subfield></datafield><datafield tag=\"010\" ind1=\" \" ind2=\" \"><subfield code=\"a\">978-2-10-086210-8</subfield><subfield code=\"b\">br.</subfield></datafield><datafield tag=\"073\" ind1=\" \" ind2=\"1\"><subfield code=\"a\">9782100862108</subfield></datafield><datafield tag=\"100\" ind1=\" \" ind2=\" \"><subfield code=\"a\">20240315h20242024m y0frey50 ba</subfield></datafield><datafield tag=\"101\" ind1=\"0\" ind2=\" \"><subfield code=\"a\">fre</subfield><subfield code=\"d\">fre</subfield><subfield code=\"2\">639-2</subfield></datafield><datafield tag=\"105\" ind1=\" \" ind2=\" \"><subfield code=\"a\">ab a 000yy</subfield></datafield><datafield tag=\"106\" ind1=\" \" ind2=\" \"><subfield code=\"a\">r</subfield></datafield><datafield tag=\"181\" ind1=\" \" ind2=\" \"><subfield code=\"6\">z01</subfield><subfield code=\"c\">txt</subfield><subfield code=\"2\">rdacontent</subfield></datafield><datafield tag=\"181\" ind1=\" \" ind2=\"1\"><subfield code=\"6\">z01</subfield><subfield code=\"a\">i#</subfield><subfield code=\"b\">xxxe##</subfield></datafield><datafield tag=\"182\" ind1=\" \" ind2=\" \"><subfield code=\"6\">z01</subfield><subfield code=\"c\">n</subfield><subfield code=\"2\">rdamedia</subfield></datafield><datafield tag=\"182\" ind1=\" \" ind2=\"1\"><subfield code=\"6\">z01</subfield><subfield code=\"a\">n</subfield></datafield><datafield tag=\"183\" ind1=\" \" ind2=\"1\"><subfield code=\"6\">z01</subfield><subfield code=\"a\">nga</subfield><subfield code=\"2\">RDAfrCarrier</subfield></datafield><datafield tag=\"102\" ind1=\" \" ind2=\" \"><subfield code=\"a\">FR</subfield></datafield><datafield tag=\"320\" ind1=\" \" ind2=\" \"><subfield code=\"a\">Biblbiogr. p. 243-250</subfield></datafield><datafield tag=\"200\" ind1=\"1\" ind2=\" \"><subfield code=\"a\">12 clés économiques pour aborder 2030</subfield><subfield code=\"e\">maîtriser les enjeux qui feront le monde de demain</subfield><subfield code=\"f\">BSI Economics</subfield><subfield code=\"g\">[ouvrage coordonné par Victor Lequillerier et Mathieu Obertelli]</subfield></datafield><datafield tag=\"517\" ind1=\"|\" ind2=\" \"><subfield code=\"a\">Douze clés économiques pour aborder deux mille trente</subfield></datafield><datafield tag=\"701\" ind1=\" \" ind2=\"1\"><subfield code=\"3\">242250564</subfield><subfield code=\"a\">Lequillerier</subfield><subfield code=\"b\">Victor</subfield><subfield code=\"4\">651</subfield></datafield><datafield tag=\"701\" ind1=\" \" ind2=\"1\"><subfield code=\"3\">276422082</subfield><subfield code=\"a\">Obertelli</subfield><subfield code=\"b\">Mathieu</subfield><subfield code=\"f\">19..-....</subfield><subfield code=\"4\">651</subfield></datafield><datafield tag=\"710\" ind1=\"0\" ind2=\"2\"><subfield code=\"3\">233994092</subfield><subfield code=\"a\">BSI Economics</subfield><subfield code=\"4\">070</subfield></datafield><datafield tag=\"801\" ind1=\" \" ind2=\"3\"><subfield code=\"a\">FR</subfield><subfield code=\"b\">Abes</subfield><subfield code=\"c\">20240731</subfield><subfield code=\"g\">AFNOR</subfield></datafield><datafield tag=\"214\" ind1=\" \" ind2=\"0\"><subfield code=\"a\">Malakoff</subfield><subfield code=\"c\">Dunod</subfield><subfield code=\"d\">DL 2024</subfield></datafield><datafield tag=\"215\" ind1=\" \" ind2=\" \"><subfield code=\"a\">1 volume (255 pages)</subfield><subfield code=\"c\">graphiques, tableaux, schémas, cartes</subfield><subfield code=\"d\">22 cm</subfield></datafield><datafield tag=\"606\" ind1=\" \" ind2=\" \"><subfield code=\"3\">028209796</subfield><subfield code=\"a\">Économie politique</subfield><subfield code=\"z\">1945-....</subfield><subfield code=\"2\">rameau</subfield></datafield><datafield tag=\"606\" ind1=\" \" ind2=\" \"><subfield code=\"3\">027323161</subfield><subfield code=\"a\">Relations économiques internationales</subfield><subfield code=\"2\">rameau</subfield></datafield><datafield tag=\"606\" ind1=\" \" ind2=\" \"><subfield code=\"3\">027245276</subfield><subfield code=\"a\">Prévision économique</subfield><subfield code=\"2\">rameau</subfield></datafield><datafield tag=\"676\" ind1=\" \" ind2=\" \"><subfield code=\"a\">337</subfield><subfield code=\"v\">23</subfield></datafield><datafield tag=\"676\" ind1=\" \" ind2=\" \"><subfield code=\"a\">330</subfield></datafield><datafield tag=\"314\" ind1=\" \" ind2=\" \"><subfield code=\"a\">Avec la collaboration de Hervé Amourda, Evelyne Banh, Ana Boata, Pierre Bossuet, Cecile Buchholz, Paul Chollet, Alexis Garatti, Charlotte Gardes, Arthur Jurus, Julien Lecumberry, Jérôme Mathis, Rodrigue Mear, Anthony Morlet-Lavidalie, Julien Moussavi, Sandra Nevoux, Ludovic Subran et Maëlle Vaille</subfield></datafield><datafield tag=\"359\" ind1=\"2\" ind2=\" \"><subfield code=\"p\">P.7</subfield><subfield code=\"b\">Introduction</subfield><subfield code=\"p\">P.9</subfield><subfield code=\"b\">1. L'endettement des États européens est-il soutenable ? Quelles sont les solutions ?</subfield><subfield code=\"p\">P.27</subfield><subfield code=\"b\">2. La mainmise de l'inflation va-t-elle disparaître ?</subfield><subfield code=\"p\">P.49</subfield><subfield code=\"b\">3. Quel avenir pour la politique monétaire ?</subfield><subfield code=\"p\">P.71</subfield><subfield code=\"b\">4. Le vieillissement démographique va-t-il raviver ou tuer l'inflation ?</subfield><subfield code=\"p\">P.89</subfield><subfield code=\"b\">5. Économie de guerre au XXIe siècle : pourquoi les États-Unis sont-ils en situation de conflit permanent ?</subfield><subfield code=\"p\">P.107</subfield><subfield code=\"b\">6. La Chine, tout d'un numéro 1 ?</subfield><subfield code=\"p\">P.130</subfield><subfield code=\"b\">7. Comment verdir la finance ?</subfield><subfield code=\"p\">P.148</subfield><subfield code=\"b\">8. La décarbonation de l'économie européenne est-elle utopique ?</subfield><subfield code=\"p\">P.169</subfield><subfield code=\"b\">9. L'économie circulaire est-elle la solution aux défis environnementaux actuels et de demain ?</subfield><subfield code=\"p\">P.188</subfield><subfield code=\"b\">10. 2035 : plein gaz sur l'électrique ?</subfield><subfield code=\"p\">P.204</subfield><subfield code=\"b\">11. Le télétravail : une opportunité pour les territoires ?</subfield><subfield code=\"p\">P.224</subfield><subfield code=\"b\">12. Les cryptomonnaies : bulle spéculative ou révolution financière ?</subfield><subfield code=\"p\">P.243</subfield><subfield code=\"b\">Bibliographie</subfield><subfield code=\"p\">P.251</subfield><subfield code=\"b\">Présentation des auteurs</subfield></datafield><datafield tag=\"330\" ind1=\" \" ind2=\" \"><subfield code=\"a\">Cet ouvrage éclaire 12 questions au coeur de l'actualité, 12 problématiques dont les enjeux sont d'une importance majeure pour notre futur. Fruit du travail d'une nouvelle génération d'économistes, il offre une vision précise de l'état du monde actuel et fournit les clés pour comprendre les enjeux de demain, afin de pouvoir réfléchir en toute connaissance de cause aux moyens d'y faire face. L'endettement des États européens est-il soutenable ? ; La mainmise de l'inflation va-t-elle disparaître ? ; Quel avenir pour la politique monétaire ? ; Le vieillissement démographique va-t-il raviver ou tuer l'inflation ? ; Économie de guerre au XXIe siècle : pourquoi les États-Unis sont-ils en situation de conflit permanent ? ; La Chine, tout d'un numéro 1 ? ; Comment verdir la finance ? ; La décarbonation de l'économie européenne est-elle utopique ? ; L'économie circulaire est-elle la solution aux défis environnementaux actuels et de demain ? ; 2035 : plein gaz sur l'électrique ? ; Le télétravail : une opportunité pour les territoires ? ; Les cryptomonnaies : bulle spéculative ou révolution financière ?</subfield><subfield code=\"2\">4e de couverture</subfield></datafield></record>\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e3c9ba34-c696-48f2-bbb3-8948aacd81f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'035': '(text) Electric vehicle tribology 2024', '033': '978-0-443-14074-7 isbn', '100': 'A Leonardo I. Farfan-Cabrera Ali Erdemir', '101': 'Y 4', '105': '4e de couv.', '106': '23 cm', '180': '1 XI 313', '181': 'ill.', '185': '23 cm', '191': '4e', '200': 'R 2', '205': '23 cm'}\n"
     ]
    }
   ],
   "source": [
    "print(extract_field_values(xml_answer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "861b1f63-fced-4103-802d-c255375203b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'035': '(OCoLC)1426782189', '010': '978-2-10-086210-8 br.', '073': '9782100862108', '100': '20240315h20242024m y0frey50 ba', '101': 'fre fre 639-2', '105': 'ab a 000yy', '106': 'r', '181': 'z01 i# xxxe##', '182': 'z01 n', '183': 'z01 nga RDAfrCarrier', '102': 'FR', '320': 'Biblbiogr. p. 243-250', '200': '12 clés économiques pour aborder 2030 maîtriser les enjeux qui feront le monde de demain BSI Economics [ouvrage coordonné par Victor Lequillerier et Mathieu Obertelli]', '517': 'Douze clés économiques pour aborder deux mille trente', '701': '276422082 Obertelli Mathieu 19..-.... 651', '710': '233994092 BSI Economics 070', '801': 'FR Abes 20240731 AFNOR', '214': 'Malakoff Dunod DL 2024', '215': '1 volume (255 pages) graphiques, tableaux, schémas, cartes 22 cm', '606': '027245276 Prévision économique rameau', '676': '330', '314': 'Avec la collaboration de Hervé Amourda, Evelyne Banh, Ana Boata, Pierre Bossuet, Cecile Buchholz, Paul Chollet, Alexis Garatti, Charlotte Gardes, Arthur Jurus, Julien Lecumberry, Jérôme Mathis, Rodrigue Mear, Anthony Morlet-Lavidalie, Julien Moussavi, Sandra Nevoux, Ludovic Subran et Maëlle Vaille', '359': \"P.7 Introduction P.9 1. L'endettement des États européens est-il soutenable ? Quelles sont les solutions ? P.27 2. La mainmise de l'inflation va-t-elle disparaître ? P.49 3. Quel avenir pour la politique monétaire ? P.71 4. Le vieillissement démographique va-t-il raviver ou tuer l'inflation ? P.89 5. Économie de guerre au XXIe siècle : pourquoi les États-Unis sont-ils en situation de conflit permanent ? P.107 6. La Chine, tout d'un numéro 1 ? P.130 7. Comment verdir la finance ? P.148 8. La décarbonation de l'économie européenne est-elle utopique ? P.169 9. L'économie circulaire est-elle la solution aux défis environnementaux actuels et de demain ? P.188 10. 2035 : plein gaz sur l'électrique ? P.204 11. Le télétravail : une opportunité pour les territoires ? P.224 12. Les cryptomonnaies : bulle spéculative ou révolution financière ? P.243 Bibliographie P.251 Présentation des auteurs\", '330': \"Cet ouvrage éclaire 12 questions au coeur de l'actualité, 12 problématiques dont les enjeux sont d'une importance majeure pour notre futur. Fruit du travail d'une nouvelle génération d'économistes, il offre une vision précise de l'état du monde actuel et fournit les clés pour comprendre les enjeux de demain, afin de pouvoir réfléchir en toute connaissance de cause aux moyens d'y faire face. L'endettement des États européens est-il soutenable ? ; La mainmise de l'inflation va-t-elle disparaître ? ; Quel avenir pour la politique monétaire ? ; Le vieillissement démographique va-t-il raviver ou tuer l'inflation ? ; Économie de guerre au XXIe siècle : pourquoi les États-Unis sont-ils en situation de conflit permanent ? ; La Chine, tout d'un numéro 1 ? ; Comment verdir la finance ? ; La décarbonation de l'économie européenne est-elle utopique ? ; L'économie circulaire est-elle la solution aux défis environnementaux actuels et de demain ? ; 2035 : plein gaz sur l'électrique ? ; Le télétravail : une opportunité pour les territoires ? ; Les cryptomonnaies : bulle spéculative ou révolution financière ? 4e de couverture\"}\n"
     ]
    }
   ],
   "source": [
    "print(extract_field_values(xml_target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "0d5b9c3c-5edd-4e45-971a-160a8fad72f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import difflib\n",
    "\n",
    "def accuracy_reward(generated_xml: str, target_xml: str) -> float:\n",
    "    try:\n",
    "        gen_fields = extract_field_values(generated_xml)\n",
    "        tgt_fields = extract_field_values(target_xml)\n",
    "    except ET.ParseError:\n",
    "        return 0.0\n",
    "\n",
    "    shared_keys = set(gen_fields) & set(tgt_fields)\n",
    "    if not shared_keys:\n",
    "        return 0.0\n",
    "\n",
    "    total_sim = 0\n",
    "    for key in shared_keys:\n",
    "        sim = difflib.SequenceMatcher(None, gen_fields[key], tgt_fields[key]).ratio()\n",
    "        total_sim += sim\n",
    "\n",
    "    return total_sim / len(shared_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "236ca6a2-60b2-4dd8-bfb4-e34ea1a9ba83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.106423478482302\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_reward(generated_xml=xml_answer, target_xml=xml_target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63aa9561-fb84-48cd-8980-5e9547a08e35",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
