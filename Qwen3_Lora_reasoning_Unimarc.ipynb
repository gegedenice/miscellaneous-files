{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "16d969d4-d3a4-4c46-b647-167236c78768",
   "metadata": {},
   "source": [
    "<h3 align=\"center\">Status : <span class=\"badge\"><b>En cours</b></span></h3>\n",
    "\n",
    "<h1 align=\"center\">RL GRPO</h1>\n",
    "\n",
    "---\n",
    "\n",
    "<h1 align=\"center\">Training a small Unimarc reasoner with RL</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "208a0dbc-baee-49c3-9ce6-2522e07c3be6",
   "metadata": {},
   "source": [
    "# Requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3fa9d1ef-0ab5-4522-b9c7-fc0f70ce3232",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filesystem      Size  Used Avail Use% Mounted on\n",
      "overlay         3.3T  1.6T  1.5T  52% /\n",
      "tmpfs            64M     0   64M   0% /dev\n",
      "tmpfs            10G     0   10G   0% /dev/shm\n",
      "/dev/sdo1       3.3T  1.6T  1.5T  52% /etc/hosts\n",
      "/dev/rbd1        98G  900M   97G   1% /home/onyxia/work\n",
      "/dev/sdt1       273G  7.8G  251G   3% /usr/bin/nvidia-smi\n",
      "tmpfs           200G   12K  200G   1% /run/secrets/kubernetes.io/serviceaccount\n",
      "tmpfs           315G     0  315G   0% /proc/acpi\n",
      "tmpfs           315G     0  315G   0% /sys/firmware\n",
      "tmpfs           315G     0  315G   0% /sys/devices/virtual/powercap\n"
     ]
    }
   ],
   "source": [
    "!df -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "25f023b3-02d5-49aa-bfad-e3918e6c6f18",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "!cd /home/onyxia/work & rm -r sft_lora_one_step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "281f8077-e3f2-4a3d-bd8a-b82808b0e168",
   "metadata": {},
   "outputs": [],
   "source": [
    "del model\n",
    "#del peft_model\n",
    "#del merged_model\n",
    "del tokenizer\n",
    "#del trainer\n",
    "torch.cuda.empty_cache() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1ddac3ec-3e4e-48b8-9a69-4d0fe027dfad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch:\n",
      "PyTorch version is:2.5.1\n",
      "The GPU model is: NVIDIA H100 80GB HBM3\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(\"PyTorch:\")\n",
    "print(\"PyTorch version is:\" + torch.__version__)\n",
    "if torch.cuda.is_available():\n",
    "    print(\"The GPU model is: \"+ torch.cuda.get_device_name(0))\n",
    "    # Enable TF32 for faster matrix multiplication on supported GPUs\n",
    "    torch.backends.cuda.matmul.allow_tf32 = True\n",
    "else:\n",
    "    print(\"Error! It is not working correctly\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d502c402-8236-4ecb-9654-6e0d7cfa994d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pip in /opt/anaconda3/lib/python3.12/site-packages (24.2)\n",
      "Collecting pip\n",
      "  Downloading pip-25.1.1-py3-none-any.whl.metadata (3.6 kB)\n",
      "Downloading pip-25.1.1-py3-none-any.whl (1.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m30.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "Installing collected packages: pip\n",
      "\u001b[33m  WARNING: The scripts pip, pip3 and pip3.12 are installed in '/home/user/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "Successfully installed pip-25.1.1\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0516e17e-d358-45e2-8ad7-f16c62cd5378",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33m  DEPRECATION: Building 'flash-attn' using the legacy setup.py bdist_wheel mechanism, which will be removed in a future version. pip 25.3 will enforce this behaviour change. A possible replacement is to use the standardized build interface by setting the `--use-pep517` option, (possibly combined with `--no-build-isolation`), or adding a `pyproject.toml` file to the source tree of 'flash-attn'. Discussion can be found at https://github.com/pypa/pip/issues/6334\u001b[0m\u001b[33m\n",
      "\u001b[33m  WARNING: The script huggingface-cli is installed in '/home/user/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[33m  WARNING: The script datasets-cli is installed in '/home/user/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[33m  WARNING: The script transformers-cli is installed in '/home/user/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[33m  WARNING: The scripts accelerate, accelerate-config, accelerate-estimate-memory, accelerate-launch and accelerate-merge-weights are installed in '/home/user/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[33m  WARNING: The script trl is installed in '/home/user/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[33m  WARNING: The script isympy is installed in '/home/user/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install -U --quiet datasets transformers trl huggingface_hub accelerate peft flash-attn tf-keras --use-deprecated=legacy-resolver\n",
    "#if A100 or H100 GPU: pip install flash-attn tf-keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ec980996-ca3c-4b66-8a88-42200f930e31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'type': 'user',\n",
       " 'id': '63256c1fa3f07c8e168c0d47',\n",
       " 'name': 'Geraldine',\n",
       " 'fullname': 'Géraldine Geoffroy',\n",
       " 'email': 'grldn.geoffroy@gmail.com',\n",
       " 'emailVerified': True,\n",
       " 'canPay': False,\n",
       " 'periodEnd': 1748735999,\n",
       " 'isPro': False,\n",
       " 'avatarUrl': '/avatars/9cb069e5e90930e818ebe69300cd35d8.svg',\n",
       " 'orgs': [{'type': 'org',\n",
       "   'id': '665f255b175693a15893b7a1',\n",
       "   'name': 'discord-community',\n",
       "   'fullname': 'Hugging Face Discord Community',\n",
       "   'email': 'lunarflu@gmail.com',\n",
       "   'canPay': False,\n",
       "   'periodEnd': 1748735999,\n",
       "   'avatarUrl': 'https://cdn-avatars.huggingface.co/v1/production/uploads/6340651b388c3fa40f9a5bc0/j6Vb_hutYuKRcQgMaDTAt.png',\n",
       "   'roleInOrg': 'read',\n",
       "   'isEnterprise': False}],\n",
       " 'auth': {'type': 'access_token',\n",
       "  'accessToken': {'displayName': 'write_hf_token',\n",
       "   'role': 'write',\n",
       "   'createdAt': '2024-11-08T10:49:12.891Z'}}}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from huggingface_hub import login, whoami\n",
    "\n",
    "login(\n",
    "  token=\"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\" # with write permissions\n",
    ")\n",
    "whoami()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07e21012-2850-4403-a395-c70cdc15465e",
   "metadata": {},
   "source": [
    "# Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "add8b2b4-0c14-4582-98ff-30df58a4ed8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8a178c0d-8bea-43c5-b2b1-fec88e470af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"Qwen/Qwen3-0.6B\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=True)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    torch_dtype=\"auto\",\n",
    "    device_map=\"auto\",\n",
    "    #attn_implementation=\"flash_attention_2\"\n",
    ")\n",
    "#model.config.sliding_window = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d70772a8-b356-4b59-b05a-dc779e9dbb0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Qwen3Config {\n",
      "  \"_attn_implementation_autoset\": true,\n",
      "  \"architectures\": [\n",
      "    \"Qwen3ForCausalLM\"\n",
      "  ],\n",
      "  \"attention_bias\": false,\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 151643,\n",
      "  \"eos_token_id\": 151645,\n",
      "  \"head_dim\": 128,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 1024,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"max_position_embeddings\": 40960,\n",
      "  \"max_window_layers\": 28,\n",
      "  \"model_type\": \"qwen3\",\n",
      "  \"num_attention_heads\": 16,\n",
      "  \"num_hidden_layers\": 28,\n",
      "  \"num_key_value_heads\": 8,\n",
      "  \"rms_norm_eps\": 1e-06,\n",
      "  \"rope_scaling\": null,\n",
      "  \"rope_theta\": 1000000,\n",
      "  \"sliding_window\": null,\n",
      "  \"tie_word_embeddings\": true,\n",
      "  \"torch_dtype\": \"bfloat16\",\n",
      "  \"transformers_version\": \"4.51.3\",\n",
      "  \"use_cache\": true,\n",
      "  \"use_sliding_window\": false,\n",
      "  \"vocab_size\": 151936\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(model.config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6db1ceba-0d68-4622-8e50-3a37e482344b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Qwen3ForCausalLM(\n",
       "  (model): Qwen3Model(\n",
       "    (embed_tokens): Embedding(151936, 1024)\n",
       "    (layers): ModuleList(\n",
       "      (0-27): 28 x Qwen3DecoderLayer(\n",
       "        (self_attn): Qwen3Attention(\n",
       "          (q_proj): Linear(in_features=1024, out_features=2048, bias=False)\n",
       "          (k_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (v_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (o_proj): Linear(in_features=2048, out_features=1024, bias=False)\n",
       "          (q_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
       "          (k_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
       "        )\n",
       "        (mlp): Qwen3MLP(\n",
       "          (gate_proj): Linear(in_features=1024, out_features=3072, bias=False)\n",
       "          (up_proj): Linear(in_features=1024, out_features=3072, bias=False)\n",
       "          (down_proj): Linear(in_features=3072, out_features=1024, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): Qwen3RMSNorm((1024,), eps=1e-06)\n",
       "        (post_attention_layernorm): Qwen3RMSNorm((1024,), eps=1e-06)\n",
       "      )\n",
       "    )\n",
       "    (norm): Qwen3RMSNorm((1024,), eps=1e-06)\n",
       "    (rotary_emb): Qwen3RotaryEmbedding()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=1024, out_features=151936, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model.config.sliding_window = None\n",
    "device = \"cuda\" # for GPU usage or \"cpu\" for CPU usage\n",
    "model = model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bca1192b-9713-4f53-9340-c17d0273e6b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !Important\n",
    "tokenizer.padding_side = \"right\"\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70fdbedb-cdcf-471b-87d1-980842de7d49",
   "metadata": {},
   "source": [
    "## Inspect tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cea2c081-d317-4090-ab34-2c9fd5d6da83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "151669"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b093e0fa-0034-4024-8b51-b685c53de48c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**EOS**\n",
      "EOS token: <|im_end|>\n",
      "- EOS token id: 151645\n",
      "\n",
      "**PAD**\n",
      "PAD token: <|endoftext|>\n",
      "- PAD token id: 151643\n"
     ]
    }
   ],
   "source": [
    "print(f\"**EOS**\\nEOS token: {tokenizer.eos_token}\\n- EOS token id: {tokenizer.eos_token_id}\\n\\n**PAD**\\nPAD token: {tokenizer.pad_token}\\n- PAD token id: {tokenizer.pad_token_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8d2ce30d-56cb-471d-b2aa-2785766222f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[151667]], device='cuda:0'), 'attention_mask': tensor([[1]], device='cuda:0')}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer(\"<think>\", return_tensors=\"pt\").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ec381b03-cedc-47ff-8d58-5d05985f7b48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'</think>'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(151668)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d1097588-e692-4a37-9253-56eefc10537f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[ 1782, 12884,   374,  6303]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1]], device='cuda:0')}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer(\"the sky is blue\", return_tensors=\"pt\").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a232afe9-f43e-405d-b470-78fa8a0f26c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = tokenizer(\"the sky is blue\", return_tensors=\"pt\").to(device).input_ids[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b85a729e-cee3-4264-82dd-90e0e62e78a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'the sky is blue'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "03458069-d640-43d2-b800-f4c1882b7dd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current chat template: {%- if tools %}\n",
      "    {{- '<|im_start|>system\\n' }}\n",
      "    {%- if messages[0].role == 'system' %}\n",
      "        {{- messages[0].content + '\\n\\n' }}\n",
      "    {%- endif %}\n",
      "    {{- \"# Tools\\n\\nYou may call one or more functions to assist with the user query.\\n\\nYou are provided with function signatures within <tools></tools> XML tags:\\n<tools>\" }}\n",
      "    {%- for tool in tools %}\n",
      "        {{- \"\\n\" }}\n",
      "        {{- tool | tojson }}\n",
      "    {%- endfor %}\n",
      "    {{- \"\\n</tools>\\n\\nFor each function call, return a json object with function name and arguments within <tool_call></tool_call> XML tags:\\n<tool_call>\\n{\\\"name\\\": <function-name>, \\\"arguments\\\": <args-json-object>}\\n</tool_call><|im_end|>\\n\" }}\n",
      "{%- else %}\n",
      "    {%- if messages[0].role == 'system' %}\n",
      "        {{- '<|im_start|>system\\n' + messages[0].content + '<|im_end|>\\n' }}\n",
      "    {%- endif %}\n",
      "{%- endif %}\n",
      "{%- set ns = namespace(multi_step_tool=true, last_query_index=messages|length - 1) %}\n",
      "{%- for message in messages[::-1] %}\n",
      "    {%- set index = (messages|length - 1) - loop.index0 %}\n",
      "    {%- if ns.multi_step_tool and message.role == \"user\" and not(message.content.startswith('<tool_response>') and message.content.endswith('</tool_response>')) %}\n",
      "        {%- set ns.multi_step_tool = false %}\n",
      "        {%- set ns.last_query_index = index %}\n",
      "    {%- endif %}\n",
      "{%- endfor %}\n",
      "{%- for message in messages %}\n",
      "    {%- if (message.role == \"user\") or (message.role == \"system\" and not loop.first) %}\n",
      "        {{- '<|im_start|>' + message.role + '\\n' + message.content + '<|im_end|>' + '\\n' }}\n",
      "    {%- elif message.role == \"assistant\" %}\n",
      "        {%- set content = message.content %}\n",
      "        {%- set reasoning_content = '' %}\n",
      "        {%- if message.reasoning_content is defined and message.reasoning_content is not none %}\n",
      "            {%- set reasoning_content = message.reasoning_content %}\n",
      "        {%- else %}\n",
      "            {%- if '</think>' in message.content %}\n",
      "                {%- set content = message.content.split('</think>')[-1].lstrip('\\n') %}\n",
      "                {%- set reasoning_content = message.content.split('</think>')[0].rstrip('\\n').split('<think>')[-1].lstrip('\\n') %}\n",
      "            {%- endif %}\n",
      "        {%- endif %}\n",
      "        {%- if loop.index0 > ns.last_query_index %}\n",
      "            {%- if loop.last or (not loop.last and reasoning_content) %}\n",
      "                {{- '<|im_start|>' + message.role + '\\n<think>\\n' + reasoning_content.strip('\\n') + '\\n</think>\\n\\n' + content.lstrip('\\n') }}\n",
      "            {%- else %}\n",
      "                {{- '<|im_start|>' + message.role + '\\n' + content }}\n",
      "            {%- endif %}\n",
      "        {%- else %}\n",
      "            {{- '<|im_start|>' + message.role + '\\n' + content }}\n",
      "        {%- endif %}\n",
      "        {%- if message.tool_calls %}\n",
      "            {%- for tool_call in message.tool_calls %}\n",
      "                {%- if (loop.first and content) or (not loop.first) %}\n",
      "                    {{- '\\n' }}\n",
      "                {%- endif %}\n",
      "                {%- if tool_call.function %}\n",
      "                    {%- set tool_call = tool_call.function %}\n",
      "                {%- endif %}\n",
      "                {{- '<tool_call>\\n{\"name\": \"' }}\n",
      "                {{- tool_call.name }}\n",
      "                {{- '\", \"arguments\": ' }}\n",
      "                {%- if tool_call.arguments is string %}\n",
      "                    {{- tool_call.arguments }}\n",
      "                {%- else %}\n",
      "                    {{- tool_call.arguments | tojson }}\n",
      "                {%- endif %}\n",
      "                {{- '}\\n</tool_call>' }}\n",
      "            {%- endfor %}\n",
      "        {%- endif %}\n",
      "        {{- '<|im_end|>\\n' }}\n",
      "    {%- elif message.role == \"tool\" %}\n",
      "        {%- if loop.first or (messages[loop.index0 - 1].role != \"tool\") %}\n",
      "            {{- '<|im_start|>user' }}\n",
      "        {%- endif %}\n",
      "        {{- '\\n<tool_response>\\n' }}\n",
      "        {{- message.content }}\n",
      "        {{- '\\n</tool_response>' }}\n",
      "        {%- if loop.last or (messages[loop.index0 + 1].role != \"tool\") %}\n",
      "            {{- '<|im_end|>\\n' }}\n",
      "        {%- endif %}\n",
      "    {%- endif %}\n",
      "{%- endfor %}\n",
      "{%- if add_generation_prompt %}\n",
      "    {{- '<|im_start|>assistant\\n' }}\n",
      "    {%- if enable_thinking is defined and enable_thinking is false %}\n",
      "        {{- '<think>\\n\\n</think>\\n\\n' }}\n",
      "    {%- endif %}\n",
      "{%- endif %}\n"
     ]
    }
   ],
   "source": [
    "if hasattr(tokenizer, \"chat_template\"):\n",
    "    print(\"Current chat template:\", tokenizer.chat_template)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "650b9be4-19ca-40cc-97af-56bd0f6f570f",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6daf62b3-b325-42ed-8dee-f4e74c704f3c",
   "metadata": {},
   "source": [
    "### Without applying chat templating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "92e78fa0-e0d2-4382-b738-98663777d509",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"<|im_start|>system: You are a helpful assistant /no_think<|im_end|><|im_start|>user: complete this sentence 'the sky is blue and '<|im_end|><|im_start|>assistant: \"\n",
    "inputs = tokenizer(prompt, return_tensors=\"pt\").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8db10eed-0a4c-4ce6-866e-65574ec0b73a",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = model.generate(**inputs,\n",
    "                         max_new_tokens = 20,\n",
    "                         use_cache = True,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f2145d5d-c8cf-4019-802e-62d49ec09230",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|im_start|>system: You are a helpful assistant /no_think<|im_end|><|im_start|>user: complete this sentence 'the sky is blue and '<|im_end|><|im_start|>assistant: <think>\n",
      "\n",
      "<think>\n",
      "</think>\n",
      "\n",
      "the sky is blue and the sun is shining bright.<|im_end|>\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.decode(outputs[0], skip_special_tokens=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55a0c2d9-0160-41be-9d2e-e3bda819782e",
   "metadata": {},
   "source": [
    "### With applying chat templating"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b379d646-b3fe-4803-9519-1723ed53586e",
   "metadata": {},
   "source": [
    "#### No thinking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "1e6303e7-c98a-44ab-a0a9-6b545df643f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"\n",
    "You are a helpful assistant expert in Unimarc/XML bibliographic records.\n",
    "Your task is to generate a valid Unimarc XML record from given bibliographic metadata.\n",
    "\"\"\"\n",
    "\n",
    "user_prompt = \"\"\"\n",
    "Title: Electric vehicle tribology\n",
    "Subtitle: Challenges and opportunities for a sustainable transportation future\n",
    "Author: Leonardo I. Farfan-Cabrera, Ali Erdemir\n",
    "Publisher: Elsevier\n",
    "Year: 2024\n",
    "ISBN: 978-0-443-14074-7\n",
    "Language: English\n",
    "Collection/Series: Elsevier Series on Tribology and Surface Engineering\n",
    "Edition: Not specified\n",
    "Material description: 1 vol. (XI-313 p.), couv. ill. en coul., 23 cm\n",
    "Abstract/Notes: \"Electric vehicle tribology, challenges and opportunities for a sustainable transportation future\" provides practical, comprehensive guidance on a new and increasingly important area of tribology. Building skills from fundamentals to solution design, this book demonstrates the unique tribological techniques essential to the efficient electrification of transport systems. Led by professors with a combined three decades in industry and academia, and collecting insights from experts around the world, this book begins with the essential knowledge regarding both electric vehicles and tribology. After outlining the unique tribological needs of EVs, the book then breaks down the components and hardware required. It provides detailed protocols and methods for the testing and improvement of lubricants and materials as well as a dedicated section on modern lubrication specific to EVs. Throughout, it considers the critical question of sustainable tribology and the long-term sustainable options for lubrication and materials for electric vehicles.\n",
    "Source of the abstract/notes: 4e de couverture\n",
    "Table of contents: Not specified\n",
    "Keywords: Tribologie (technologie), Tribologie (Technologie)\n",
    "\"\"\"\n",
    "\n",
    "messages = [\n",
    "  {\"role\": \"system\", \"content\": system_prompt},\n",
    "  {\"role\": \"user\", \"content\": user_prompt},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6400bc7e-061f-4dc5-a465-d8be980a008f",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer.apply_chat_template(\n",
    "    messages,\n",
    "    return_dict=True,\n",
    "    tokenize = True,\n",
    "    add_generation_prompt = True, # Must add for generation\n",
    "    return_tensors = \"pt\",\n",
    "    enable_thinking=False\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "39395bd2-69eb-4689-8cb6-ffafb1de6e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = model.generate(\n",
    "    **inputs,\n",
    "    max_new_tokens = 32768,\n",
    "    use_cache = True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bf8b8c06-ca8e-46b2-aaf4-e5e9034d89e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_ids = outputs[0][len(inputs.input_ids[0]):].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2277029b-87e2-4d3b-8774-869a1b1feb00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thinking content: \n",
      "content: <unimarc:record>\n",
      "<unimarc:isbn>978-0-443-14074-7</unimarc:isbn>\n",
      "<unimarc:year>2024</unimarc:year>\n",
      "<unimarc:collection>Elsevier Series on Tribology and Surface Engineering</unimarc:collection>\n",
      "<unimarc:edition>Not specified</unimarc:edition>\n",
      "<unimarc:language>English</unimarc:language>\n",
      "<unimarc:publisher>Elsevier</unimarc:publisher>\n",
      "<unimarc:author>Leonardo I. Farfan-Cabrera, Ali Erdemir</unimarc:author>\n",
      "<unimarc:abstract>Electric vehicle tribology, challenges and opportunities for a sustainable transportation future provides practical, comprehensive guidance on a new and increasingly important area of tribology. Building skills from fundamentals to solution design, this book demonstrates the unique tribological techniques essential to the efficient electrification of transport systems. Led by professors with a combined three decades in industry and academia, and collecting insights from experts around the world, this book begins with the essential knowledge regarding both electric vehicles and tribology. After outlining the unique tribological needs of EVs, the book then breaks down the components and hardware required. It provides detailed protocols and methods for the testing and improvement of lubricants and materials as well as a dedicated section on modern lubrication specific to EVs. Throughout, it considers the critical question of sustainable tribology and the long-term sustainable options for lubrication and materials for electric vehicles.</unimarc:abstract>\n",
      "<unimarc:notes>4e de couverture</unimarc:notes>\n",
      "<unimarc:table-of-contents>Not specified</unimarc:table-of-contents>\n",
      "<unimarc:keywords>tribologie (technologie), tribologie (Technologie)</unimarc:keywords>\n",
      "</unimarc:record>\n"
     ]
    }
   ],
   "source": [
    "# parsing thinking content\n",
    "try:\n",
    "    # rindex finding 151668 (</think>)\n",
    "    index = len(output_ids) - output_ids[::-1].index(151668)\n",
    "except ValueError:\n",
    "    index = 0\n",
    "\n",
    "thinking_content = tokenizer.decode(output_ids[:index], skip_special_tokens=True).strip(\"\\n\")\n",
    "content = tokenizer.decode(output_ids[index:], skip_special_tokens=True).strip(\"\\n\")\n",
    "\n",
    "print(\"thinking content:\", thinking_content)\n",
    "print(\"content:\", content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "291fe1e1-552d-4768-b61a-11c7a3db482e",
   "metadata": {},
   "source": [
    "#### Thinking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "de048f76-03c7-413c-bb0e-05b714dcda1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"\n",
    "You are an expert in Unimarc/XML bibliographic records encoding.\n",
    "Here is bibliographic metadata: explain step-by-step how to transform metadata into this a compliant Unimarc/XML record.\n",
    "For example:\n",
    "- Title maps to 200$a\n",
    "- Subtitle to 200$e\n",
    "- ...\n",
    "Then generate Unimarc/XML from your reasoning\n",
    "\"\"\"\n",
    "\n",
    "user_prompt = \"\"\"\n",
    "Title: Electric vehicle tribology\n",
    "Subtitle: Challenges and opportunities for a sustainable transportation future\n",
    "Author: Leonardo I. Farfan-Cabrera, Ali Erdemir\n",
    "Publisher: Elsevier\n",
    "Year: 2024\n",
    "ISBN: 978-0-443-14074-7\n",
    "Language: English\n",
    "Collection/Series: Elsevier Series on Tribology and Surface Engineering\n",
    "Edition: Not specified\n",
    "Material description: 1 vol. (XI-313 p.), couv. ill. en coul., 23 cm\n",
    "Abstract/Notes: \"Electric vehicle tribology, challenges and opportunities for a sustainable transportation future\" provides practical, comprehensive guidance on a new and increasingly important area of tribology. Building skills from fundamentals to solution design, this book demonstrates the unique tribological techniques essential to the efficient electrification of transport systems. Led by professors with a combined three decades in industry and academia, and collecting insights from experts around the world, this book begins with the essential knowledge regarding both electric vehicles and tribology. After outlining the unique tribological needs of EVs, the book then breaks down the components and hardware required. It provides detailed protocols and methods for the testing and improvement of lubricants and materials as well as a dedicated section on modern lubrication specific to EVs. Throughout, it considers the critical question of sustainable tribology and the long-term sustainable options for lubrication and materials for electric vehicles.\n",
    "Source of the abstract/notes: 4e de couverture\n",
    "Table of contents: Not specified\n",
    "Keywords: Tribologie (technologie), Tribologie (Technologie)\n",
    "\"\"\"\n",
    "\n",
    "messages = [\n",
    "  {\"role\": \"system\", \"content\": system_prompt},\n",
    "  {\"role\": \"user\", \"content\": user_prompt},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "97d0dd62-9dac-4d82-9a7a-71ac6bb727e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer.apply_chat_template(\n",
    "    messages,\n",
    "    return_dict=True,\n",
    "    tokenize = True,\n",
    "    add_generation_prompt = True, # Must add for generation\n",
    "    return_tensors = \"pt\",\n",
    "    enable_thinking=True\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0604e9bb-95cb-4dba-92a8-98fefba1b62c",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = model.generate(\n",
    "    **inputs,\n",
    "    max_new_tokens = 32768,\n",
    "    use_cache = True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "770fcb0f-f46e-4fd0-994e-b0885fc1bbce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thinking content: <think>\n",
      "Okay, let's start by understanding the user's request. They want me to transform the provided bibliographic metadata into a compliant Unimarc/XML record. The example given was a structure where each field maps to specific numbers like 200$a, 200$e, etc. So, I need to follow that format step by step.\n",
      "\n",
      "First, I'll check the title. The title is \"Electric vehicle tribology\". The example uses 200$a, so I'll map that to the title. The subtitle is \"Challenges and opportunities for a sustainable transportation future\". The example uses 200$e, so that's the subtitle. \n",
      "\n",
      "Next, the authors are Leonardo I. Farfan-Cabrera and Ali Erdemir. The example uses 200$e for the authors, so I'll list them as such. The publisher is Elsevier, and the year is 2024. The ISBN is 978-0-443-14074-7, which maps to 200$e as well. \n",
      "\n",
      "The collection/series is \"Elsevier Series on Tribology and Surface Engineering\". The example uses 200$e again, so that's the series. The edition is \"Not specified\", so maybe leave it as is. The material description has 1 vol. (XI-313 p.), couv. ill. en coul., 23 cm. The abstract/notes mention sustainable tribology and EVs. The source of the abstract is 4e de couverture, which maps to 200$e. \n",
      "\n",
      "I need to make sure each field is mapped correctly. Let me double-check the example structure. The example uses 200$a for the title, 200$e for the subtitle, and so on. So, each key in the metadata should correspond to a 200$ number. \n",
      "\n",
      "Wait, the user's example uses 200$a for title, 200$e for subtitle, and so on. So, the key is to map each field to the corresponding 200$ code. Let me list out each part:\n",
      "\n",
      "- Title: 200$a\n",
      "- Subtitle: 200$e\n",
      "- Authors: 200$e\n",
      "- Publisher: 200$e\n",
      "- Year: 200$a\n",
      "- ISBN: 200$e\n",
      "- Collection/Series: 200$e\n",
      "- Edition: 200$e\n",
      "- Material description: 200$a (volume, pages, etc.)\n",
      "\n",
      "I need to ensure that each field is mapped correctly. Let me check again. The example uses 200$a for the title, which matches the first field. The subtitle is 200$e. Authors are 200$e. The publisher is 200$e. Year is 200$a. ISBN is 200$e. Collection/Series is 200$e. Edition is 200$e. Material description has volume, pages, etc., which would be 200$a. \n",
      "\n",
      "So, putting it all together, the Unimarc/XML record should have each key mapped to the corresponding 200$ number. I need to make sure there are no typos and that each part is correctly placed. Once all fields are mapped, the final XML should look like the example provided.\n",
      "</think>\n",
      "content: - Title maps to 200$a  \n",
      "- Subtitle maps to 200$e  \n",
      "- Authors map to 200$e  \n",
      "- Publisher maps to 200$e  \n",
      "- Year maps to 200$a  \n",
      "- ISBN maps to 200$e  \n",
      "- Collection/Series maps to 200$e  \n",
      "- Edition maps to 200$e  \n",
      "- Volume maps to 200$a  \n",
      "- Pages maps to 200$a  \n",
      "- Cover illustrations maps to 200$e  \n",
      "- Language maps to 200$e  \n",
      "- Abstract/Notes maps to 200$e  \n",
      "\n",
      "```xml\n",
      "<unimarc:record>\n",
      "  <unimarc:identifier>\n",
      "    <unimarc:identifierType>ISBN</unimarc:identifierType>\n",
      "    <unimarc:identifierValue>978-0-443-14074-7</unimarc:identifier>\n",
      "  </unimarc:identifier>\n",
      "  <unimarc:title>Electric vehicle tribology</unimarc:title>\n",
      "  <unimarc:subtitle>Challenges and opportunities for a sustainable transportation future</unimarc:subtitle>\n",
      "  <unimarc:author>Leonardo I. Farfan-Cabrera, Ali Erdemir</unimarc:author>\n",
      "  <unimarc:publisher>Elsevier</unimarc:publisher>\n",
      "  <unimarc:year>2024</unimarc:year>\n",
      "  <unimarc:collection>Elsevier Series on Tribology and Surface Engineering</unimarc:collection>\n",
      "  <unimarc:edition>Not specified</unimarc:edition>\n",
      "  <unimarc:material>1 vol. (XI-313 p.), couv. ill. en coul., 23 cm</unimarc:material>\n",
      "  <unimarc:abstract>...</unimarc:abstract>\n",
      "  <unimarc:notes>4e de couverture</unimarc:notes>\n",
      "</unimarc:record>\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "output_ids = outputs[0][len(inputs.input_ids[0]):].tolist()\n",
    "# parsing thinking content\n",
    "try:\n",
    "    # rindex finding 151668 (</think>)\n",
    "    index = len(output_ids) - output_ids[::-1].index(151668)\n",
    "except ValueError:\n",
    "    index = 0\n",
    "\n",
    "thinking_content = tokenizer.decode(output_ids[:index], skip_special_tokens=True).strip(\"\\n\")\n",
    "content = tokenizer.decode(output_ids[index:], skip_special_tokens=True).strip(\"\\n\")\n",
    "\n",
    "print(\"thinking content:\", thinking_content)\n",
    "print(\"content:\", content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52e940fb-b2f3-4340-8a86-55c0aacc2877",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(tokenizer.decode(outputs[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c037b7da-39f5-4576-80a3-7267775e0408",
   "metadata": {},
   "outputs": [],
   "source": [
    "#generated_ids = [\n",
    "#   output_ids[len(input_ids):] for input_ids, output_ids in zip(inputs.input_ids, outputs)\n",
    "#]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "766efb3a-dc8c-4278-b4be-1174ba8aa78f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c09f9a3-8e84-4392-a2c1-eacfe5d26b3d",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e481b67f-1e1f-4ec2-b573-a5a8c61ef24c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset, Dataset\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4ea14964-a96a-400b-a2ac-855241bc2ea4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "774b720139494d8285e9530b546891b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/392 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3764d8b27c13434fa53323a1e26f71bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00000-of-00001.parquet:   0%|          | 0.00/4.90M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be833d5a5ec14cc7bff551d625c4a575",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/673 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['ppn', 'metadata', 'unimarc_record', 'reasoning'],\n",
       "    num_rows: 673\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = load_dataset(\"Geraldine/metadata-to-unimarc-traces\", split=\"train\")\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7ac3a96d-a170-44f7-a56d-9818ff24dd49",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.select(range(100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30e138e2-5597-4c34-b889-e74ea23a379d",
   "metadata": {},
   "source": [
    "# One-step training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fb3eb03c-99b5-4551-aa2b-9bb73306ee84",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM, TrainingArguments\n",
    "from trl import SFTTrainer\n",
    "from peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8dbe511f-d76b-4e52-a0dc-d1835f529e92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<|im_end|>'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d0ce034-fb6c-4766-bb36-50c38e07fbfa",
   "metadata": {},
   "source": [
    "## Lora"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65d50e36-36fc-469d-84fd-66a78be8d9e9",
   "metadata": {},
   "source": [
    "### Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ba6d5d8f-a3d5-4f25-83aa-0765a911d1c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b12991f12d674645866711f47b6d48c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/673 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['messages'],\n",
       "    num_rows: 673\n",
       "})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "system_prompt = \"\"\"\n",
    "You are an expert bibliographic cataloger assistant specializing in UNIMARC format. \n",
    "Your task is to convert bibliographical metadata into UNIMARC/XML records by explaining the reasoning behind converting (step-by-step explanations of the field mappings, encoding decisions, and cataloging rules applied).\"\"\"\n",
    "\n",
    "def create_conversation(row):\n",
    "  return {\n",
    "    \"messages\": [\n",
    "            {\"role\": \"system\", \"content\": f\"{system_prompt} /think\"},\n",
    "            {\"role\": \"user\", \"content\": f\"# Bibliographical metadata:\\n{row['metadata']}\"},\n",
    "            {\"role\": \"assistant\", \"content\": f\"<think>\\n{row['reasoning']}\\n</think>\\n\\nBased on the metadata, here is the UNIMARC/XML record:\\n\\n{row['unimarc_record']}\"}\n",
    "        ]\n",
    "  }\n",
    "\n",
    "dataset = dataset.map(create_conversation, remove_columns=dataset.features, batched=False)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "170e829f-b741-4e79-acbe-01b1eb2202ed",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ed30eb4c-caf2-4177-99b5-bdee8d1d9229",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
     ]
    }
   ],
   "source": [
    "# ---- 3. Define LoRA config ----\n",
    "peft_config = LoraConfig(\n",
    "    r=8,\n",
    "    lora_alpha=32,\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\",\n",
    "    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\"] # may vary based on model, check with `model.named_modules()` in previous cell\n",
    ")\n",
    "\n",
    "# ---- 4. Training args ----\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./sft_distill\",\n",
    "    per_device_train_batch_size=1,\n",
    "    gradient_accumulation_steps=4,\n",
    "    logging_steps=50,\n",
    "    save_strategy=\"epoch\",\n",
    "    num_train_epochs=20,\n",
    "    learning_rate=5e-5,\n",
    "    fp16=True,\n",
    "    report_to=\"none\"\n",
    ")\n",
    "\n",
    "# ---- 5. Launch training ----\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    train_dataset=dataset,\n",
    "    peft_config=peft_config,\n",
    "    args=training_args\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9ee38e6-b646-4c7e-bd84-769e1d8c1342",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19040fb4b16e40ccbba3724b71b56ffb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Converting train dataset to ChatML:   0%|          | 0/538 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80373b2e416446c680e4992bd3cfea85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Applying chat template to train dataset:   0%|          | 0/538 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df3a8dba3ece4f6ea4ec406c4b4ab772",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tokenizing train dataset:   0%|          | 0/538 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "000ce63dc20647f9b5da203b4822699d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Truncating train dataset:   0%|          | 0/538 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17823bae1b2f4289a31ce4cdf14298c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Converting eval dataset to ChatML:   0%|          | 0/135 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a594cd5484e482e8750da51efa04f73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Applying chat template to eval dataset:   0%|          | 0/135 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "881d5d65b3db479fba8dffc9038f372b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tokenizing eval dataset:   0%|          | 0/135 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ed2049d822d4b3eb7a5c731ce40527e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Truncating eval dataset:   0%|          | 0/135 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='13' max='165' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 13/165 00:31 < 07:17, 0.35 it/s, Epoch 0.36/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ---- 3. Define LoRA config ----\n",
    "peft_config = LoraConfig(\n",
    "    r=16,                     # Rank of the update matrices\n",
    "    lora_alpha=32,            # Alpha parameter for LoRA scaling\n",
    "    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\", \"gate_proj\", \"down_proj\", \"up_proj\"],\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\",\n",
    ")\n",
    "\n",
    "# ---- 4. Training args ----\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./sft_lora\",\n",
    "    num_train_epochs=5,            # Increased from 3 to 10 for small dataset\n",
    "    per_device_train_batch_size=2,  # Smaller batch size for more update steps\n",
    "    gradient_accumulation_steps=8,  # Increased to get effective batch size of 16\n",
    "    gradient_checkpointing=True,\n",
    "    optim=\"adamw_torch\",\n",
    "    learning_rate=1e-4,             # Slightly reduced learning rate\n",
    "    warmup_ratio=0.1,               # Add warmup to stabilize early training\n",
    "    weight_decay=0.03,\n",
    "    bf16=True,                      # Use bfloat16 if available\n",
    "    logging_steps=5,                # Log more frequently with small dataset\n",
    "    eval_strategy=\"epoch\",    # Evaluate each epoch\n",
    "    save_strategy=\"epoch\",          # Save each epoch\n",
    "    save_total_limit=3,             # Keep only the best 3 checkpoints\n",
    "    load_best_model_at_end=True,\n",
    "    report_to=\"none\",\n",
    "    remove_unused_columns=False,\n",
    "    # Add early stopping\n",
    "    metric_for_best_model=\"eval_loss\",\n",
    "    greater_is_better=False,\n",
    ")\n",
    "\n",
    "# Split dataset\n",
    "train_size = int(len(dataset) * 0.8)\n",
    "train_dataset = dataset.select(range(train_size))\n",
    "eval_dataset = dataset.select(range(train_size, len(dataset)))\n",
    "    \n",
    "# ---- 5. Launch training ----\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    peft_config=peft_config,\n",
    "    args=training_args\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b91e418b-0801-4a3f-8e20-87344b179ce8",
   "metadata": {},
   "source": [
    "## Save adapter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1d277086-7049-4f42-a0b6-e12ff456ee89",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04d565d9-6ff7-4ed4-9615-a16e338203e7",
   "metadata": {},
   "source": [
    "### Merging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "34dae021-660d-43e0-ae94-3626ab5949c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import PeftModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "31726b78-f7dd-4ff5-a6e5-1ff83d29c739",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/site-packages/peft/tuners/tuners_utils.py:167: UserWarning: Already found a `peft_config` attribute in the model. This will lead to having multiple adapters in the model. Make sure to know what you are doing!\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "peft_model = PeftModel.from_pretrained(model, \"./sft_lora\")\n",
    "merged_model = peft_model.merge_and_unload()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee7294b0-e14c-4977-860e-5b31fd528764",
   "metadata": {},
   "source": [
    "### Test inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "354bb327-42ac-42ac-829e-3a833c6476cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_model = merged_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8cc8e7af-40f7-40b3-92b6-8b0322e8330a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# simple test\n",
    "messages = [\n",
    "  {\"role\": \"system\", \"content\": \"You are a helpful assistant\"},\n",
    "  {\"role\": \"user\", \"content\": \"Give me a short introduction to large language model.\"},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "93db4a2b-d8da-4609-9c98-4ade1b7dd77a",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"\n",
    "You are an expert in Unimarc/XML bibliographic records encoding.\n",
    "Explains how to generate Unimarc records from the following metadata.\n",
    "Then generate the Unimarc/XML record.\n",
    "\"\"\"\n",
    "\n",
    "user_prompt = \"\"\"\n",
    "Title: Electric vehicle tribology\n",
    "Subtitle: Challenges and opportunities for a sustainable transportation future\n",
    "Author: Leonardo I. Farfan-Cabrera, Ali Erdemir\n",
    "Publisher: Elsevier\n",
    "Year: 2024\n",
    "ISBN: 978-0-443-14074-7\n",
    "Language: English\n",
    "Collection/Series: Elsevier Series on Tribology and Surface Engineering\n",
    "Edition: Not specified\n",
    "Material description: 1 vol. (XI-313 p.), couv. ill. en coul., 23 cm\n",
    "Abstract/Notes: \"Electric vehicle tribology, challenges and opportunities for a sustainable transportation future\" provides practical, comprehensive guidance on a new and increasingly important area of tribology. Building skills from fundamentals to solution design, this book demonstrates the unique tribological techniques essential to the efficient electrification of transport systems. Led by professors with a combined three decades in industry and academia, and collecting insights from experts around the world, this book begins with the essential knowledge regarding both electric vehicles and tribology. After outlining the unique tribological needs of EVs, the book then breaks down the components and hardware required. It provides detailed protocols and methods for the testing and improvement of lubricants and materials as well as a dedicated section on modern lubrication specific to EVs. Throughout, it considers the critical question of sustainable tribology and the long-term sustainable options for lubrication and materials for electric vehicles.\n",
    "Source of the abstract/notes: 4e de couverture\n",
    "Table of contents: Not specified\n",
    "Keywords: Tribologie (technologie), Tribologie (Technologie)\n",
    "\"\"\"\n",
    "\n",
    "messages = [\n",
    "  {\"role\": \"system\", \"content\": system_prompt},\n",
    "  {\"role\": \"user\", \"content\": user_prompt},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "66bbd983-8d09-4e03-98fa-51a6d87c43ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer.apply_chat_template(\n",
    "    messages,\n",
    "    return_dict=True,\n",
    "    tokenize = True,\n",
    "    add_generation_prompt = True, # Must add for generation\n",
    "    return_tensors = \"pt\",\n",
    "    enable_thinking=True\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3f61a4da-4160-438b-8761-a441c149d8f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = merged_model.generate(\n",
    "    **inputs,\n",
    "    max_new_tokens = 32768,\n",
    "    use_cache = True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ff49048e-d2c7-484c-8278-5c0ce25ce50d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "system\n",
      "\n",
      "You are an expert in Unimarc/XML bibliographic records encoding.\n",
      "Explains how to generate Unimarc records from the following metadata.\n",
      "Then generate the Unimarc/XML record.\n",
      "\n",
      "user\n",
      "\n",
      "Title: Electric vehicle tribology\n",
      "Subtitle: Challenges and opportunities for a sustainable transportation future\n",
      "Author: Leonardo I. Farfan-Cabrera, Ali Erdemir\n",
      "Publisher: Elsevier\n",
      "Year: 2024\n",
      "ISBN: 978-0-443-14074-7\n",
      "Language: English\n",
      "Collection/Series: Elsevier Series on Tribology and Surface Engineering\n",
      "Edition: Not specified\n",
      "Material description: 1 vol. (XI-313 p.), couv. ill. en coul., 23 cm\n",
      "Abstract/Notes: \"Electric vehicle tribology, challenges and opportunities for a sustainable transportation future\" provides practical, comprehensive guidance on a new and increasingly important area of tribology. Building skills from fundamentals to solution design, this book demonstrates the unique tribological techniques essential to the efficient electrification of transport systems. Led by professors with a combined three decades in industry and academia, and collecting insights from experts around the world, this book begins with the essential knowledge regarding both electric vehicles and tribology. After outlining the unique tribological needs of EVs, the book then breaks down the components and hardware required. It provides detailed protocols and methods for the testing and improvement of lubricants and materials as well as a dedicated section on modern lubrication specific to EVs. Throughout, it considers the critical question of sustainable tribology and the long-term sustainable options for lubrication and materials for electric vehicles.\n",
      "Source of the abstract/notes: 4e de couverture\n",
      "Table of contents: Not specified\n",
      "Keywords: Tribologie (technologie), Tribologie (Technologie)\n",
      "\n",
      "assistant\n",
      "<think>\n",
      "Okay, I need to generate the Unimarc/XML record for the provided bibliographic data. Let me start by understanding the structure of the Unimarc record. The user mentioned the title, subtitle, author, publisher, year, ISBN, collection/series, material description, and other relevant details.\n",
      "\n",
      "First, the main elements: Title and subtitle, Author, Publisher, Year, ISBN, Language (eng), Collection/Series (Elsevier Series on Tribology), Material description includes 1 vol., 313 pages, cover illustrated. Keywords include Tribology and Surface Engineering.\n",
      "\n",
      "I should check the format rules. The XML starts with <<record>> and includes relevant tags. The date is 2024, but the user provided the year as 2024. The abstract/notes are on the cover, so that's part of the content control. The keywords are under the content control.\n",
      "\n",
      "Now, translating the content into the correct Unimarc tags. The title and subtitle are in French, so the language code is eng. The collection is Elsevier Series on Tribology. The material description includes the volume number, pages, and illustrated cover. The keywords are in the content control.\n",
      "\n",
      "I need to ensure proper capitalization and field names. Let me verify each field: Title (French), Subtitle (French), Author (Leonardo I. Farfan-Cabrera, Ali Erdemir), Publisher (Elsevier), Year 2024, ISBN 978-0-443-14074-7, Language eng, Collection/Series (Elsevier Series on Tribology), Material description (1 vol., 313 p.), illustrated cover, Keywords (Tribology, Tribology, Surface Engineering).\n",
      "\n",
      "Finally, structure the XML accordingly, making sure to include the correct tags and attributes as specified.\n",
      "</think>\n",
      "\n",
      "<<record>>  \n",
      "#### Title  \n",
      "Electric vehicle tribology | Challenges and opportunities for a sustainable transportation future  \n",
      "\n",
      "#### Subtitle  \n",
      "Subtitle: Challenges and opportunities for a sustainable transportation future  \n",
      "\n",
      "#### Author  \n",
      "Leonardo I. Farfan-Cabrera, Ali Erdemir  \n",
      "\n",
      "#### Publisher  \n",
      "Elsevier (4e de couverture)  \n",
      "\n",
      "#### Year  \n",
      "2024  \n",
      "\n",
      "#### ISBN  \n",
      "978-0-443-14074-7  \n",
      "\n",
      "#### Language  \n",
      "English (eng)  \n",
      "\n",
      "#### Collection/Series  \n",
      "Elsevier Series on Tribology and Surface Engineering  \n",
      "\n",
      "#### Material description  \n",
      "1 vol. (XI-313 p.), couv. ill., 23 cm  \n",
      "\n",
      "#### Keywords  \n",
      "Tribology, Tribology (Technologie)  \n",
      "\n",
      "#### Control fields  \n",
      "\n",
      "- **Keywords:** Tribology (technologie), Tribology (Technologie)  \n",
      "- **Content control:** 4e de couverture (4e de couverture)  \n",
      "\n",
      "<< /record >>\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.decode(outputs[0], skip_special_tokens=True))\n",
    "# or tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "85fff40c-e05e-4a49-beda-8aa175b2f266",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<think>\n",
      "Okay, the user is asking for a short introduction to a large language model. I need to make sure I cover the key points without being too technical. Let me start by recalling what a large language model is. They are AI systems trained on vast amounts of text data, like books, articles, or internet sources. These models can understand and generate human-like text, perform tasks like answering questions, summarizing articles, or even creating creative content. I should mention their capabilities, like understanding context, language nuances, and generating coherent responses. Also, emphasize their use cases, such as writing, translation, or customer support. Keep it concise, around a paragraph. Avoid jargon but still sound informative. Check if there's any specific detail they want to include, but since they didn't ask for specifics, a general introduction should suffice.\n",
      "</think>\n",
      "\n",
      "A large language model (LLM) is an artificial intelligence system designed to understand and generate human-like text based on vast datasets of natural language. These models, trained on corpora of books, articles, or web content, can comprehend context, grasp nuances, and understand grammar and syntax. They can answer questions, summarize texts, create creative content, or assist with translation, among other tasks. Unlike traditional AI models, LLMs are capable of evolving and adapting to new data, making them versatile tools for various applications.\n"
     ]
    }
   ],
   "source": [
    "generated_ids = [\n",
    "   output_ids[len(input_ids):] for input_ids, output_ids in zip(inputs.input_ids, outputs)\n",
    "]\n",
    "print(tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6b9fca92-0aa7-4715-a1bb-edfedce7cff1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thinking content: <think>\n",
      "Okay, I need to generate the Unimarc/XML record from the provided metadata. Let me start by recalling the structure of the Unimarc record. The fields are usually titled as follows:\n",
      "\n",
      "- Title (title field)\n",
      "- Author (author field)\n",
      "- Publisher (publisher)\n",
      "- Year (year)\n",
      "- ISBN (isbn field)\n",
      "- Collection/Series (collection)\n",
      "- Material description (material description)\n",
      "- Abstract/Notes (abstract/notes)\n",
      "\n",
      "The user provided the title, author, publisher, year, ISBN, collection, material description, and keywords. Also, the source of the abstract/notes is mentioned as 4e de couverture, which is a note about the cover page.\n",
      "\n",
      "I need to check the exact numbering of the fields. The Unimarc record typically has 13 fields, but sometimes the order can be different. Let me confirm:\n",
      "\n",
      "- 1: Title (title)\n",
      "- 2: Author (author)\n",
      "- 3: Publisher (publisher)\n",
      "- 4: Year (year)\n",
      "- 5: ISBN (isbn)\n",
      "- 6: Collection/Series (collection)\n",
      "- 7: Material description (material)\n",
      "- 8: Abstract/Notes (abstract/notes)\n",
      "- 9: Keywords (keyword)\n",
      "- 10: Source of abstract/notes (source)\n",
      "- 11: Notes on the source (note)\n",
      "- 12: Notes on the source (another note)\n",
      "- 13: Notes on the source (third note)\n",
      "\n",
      "Wait, the user's provided abstract/notes are already part of the source field. So the 10th and 11th fields would be the source and note. But the user mentioned \"Source of the abstract/notes: 4e de couverture\" which is a note. So the 10th field is the source, and the 11th is the note. However, the original data has the source as the 4th field. So the structure is:\n",
      "\n",
      "1: Title\n",
      "2: Author\n",
      "3: Publisher\n",
      "4: Year\n",
      "5: ISBN\n",
      "6: Collection/Series\n",
      "7: Material description\n",
      "8: Abstract/Notes (source)\n",
      "9: Keywords\n",
      "10: Source of abstract/notes\n",
      "11: Notes on the source\n",
      "12: Notes on the source\n",
      "13: Notes on the source\n",
      "\n",
      "But the user's data shows that the source is already in the abstract/notes field. So maybe the 8th and 10th fields are the source and note. Let me check again.\n",
      "\n",
      "The original data provided by the user includes:\n",
      "\n",
      "- Source of abstract/notes: 4e de couverture\n",
      "- Notes: (not provided in the original data, just the 4e)\n",
      "\n",
      "So the Unimarc fields would be:\n",
      "\n",
      "1: Title: Electric vehicle tribology\n",
      "2: Author: Leonardo I. Farfan-Cabrera, Ali Erdemir\n",
      "3: Publisher: Elsevier\n",
      "4: Year: 2024\n",
      "5: ISBN: 978-0-443-14074-7\n",
      "6: Collection/Series: Elsevier Series on Tribology and Surface Engineering\n",
      "7: Material description: 1 vol. (XI-313 p.), couv. ill., 23 cm\n",
      "8: Abstract/Notes: 4e de couverture\n",
      "9: Keywords: Tribologie (technologie)\n",
      "10: Source of abstract/notes: 4e de couverture\n",
      "11: Notes on the source: couv. ill.\n",
      "12: Notes on the source: 23 cm\n",
      "13: Notes on the source: 4e de couverture\n",
      "\n",
      "Wait, but the original data doesn't have the 11th and 12th fields. The user only provided the 4th and 8th fields. Maybe there are more notes. The user's input includes:\n",
      "\n",
      "- \"Source of the abstract/notes: 4e de couverture\" (so 4e is the source)\n",
      "- \"Notes: Not specified\" (but the 4e is the source)\n",
      "\n",
      "So the 10th field is the source, and the 11th and 12th are the note fields. But the original data only includes 4e and couv. ill. So perhaps the 10th field is the source, and the 11th is the note. The user might have made a typo, but I'll follow the given data.\n",
      "\n",
      "Now, putting it all together into the Unimarc/XML format. The fields are as follows:\n",
      "\n",
      "- Title: Electric vehicle tribology\n",
      "- Author: Leonardo I. Farfan-Cabrera, Ali Erdemir\n",
      "- Publisher: Elsevier\n",
      "- Year: 2024\n",
      "- ISBN: 978-0-443-14074-7\n",
      "- Collection/Series: Elsevier Series on Tribology and Surface Engineering\n",
      "- Material description: 1 vol. (XI-313 p.), couv. ill., 23 cm\n",
      "- Abstract/Notes: 4e de couverture\n",
      "- Keywords: Tribologie (technologie)\n",
      "\n",
      "The source of the abstract/notes is in the 4th field, and the notes are in the 8th field.\n",
      "\n",
      "I think that's all. Now, I need to format this into the Unimarc record. Let me check the exact codes again. The Unimarc fields for the record would be as follows:\n",
      "\n",
      "1. Title: [Electric vehicle tribology]\n",
      "2. Author: [Leonardo I. Farfan-Cabrera, Ali Erdemir]\n",
      "3. Publisher: Elsevier\n",
      "4. Year: 2024\n",
      "5. ISBN: 978-0-443-14074-7\n",
      "6. Collection/Series: Elsevier Series on Tribology and Surface Engineering\n",
      "7. Material description: 1 vol. (XI-313 p.), couv. ill., 23 cm\n",
      "8. Abstract/Notes: 4e de couverture\n",
      "9. Keywords: Tribologie (technologie)\n",
      "10. Source of abstract/notes: 4e de couverture\n",
      "11. Notes on the source: couv. ill.\n",
      "12. Notes on the source: 23 cm\n",
      "13. Notes on the source: 4e de couverture\n",
      "\n",
      "Yes, that's correct. Now, I need to present this in the required Unimarc/XML format, making sure the numbers are correctly placed and the fields are properly labeled.\n",
      "</think>\n",
      "content: ```xml\n",
      "<record><controlfield tag=\"005\">20250212153703.000</controlfield><datafield tag=\"035\" ind1=\" \" ind2=\" \"><subfield code=\"a\">(text)</subfield><subfield code=\"b\">Electric vehicle tribology</subfield><subfield code=\"b\">2024</subfield></datafield><datafield tag=\"033\" ind1=\" \" ind2=\" \"><subfield code=\"a\">978-0-443-14074-7</subfield><subfield code=\"b\">isbn</subfield></datafield><datafield tag=\"100\" ind1=\" \" ind2=\" \"><subfield code=\"a\">A</subfield><subfield code=\"2\">Leonardo I. Farfan-Cabrera</subfield><subfield code=\"2\">Ali Erdemir</subfield></datafield><datafield tag=\"101\" ind1=\"0\" ind2=\" \"><subfield code=\"a\">X</subfield><subfield code=\"2\">2024</subfield></datafield><datafield tag=\"101\" ind1=\"0\" ind2=\" \"><subfield code=\"a\">Y</subfield><subfield code=\"2\">4</subfield></datafield><datafield tag=\"105\" ind1=\" \" ind2=\" \"><subfield code=\"a\">4e</subfield><subfield code=\"2\">de couv.</subfield></datafield><datafield tag=\"106\" ind1=\" \" ind2=\" \"><subfield code=\"a\">23 cm</subfield></datafield><datafield tag=\"180\" ind1=\" \" ind2=\" \"><subfield code=\"a\">1</subfield><subfield code=\"2\">XI</subfield><subfield code=\"2\">313</subfield></datafield><datafield tag=\"181\" ind1=\" \" ind2=\" \"><subfield code=\"a\">313</subfield></datafield><datafield tag=\"181\" ind1=\" \" ind2=\" \"><subfield code=\"a\">couv</subfield></datafield><datafield tag=\"181\" ind1=\" \" ind2=\" \"><subfield code=\"a\">ill.</subfield></datafield><datafield tag=\"185\" ind1=\" \" ind2=\" \"><subfield code=\"a\">23 cm</subfield></datafield><datafield tag=\"185\" ind1=\" \" ind2=\" \"><subfield code=\"a\">23 cm</subfield></datafield><datafield tag=\"191\" ind1=\" \" ind2=\" \"><subfield code=\"a\">2</subfield><subfield code=\"2\">4</subfield></datafield><datafield tag=\"191\" ind1=\" \" ind2=\" \"><subfield code=\"a\">4e</subfield><subfield code=\"2\">de</subfield></datafield><datafield tag=\"191\" ind1=\" \" ind2=\" \"><subfield code=\"a\">23 cm</subfield></datafield><datafield tag=\"191\" ind1=\" \" ind2=\" \"><subfield code=\"a\">4e</subfield></datafield><datafield tag=\"200\" ind1=\" \" ind2=\" \"><subfield code=\"a\">R</subfield><subfield code=\"2\">2</subfield></datafield><datafield tag=\"205\" ind1=\" \" ind2=\" \"><subfield code=\"a\">4e</subfield></datafield><datafield tag=\"205\" ind1=\" \" ind2=\" \"><subfield code=\"a\">de</subfield></datafield><datafield tag=\"205\" ind1=\" \" ind2=\" \"><subfield code=\"a\">23 cm</subfield></datafield></record>\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "output_ids = outputs[0][len(inputs.input_ids[0]):].tolist()\n",
    "# parsing thinking content\n",
    "try:\n",
    "    # rindex finding 151668 (</think>)\n",
    "    index = len(output_ids) - output_ids[::-1].index(151668)\n",
    "except ValueError:\n",
    "    index = 0\n",
    "\n",
    "thinking_content = tokenizer.decode(output_ids[:index], skip_special_tokens=True).strip(\"\\n\")\n",
    "content = tokenizer.decode(output_ids[index:], skip_special_tokens=True).strip(\"\\n\")\n",
    "\n",
    "print(\"thinking content:\", thinking_content)\n",
    "print(\"content:\", content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e201b84b-dc33-453a-85ca-65494aa26331",
   "metadata": {},
   "source": [
    "### Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3627df69-0972-4325-96ec-d7c8ef7475f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./qwen3_unimarc_model/tokenizer_config.json',\n",
       " './qwen3_unimarc_model/special_tokens_map.json',\n",
       " './qwen3_unimarc_model/vocab.json',\n",
       " './qwen3_unimarc_model/merges.txt',\n",
       " './qwen3_unimarc_model/added_tokens.json',\n",
       " './qwen3_unimarc_model/tokenizer.json')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_model.save_pretrained(\"./qwen3_unimarc_model\")\n",
    "tokenizer.save_pretrained(\"./qwen3_unimarc_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f2218eb8-0745-478f-bfa9-b59933ab079e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "model.safetensors: 100%|██████████| 1.19G/1.19G [00:45<00:00, 25.9MB/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/Geraldine/Qwen3-0.6B-finetuned-unimarc-reasoning/commit/16f4538ea8fb96da752c14ae8b89ad447c005c06', commit_message='Upload Qwen3ForCausalLM', commit_description='', oid='16f4538ea8fb96da752c14ae8b89ad447c005c06', pr_url=None, repo_url=RepoUrl('https://huggingface.co/Geraldine/Qwen3-0.6B-finetuned-unimarc-reasoning', endpoint='https://huggingface.co', repo_type='model', repo_id='Geraldine/Qwen3-0.6B-finetuned-unimarc-reasoning'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_model.push_to_hub(f\"Geraldine/Qwen3-0.6B-finetuned-unimarc-reasoning\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9d40c86c-ee3c-4623-bce6-eb3532b7e755",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tokenizer.json: 100%|██████████| 11.4M/11.4M [00:00<00:00, 29.9MB/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/Geraldine/Qwen3-0.6B-finetuned-unimarc-reasoning/commit/ba3c695f452717db81ce7ff30851cf392a67f866', commit_message='Upload tokenizer', commit_description='', oid='ba3c695f452717db81ce7ff30851cf392a67f866', pr_url=None, repo_url=RepoUrl('https://huggingface.co/Geraldine/Qwen3-0.6B-finetuned-unimarc-reasoning', endpoint='https://huggingface.co', repo_type='model', repo_id='Geraldine/Qwen3-0.6B-finetuned-unimarc-reasoning'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.push_to_hub(f\"Geraldine/Qwen3-0.6B-finetuned-unimarc-reasoning\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d201191-01cb-4ee2-9189-e89f511cfe98",
   "metadata": {},
   "source": [
    "## Distillation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3cb27dc-d246-4c74-aef3-7d877929a723",
   "metadata": {},
   "source": [
    "### Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c907b043-b85f-42bd-a4f8-b6e8b55918c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e628fc542d2642dea870b2ba5d45c323",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/673 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['messages'],\n",
       "    num_rows: 673\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Distillation\n",
    "system_message = \"\"\"\n",
    "You are an expert bibliographic cataloguer specialized in Unimarc/XML.\n",
    "Given bibliographic metadata, your task is to generate the corresponding Unimarc/XML bibliographic record.\"\"\"\n",
    "\n",
    "def create_conversation(row):\n",
    "  return {\n",
    "    \"messages\": [\n",
    "      {\"role\": \"system\", \"content\": system_message + \" /think\"},\n",
    "      {\"role\": \"user\", \"content\": f\"# Bibliographical metadata:\\n{row['metadata']}\"},\n",
    "      {\"role\": \"assistant\", \"content\": f\"<think>{row['reasoning']}</think>. Final answer: {row['unimarc_record']}\"}\n",
    "    ]\n",
    "  }\n",
    "\n",
    "dataset = dataset.map(create_conversation, remove_columns=dataset.features)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4300654f-5977-4fe7-9ea3-528b3a4d6165",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8d244c9e-1453-4154-a56f-51ed9affddef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_with_distillation(output_dir, model_name=\"Qwen/Qwen3-0.6B\", device=\"cuda\", lora=False):\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=True)\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        model_name,\n",
    "        torch_dtype=\"auto\",\n",
    "        device_map=\"auto\",\n",
    "        attn_implementation=\"flash_attention_2\"\n",
    "    )\n",
    "    model = model.to(device)\n",
    "    # !Important\n",
    "    tokenizer.padding_side = \"right\"\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "    # Apply LoRA if selected\n",
    "    if lora:\n",
    "        # Configure LoRA\n",
    "        lora_config = LoraConfig(\n",
    "            r=16,                     # Rank of the update matrices\n",
    "            lora_alpha=32,            # Alpha parameter for LoRA scaling\n",
    "            target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\", \"gate_proj\", \"down_proj\", \"up_proj\"],\n",
    "            lora_dropout=0.05,\n",
    "            bias=\"none\",\n",
    "            task_type=\"CAUSAL_LM\",\n",
    "        )\n",
    "        \n",
    "        # Prepare model for PEFT\n",
    "        model = prepare_model_for_kbit_training(model)\n",
    "        model = get_peft_model(model, lora_config)\n",
    "        model.print_trainable_parameters()  # Log the trainable parameters percentage\n",
    "    \n",
    "    # Define training arguments\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=output_dir,\n",
    "        num_train_epochs=30,            # Increased from 3 to 10 for small dataset\n",
    "        per_device_train_batch_size=2,  # Smaller batch size for more update steps\n",
    "        gradient_accumulation_steps=8,  # Increased to get effective batch size of 16\n",
    "        gradient_checkpointing=True,\n",
    "        optim=\"adamw_torch\",\n",
    "        learning_rate=1e-4,             # Slightly reduced learning rate\n",
    "        warmup_ratio=0.1,               # Add warmup to stabilize early training\n",
    "        weight_decay=0.01,\n",
    "        bf16=True,                      # Use bfloat16 if available\n",
    "        logging_steps=5,                # Log more frequently with small dataset\n",
    "        eval_strategy=\"epoch\",    # Evaluate each epoch\n",
    "        save_strategy=\"epoch\",          # Save each epoch\n",
    "        save_total_limit=3,             # Keep only the best 3 checkpoints\n",
    "        load_best_model_at_end=True,\n",
    "        report_to=\"none\",\n",
    "        remove_unused_columns=False,\n",
    "        # Add early stopping\n",
    "        metric_for_best_model=\"eval_loss\",\n",
    "        greater_is_better=False,\n",
    "    )\n",
    "    \n",
    "    # Split dataset\n",
    "    train_size = int(len(dataset) * 0.9)\n",
    "    train_dataset = dataset.select(range(train_size))\n",
    "    eval_dataset = dataset.select(range(train_size, len(dataset)))\n",
    "    \n",
    "    # Set up the SFTTrainer\n",
    "    trainer = SFTTrainer(\n",
    "        model=model,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=eval_dataset,\n",
    "        args=training_args,\n",
    "        peft_config=lora_config if lora else None,\n",
    "        #max_seq_length=32768,\n",
    "        )\n",
    "    \n",
    "    # Train the model\n",
    "    trainer.train()\n",
    "    \n",
    "    # Save the model\n",
    "    if lora:\n",
    "        model.save_pretrained(f\"{output_dir}/final_model\")\n",
    "    else:\n",
    "        trainer.save_model(f\"{output_dir}/final_model\")\n",
    "    tokenizer.save_pretrained(f\"{output_dir}/final_model\")\n",
    "    \n",
    "    return model, tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3eb87a9e-4db5-493a-8c87-3e35b6e305bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aec1ff5917dd413abf7f031e0c4260e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Converting train dataset to ChatML:   0%|          | 0/605 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98ae203547384a8ca65fa4705d5311f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Applying chat template to train dataset:   0%|          | 0/605 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "566eff4315a84063bbac46ef252e58fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tokenizing train dataset:   0%|          | 0/605 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c9381421961415d96f07b9ba3175fad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Truncating train dataset:   0%|          | 0/605 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc9ed9d0c1064d588db1c9fe9f249cd4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Converting eval dataset to ChatML:   0%|          | 0/68 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f54424bdb66467cb579d20ebd4dce75",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Applying chat template to eval dataset:   0%|          | 0/68 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a2aec495c5349bebe1afc2312dfebce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tokenizing eval dataset:   0%|          | 0/68 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "254d3c505a3a4cac922968a54c938b22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Truncating eval dataset:   0%|          | 0/68 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='469' max='1110' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 469/1110 16:24 < 22:31, 0.47 it/s, Epoch 12.63/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.686100</td>\n",
       "      <td>1.628744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.372700</td>\n",
       "      <td>1.443199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.180600</td>\n",
       "      <td>1.434778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.933500</td>\n",
       "      <td>1.480197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.755300</td>\n",
       "      <td>1.588010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.520900</td>\n",
       "      <td>1.710018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.381400</td>\n",
       "      <td>1.881822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.282600</td>\n",
       "      <td>2.006584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.193200</td>\n",
       "      <td>2.132270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.148900</td>\n",
       "      <td>2.222727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.108600</td>\n",
       "      <td>2.317419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.083300</td>\n",
       "      <td>2.396006</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m new_model, tokenizer \u001b[38;5;241m=\u001b[39m train_with_distillation(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./sft_distill\u001b[39m\u001b[38;5;124m\"\u001b[39m, lora\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "Cell \u001b[0;32mIn[8], line 70\u001b[0m, in \u001b[0;36mtrain_with_distillation\u001b[0;34m(output_dir, model_name, device, lora)\u001b[0m\n\u001b[1;32m     60\u001b[0m trainer \u001b[38;5;241m=\u001b[39m SFTTrainer(\n\u001b[1;32m     61\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m     62\u001b[0m     train_dataset\u001b[38;5;241m=\u001b[39mtrain_dataset,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[38;5;66;03m#max_seq_length=32768,\u001b[39;00m\n\u001b[1;32m     67\u001b[0m     )\n\u001b[1;32m     69\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m trainer\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m     72\u001b[0m \u001b[38;5;66;03m# Save the model\u001b[39;00m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m lora:\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/transformers/trainer.py:2245\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   2243\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   2244\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2245\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m inner_training_loop(\n\u001b[1;32m   2246\u001b[0m         args\u001b[38;5;241m=\u001b[39margs,\n\u001b[1;32m   2247\u001b[0m         resume_from_checkpoint\u001b[38;5;241m=\u001b[39mresume_from_checkpoint,\n\u001b[1;32m   2248\u001b[0m         trial\u001b[38;5;241m=\u001b[39mtrial,\n\u001b[1;32m   2249\u001b[0m         ignore_keys_for_eval\u001b[38;5;241m=\u001b[39mignore_keys_for_eval,\n\u001b[1;32m   2250\u001b[0m     )\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/transformers/trainer.py:2560\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2553\u001b[0m context \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   2554\u001b[0m     functools\u001b[38;5;241m.\u001b[39mpartial(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39mno_sync, model\u001b[38;5;241m=\u001b[39mmodel)\n\u001b[1;32m   2555\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(batch_samples) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   2556\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39mdistributed_type \u001b[38;5;241m!=\u001b[39m DistributedType\u001b[38;5;241m.\u001b[39mDEEPSPEED\n\u001b[1;32m   2557\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m contextlib\u001b[38;5;241m.\u001b[39mnullcontext\n\u001b[1;32m   2558\u001b[0m )\n\u001b[1;32m   2559\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m context():\n\u001b[0;32m-> 2560\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining_step(model, inputs, num_items_in_batch)\n\u001b[1;32m   2562\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   2563\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[1;32m   2564\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_xla_available()\n\u001b[1;32m   2565\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misinf(tr_loss_step))\n\u001b[1;32m   2566\u001b[0m ):\n\u001b[1;32m   2567\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[1;32m   2568\u001b[0m     tr_loss \u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m+\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/transformers/trainer.py:3782\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   3779\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39mdistributed_type \u001b[38;5;241m==\u001b[39m DistributedType\u001b[38;5;241m.\u001b[39mDEEPSPEED:\n\u001b[1;32m   3780\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscale_wrt_gas\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m-> 3782\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39mbackward(loss, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   3784\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\u001b[38;5;241m.\u001b[39mdetach()\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/accelerate/accelerator.py:2454\u001b[0m, in \u001b[0;36mAccelerator.backward\u001b[0;34m(self, loss, **kwargs)\u001b[0m\n\u001b[1;32m   2452\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlomo_backward(loss, learning_rate)\n\u001b[1;32m   2453\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2454\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/torch/_tensor.py:581\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    571\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    572\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    573\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    574\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    579\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    580\u001b[0m     )\n\u001b[0;32m--> 581\u001b[0m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mbackward(\n\u001b[1;32m    582\u001b[0m     \u001b[38;5;28mself\u001b[39m, gradient, retain_graph, create_graph, inputs\u001b[38;5;241m=\u001b[39minputs\n\u001b[1;32m    583\u001b[0m )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/torch/autograd/__init__.py:347\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    342\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    344\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    345\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 347\u001b[0m _engine_run_backward(\n\u001b[1;32m    348\u001b[0m     tensors,\n\u001b[1;32m    349\u001b[0m     grad_tensors_,\n\u001b[1;32m    350\u001b[0m     retain_graph,\n\u001b[1;32m    351\u001b[0m     create_graph,\n\u001b[1;32m    352\u001b[0m     inputs,\n\u001b[1;32m    353\u001b[0m     allow_unreachable\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    354\u001b[0m     accumulate_grad\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    355\u001b[0m )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/torch/autograd/graph.py:825\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    823\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    824\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 825\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Variable\u001b[38;5;241m.\u001b[39m_execution_engine\u001b[38;5;241m.\u001b[39mrun_backward(  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    826\u001b[0m         t_outputs, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m    827\u001b[0m     )  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    828\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    829\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "new_model, tokenizer = train_with_distillation(\"./sft_distill\", lora=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19f21303-130f-448a-b834-5a4b06d4e649",
   "metadata": {},
   "source": [
    "### Test inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3768b13f-7c4c-495e-9dfe-5ba849f4ef14",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_eval = load_dataset(\"Geraldine/Unimarc-iln050-5k\", split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a346977c-5ca7-49c0-8d0e-9c3de5fd1150",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_response(system_prompt, user_prompt, model=new_model, tokenizer=tokenizer):\n",
    "    \n",
    "    # Create chat message format like your training data\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_promp},\n",
    "        {\"role\": \"user\", \"content\": user_prompt}\n",
    "    ]\n",
    "    \n",
    "    # Tokenize and generate\n",
    "    inputs = tokenizer.apply_chat_template(\n",
    "        messages,\n",
    "        return_dict=True,\n",
    "        tokenize = True,\n",
    "        add_generation_prompt = True, # Must add for generation\n",
    "        return_tensors = \"pt\",\n",
    "        enable_thinking=True\n",
    "    ).to(device)\n",
    "    \n",
    "    # Generate response\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens = 32768,\n",
    "            use_cache = True,\n",
    "        )\n",
    "    \n",
    "    # Decode response\n",
    "    response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    \n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fbc0440-9c85-4750-9727-fd062f17978e",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"You are an expert bibliographic cataloguer specialized in Unimarc/XML.\n",
    "Generate an Unimarc/XML bibliographic record from the given bibliographic metadata\"\"\"\n",
    "user_prompt = dataset_eval[0][\"question\"]\n",
    "\n",
    "response = generate_response(system_prompt, user_prompt, model=new_model, tokenizer=tokenizer)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0480fb14-b01c-42fb-a766-0babb82239a7",
   "metadata": {},
   "source": [
    "# Two-Step Training (Swappable LoRA Adapters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "33e6efce-6819-4a66-b9a2-903b8a3890ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM, TrainingArguments\n",
    "from trl import SFTTrainer\n",
    "from peft import LoraConfig\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a07e3324-afcc-4840-9461-32dca72ed9ad",
   "metadata": {},
   "source": [
    "## Train lora_trace Adapter (Text → Trace)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9b4b5dd-1d62-494b-875e-fd560f377ebb",
   "metadata": {},
   "source": [
    "### Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8bf7954f-a402-472f-ac64-6c230f3c0abc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 173/173 [00:00<00:00, 2180.10 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['messages'],\n",
       "    num_rows: 173\n",
       "})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "system_message = \"\"\"You are an expert assistant in cataloging and Unimarc/XML standards. \n",
    "Your task is to explain how to generate Unimarc/XML fields from bibliographic data using structured reasoning. \"\"\"\n",
    "def create_conversation(row):\n",
    "  return {\n",
    "    \"messages\": [\n",
    "      {\"role\": \"system\", \"content\": system_message + \" /think\"},\n",
    "      {\"role\": \"user\", \"content\": f\"# Bibliographical metadata:\\n{row['metadata']}\\n\\n# Unimarc/XML record:\\n{row['unimarc_record']}\"},\n",
    "      {\"role\": \"assistant\", \"content\": row[\"reasoning\"]} # to avoid infinite generation\n",
    "    ]\n",
    "  }\n",
    "\n",
    "dataset = dataset.map(create_conversation, remove_columns=dataset.features, batched=False)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dcb5b2d-5b96-4ade-bf2f-0c3445e4f913",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = \"\"\"You are an expert assistant in cataloging and Unimarc/XML standards. \n",
    "Your task is to explain how to generate Unimarc/XML fields from bibliographic data\"\"\"\n",
    "def create_conversation(row):\n",
    "  return {\n",
    "    \"messages\": [\n",
    "      {\"role\": \"system\", \"content\": system_message + \" /think\"},\n",
    "      {\"role\": \"user\", \"content\": f\"# Bibliographical metadata:\\n{row['metadata']}\\n\\n# Unimarc/XML record:\\n{row['unimarc_record']}\"},\n",
    "      {\"role\": \"assistant\", \"content\": row[\"reasoning\"]} # to avoid infinite generation\n",
    "    ]\n",
    "  }\n",
    "\n",
    "dataset = dataset.map(create_conversation, remove_columns=dataset.features, batched=False)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bdc9105-ed3a-442a-bfbe-859981519aa2",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "3d9f8c4f-6cad-4c58-a362-cbbfae50760c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting train dataset to ChatML: 100%|██████████| 173/173 [00:00<00:00, 3676.68 examples/s]\n",
      "Applying chat template to train dataset: 100%|██████████| 173/173 [00:00<00:00, 1979.72 examples/s]\n",
      "Tokenizing train dataset: 100%|██████████| 173/173 [00:03<00:00, 53.17 examples/s]\n",
      "Truncating train dataset: 100%|██████████| 173/173 [00:00<00:00, 17814.80 examples/s]\n",
      "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
     ]
    }
   ],
   "source": [
    "# ---- 3. Define LoRA config ----\n",
    "peft_config = LoraConfig(\n",
    "    r=8,\n",
    "    lora_alpha=32,\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\",\n",
    "    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\"] # may vary based on model, check with `model.named_modules()` in previous cell\n",
    ")\n",
    "\n",
    "# ---- 4. Training args ----\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./sft_lora_trace\",\n",
    "    per_device_train_batch_size=1,\n",
    "    gradient_accumulation_steps=4,\n",
    "    logging_steps=10,\n",
    "    save_strategy=\"epoch\",\n",
    "    num_train_epochs=30,\n",
    "    learning_rate=5e-5,\n",
    "    fp16=True,\n",
    "    report_to=\"none\"\n",
    ")\n",
    "\n",
    "# ---- 5. Launch training ----\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    train_dataset=dataset,\n",
    "    peft_config=peft_config,\n",
    "    args=training_args\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "c968e1ef-8dce-4f93-be34-9caaab1803de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1290' max='1290' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1290/1290 57:30, Epoch 29/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>2.257600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>2.059800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>2.010000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1.870200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.759400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>1.615700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>1.523400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>1.586800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>1.428100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.453600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>1.509700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>1.441500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>1.351200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>1.359300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1.312100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>1.324500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>1.464200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>1.283000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>1.271900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1.283900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>1.392300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>1.359500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>1.361600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>1.308300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>1.249800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>1.199000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>1.327700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>1.180700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>1.279800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>1.268500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>1.304300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>1.231700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>1.255600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>1.242600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>1.202700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>1.304100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>370</td>\n",
       "      <td>1.201600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>1.221500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>390</td>\n",
       "      <td>1.232600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>1.119500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>410</td>\n",
       "      <td>1.153700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>1.181500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>430</td>\n",
       "      <td>1.322700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>440</td>\n",
       "      <td>1.162500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>1.141600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>460</td>\n",
       "      <td>1.236100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>470</td>\n",
       "      <td>1.167800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>1.159100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>490</td>\n",
       "      <td>1.283100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>1.213700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>510</td>\n",
       "      <td>1.159800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>520</td>\n",
       "      <td>1.135300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>530</td>\n",
       "      <td>1.110400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>1.177100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>1.147400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>560</td>\n",
       "      <td>1.222600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>570</td>\n",
       "      <td>1.091700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>580</td>\n",
       "      <td>1.144200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>590</td>\n",
       "      <td>1.093900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>1.228600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>610</td>\n",
       "      <td>1.187900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>620</td>\n",
       "      <td>1.119300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>630</td>\n",
       "      <td>1.109900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>640</td>\n",
       "      <td>1.178100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>1.154000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>660</td>\n",
       "      <td>1.053100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>670</td>\n",
       "      <td>1.179600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>680</td>\n",
       "      <td>1.053900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>690</td>\n",
       "      <td>1.059700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>1.151000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>710</td>\n",
       "      <td>1.176000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>720</td>\n",
       "      <td>1.063900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>730</td>\n",
       "      <td>1.103400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>740</td>\n",
       "      <td>1.121000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>1.075800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>760</td>\n",
       "      <td>1.101700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>770</td>\n",
       "      <td>1.102900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>780</td>\n",
       "      <td>1.057400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>790</td>\n",
       "      <td>1.125400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>1.093300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>810</td>\n",
       "      <td>1.073900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>820</td>\n",
       "      <td>1.081300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>830</td>\n",
       "      <td>1.075900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>840</td>\n",
       "      <td>1.128900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>1.124900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>860</td>\n",
       "      <td>1.132900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>870</td>\n",
       "      <td>1.001500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>880</td>\n",
       "      <td>1.090600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>890</td>\n",
       "      <td>0.989100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>1.139000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>910</td>\n",
       "      <td>1.069500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>920</td>\n",
       "      <td>1.108100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>930</td>\n",
       "      <td>1.036000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>940</td>\n",
       "      <td>1.023000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>1.036800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>960</td>\n",
       "      <td>1.023600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>970</td>\n",
       "      <td>1.124700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>980</td>\n",
       "      <td>1.095100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>990</td>\n",
       "      <td>1.044700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>1.032800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1010</td>\n",
       "      <td>1.033600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1020</td>\n",
       "      <td>1.104400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1030</td>\n",
       "      <td>0.997200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1040</td>\n",
       "      <td>1.049900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1050</td>\n",
       "      <td>1.105300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1060</td>\n",
       "      <td>1.065900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1070</td>\n",
       "      <td>0.965400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1080</td>\n",
       "      <td>1.069100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1090</td>\n",
       "      <td>1.042000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>1.084800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1110</td>\n",
       "      <td>1.105200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1120</td>\n",
       "      <td>1.036000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1130</td>\n",
       "      <td>1.004100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1140</td>\n",
       "      <td>0.986500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1150</td>\n",
       "      <td>1.054000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1160</td>\n",
       "      <td>1.049300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1170</td>\n",
       "      <td>1.010700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1180</td>\n",
       "      <td>1.000900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1190</td>\n",
       "      <td>1.068700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.994600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1210</td>\n",
       "      <td>1.056900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1220</td>\n",
       "      <td>1.037600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1230</td>\n",
       "      <td>1.025000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1240</td>\n",
       "      <td>1.017200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1250</td>\n",
       "      <td>1.035100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1260</td>\n",
       "      <td>1.023400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1270</td>\n",
       "      <td>0.994800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1280</td>\n",
       "      <td>1.105000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1290</td>\n",
       "      <td>1.009000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1290, training_loss=1.192039508228154, metrics={'train_runtime': 3453.4002, 'train_samples_per_second': 1.503, 'train_steps_per_second': 0.374, 'total_flos': 1.3800208274030592e+16, 'train_loss': 1.192039508228154})"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0f61e68-0def-4bbf-a87e-f3a8e742ee7e",
   "metadata": {},
   "source": [
    "### Save adapter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "91449f14-9eb8-41d2-9e61-b00671db2275",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9716e5b-3d69-4953-b777-96d315e1f992",
   "metadata": {},
   "source": [
    "### Test inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "cda389b5-0fed-4645-bfc5-2edc046a02f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import PeftModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "1c61d94f-34b0-4930-b7a8-8af92fbf7190",
   "metadata": {},
   "outputs": [],
   "source": [
    "peft_model_id = \"./sft_lora_trace\"\n",
    "tr_model_id = \"Qwen/Qwen3-0.6B\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "3e59cb04-56b6-4e7a-98b4-d05bb94877d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(tr_model_id, trust_remote_code=True, torch_dtype=torch.float16,\n",
    "     low_cpu_mem_usage=True,)\n",
    "model = PeftModel.from_pretrained(model, peft_model_id)\n",
    "merged_model = model.merge_and_unload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "00f0ef26-7d19-4a60-8048-0715a1cc0e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_model = merged_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "709e1910-a0dd-46b2-98c2-83b92375b804",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"\n",
    "You are a helpful assistant expert in Unimarc/XML bibliographic records.\n",
    "\"\"\"\n",
    "\n",
    "user_prompt = \"\"\"\n",
    "# Bibliographical metadata\n",
    "Title: Traverser\n",
    "Subtitle: = Crossings\n",
    "Author: Marie Liénard-Yeterian, Valérie Simon\n",
    "Author (authorized access point): Liénard-Yeterian, Marie; Simon, Valérie\n",
    "Language of text: French (fre), with English (eng) parallel title and content indicated\n",
    "Title in English: Crossings\n",
    "Country of publication: France (FR)\n",
    "Publisher: Skepsi Editions La Pensée\n",
    "Place of publication: [Caen]\n",
    "Date of publication: DL 2024 (date of legal deposit 2024)\n",
    "Physical description: 1 volume (86 pages)\n",
    "Illustrations: Photographic illustrations in color, both within and outside the text\n",
    "Dimensions: 24 cm\n",
    "ISBN: 978-29-595-9903-3\n",
    "Source of control number: http://www.sudoc.fr/283499370\n",
    "Abstract/Notes: It is a dialogue between images and words based on photographs and texts in two languages (French and English) distinct in their sense and dynamism, to explore the idea of crossing. The absence of punctuation allows the reader to let their own reactions emerge. The reader as the third author.\n",
    "Subject headings / Keywords:\n",
    "- Poésie autobiographique (Autobiographical poetry) [RAMEAU]\n",
    "- Livres de photographies (Photography books) [RAMEAU]\n",
    "\n",
    "Additional codes:\n",
    "- RDA content types: text, still image\n",
    "- RDA media type: n (unmediated)\n",
    "- RDA carrier type: nga (volume)\n",
    "Country code: FR\n",
    "Data format and encoding level: Unimarc XML with RDA elements\n",
    "\"\"\"\n",
    "\n",
    "messages = [\n",
    "  {\"role\": \"system\", \"content\": system_prompt + \" /think\"},\n",
    "  {\"role\": \"user\", \"content\": user_prompt},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "182d2853-81a2-4b88-a72e-0c2b0005377c",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer.apply_chat_template(\n",
    "    messages,\n",
    "    return_dict=True,\n",
    "    tokenize = True,\n",
    "    add_generation_prompt = True, # Must add for generation\n",
    "    return_tensors = \"pt\",\n",
    "    enable_thinking=True\n",
    ").to(device)\n",
    "\n",
    "outputs = merged_model.generate(\n",
    "    **inputs,\n",
    "    max_new_tokens = 32768,\n",
    "    use_cache = True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "26aac89e-2efd-42dc-a2fa-2071512245cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thinking content: \n",
      "content: ## Bibliographical metadata:\n",
      "\n",
      "### Title: Traverser  \n",
      "**Subtitle: = Crossings**  \n",
      "**Author: Marie Liénard-Yeterian, Valérie Simon**  \n",
      "**Author (authorized access point):** Liénard-Yeterian, Marie; Simon, Valérie  \n",
      "\n",
      "### Author details:  \n",
      "- Liénard-Yeterian, Marie  \n",
      "- Simon, Valérie  \n",
      "\n",
      "### Language:  \n",
      "- French (fre)  \n",
      "- English (eng) parallel title and content  \n",
      "\n",
      "### Country of publication: France (FR)  \n",
      "- Publication place: Caen  \n",
      "- Publication date: 2024 (DL 2024)  \n",
      "\n",
      "### Publisher:  \n",
      "- Skepsi Editions La Pensée  \n",
      "- Place of publication: [Caen]  \n",
      "- Date of legal deposit: 2024 (physical description: 1 volume (86 pages), illustrated with photomontages and text in color)  \n",
      "\n",
      "### Physical description:  \n",
      "- 24 cm height  \n",
      "- Photographs and text in color, as well as inside the text (photographic and textual illustrations)  \n",
      "- Media type: still image (photographic) and text (non-mediating text)  \n",
      "- Carrier type: volume (nga)  \n",
      "\n",
      "### ISBN: 9782959599033  \n",
      "\n",
      "### Source of control number: [SUDOC] 283499370  \n",
      "\n",
      "### Abstract/Notes:  \n",
      "- This book presents a dialogue between photographs and texts in two languages, \"Crossings\" and \"Traverser,\" to explore the idea of crossing.  \n",
      "- The absence of punctuation allows the reader to let their own reactions emerge.  \n",
      "- The reader is considered the third author.  \n",
      "\n",
      "### Subject headings and keywords:  \n",
      "- Poésie autobiographique (Autobiographical poetry) [RAMEAU]  \n",
      "- Livres de photographies (Photography books) [RAMEAU]  \n",
      "\n",
      "### Control number:  \n",
      "- Roland de Montreuil, France (283499370)  \n",
      "\n",
      "### Country code: FR  \n",
      "- Data format and encoding level: Unimarc/XML with RDA elements  \n",
      "\n",
      "---  \n",
      "This bibliographic record includes author information, title details, publication details, and subject headings. The record is structured in Unimarc/XML format.\n"
     ]
    }
   ],
   "source": [
    "output_ids = outputs[0][len(inputs.input_ids[0]):].tolist()\n",
    "# parsing thinking content\n",
    "try:\n",
    "    # rindex finding 151668 (</think>)\n",
    "    index = len(output_ids) - output_ids[::-1].index(151668)\n",
    "except ValueError:\n",
    "    index = 0\n",
    "\n",
    "thinking_content = tokenizer.decode(output_ids[:index], skip_special_tokens=True).strip(\"\\n\")\n",
    "content = tokenizer.decode(output_ids[index:], skip_special_tokens=True).strip(\"\\n\")\n",
    "\n",
    "print(\"thinking content:\", thinking_content)\n",
    "print(\"content:\", content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6ec8952-08f7-4327-8ed6-552759feb060",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load lora_trace adapter\n",
    "#model_trace = PeftModel.from_pretrained(model, \"./sft_lora_trace\")\n",
    "#model_trace.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a8697ac-1da7-4d65-8c42-cf2defdcbba3",
   "metadata": {},
   "source": [
    "### Full training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "41c00ced-ade2-420a-8d8e-4fe37725d1da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c03fbc2c59624477a231105a1731e03a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/673 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['messages'],\n",
       "    num_rows: 673\n",
       "})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "system_reasoning = \"\"\"# TASK: Generate step-by-step reasoning explaining how to convert this metadata into a UNIMARC record.\"\"\"\n",
    "\n",
    "def create_reasoning_conversation(row):\n",
    "    return {\n",
    "        \"messages\": [\n",
    "            {\"role\": \"system\", \"content\": system_reasoning},\n",
    "            {\"role\": \"user\", \"content\": f\"# Metadata:\\n{row['metadata']}\"},\n",
    "            {\"role\": \"assistant\", \"content\": row[\"reasoning\"]}\n",
    "        ]\n",
    "    }\n",
    "\n",
    "# Apply mapping\n",
    "dataset_reasoning = dataset.map(create_reasoning_conversation, remove_columns=dataset.features)\n",
    "dataset_reasoning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d521574a-2e65-41eb-94a6-e8e221cca31a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def full_train(output_dir, model_name=\"Qwen/Qwen3-0.6B\", dataset=dataset_reasoning,device=\"cuda\", lora=False):\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=True)\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        model_name,\n",
    "        torch_dtype=\"auto\",\n",
    "        device_map=\"auto\",\n",
    "        attn_implementation=\"flash_attention_2\"\n",
    "    )\n",
    "    model = model.to(device)\n",
    "    # !Important\n",
    "    tokenizer.padding_side = \"right\"\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "    # Apply LoRA if selected\n",
    "    if lora:\n",
    "        # Configure LoRA\n",
    "        lora_config = LoraConfig(\n",
    "            r=16,                     # Rank of the update matrices\n",
    "            lora_alpha=32,            # Alpha parameter for LoRA scaling\n",
    "            target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\", \"gate_proj\", \"down_proj\", \"up_proj\"],\n",
    "            lora_dropout=0.05,\n",
    "            bias=\"none\",\n",
    "            task_type=\"CAUSAL_LM\",\n",
    "        )\n",
    "        \n",
    "        # Prepare model for PEFT\n",
    "        model = prepare_model_for_kbit_training(model)\n",
    "        model = get_peft_model(model, lora_config)\n",
    "        model.print_trainable_parameters()  # Log the trainable parameters percentage\n",
    "    \n",
    "    # Define training arguments\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=output_dir,\n",
    "        num_train_epochs=30,                   # Good: more epochs help with small datasets\n",
    "        per_device_train_batch_size=1,         # Reduced to 1 due to long context length\n",
    "        gradient_accumulation_steps=16,        # Compensate batch size → effective batch size = 16\n",
    "        gradient_checkpointing=True,           # Reduces memory usage\n",
    "        optim=\"adamw_torch\",                   # Good choice\n",
    "        learning_rate=5e-5,                    # Slightly lower than default; helps stability\n",
    "        warmup_ratio=0.1,                      # Helps stabilize early training\n",
    "        weight_decay=0.01,                     # Regularization\n",
    "        bf16=True,                             # Use bfloat16 if supported\n",
    "        logging_steps=5,                       # Frequent logs help monitor training\n",
    "        eval_strategy=\"epoch\",                 # Evaluate every epoch\n",
    "        save_strategy=\"epoch\",\n",
    "        save_total_limit=3,\n",
    "        load_best_model_at_end=True,\n",
    "        report_to=\"none\",\n",
    "        remove_unused_columns=False,\n",
    "        metric_for_best_model=\"eval_loss\",\n",
    "        greater_is_better=False,\n",
    "    )\n",
    "    \n",
    "    # Split dataset\n",
    "    train_size = int(len(dataset) * 0.9)\n",
    "    train_dataset = dataset.select(range(train_size))\n",
    "    eval_dataset = dataset.select(range(train_size, len(dataset)))\n",
    "    \n",
    "    # Set up the SFTTrainer\n",
    "    trainer = SFTTrainer(\n",
    "        model=model,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=eval_dataset,\n",
    "        args=training_args,\n",
    "        peft_config=lora_config if lora else None,\n",
    "        #max_seq_length=32768,\n",
    "        )\n",
    "    \n",
    "    # Train the model\n",
    "    trainer.train()\n",
    "    \n",
    "    # Save the model\n",
    "    if lora:\n",
    "        model.save_pretrained(f\"{output_dir}/final_model\")\n",
    "    else:\n",
    "        trainer.save_model(f\"{output_dir}/final_model\")\n",
    "    tokenizer.save_pretrained(f\"{output_dir}/final_model\")\n",
    "    \n",
    "    return model, tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c02750c0-7063-47e6-bf3c-77eec9c5a70f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de306a9da7814a0c92c02c35d582da31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Converting train dataset to ChatML:   0%|          | 0/605 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "830d6602e52242e893968c62d493ba85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Applying chat template to train dataset:   0%|          | 0/605 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8fe891408a2410e960e15a1ae3b8ebc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tokenizing train dataset:   0%|          | 0/605 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ef20df76e43494d94dbf25b464328d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Truncating train dataset:   0%|          | 0/605 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3169f40a7e404f0f96aa91a766a6d25a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Converting eval dataset to ChatML:   0%|          | 0/68 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ef005569f474b6688d43918e4af980c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Applying chat template to eval dataset:   0%|          | 0/68 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "349244e65c604f029002959a672b154a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tokenizing eval dataset:   0%|          | 0/68 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45352ab3b1194428af349d3953ccd26f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Truncating eval dataset:   0%|          | 0/68 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1110' max='1110' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1110/1110 45:34, Epoch 29/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.955300</td>\n",
       "      <td>1.849670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.535500</td>\n",
       "      <td>1.528334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.351600</td>\n",
       "      <td>1.450760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.193800</td>\n",
       "      <td>1.439757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.000200</td>\n",
       "      <td>1.472945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.834200</td>\n",
       "      <td>1.544397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.729200</td>\n",
       "      <td>1.651600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.620200</td>\n",
       "      <td>1.749936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.500500</td>\n",
       "      <td>1.882633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.417800</td>\n",
       "      <td>2.000340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.346900</td>\n",
       "      <td>2.129761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.292300</td>\n",
       "      <td>2.265042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.240400</td>\n",
       "      <td>2.387098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.199300</td>\n",
       "      <td>2.507087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.154800</td>\n",
       "      <td>2.596976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.140100</td>\n",
       "      <td>2.718662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.115700</td>\n",
       "      <td>2.792217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.096100</td>\n",
       "      <td>2.861019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.084100</td>\n",
       "      <td>2.940986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.072700</td>\n",
       "      <td>3.008924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>0.065400</td>\n",
       "      <td>3.068115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0.056400</td>\n",
       "      <td>3.099624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>0.049700</td>\n",
       "      <td>3.147060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0.042700</td>\n",
       "      <td>3.181908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.041500</td>\n",
       "      <td>3.199549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>0.039100</td>\n",
       "      <td>3.227810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>0.037700</td>\n",
       "      <td>3.234357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>0.036700</td>\n",
       "      <td>3.241543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>0.035900</td>\n",
       "      <td>3.243405</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "There were missing keys in the checkpoint model loaded: ['lm_head.weight'].\n"
     ]
    }
   ],
   "source": [
    "model_one, tokenizer = full_train(\"./sft_phase_one\", dataset=dataset_reasoning,device=\"cuda\", lora=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7104b936-9468-43ff-81a1-2d1f31a48dd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['checkpoint-1102', 'checkpoint-1110', 'checkpoint-152']\n",
      "checkpoint-1102: 3.2428648471832275\n",
      "checkpoint-1110: 3.2434046268463135\n",
      "checkpoint-152: 1.4397573471069336\n",
      "\n",
      "✅ Best checkpoint: checkpoint-152 (eval_loss = 1.4397573471069336)\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import json\n",
    "import os\n",
    "\n",
    "output_dir = \"./sft_phase_one\"  # Replace with actual path\n",
    "checkpoints = [d for d in os.listdir(output_dir) if d.startswith(\"checkpoint\")]\n",
    "print(checkpoints)\n",
    "\n",
    "best_checkpoint = None\n",
    "best_loss = float('inf')\n",
    "\n",
    "for cp in checkpoints:\n",
    "    state_file = Path(output_dir) / cp / \"trainer_state.json\"\n",
    "    if not state_file.exists():\n",
    "        continue\n",
    "    with open(state_file, \"r\") as f:\n",
    "        state = json.load(f)\n",
    "    \n",
    "    eval_loss = None\n",
    "    for log in reversed(state[\"log_history\"]):\n",
    "        if \"eval_loss\" in log:\n",
    "            eval_loss = log[\"eval_loss\"]\n",
    "            break\n",
    "    \n",
    "    print(f\"{cp}: {eval_loss}\")\n",
    "    \n",
    "    if eval_loss is not None and eval_loss < best_loss:\n",
    "        best_loss = eval_loss\n",
    "        best_checkpoint = cp\n",
    "\n",
    "print(f\"\\n✅ Best checkpoint: {best_checkpoint} (eval_loss = {best_loss})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41d92ed4-502e-43ea-a174-8be035f6dfce",
   "metadata": {},
   "source": [
    "## Train lora_output Adapter (Trace → XML)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e695b42e-5466-49c0-9ed0-2512854e58cf",
   "metadata": {},
   "source": [
    "### Reload model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "08af63d6-45b6-41c5-af3f-c1c255141a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "del model\n",
    "del tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "951034ba-8886-437e-bf73-7f6c05812633",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"Qwen/Qwen3-0.6B\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    torch_dtype=\"auto\",\n",
    "    device_map=\"auto\",\n",
    "    #attn_implementation=\"flash_attention_2\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "79ae9183-e18f-4293-b37a-ab209ed9a3fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Qwen3ForCausalLM(\n",
       "  (model): Qwen3Model(\n",
       "    (embed_tokens): Embedding(151936, 1024)\n",
       "    (layers): ModuleList(\n",
       "      (0-27): 28 x Qwen3DecoderLayer(\n",
       "        (self_attn): Qwen3Attention(\n",
       "          (q_proj): Linear(in_features=1024, out_features=2048, bias=False)\n",
       "          (k_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (v_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (o_proj): Linear(in_features=2048, out_features=1024, bias=False)\n",
       "          (q_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
       "          (k_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
       "        )\n",
       "        (mlp): Qwen3MLP(\n",
       "          (gate_proj): Linear(in_features=1024, out_features=3072, bias=False)\n",
       "          (up_proj): Linear(in_features=1024, out_features=3072, bias=False)\n",
       "          (down_proj): Linear(in_features=3072, out_features=1024, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): Qwen3RMSNorm((1024,), eps=1e-06)\n",
       "        (post_attention_layernorm): Qwen3RMSNorm((1024,), eps=1e-06)\n",
       "      )\n",
       "    )\n",
       "    (norm): Qwen3RMSNorm((1024,), eps=1e-06)\n",
       "    (rotary_emb): Qwen3RotaryEmbedding()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=1024, out_features=151936, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"cuda\" # for GPU usage or \"cpu\" for CPU usage\n",
    "model = model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "d28eaac4-55e5-4868-9dff-20866af6532d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !Important\n",
    "tokenizer.padding_side = \"right\"\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4d914a0-e23a-4e27-afd5-06a28ba68f90",
   "metadata": {},
   "source": [
    "### Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2de6716a-7f29-421c-b935-53d957035037",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"Geraldine/metadata-to-unimarc-traces\", split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e7564d51-016c-4e76-ad92-8aad2803f27d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 173/173 [00:00<00:00, 3746.52 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['messages'],\n",
       "    num_rows: 173\n",
       "})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "system_message = \"\"\"You are an expert assistant in cataloging and Unimarc/XML standards. \n",
    "Given detailed reasoning about how bibliographic metadata should be mapped to Unimarc fields, \n",
    "your task is to generate the corresponding Unimarc/XML bibliographic record, strictly following the Unimarc standards.\"\"\"\n",
    "def create_conversation(row):\n",
    "  return {\n",
    "    \"messages\": [\n",
    "      {\"role\": \"system\", \"content\": system_message + \" /think\"},\n",
    "      {\"role\": \"user\", \"content\": row[\"reasoning\"]},\n",
    "      {\"role\": \"assistant\", \"content\": row['unimarc_record'] + tokenizer.eos_token} # to avoid infinite generation\n",
    "    ]\n",
    "  }\n",
    "\n",
    "dataset = dataset.map(create_conversation, remove_columns=dataset.features, batched=False)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d3c6174e-5969-41e3-9f7a-36f52fd7904e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [{'content': 'You are an expert assistant in cataloging and Unimarc/XML standards. \\nGiven detailed reasoning about how bibliographic metadata should be mapped to Unimarc fields, \\nyour task is to generate the corresponding Unimarc/XML bibliographic record, strictly following the Unimarc standards. /think',\n",
       "   'role': 'system'},\n",
       "  {'content': 'To transform the provided bibliographical metadata into the given UNIMARC/XML record, proceed step-by-step, field by field, as follows:\\n\\n1. **Control fields** (these are often generated/managed by the cataloguing system):\\n\\n   - `<controlfield tag=\"001\">` — Record identifier: `236807005` (not present in metadata; assigned by system)\\n   - `<controlfield tag=\"003\">` — Control number identifier (URI source): `http://www.sudoc.fr/236807005`\\n   - `<controlfield tag=\"005\">` — Date and time of record processing: `20210208123415.000` (recording timestamp)\\n   - `<controlfield tag=\"035\">` — Various system identifiers:\\n     - `(OCoLC)1107377985` from OCLC number metadata\\n     - `FRBNF...` codes from French national bibliographic authority (not explicitly given but part of cataloguing)\\n   - `<controlfield tag=\"010\">` — International Standard Book Number with binding type: `978-2-221-24174-5` and a binding subfield `$b`: `br.` (broché = paperback)\\n   - `<controlfield tag=\"073\">` — EAN (European article number) from \"Other identifier\": `9782221241745`\\n\\n2. **Leader**\\n\\n   - Encodes record status, type, bibliographic level, encoding level, etc. (`cam0 22        450`) - typically system generated.\\n\\n3. **010 field** (ISBN with binding):\\n\\n   - Maps ISBN to `<datafield tag=\"010\"><subfield code=\"a\">978-2-221-24174-5</subfield><subfield code=\"b\">br.</subfield></datafield>`\\n   - Binding \"br.\" corresponds to paperback (derived or cataloguer\\'s addition).\\n\\n4. **073 field** (EAN):\\n\\n   - `<datafield tag=\"073\"><subfield code=\"a\">9782221241745</subfield></datafield>`  \\n   - From \"Other identifier\" (EAN in metadata).\\n\\n5. **035 field** (other system numbers):\\n\\n   - OCLC: `(OCoLC)1107377985`\\n   - Other French identifiers (cataloguing institution codes), e.g. `FRBNF...`  \\n   - These are authority/control numbers for integration between systems.\\n\\n6. **100 field** — Date and activity code (special code field for cataloguing date/level):\\n\\n   - `<datafield tag=\"100\"><subfield code=\"a\">20190703h20192019m  y0frey50      ba</subfield>`  \\n   - This is a coded field indicating cataloguing dates or activity; this comes from cataloguing process and legal deposit year.  \\n   - The year 2019 comes from \"DL 2019\" (Deposited Legal year 2019).\\n\\n7. **101 field** — Language of the item:\\n\\n   - `<datafield tag=\"101\" ind1=\"0\"><subfield code=\"a\">fre</subfield><subfield code=\"2\">639-2</subfield></datafield>`  \\n   - From metadata language \"French (fre)\".\\n\\n8. **105, 106 fields** — Related to material form and genre:\\n\\n   - `<datafield tag=\"105\"><subfield code=\"a\">a   ||||000yy</subfield></datafield>`  \\n   - `<datafield tag=\"106\"><subfield code=\"a\">r</subfield></datafield>`\\n   - \\'a\\' = text, \\'r\\' indicates genre/form type (e.g., normal printed book).  \\n   - These are based on \"Material type: text, printed book\" from metadata.\\n\\n9. **181, 182, 183 fields** — Content, Media, and Carrier types (RDA):\\n\\n   - `<datafield tag=\"181\"><subfield code=\"c\">txt</subfield><subfield code=\"2\">rdacontent</subfield></datafield>`: Content type = text.\\n   - `<datafield tag=\"182\"><subfield code=\"c\">n</subfield><subfield code=\"2\">rdamedia</subfield></datafield>`: Media type (unmediated).\\n   - `<datafield tag=\"183\"><subfield code=\"a\">nga</subfield><subfield code=\"2\">RDAfrCarrier</subfield></datafield>`: Carrier type = volume (nga).\\n   - These correspond to the metadata fields \"Material type: text, printed book\" and \"Carrier type: volume (nga)\".\\n\\n10. **102 field** — Place of publication country code:\\n\\n    - `<datafield tag=\"102\"><subfield code=\"a\">FR</subfield></datafield>`\\n    - From \"Country of publication: France (FR)\".\\n\\n11. **320 field** — Notes on bibliography:\\n\\n    - `<datafield tag=\"320\"><subfield code=\"a\">Notes bibliogr.</subfield></datafield>`\\n    - From metadata \"Notes bibliogr.\" under Notes/Bibliographic references.\\n\\n12. **200 field** — Title and statement of responsibility:\\n\\n    - `<datafield tag=\"200\" ind1=\"1\" ind2=\" \">`\\n      - `<subfield code=\"a\">Yoga senior</subfield>` -- maps Title\\n      - `<subfield code=\"e\">la méthode de Gasquet</subfield>` -- maps Subtitle\\n      - `<subfield code=\"f\">Dr Bernadette de Gasquet</subfield>` -- maps Author (statement of responsibility)\\n      - `<subfield code=\"f\">avec la participation du Dr Marie Thirion</subfield>` -- maps Participation statement\\n    - So:\\n      - 200$a = Title\\n      - 200$e = Subtitle\\n      - 200$f = Author(s) / participation statement\\n\\n13. **700 field** — Main personal author details:\\n\\n    - `<datafield tag=\"700\" ind1=\" \" ind2=\"1\">`\\n      - `<subfield code=\"3\">084278986</subfield>` — Local control number or authority key\\n      - `<subfield code=\"a\">Gasquet</subfield>` — family name\\n      - `<subfield code=\"b\">Bernadette de</subfield>` — given names\\n      - `<subfield code=\"f\">1946-....</subfield>` — dates of birth (metadata: born 1946)\\n      - `<subfield code=\"4\">070</subfield>` — relator code for author (UNIMARC relators, \\'070\\' = author)\\n    - From Author details metadata for Bernadette de Gasquet\\n    - Note: The names are split into family and given according to French conventions and authority data.\\n\\n14. **702 field** — Secondary personal contributor details (participant):\\n\\n    - `<datafield tag=\"702\" ind1=\" \" ind2=\"1\">`\\n      - `<subfield code=\"3\">028312635</subfield>` — local control number\\n      - `<subfield code=\"a\">Thirion</subfield>` — family name\\n      - `<subfield code=\"b\">Marie</subfield>` — given name\\n      - `<subfield code=\"f\">1944-....</subfield>` — birth year\\n      - `<subfield code=\"c\">pédiatre</subfield>` — profession (from metadata \"pediatrician\")\\n      - `<subfield code=\"4\">205</subfield>` — relator code for contributor function (\\'205\\' = collaborator)\\n    - Matches \"avec la participation du Dr Marie Thirion\" and author\\'s birth details + profession.\\n\\n15. **801 fields** — Cataloguing source and date(s):\\n\\n    - Two 801 fields with different subfields showing cataloguing institution, date, and processing. E.g.:\\n      - `<datafield tag=\"801\" ind1=\" \" ind2=\"3\">`\\n      - `<datafield tag=\"801\" ind1=\" \" ind2=\"0\">`\\n    - From cataloguing administrative metadata, not in source but typical.\\n\\n16. **214 field** — Imprint information (Publication):\\n\\n    - `<datafield tag=\"214\" ind1=\" \" ind2=\"0\">`\\n      - `<subfield code=\"a\">Paris</subfield>` — place of publication (metadata: Paris)\\n      - `<subfield code=\"c\">Robert Laffont</subfield>` — publisher\\n      - `<subfield code=\"d\">DL 2019</subfield>` — date, legal deposit year (DL 2019)\\n    - Maps directly from metadata imprint data.\\n\\n17. **215 field** — Physical description:\\n\\n    - `<datafield tag=\"215\" ind1=\" \" ind2=\" \">`\\n      - `<subfield code=\"a\">1 vol. (250 p.)</subfield>` — volume and pages\\n      - `<subfield code=\"c\">ill., couv. ill. en coul.</subfield>` — includes illustrations and cover in color (from \"Illustrations, color illustrated cover\")\\n      - `<subfield code=\"d\">22 cm</subfield>` — physical size\\n    - Direct mapping from metadata \"Material description\".\\n\\n18. **225 and 410 fields** — Series or Collection:\\n\\n    - `<datafield tag=\"225\" ind1=\"0\" ind2=\" \">`\\n      - `<subfield code=\"a\">Réponses</subfield>`\\n    - `<datafield tag=\"410\" ind1=\" \" ind2=\"|\">`\\n      - `<subfield code=\"0\">001026399</subfield>` — series identifier (from catalogue\\'s own authority files)\\n      - `<subfield code=\"t\">Réponses (Paris. 1967)</subfield>` — series title with place and founding year\\n      - `<subfield code=\"x\">0750-7747</subfield>` — ISSN for the series\\n    - From metadata \"Collection/Series: Réponses\" and ISSN 0750-7747\\n\\n19. **606 fields** — Subject headings:\\n\\n    - Two fields for RAMEAU subjects:\\n      - `<datafield tag=\"606\"><subfield code=\"3\">027347893</subfield><subfield code=\"a\">Hatha-yoga</subfield><subfield code=\"2\">rameau</subfield></datafield>`\\n      - `<datafield tag=\"606\"><subfield code=\"3\">027425541</subfield><subfield code=\"a\">Exercices physiques pour personnes âgées</subfield><subfield code=\"2\">rameau</subfield></datafield>`\\n    - Map from keywords/subject headings with authority source \"RAMEAU\".\\n\\n20. **676 and 686 fields** — Classification schemes:\\n\\n    - `<datafield tag=\"676\"><subfield code=\"a\">613.710 846</subfield><subfield code=\"v\">23</subfield></datafield>`\\n      - 613.710 is Dewey number, 846 possibly language or variant, 23 is DDC edition.\\n    - `<datafield tag=\"686\"><subfield code=\"a\">610</subfield><subfield code=\"2\">Cadre de classement de la Bibliographie nationale française</subfield></datafield>`\\n      - The French national bibliography classification number 610\\n\\n21. **330 field** — Summary / Abstract:\\n\\n    - `<datafield tag=\"330\"><subfield code=\"a\">[full abstract text]</subfield><subfield code=\"2\">éditeur</subfield></datafield>`\\n    - The long abstract text from metadata \"Abstract/Notes\" with the source \"éditeur\" (publisher).\\n\\n---\\n\\n### Summary Table of key mappings:\\n\\n| Metadata element                  | UNIMARC tag and subfield      | Note                                      |\\n|---------------------------------|-------------------------------|-------------------------------------------|\\n| Title                           | 200$a                         | Main title                               |\\n| Subtitle                        | 200$e                         | Subtitle                                 |\\n| Author (main)                   | 200$f, 700$a(b)(f)            | Statement of responsibility and author info with dates |\\n| Participant                    | 200$f, 702$a(b)(f)(c)         | Statement and contributor info with profession  |\\n| ISBN                           | 010$a                        | ISBN number                              |\\n| Binding                        | 010$b                        | Binding type (\\'br.\\' for paperback)       |\\n| EAN                            | 073$a                        | EAN other identifier                     |\\n| OCLC number                    | 035$a                        | System control number                     |\\n| Language                       | 101$a                        | lang code \\'fre\\'                          |\\n| Place of publication           | 214$a                        | Place of publication                     |\\n| Publisher                     | 214$c                        | Publisher                               |\\n| Date of publication (legal deposit) | 214$d                    | Date (DL 2019)                          |\\n| Physical description (volumes, pages) | 215$a                 | Number of volumes and pages              |\\n| Physical description (illustrations) | 215$c                  | Illustrations and cover details           |\\n| Physical description (dimensions) | 215$d                      | Size in cm                              |\\n| Series                        | 225$a                         | Series name                            |\\n| Series info (Series identifier, title, ISSN) | 410$0 410$t 410$x | Series authority and ISSN info          |\\n| Subjects (RAMEAU terms)        | 606$a and 606$2               | Subject headings with authority code    |\\n| Dewey / French classification | 676$a (DDC), 686$a (FNB classification) | Classification schemes                |\\n| Notes bibliogr.               | 320$a                        | Bibliographic notes                      |\\n| Abstract                      | 330$a and 330$2               | Abstract and its source (publisher)      |\\n| Material type and carrier info | 105, 106, 181, 182, 183       | Content, media, carrier codes             |\\n| Place of publication country   | 102$a                        | Country code                            |\\n| Authority and control numbers  | 035, 100 etc.                  | IDs and cataloguing system info          |\\n| Cataloguing data and source    | 801                           | Cataloguing institution, date            |\\n\\n---\\n\\n### Additional notes:\\n\\n- Some fields (controlfields 001, 003, 005, 035, 100, 801) are system-generated and come from cataloguing process and integration with national and international systems.\\n- Relator codes `$4` in 700/702 fields correspond to the role of the person (author or contributor), respectively 070 and 205.\\n- The authors\\' names are split by family name and given name parts according to authority records.\\n- Professional designation (pédiatre) is placed in 702$c.\\n- Binding type \"br.\" (broché) is deduced from material (typical for paperbacks).\\n- The \"DL 2019\" is copied literally into 214$d noting the legal deposit date.\\n- Language code is \"fre\" per ISO 639-2.\\n- Abstract is very long and fully included in 330$a with subfield $2 indicating its source.\\n- ISBN appears twice: as 010$a/b (ISBN + binding type) and 073$a (EAN without hyphens).\\n- The dimensions, volume count, number of pages, and illustration details are composed in 215.\\n- The series information includes both 225 (series title) and 410 (series authority control number, titles, ISSN).\\n- Subject headings use RAMEAU authority code in $2.\\n\\n---\\n\\nThis stepwise mapping explains how each piece of your metadata is encoded into UNIMARC XML fields and subfields as presented in the example record.',\n",
       "   'role': 'user'},\n",
       "  {'content': '<record><controlfield tag=\"005\">20210208123415.000</controlfield><leader> cam0 22        450 </leader><controlfield tag=\"001\">236807005</controlfield><controlfield tag=\"003\">http://www.sudoc.fr/236807005</controlfield><datafield tag=\"035\" ind1=\" \" ind2=\" \"><subfield code=\"a\">(OCoLC)1107377985</subfield></datafield><datafield tag=\"010\" ind1=\" \" ind2=\" \"><subfield code=\"a\">978-2-221-24174-5</subfield><subfield code=\"b\">br.</subfield></datafield><datafield tag=\"073\" ind1=\" \" ind2=\"1\"><subfield code=\"a\">9782221241745</subfield></datafield><datafield tag=\"035\" ind1=\" \" ind2=\" \"><subfield code=\"a\">FRBNF457384730000008</subfield><subfield code=\"z\">FRBNF45738473</subfield></datafield><datafield tag=\"100\" ind1=\" \" ind2=\" \"><subfield code=\"a\">20190703h20192019m  y0frey50      ba</subfield></datafield><datafield tag=\"101\" ind1=\"0\" ind2=\" \"><subfield code=\"a\">fre</subfield><subfield code=\"2\">639-2</subfield></datafield><datafield tag=\"105\" ind1=\" \" ind2=\" \"><subfield code=\"a\">a   ||||000yy</subfield></datafield><datafield tag=\"106\" ind1=\" \" ind2=\" \"><subfield code=\"a\">r</subfield></datafield><datafield tag=\"181\" ind1=\" \" ind2=\" \"><subfield code=\"6\">z01</subfield><subfield code=\"c\">txt</subfield><subfield code=\"2\">rdacontent</subfield></datafield><datafield tag=\"181\" ind1=\" \" ind2=\"1\"><subfield code=\"6\">z01</subfield><subfield code=\"a\">i#</subfield><subfield code=\"b\">xxxe##</subfield></datafield><datafield tag=\"182\" ind1=\" \" ind2=\" \"><subfield code=\"6\">z01</subfield><subfield code=\"c\">n</subfield><subfield code=\"2\">rdamedia</subfield></datafield><datafield tag=\"182\" ind1=\" \" ind2=\"1\"><subfield code=\"6\">z01</subfield><subfield code=\"a\">n</subfield></datafield><datafield tag=\"183\" ind1=\" \" ind2=\"1\"><subfield code=\"6\">z01</subfield><subfield code=\"a\">nga</subfield><subfield code=\"2\">RDAfrCarrier</subfield></datafield><datafield tag=\"102\" ind1=\" \" ind2=\" \"><subfield code=\"a\">FR</subfield></datafield><datafield tag=\"320\" ind1=\" \" ind2=\" \"><subfield code=\"a\">Notes bibliogr.</subfield></datafield><datafield tag=\"200\" ind1=\"1\" ind2=\" \"><subfield code=\"a\">Yoga senior</subfield><subfield code=\"e\">la méthode de Gasquet</subfield><subfield code=\"f\">Dr Bernadette de Gasquet</subfield><subfield code=\"f\">avec la participation du Dr Marie Thirion</subfield></datafield><datafield tag=\"700\" ind1=\" \" ind2=\"1\"><subfield code=\"3\">084278986</subfield><subfield code=\"a\">Gasquet</subfield><subfield code=\"b\">Bernadette de</subfield><subfield code=\"f\">1946-....</subfield><subfield code=\"4\">070</subfield></datafield><datafield tag=\"702\" ind1=\" \" ind2=\"1\"><subfield code=\"3\">028312635</subfield><subfield code=\"a\">Thirion</subfield><subfield code=\"b\">Marie</subfield><subfield code=\"f\">1944-....</subfield><subfield code=\"c\">pédiatre</subfield><subfield code=\"4\">205</subfield></datafield><datafield tag=\"801\" ind1=\" \" ind2=\"3\"><subfield code=\"a\">FR</subfield><subfield code=\"b\">Abes</subfield><subfield code=\"c\">20210208</subfield><subfield code=\"g\">AFNOR</subfield></datafield><datafield tag=\"214\" ind1=\" \" ind2=\"0\"><subfield code=\"a\">Paris</subfield><subfield code=\"c\">Robert Laffont</subfield><subfield code=\"d\">DL 2019</subfield></datafield><datafield tag=\"215\" ind1=\" \" ind2=\" \"><subfield code=\"a\">1 vol. (250 p.)</subfield><subfield code=\"c\">ill., couv. ill. en coul.</subfield><subfield code=\"d\">22 cm</subfield></datafield><datafield tag=\"225\" ind1=\"0\" ind2=\" \"><subfield code=\"a\">Réponses</subfield></datafield><datafield tag=\"410\" ind1=\" \" ind2=\"|\"><subfield code=\"0\">001026399</subfield><subfield code=\"t\">Réponses (Paris. 1967)</subfield><subfield code=\"x\">0750-7747</subfield></datafield><datafield tag=\"606\" ind1=\" \" ind2=\" \"><subfield code=\"3\">027347893</subfield><subfield code=\"a\">Hatha-yoga</subfield><subfield code=\"2\">rameau</subfield></datafield><datafield tag=\"606\" ind1=\" \" ind2=\" \"><subfield code=\"3\">027425541</subfield><subfield code=\"a\">Exercices physiques pour personnes âgées</subfield><subfield code=\"2\">rameau</subfield></datafield><datafield tag=\"676\" ind1=\" \" ind2=\" \"><subfield code=\"a\">613.710 846</subfield><subfield code=\"v\">23</subfield></datafield><datafield tag=\"686\" ind1=\" \" ind2=\" \"><subfield code=\"a\">610</subfield><subfield code=\"2\">Cadre de classement de la Bibliographie nationale française</subfield></datafield><datafield tag=\"801\" ind1=\" \" ind2=\"0\"><subfield code=\"a\">FR</subfield><subfield code=\"b\">FR-751131015</subfield><subfield code=\"c\">20190529</subfield><subfield code=\"g\">AFNOR</subfield><subfield code=\"2\">intermrc</subfield></datafield><datafield tag=\"330\" ind1=\" \" ind2=\" \"><subfield code=\"a\">La méthode de Gasquet enfin adaptée aux seniors ! Quelle activité physique pratiquer lorsque, à 50 ans, des fragilités corporelles et des douleurs apparaissent ? Comment prendre soin de soi, garder un corps fonctionnel et source de plaisir ? Spécialiste du périnée, professeure de yoga, reconnue et suivie par des médecins, des sages-femmes, des kinésithérapeutes et des coachs sportifs dans le monde entier, Bernadette de Gasquet adapte dans ce livre sa célèbre méthode aux seniors et propose un travail sur le renforcement musculaire, sans recherche de la performance, à travers des exercices simples. Travail corporel sans douleur et sans risque, discipline au service de l\\'être humain, le yoga peut être pratiqué à tout âge. En alternant tonification et détente, renforcements et étirements, en associant respiration et action sur les fonctions vitales, on peut garder un corps en pleine forme. Bernadette de Gasquet reprend ici les bases de l\\'activité physique – postures, respiration, abdominaux – en se concentrant sur les maux des seniors – douleurs articulaires, problèmes de circulation, de constipation, hypertension, troubles respiratoires, rhumatismes... – pour leur donner les clés d\\'une vie plus saine et du bien-être au quotidien. 200 photos, 15 schémas, des exercices filmés... Yoga senior vous propose de nombreux conseils pratiques et des exercices physiques adaptés pour rester en forme après 50 ans</subfield><subfield code=\"2\">éditeur</subfield></datafield></record><|im_end|>',\n",
       "   'role': 'assistant'}]}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "470ff6c9-89c2-4ffc-87f9-c5a5d7cafdd9",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d1a95351-3edf-44d9-9352-1c917fb60f23",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting train dataset to ChatML: 100%|██████████| 173/173 [00:00<00:00, 4952.93 examples/s]\n",
      "Applying chat template to train dataset: 100%|██████████| 173/173 [00:00<00:00, 1766.54 examples/s]\n",
      "Tokenizing train dataset: 100%|██████████| 173/173 [00:02<00:00, 59.88 examples/s]\n",
      "Truncating train dataset: 100%|██████████| 173/173 [00:00<00:00, 12157.81 examples/s]\n",
      "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
     ]
    }
   ],
   "source": [
    "# ---- 3. Define LoRA config ----\n",
    "peft_config = LoraConfig(\n",
    "    r=8,\n",
    "    lora_alpha=32,\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\",\n",
    "    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\"] # may vary based on model, check with `model.named_modules()` in previous cell\n",
    ")\n",
    "\n",
    "# ---- 4. Training args ----\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./sft_lora_unimarc_output\",\n",
    "    per_device_train_batch_size=1,\n",
    "    gradient_accumulation_steps=4,\n",
    "    logging_steps=10,\n",
    "    save_strategy=\"epoch\",\n",
    "    num_train_epochs=30,\n",
    "    learning_rate=5e-5,\n",
    "    fp16=True,\n",
    "    report_to=\"none\"\n",
    ")\n",
    "\n",
    "# ---- 5. Launch training ----\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    train_dataset=dataset,\n",
    "    peft_config=peft_config,\n",
    "    args=training_args\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3bb2add3-b304-4e7b-a368-a5550c3b3749",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1290' max='1290' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1290/1290 56:52, Epoch 29/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>2.000300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1.849600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1.748500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1.629000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.527200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>1.409600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>1.418000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>1.322800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>1.267500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.218000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>1.247400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>1.243700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>1.250800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>1.200200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1.163300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>1.171300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>1.145500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>1.080300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>1.086300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1.051000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>1.126600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>1.146100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>1.059600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>1.096200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>1.070800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.981900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>0.992000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.958800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>0.973700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>1.068000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>0.970900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.988000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>0.953400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>0.921500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>1.007800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>1.011200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>370</td>\n",
       "      <td>0.982400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>0.862100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>390</td>\n",
       "      <td>0.956800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.885200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>410</td>\n",
       "      <td>0.896400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>0.919500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>430</td>\n",
       "      <td>0.940200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>440</td>\n",
       "      <td>0.923300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.889900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>460</td>\n",
       "      <td>0.892100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>470</td>\n",
       "      <td>0.928400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>0.862200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>490</td>\n",
       "      <td>0.858300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.880000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>510</td>\n",
       "      <td>0.908400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>520</td>\n",
       "      <td>0.831600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>530</td>\n",
       "      <td>0.945500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>0.818700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.875700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>560</td>\n",
       "      <td>0.855600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>570</td>\n",
       "      <td>0.852100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>580</td>\n",
       "      <td>0.870300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>590</td>\n",
       "      <td>0.850900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.845600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>610</td>\n",
       "      <td>0.866700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>620</td>\n",
       "      <td>0.819700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>630</td>\n",
       "      <td>0.859000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>640</td>\n",
       "      <td>0.819200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>0.781800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>660</td>\n",
       "      <td>0.863300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>670</td>\n",
       "      <td>0.848700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>680</td>\n",
       "      <td>0.792800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>690</td>\n",
       "      <td>0.848300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.791400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>710</td>\n",
       "      <td>0.775500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>720</td>\n",
       "      <td>0.739000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>730</td>\n",
       "      <td>0.855300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>740</td>\n",
       "      <td>0.797900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>0.818100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>760</td>\n",
       "      <td>0.783000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>770</td>\n",
       "      <td>0.803100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>780</td>\n",
       "      <td>0.783800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>790</td>\n",
       "      <td>0.802300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.768100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>810</td>\n",
       "      <td>0.758600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>820</td>\n",
       "      <td>0.798100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>830</td>\n",
       "      <td>0.778100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>840</td>\n",
       "      <td>0.749500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>0.794300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>860</td>\n",
       "      <td>0.779200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>870</td>\n",
       "      <td>0.773100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>880</td>\n",
       "      <td>0.760300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>890</td>\n",
       "      <td>0.734800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.757800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>910</td>\n",
       "      <td>0.767700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>920</td>\n",
       "      <td>0.760500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>930</td>\n",
       "      <td>0.852700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>940</td>\n",
       "      <td>0.740700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>0.704000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>960</td>\n",
       "      <td>0.736700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>970</td>\n",
       "      <td>0.782100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>980</td>\n",
       "      <td>0.727300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>990</td>\n",
       "      <td>0.729700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.730400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1010</td>\n",
       "      <td>0.795300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1020</td>\n",
       "      <td>0.788000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1030</td>\n",
       "      <td>0.669500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1040</td>\n",
       "      <td>0.723300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1050</td>\n",
       "      <td>0.773200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1060</td>\n",
       "      <td>0.733200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1070</td>\n",
       "      <td>0.693400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1080</td>\n",
       "      <td>0.754200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1090</td>\n",
       "      <td>0.731400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.738100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1110</td>\n",
       "      <td>0.731600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1120</td>\n",
       "      <td>0.731300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1130</td>\n",
       "      <td>0.721900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1140</td>\n",
       "      <td>0.712700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1150</td>\n",
       "      <td>0.788900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1160</td>\n",
       "      <td>0.701100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1170</td>\n",
       "      <td>0.734800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1180</td>\n",
       "      <td>0.727700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1190</td>\n",
       "      <td>0.677900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.728100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1210</td>\n",
       "      <td>0.706600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1220</td>\n",
       "      <td>0.748700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1230</td>\n",
       "      <td>0.711800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1240</td>\n",
       "      <td>0.752400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1250</td>\n",
       "      <td>0.694600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1260</td>\n",
       "      <td>0.684000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1270</td>\n",
       "      <td>0.736700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1280</td>\n",
       "      <td>0.698200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1290</td>\n",
       "      <td>0.661800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1290, training_loss=0.9083033358403879, metrics={'train_runtime': 3415.5117, 'train_samples_per_second': 1.52, 'train_steps_per_second': 0.378, 'total_flos': 1.3800208274030592e+16, 'train_loss': 0.9083033358403879})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8c3fec2-3f4c-4943-a4c8-ebf5748b5ee7",
   "metadata": {},
   "source": [
    "### Save adapter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f2560c8c-7690-4997-853c-05267c844b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b39139f-faae-4f06-aab2-95e9dd960465",
   "metadata": {},
   "source": [
    "### Test inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c9015c0f-00e7-4db5-ad72-074d799928da",
   "metadata": {},
   "outputs": [],
   "source": [
    "peft_model_id = \"./sft_lora_unimarc_output\"\n",
    "tr_model_id = \"Qwen/Qwen3-0.6B\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "087cb0b1-05a5-4809-8661-47e729b94f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(tr_model_id, trust_remote_code=True, torch_dtype=torch.float16,\n",
    "     low_cpu_mem_usage=True,)\n",
    "model = PeftModel.from_pretrained(model, peft_model_id)\n",
    "merged_model = model.merge_and_unload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "59e473ea-7d21-4321-bd3c-ab4f3ca2e8e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_model = merged_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "07c1c517-7cec-4245-a6e8-4b34ec9cd553",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"\n",
    "You are a helpful assistant expert in Unimarc/XML bibliographic records.\n",
    "Used the given structured reasoning to generate Unimarc/XML record.\n",
    "\"\"\"\n",
    "\n",
    "user_prompt = \"\"\"\n",
    "Here's a step-by-step explanation of how the bibliographic metadata maps into the given UNIMARC/XML record:\n",
    "\n",
    "---\n",
    "\n",
    "### Main Title and Subtitle\n",
    "- **Title**: \"Les Jeux olympiques de 1892 à 2024\"  \n",
    "  → `datafield tag=\"200\" ind1=\"1\" ind2=\" \"` subfield `$a`\n",
    "\n",
    "- **Subtitle**: \"une aventure mondiale\"  \n",
    "  → `datafield tag=\"200\" ind1=\"1\" ind2=\" \"` subfield `$e`\n",
    "\n",
    "### Author (Main Entry - Personal Name)\n",
    "- Author: Patrick Clastres  \n",
    "  → `datafield tag=\"200\"` subfield `$f` contains author name \"Patrick Clastres\" (statement of responsibility)\n",
    "\n",
    "- Additional author info: \"Clastres, Patrick (19..-....)\"  \n",
    "  → `datafield tag=\"700\" ind1=\" \" ind2=\"1\"`  \n",
    "    - `$a` = Family Name \"Clastres\"  \n",
    "    - `$b` = Given Name \"Patrick\"  \n",
    "    - `$f` = Dates \"19..-....\"  \n",
    "    - `$4` = Code \"070\" (UNIMARC relator code for author or principal)  \n",
    "    - `$3` = \"080640443\" (possibly a local control number or authority ID)\n",
    "\n",
    "### ISBN, Physical Description and Related Information\n",
    "- ISBN: \"978-2-7535-9645-0 (br.)\"  \n",
    "  → `datafield tag=\"010\"` with subfields:  \n",
    "    - `$a` = ISBN \"978-2-7535-9645-0\"  \n",
    "    - `$b` = Specific edition/type \"br.\" (broché = paperback)  \n",
    "  → `datafield tag=\"073\"` (EAN barcode probably) with subfield `$a` = \"9782753596450\"\n",
    "\n",
    "### Place of Publication, Publisher, and Date\n",
    "- Place: \"Rennes\"  \n",
    "  → `datafield tag=\"214\" ind1=\" \" ind2=\"0\"` subfield `$a`\n",
    "\n",
    "- Publisher: \"Presses universitaires de Rennes\"  \n",
    "  → `datafield tag=\"214\"` subfield `$c`\n",
    "\n",
    "- Date: \"2025 (DL 2025)\"  \n",
    "  → `datafield tag=\"214\"` subfield `$d`\n",
    "\n",
    "### Language and Relevant Codes\n",
    "- Language: French (fre)  \n",
    "  → `datafield tag=\"101\"` subfield `$a` = \"fre\"  \n",
    "  → Also `$2` = \"639-2\" (ISO 639-2)\n",
    "\n",
    "- Country of publication: France (FR)  \n",
    "  → `datafield tag=\"102\"` subfield `$a`\n",
    "\n",
    "### Material Description\n",
    "- \"1 volume (463 pages); color illustrated cover; 24 cm\"  \n",
    "  → `datafield tag=\"215\"`  \n",
    "    - `$a` = \"1 vol. (463 p.)\"  \n",
    "    - `$c` = \"couv. ill. en coul.\" (color illustrated cover)  \n",
    "    - `$d` = \"24 cm\" (physical size)\n",
    "\n",
    "### Collection/Series and ISSN\n",
    "- Collection: Collection \"Histoire\"  \n",
    "  → `datafield tag=\"225\"` subfield `$a`\n",
    "\n",
    "- Series: \"Histoire (Rennes)\" with ISSN 1255-2364  \n",
    "  → `datafield tag=\"410\" ind1=\" \" ind2=\"|\"`  \n",
    "    - `$0` = \"003326195\" (authority or control number for the series)  \n",
    "    - `$t` = \"Histoire (Rennes)\" (series title)  \n",
    "    - `$x` = \"1255-2364\" (ISSN)\n",
    "\n",
    "### Keywords / Subject Headings\n",
    "- Keywords: Olympisme, Jeux olympiques, Histoire  \n",
    "  → `datafield tag=\"606\"` (subject headings from RAMEAU)  \n",
    "    For \"Olympisme\" and \"Jeux olympiques\":  \n",
    "    - `$a` = topical heading: e.g., \"Olympisme\" or \"Jeux olympiques\"  \n",
    "    - `$x` = subdivision: \"Histoire\"  \n",
    "    - `$2` = source of subject headings: \"rameau\"  \n",
    "    - `$3` = local identifier for the subject heading\n",
    "\n",
    "### Classification\n",
    "- Classification number: 796(23a)  \n",
    "  → `datafield tag=\"676\"`  \n",
    "    - `$a` = \"796\" (main class)  \n",
    "    - `$v` = \"23a\" (likely subclass or notation for Olympic Games)\n",
    "\n",
    "### Abstract/Notes\n",
    "- Abstract text (from back cover)  \n",
    "  → `datafield tag=\"330\"`  \n",
    "    - `$a` = the full abstract text  \n",
    "    - `$2` = source of abstract \"4e de couverture\"\n",
    "\n",
    "### Bibliographic References\n",
    "- \"Bibliogr. p. 419-424; includes index\"  \n",
    "  → `datafield tag=\"320\"` subfield `$a`\n",
    "\n",
    "### Control and Identification Fields\n",
    "- Control number (SUDOC): 284189537  \n",
    "  → `controlfield tag=\"001\"`\n",
    "\n",
    "- SUDOC URL as source  \n",
    "  → `controlfield tag=\"003\"` = \"http://www.sudoc.fr/284189537\"\n",
    "\n",
    "- Additional identifier (OCLC number)  \n",
    "  → `datafield tag=\"035\"` subfield `$a` = \"(OCoLC)1513823097\"\n",
    "\n",
    "### Administrative Data\n",
    "- Leader and control fields set for date/time and encoding specifics\n",
    "\n",
    "- `datafield tag=\"801\"` indicating cataloging source  \n",
    "  - `$a` = country code \"FR\"  \n",
    "  - `$b` = agency \"Abes\"  \n",
    "  - `$c` = date of cataloging \"20250424\"  \n",
    "  - `$g` = additional agency \"AFNOR\"\n",
    "\n",
    "---\n",
    "\n",
    "### Summary Table of mappings:\n",
    "\n",
    "| Metadata element                  | UNIMARC Tag | Subfields/Notes                             |\n",
    "|---------------------------------|-------------|--------------------------------------------|\n",
    "| Title                           | 200         | $a                                          |\n",
    "| Subtitle                        | 200         | $e                                          |\n",
    "| Author (statement of resp.)     | 200         | $f                                          |\n",
    "| Author (authorized form)        | 700         | $a family, $b given, $f dates, $4 relator  |\n",
    "| ISBN                           | 010         | $a ISBN, $b edition/type                    |\n",
    "| ISBN Barcode                   | 073         | $a EAN code                                 |\n",
    "| Place of publication           | 214         | $a                                          |\n",
    "| Publisher                     | 214         | $c                                          |\n",
    "| Date of publication           | 214         | $d                                          |\n",
    "| Language                      | 101         | $a iso639-2 code, $2 authority              |\n",
    "| Country                      | 102         | $a                                          |\n",
    "| Physical description          | 215         | $a extent, $c cover, $d size                 |\n",
    "| Collection/Series             | 225         | $a                                          |\n",
    "| Series title and ISSN         | 410         | $0 control number, $t title, $x ISSN        |\n",
    "| Subject headings (RAMEAU)      | 606         | $a topical, $x subdivision, $2 source, $3 ID|\n",
    "| Classification                | 676         | $a main class, $v subdivision                |\n",
    "| Abstract/Notes                | 330         | $a text, $2 source                           |\n",
    "| Bibliographic references       | 320         | $a                                          |\n",
    "| Control number (internal)       | 001         |                                              |\n",
    "| Source URL                    | 003         |                                              |\n",
    "| Identifier (OCLC)              | 035         | $a                                          |\n",
    "| Cataloging agency & date         | 801         | $a country, $b agency, $c date, $g agency   |\n",
    "\n",
    "---\n",
    "\n",
    "This is how the provided metadata has been structured and encoded into UNIMARC in the XML representation. Each data element corresponds to a standard UNIMARC field and subfield, respecting cataloging rules and controlled vocabularies.\n",
    "\"\"\"\n",
    "\n",
    "messages = [\n",
    "  {\"role\": \"system\", \"content\": system_prompt + \" /think\"},\n",
    "  {\"role\": \"user\", \"content\": user_prompt},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b11ac3aa-3983-4e01-8d4e-153cdd95ef60",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer.apply_chat_template(\n",
    "    messages,\n",
    "    return_dict=True,\n",
    "    tokenize = True,\n",
    "    add_generation_prompt = True, # Must add for generation\n",
    "    return_tensors = \"pt\",\n",
    "    enable_thinking=False\n",
    ").to(device)\n",
    "\n",
    "outputs = merged_model.generate(\n",
    "    **inputs,\n",
    "    max_new_tokens = 32768,\n",
    "    use_cache = True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "85b5aac4-7aa2-481b-a5e7-c66ed0b13c56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thinking content: \n",
      "content: Here is the corresponding UNIMARC bibliographic record, mapped from the provided metadata:\n",
      "\n",
      "```xml\n",
      "<Datafield tag=\"200\" ind1=\"1\" ind2=\" \">\n",
      "  <subfield code=\"a\">Les Jeux olympiques de 1892 à 2024</subfield>\n",
      "  <subfield code=\"e\">une aventure mondiale</subfield>\n",
      "</Datafield>\n",
      "\n",
      "<Datafield tag=\"101\" ind1=\" \");\n",
      "  <subfield code=\"a\">fre</subfield>\n",
      "  <subfield code=\"2\">639-2</subfield>\n",
      "</Datafield>\n",
      "\n",
      "<Datafield tag=\"102\" ind1=\" \");\n",
      "  <subfield code=\"a\">FR</subfield>\n",
      "</Datafield>\n",
      "\n",
      "<Datafield tag=\"102\" ind1=\"0\">\n",
      "  <subfield code=\"a\">RFR</subfield>\n",
      "</Datafield>\n",
      "\n",
      "<Datafield tag=\"320\" ind1=\"1\" ind2=\" \">\n",
      "  <subfield code=\"a\">Bibliogr. p. 419-424; includes index</subfield>\n",
      "</Datafield>\n",
      "\n",
      "<Datafield tag=\"410\" ind1=\" \">\n",
      "  <subfield code=\"0\">006751902</subfield>\n",
      "  <subfield code=\"t\">Histoire (Rennes)</subfield>\n",
      "  <subfield code=\"x\">1255-2364</subfield>\n",
      "</Datafield>\n",
      "```\n",
      "\n",
      "---\n",
      "\n",
      "### Key elements mapping:\n",
      "\n",
      "- **Title and Subtitle** → `200$a` and `200$e`\n",
      "- **Language** → `101$a` and `102$a` (French and FR)\n",
      "- **Publisher and Place of Publication** → `214$c`, `214$a`\n",
      "- **Date of Publication** → `214$d`\n",
      "- **Edition and Other Details** → `010$a` (ISBN + edition + price), `073$a` (EAN barcode)\n",
      "- **Country of Publication** → `102$a` (FR)\n",
      "- **Series, Collection, and ISSN** → `225$t`, `410$t`, `410$0`\n",
      "- **Subject Headings** → `606$a` (subjects) and `606$x` (subdivisions)\n",
      "- **Classification and Code** → `676$a` (main class), `676$v` (subclass)\n",
      "- **Abstract and Notes** → `330$a` (full abstract), `320$a` (index info)\n",
      "- **Control Numbers and Authorities** → `001`, `035$a` (internal control number), `801$a` (country, agency, date)\n",
      "- **Language Code and Authority** → `102$a` (ISO 639-2)\n",
      "\n",
      "---\n",
      "\n",
      "### Notes on Record Construction:\n",
      "\n",
      "- The record uses an authority ID (`006751902`) for internal cataloging.\n",
      "- The series name \"Histoire (Rennes)\" is included in `410$t` as a classification.\n",
      "- Subject headings and classification codes are derived from RAMEAU standards.\n",
      "- The language and country are encoded in `101` and `102`.\n",
      "- The control number is encoded in `035` as a source of the catalog.\n",
      "\n",
      "This record is typically generated by an XML cataloger based on:\n",
      "- Title, subtitle\n",
      "- Author statement\n",
      "- ISBN and related info\n",
      "- Series name, ISSN, and place of publication\n",
      "- Language, country of publication\n",
      "- Subject heading and classification codes\n",
      "- Control numbers and authority info\n",
      "- Bibliographic info (index, bibliography notes)\n",
      "\n",
      "Let me know if you want to see how the cataloger would process this particular record from the given bibliographical elements.\n"
     ]
    }
   ],
   "source": [
    "output_ids = outputs[0][len(inputs.input_ids[0]):].tolist()\n",
    "# parsing thinking content\n",
    "try:\n",
    "    # rindex finding 151668 (</think>)\n",
    "    index = len(output_ids) - output_ids[::-1].index(151668)\n",
    "except ValueError:\n",
    "    index = 0\n",
    "\n",
    "thinking_content = tokenizer.decode(output_ids[:index], skip_special_tokens=True).strip(\"\\n\")\n",
    "content = tokenizer.decode(output_ids[index:], skip_special_tokens=True).strip(\"\\n\")\n",
    "\n",
    "print(\"thinking content:\", thinking_content)\n",
    "print(\"content:\", content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bccae09-0f53-47c8-86d5-f3db1f038c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load lora_trace adapter\n",
    "#model_trace = PeftModel.from_pretrained(model, \"./sft_lora_unimarc_output\")\n",
    "#model_trace.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fcefedf-430d-43b5-a33a-33202d8b3a29",
   "metadata": {},
   "source": [
    "### Full training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d8b1955c-f4a6-4c78-889c-1420ff978ece",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9afd57346114456fb9282812a866d812",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/673 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['messages'],\n",
       "    num_rows: 673\n",
       "})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "system_xml = \"\"\"# TASK: Convert the above into a UNIMARC/XML record.\"\"\"\n",
    "\n",
    "def create_xml_conversation(row):\n",
    "    user_input = f\"# METADATA:\\n{row['metadata']}\\n\\n# REASONING:\\n{row['reasoning']}\"\n",
    "    return {\n",
    "        \"messages\": [\n",
    "            {\"role\": \"system\", \"content\": system_xml},\n",
    "            {\"role\": \"user\", \"content\": user_input},\n",
    "            {\"role\": \"assistant\", \"content\": row['unimarc_record']}\n",
    "        ]\n",
    "    }\n",
    "\n",
    "# Apply mapping\n",
    "dataset_xml = dataset.map(create_xml_conversation, remove_columns=dataset.features)\n",
    "dataset_xml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a92a4fe5-b18b-433d-b033-6dd26c54b650",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a04fea21b5094c2297a623f3d9bba6ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Converting train dataset to ChatML:   0%|          | 0/605 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8415ae083b5d49f4b55e16591c86190a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Applying chat template to train dataset:   0%|          | 0/605 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07ef538c4dd04000a881fea2275f033f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tokenizing train dataset:   0%|          | 0/605 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "918156accb4440e9bf36984d5c72b7f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Truncating train dataset:   0%|          | 0/605 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "297dba7ded894dfa8ee21c3510bc38f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Converting eval dataset to ChatML:   0%|          | 0/68 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75f1972187bf40cb8afb4816ba36282d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Applying chat template to eval dataset:   0%|          | 0/68 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6dea23fced46484280c392a7b35d2bf2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tokenizing eval dataset:   0%|          | 0/68 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e847710644d4948bfa4112b7e9de264",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Truncating eval dataset:   0%|          | 0/68 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='840' max='1110' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 840/1110 34:33 < 11:08, 0.40 it/s, Epoch 22.08/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.020600</td>\n",
       "      <td>1.476525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.016400</td>\n",
       "      <td>1.489472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.937900</td>\n",
       "      <td>1.528380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.873100</td>\n",
       "      <td>1.594949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.710300</td>\n",
       "      <td>1.697732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.568200</td>\n",
       "      <td>1.824500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.485900</td>\n",
       "      <td>1.922696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.401500</td>\n",
       "      <td>2.064939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.318600</td>\n",
       "      <td>2.174124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.258000</td>\n",
       "      <td>2.308712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.209200</td>\n",
       "      <td>2.408026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.176400</td>\n",
       "      <td>2.548698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.141600</td>\n",
       "      <td>2.652872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.121000</td>\n",
       "      <td>2.766802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.094000</td>\n",
       "      <td>2.816535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.085400</td>\n",
       "      <td>2.903454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.068800</td>\n",
       "      <td>2.971427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.056400</td>\n",
       "      <td>3.040031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.048300</td>\n",
       "      <td>3.097449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.040100</td>\n",
       "      <td>3.175221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>0.034900</td>\n",
       "      <td>3.217942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0.031300</td>\n",
       "      <td>3.235132</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "best_model_path = os.path.join(output_dir, best_checkpoint)\n",
    "model_two, tokenizer = full_train(\"./sft_phase_two\", model_name=best_model_path, dataset=dataset_xml,device=\"cuda\", lora=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "402963bd-a20c-4f7c-8bc8-a84dc3016ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = \"./sft_phase_two\"  # Replace with actual path\n",
    "checkpoints = [d for d in os.listdir(output_dir) if d.startswith(\"checkpoint\")]\n",
    "print(checkpoints)\n",
    "\n",
    "best_checkpoint = None\n",
    "best_loss = float('inf')\n",
    "\n",
    "for cp in checkpoints:\n",
    "    state_file = Path(output_dir) / cp / \"trainer_state.json\"\n",
    "    if not state_file.exists():\n",
    "        continue\n",
    "    with open(state_file, \"r\") as f:\n",
    "        state = json.load(f)\n",
    "    \n",
    "    eval_loss = None\n",
    "    for log in reversed(state[\"log_history\"]):\n",
    "        if \"eval_loss\" in log:\n",
    "            eval_loss = log[\"eval_loss\"]\n",
    "            break\n",
    "    \n",
    "    print(f\"{cp}: {eval_loss}\")\n",
    "    \n",
    "    if eval_loss is not None and eval_loss < best_loss:\n",
    "        best_loss = eval_loss\n",
    "        best_checkpoint = cp\n",
    "\n",
    "print(f\"\\n✅ Best checkpoint: {best_checkpoint} (eval_loss = {best_loss})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "115cba5d-108f-4d3c-a0b9-fbfe4a30809a",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_path = os.path.join(output_dir, best_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a6c8a08-97fd-41dd-a76c-19f8dbbc35dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(best_model_path)\n",
    "final_model = AutoModelForCausalLM.from_pretrained(best_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d958d2bb-09bc-45fa-a476-5204bedc1251",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_save_path = \"./sft/final_best_model\"\n",
    "final_model.save_pretrained(final_save_path)\n",
    "tokenizer.save_pretrained(final_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "076f3ec4-f531-4922-b0f6-13b41f6f48a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model.push_to_hub(\"Geraldine/qwen3-0.6B-unimarc-reasoning\")\n",
    "tokenizer.push_to_hub(\"Geraldine/qwen3-0.6B-unimarc-reasoning\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51c22d00-10b7-440e-949d-b0b540cc18e1",
   "metadata": {},
   "source": [
    "##  Merge the Two LoRA Adapters into One Adapter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "4212e953-fc9e-4a7a-b76f-8a78d9c9b921",
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import PeftModel, PeftConfig, get_peft_model, LoraConfig\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bd39bad-6a62-448a-96a6-927557f8ac95",
   "metadata": {},
   "source": [
    "### Reload first model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "192138b1-09d3-4e72-a803-81515bb896db",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"Qwen/Qwen3-0.6B\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    torch_dtype=\"auto\",\n",
    "    device_map=\"auto\",\n",
    "    #attn_implementation=\"flash_attention_2\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "ec4efa56-9a94-4df1-b362-8fe99dd769b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Qwen3ForCausalLM(\n",
       "  (model): Qwen3Model(\n",
       "    (embed_tokens): Embedding(151936, 1024)\n",
       "    (layers): ModuleList(\n",
       "      (0-27): 28 x Qwen3DecoderLayer(\n",
       "        (self_attn): Qwen3Attention(\n",
       "          (q_proj): Linear(in_features=1024, out_features=2048, bias=False)\n",
       "          (k_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (v_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (o_proj): Linear(in_features=2048, out_features=1024, bias=False)\n",
       "          (q_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
       "          (k_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
       "        )\n",
       "        (mlp): Qwen3MLP(\n",
       "          (gate_proj): Linear(in_features=1024, out_features=3072, bias=False)\n",
       "          (up_proj): Linear(in_features=1024, out_features=3072, bias=False)\n",
       "          (down_proj): Linear(in_features=3072, out_features=1024, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): Qwen3RMSNorm((1024,), eps=1e-06)\n",
       "        (post_attention_layernorm): Qwen3RMSNorm((1024,), eps=1e-06)\n",
       "      )\n",
       "    )\n",
       "    (norm): Qwen3RMSNorm((1024,), eps=1e-06)\n",
       "    (rotary_emb): Qwen3RotaryEmbedding()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=1024, out_features=151936, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"cuda\" # for GPU usage or \"cpu\" for CPU usage\n",
    "model = model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "810ca108-f513-4344-84ed-d1cbf34bdcc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !Important\n",
    "tokenizer.padding_side = \"right\"\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "b27c6b01-dc17-4e29-a0b6-f875861d1dec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thinking content: <think>\n",
      "Okay, the user asked for a short introduction to a large language model. Let me start by recalling what I know about LLMs. They are big language models, right? So I should mention their ability to understand and generate text, which is their main function.\n",
      "\n",
      "I need to keep it concise. Maybe start with \"Large language models (LLMs)\" and then explain their capabilities. Since they can understand and generate text, that's a key point. Also, their use cases like writing, answering questions, etc. \n",
      "\n",
      "Wait, should I mention something about training data? Oh yes, LLMs are trained on vast amounts of text, which allows them to learn from a wide range of information. That adds value. \n",
      "\n",
      "I should make sure the introduction flows well and covers the main points without getting too technical. Let me check if there's anything else I need to include. Maybe mention how they are used in various applications, like customer service or creative writing. \n",
      "\n",
      "No, the user just wants a short intro. Keep it to a couple of sentences. Alright, time to put it all together.\n",
      "</think>\n",
      "content: A large language model (LLM) is a type of artificial intelligence designed to understand and generate human language. They can comprehend text, answer questions, and create creative content by learning from vast amounts of data. LLMs are used in various applications, from writing to customer service, enabling them to process and respond to complex queries effectively.\n"
     ]
    }
   ],
   "source": [
    "# Little test\n",
    "messages = [\n",
    "  {\"role\": \"system\", \"content\": \"You are a helpful assistant\"},\n",
    "  {\"role\": \"user\", \"content\": \"Give me a short introduction to large language model.\"},\n",
    "]\n",
    "\n",
    "inputs = tokenizer.apply_chat_template(\n",
    "    messages,\n",
    "    return_dict=True,\n",
    "    tokenize = True,\n",
    "    add_generation_prompt = True, # Must add for generation\n",
    "    return_tensors = \"pt\",\n",
    "    enable_thinking=True\n",
    ").to(device)\n",
    "\n",
    "outputs = model.generate(\n",
    "    **inputs,\n",
    "    max_new_tokens = 32768,\n",
    "    use_cache = True,\n",
    ")\n",
    "\n",
    "output_ids = outputs[0][len(inputs.input_ids[0]):].tolist()\n",
    "# parsing thinking content\n",
    "try:\n",
    "    # rindex finding 151668 (</think>)\n",
    "    index = len(output_ids) - output_ids[::-1].index(151668)\n",
    "except ValueError:\n",
    "    index = 0\n",
    "\n",
    "thinking_content = tokenizer.decode(output_ids[:index], skip_special_tokens=True).strip(\"\\n\")\n",
    "content = tokenizer.decode(output_ids[index:], skip_special_tokens=True).strip(\"\\n\")\n",
    "\n",
    "print(\"thinking content:\", thinking_content)\n",
    "print(\"content:\", content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc32b6a2-dffb-489b-bf51-0081cbdb92be",
   "metadata": {},
   "source": [
    "### Merging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "529ad193-e3d1-4eb0-8880-7b6cbdc209c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the first adapter\n",
    "model = PeftModel.from_pretrained(base_model, \"./sft_lora_trace\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "2869dbc1-f070-4311-9814-89963eb81ebf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the second adapter (into the same PeftModel)\n",
    "model.load_adapter(\"./sft_lora_unimarc_output\", adapter_name=\"adapter2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "d2e4683e-482c-4bfb-8f70-3fe0cc2e52fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_model = model.merge_and_unload()  # This returns a base model with merged LoRA weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "e1aa6bd3-32b4-49ba-b50d-20c2944c9d60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Qwen3Config {\n",
      "  \"architectures\": [\n",
      "    \"Qwen3ForCausalLM\"\n",
      "  ],\n",
      "  \"attention_bias\": false,\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 151643,\n",
      "  \"eos_token_id\": 151645,\n",
      "  \"head_dim\": 128,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 1024,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"max_position_embeddings\": 40960,\n",
      "  \"max_window_layers\": 28,\n",
      "  \"model_type\": \"qwen3\",\n",
      "  \"num_attention_heads\": 16,\n",
      "  \"num_hidden_layers\": 28,\n",
      "  \"num_key_value_heads\": 8,\n",
      "  \"rms_norm_eps\": 1e-06,\n",
      "  \"rope_scaling\": null,\n",
      "  \"rope_theta\": 1000000,\n",
      "  \"sliding_window\": null,\n",
      "  \"tie_word_embeddings\": true,\n",
      "  \"torch_dtype\": \"bfloat16\",\n",
      "  \"transformers_version\": \"4.51.3\",\n",
      "  \"use_cache\": true,\n",
      "  \"use_sliding_window\": false,\n",
      "  \"vocab_size\": 151936\n",
      "}\n",
      "\n",
      "model\n",
      "<class 'transformers.models.qwen3.modeling_qwen3.Qwen3ForCausalLM'>\n"
     ]
    }
   ],
   "source": [
    "print(merged_model.config)\n",
    "print(merged_model.base_model_prefix)\n",
    "print(merged_model.__class__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31ef70d4-4a97-4c76-a85e-5201df24d323",
   "metadata": {},
   "source": [
    "### Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "3b05b047-80dd-48ba-b901-44b4574144f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./final_qwen3_unimarc_model/tokenizer_config.json',\n",
       " './final_qwen3_unimarc_model/special_tokens_map.json',\n",
       " './final_qwen3_unimarc_model/vocab.json',\n",
       " './final_qwen3_unimarc_model/merges.txt',\n",
       " './final_qwen3_unimarc_model/added_tokens.json',\n",
       " './final_qwen3_unimarc_model/tokenizer.json')"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the fully merged model (final model: Metadata → XML directly)\n",
    "merged_model.save_pretrained(\"./final_qwen3_unimarc_model\")\n",
    "tokenizer.save_pretrained(\"./final_qwen3_unimarc_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "a2ef651c-7d89-4939-b164-5054d124965b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "model.safetensors: 100%|██████████| 1.19G/1.19G [00:40<00:00, 29.2MB/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/Geraldine/Qwen3-0.6B-finetuned-unimarc-reasoning/commit/3b995572149c1ea0f73beb9f2eaae54d08b2401b', commit_message='Upload Qwen3ForCausalLM', commit_description='', oid='3b995572149c1ea0f73beb9f2eaae54d08b2401b', pr_url=None, repo_url=RepoUrl('https://huggingface.co/Geraldine/Qwen3-0.6B-finetuned-unimarc-reasoning', endpoint='https://huggingface.co', repo_type='model', repo_id='Geraldine/Qwen3-0.6B-finetuned-unimarc-reasoning'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_model.push_to_hub(f\"Geraldine/Qwen3-0.6B-finetuned-unimarc-reasoning\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "7e1e03bd-e4bb-44a1-9577-f834d5c1dc9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tokenizer.json: 100%|██████████| 11.4M/11.4M [00:00<00:00, 12.3MB/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/Geraldine/Qwen3-0.6B-finetuned-unimarc-reasoning/commit/7e2cef8370c43dec36a3bf4e4ac49d0f9eed6db2', commit_message='Upload tokenizer', commit_description='', oid='7e2cef8370c43dec36a3bf4e4ac49d0f9eed6db2', pr_url=None, repo_url=RepoUrl('https://huggingface.co/Geraldine/Qwen3-0.6B-finetuned-unimarc-reasoning', endpoint='https://huggingface.co', repo_type='model', repo_id='Geraldine/Qwen3-0.6B-finetuned-unimarc-reasoning'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.push_to_hub(f\"Geraldine/Qwen3-0.6B-finetuned-unimarc-reasoning\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72372564-0a26-49ab-8293-3c11c88fa9aa",
   "metadata": {},
   "source": [
    "## Test inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "c75be792-f7ba-437d-a5bf-84607e7d32c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_model = merged_model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1fdbf59-f6a6-4d5c-80cf-a389a7a38474",
   "metadata": {},
   "source": [
    "or"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b405cd22-c3be-42f5-86ca-f2fa3148576f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"Geraldine/Qwen3-0.6B-finetuned-unimarc-reasoning\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "merged_model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    torch_dtype=\"auto\",\n",
    "    device_map=\"auto\",\n",
    "    #attn_implementation=\"flash_attention_2\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e68cd63a-04c0-4b8f-8567-47b29da93114",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" # for GPU usage or \"cpu\" for CPU usage\n",
    "merged_model = merged_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a4388a87-20a5-430a-bae1-aa4ec9847e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.padding_side = \"right\"\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "578e75aa-28a3-466c-b44b-00bafe956aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# simple test\n",
    "messages = [\n",
    "  {\"role\": \"system\", \"content\": \"You are a helpful assistant\"},\n",
    "  {\"role\": \"user\", \"content\": \"Give me a short introduction to large language model.\"},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1a4882ae-6ea1-4154-803d-efcc71abc1f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"\n",
    "You are an expert in Unimarc/XML generation from bibliographic metadata.\n",
    "\"\"\"\n",
    "\n",
    "user_prompt = \"\"\"\n",
    "Here are the metadata:\n",
    "# Bibliographical metadata\n",
    "Title: Technopolitique\n",
    "Subtitle: Comment la technologie fait de nous des soldats\n",
    "Author: Asma Mhalla\n",
    "Publisher: Éditions du Seuil\n",
    "Year: 2024\n",
    "ISBN: 978-2-0215-4854-9\n",
    "Language: French\n",
    "Collection/Series: N/A\n",
    "Edition: N/A\n",
    "Material description: 1 volume (275 pages), couverture illustrée, 21 cm\n",
    "Abstract/Notes: Intelligence artificielle, réseaux sociaux, implants cérébraux, satellites, métavers… Le choc technologique sera l’un des enjeux clés du XXIe siècle et les géants américains, les « BigTech », sont à l’avant-garde. Entités hybrides, ils remodèlent la morphologie des États, redéfinissent les jeux de pouvoir et de puissance entre nations, interviennent dans la guerre, tracent les nouvelles frontières de la souveraineté. S’ils sont au cœur de la fabrique de la puissance étatsunienne face à la Chine, ils sont également des agents perturbateurs de la démocratie. De ces liens ambivalents entre BigTech et « BigState » est né un nouveau Léviathan à deux têtes, animé par un désir de puissance hors limites. Mais qui gouverne ces nouveaux acteurs privés de la prolifération technologique ? A cette vertigineuse question, nous n’avons d’autre choix que d’opposer l’innovation politique ! S’attaquant à tous les faux débats qui nous font manquer l’essentiel, Asma Mhalla ose ainsi une thèse forte et perturbante : les technologies de l’hypervitesse, à la fois civiles et militaires, font de chacun d’entre nous, qu’on le veuille ou non, des soldats. Nos cerveaux sont devenus l’ultime champ de bataille. Il est urgent de le penser car ce n’est rien de moins que le nouvel ordre mondial qui est en jeu, mais aussi la démocratie.\n",
    "Source of the abstract/notes: 4e de couverture\n",
    "Table of contents:\n",
    "- Introduction\n",
    "- Chapitre 1. Le siècle de la Technologie Totale\n",
    "- Chapitre 2. Le Triptyque des Bigtech\n",
    "- Chapitre 3. L'intelligence artificielle au cœur des batailles culturelles et idéologiques de la vallée\n",
    "- Chapitre 4. Aux confins des réseaux sociaux\n",
    "- Chapitre 5. De la guerre cognitive en démocratie\n",
    "- Chapitre 6. Puissance n'est pas (toujours) pouvoir\n",
    "- Chapitre 7. La militarisation du monde\n",
    "- Chapitre 8. Le spectre de l'hyperguerre\n",
    "- Chapitre 9. Naissance du complexe techno-militaire américain ?\n",
    "- Chapitre 10. La doctrine de l'information totale\n",
    "- Chapitre 11. Odyssée vers le futur\n",
    "- Conclusion. Entrer dans le nouveau siècle politique\n",
    "Keywords: Société numérique, Technologies de l'information et de la communication, Humanité, Science politique, Relations internationales, Société, Effets des innovations technologiques\n",
    "\"\"\"\n",
    "\n",
    "messages = [\n",
    "  {\"role\": \"system\", \"content\": system_prompt},\n",
    "  {\"role\": \"user\", \"content\": user_prompt},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b381a46b-e8d4-4614-984b-d27fb951f93f",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer.apply_chat_template(\n",
    "    messages,\n",
    "    return_dict=True,\n",
    "    tokenize = True,\n",
    "    add_generation_prompt = True, # Must add for generation\n",
    "    return_tensors = \"pt\",\n",
    "    enable_thinking=True\n",
    ").to(device)\n",
    "\n",
    "outputs = merged_model.generate(\n",
    "    **inputs,\n",
    "    max_new_tokens = 32768,\n",
    "    use_cache = True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "845743fc-e35f-4b16-b425-1d5f35b82059",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thinking content: <think>\n",
      "Okay, let's look at the bibliographic metadata for the book \"Technopolitique\" by Asma Mhalla. The user wants the 2024 Unimarc/XML representation of this book's metadata.\n",
      "\n",
      "First, the author is Asma Mhalla, and the publication is Éditions du Seuil, 2024. The ISBN is 978-2-0215-4854-9. The language is French. The collection is not specified, but the main subject field includes \"Société numérique\", \"Technologies de l'information et de la communication\", \"Humanité\", and \"Science politique\". The subject headings also mention international relations, social sciences, and technological effects.\n",
      "\n",
      "The physical description indicates one volume of 275 pages with an illustrated cover. The abstract/notes is a full text summary from the back cover. The edition is not specified further. \n",
      "\n",
      "No other authors or contributors are present. The format and content fields are all present, and the data is correctly structured according to the Unimarc XML standards. The subject headings are in the correct RAMEAU language code. The metadata is comprehensive and correctly captures all relevant information related to the book. No errors or missing fields are present. This confirms that the book is a well-documented and informative work on technological influence on politics and society.\n",
      "</think>\n",
      "content: <file><ref><title>Technopolitique</title><author>Asma Mhalla</author><publisher>Éditions du Seuil</publisher><year>2024</year><isbn>978-2-0215-4854-9</language>fre</language><physical_description>1 volume (275 pages), couverture illustrée</physical_description><subjects><symbol>RAMEAU</symbol> Société numérique, Technologies de l'information et de la communication, Humanité, Science politique, Relations internationales, Société, Effets des innovations technologiques</subjects><collection>Non spécifié</collection><date>2024</date></file>\n"
     ]
    }
   ],
   "source": [
    "output_ids = outputs[0][len(inputs.input_ids[0]):].tolist()\n",
    "# parsing thinking content\n",
    "try:\n",
    "    # rindex finding 151668 (</think>)\n",
    "    index = len(output_ids) - output_ids[::-1].index(151668)\n",
    "except ValueError:\n",
    "    index = 0\n",
    "\n",
    "thinking_content = tokenizer.decode(output_ids[:index], skip_special_tokens=True).strip(\"\\n\")\n",
    "content = tokenizer.decode(output_ids[index:], skip_special_tokens=True).strip(\"\\n\")\n",
    "\n",
    "print(\"thinking content:\", thinking_content)\n",
    "print(\"content:\", content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa5c29fc-14f8-4428-b961-5ad2f92ed3f9",
   "metadata": {},
   "source": [
    "# Reload model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d4a0e43e-411c-4bde-b72d-4d66156cbac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "78ac603c-bed7-4c20-b7f0-b1eacd1ab52e",
   "metadata": {},
   "outputs": [],
   "source": [
    "del model\n",
    "del tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "af78dffb-a39f-4d1b-9a5d-75d3b66fbc08",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"Geraldine/Qwen3-0.6B-finetuned-unimarc-reasoning\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    torch_dtype=\"auto\",\n",
    "    device_map=\"auto\",\n",
    "    #attn_implementation=\"flash_attention_2\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "126df7f7-9028-4725-b5fd-976d86fb0350",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Qwen3ForCausalLM(\n",
       "  (model): Qwen3Model(\n",
       "    (embed_tokens): Embedding(151936, 1024)\n",
       "    (layers): ModuleList(\n",
       "      (0-27): 28 x Qwen3DecoderLayer(\n",
       "        (self_attn): Qwen3Attention(\n",
       "          (q_proj): Linear(in_features=1024, out_features=2048, bias=False)\n",
       "          (k_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (v_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (o_proj): Linear(in_features=2048, out_features=1024, bias=False)\n",
       "          (q_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
       "          (k_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
       "        )\n",
       "        (mlp): Qwen3MLP(\n",
       "          (gate_proj): Linear(in_features=1024, out_features=3072, bias=False)\n",
       "          (up_proj): Linear(in_features=1024, out_features=3072, bias=False)\n",
       "          (down_proj): Linear(in_features=3072, out_features=1024, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): Qwen3RMSNorm((1024,), eps=1e-06)\n",
       "        (post_attention_layernorm): Qwen3RMSNorm((1024,), eps=1e-06)\n",
       "      )\n",
       "    )\n",
       "    (norm): Qwen3RMSNorm((1024,), eps=1e-06)\n",
       "    (rotary_emb): Qwen3RotaryEmbedding()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=1024, out_features=151936, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"cuda\" # for GPU usage or \"cpu\" for CPU usage\n",
    "model = model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "52f2731b-cbdf-414f-bf04-ce6a5a10c05b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !Important\n",
    "tokenizer.padding_side = \"right\"\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "27d6369a-2244-42d1-a7b9-1942ab863e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"\n",
    "You are an expert in Unimarc/XML bibliographic records encoding.\n",
    "Generate an XML Unimarc record from the given bibliographic metadata.\n",
    "\"\"\"\n",
    "\n",
    "user_prompt = \"\"\"\n",
    "Title: Comprendre l'autisme pour les nuls\n",
    "Authors: Stephen M. Shore, Linda G. Rastelli\n",
    "With: avant-propos de Temple Grandin; traduction et avant-propos de Josef Schovanec et Caroline Glorion\n",
    "Publisher: First éditions, Paris\n",
    "Year: DL 2015\n",
    "Edition: (not explicitly stated)\n",
    "Collection/Series: Pour les nuls\n",
    "Material description: 1 vol. (XXVI-382 p.); ill., couv. ill. en coul.; 23 cm\n",
    "ISBN: 978-2-7540-6581-8\n",
    "Price: 22,95 EUR\n",
    "Language: French (fre); with English (eng) secondary coding\n",
    "Country of publication: FR (France)\n",
    "Notes/Bibliography: Bibliogr. p. 374-375. Liste de sites internet p. 370-373. Index\n",
    "Additional description: La couv. porte en plus : \"Comment diagnostiquer l'autisme ; Les différents syndromes : Asperger, Rett ; Enfant, adulte, trouver l'aide nécessaire et savoir réagir\"\n",
    "Abstract/Notes Source: (not explicitly given)\n",
    "Keywords / Subject Headings:\n",
    "- Trouble autistique (MeSH)\n",
    "- Troubles généralisés du développement de l'enfant (MeSH)\n",
    "- Syndrome de Rett (MeSH)\n",
    "- Syndrome d'Asperger (MeSH)\n",
    "- Autisme (RAMEAU)\n",
    "- Syndrome de Rett (RAMEAU)\n",
    "- Syndrome d'Asperger (RAMEAU)\n",
    "\n",
    "Contributors:\n",
    "- Shore, Stephen M. (1961-), author\n",
    "- Rastelli, Linda G. (19..-), author\n",
    "- Grandin, Temple (1947-), avant-propos\n",
    "- Schovanec, Josef (1981-), philosophe et sociologue, traduction et avant-propos\n",
    "- Glorion, Caroline (1954-), traduction et avant-propos\n",
    "\n",
    "Other titles: Understanding autism for dummies (English equivalent title)\n",
    "Source: French national catalog record (http://www.sudoc.fr/184834244)\n",
    "Control Numbers:\n",
    "- OCLC: 907002543\n",
    "- SUDOC: 184834244\n",
    "- Identifiant local: 184834244\n",
    "\n",
    "Language Codes: fre (French), eng (English)\n",
    "Format content: text\n",
    "Media type: non-projectable medium\n",
    "Carrier type: graphic carrier\n",
    "\n",
    "Library info:\n",
    "- ABES cataloging date: 2024-04-10\n",
    "- Cataloged by ABES (France)\n",
    "\n",
    "This record describes a French translation (with added prefaces) of a book on autism for general readers, part of the well-known \"Pour les nuls\" series.\n",
    "\"\"\"\n",
    "\n",
    "messages = [\n",
    "  {\"role\": \"system\", \"content\": system_prompt},\n",
    "  {\"role\": \"user\", \"content\": user_prompt},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "97c31e28-d1b5-4864-9059-1a81e85b9951",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer.apply_chat_template(\n",
    "    messages,\n",
    "    return_dict=True,\n",
    "    tokenize = True,\n",
    "    add_generation_prompt = True, # Must add for generation\n",
    "    return_tensors = \"pt\",\n",
    "    enable_thinking=True\n",
    ").to(device)\n",
    "\n",
    "outputs = model.generate(\n",
    "    **inputs,\n",
    "    max_new_tokens = 32768,\n",
    "    use_cache = True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f81743a4-d36a-42bf-849f-85cc5a056f47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<think>\n",
      "Okay, let me start by looking at the user's request. They provided a bibliographic metadata about \"Comprendre l'autisme pour les nuls\" by Stephen M. Shore and Linda G. Rastelli, and they want me to generate an XML Unimarc record from that data.\n",
      "\n",
      "First, I need to recall the structure of the Unimarc XML record. The fields include title, authors, publisher, year, material description, price, country, ISBN, and notes. Also, there are keywords and bibliographic notes. The user included some codes like \"fre\" (French), \"eng\" (English), and \"RAMEAU\" (French keywords). The collection/series is \"Pour les nuls\" with an additional note about the websites.\n",
      "\n",
      "I should check the original data provided. The original title is \"Comprendre l'autisme pour les nuls\", authors are mentioned as Shore and Rastelli, with prefaces from Temple Grandin and Josef Schovanec. The publisher is First éditions, year 2015, collection \"Pour les nuls\", material description as mentioned, price 22,95 EUR, country France, ISBN 978-2-7540-6581-8, and additional notes about the cover and supplementary material.\n",
      "\n",
      "The keywords and notes include MeSH codes and additional information. The language codes are already included. The control numbers are OCLC and SUDOC codes. The library info includes ABES date and cataloging details.\n",
      "\n",
      "I need to ensure that all the provided information is correctly mapped into the Unimarc XML structure. I'll start by creating the basic elements: title, authors, publisher, year, material description, price, country, etc. Then include the keywords and notes. The abstract or source notes might be included under the \"notes\" section. The language codes are already covered in the \"language\" field. The collection/Series is noted as \"Pour les nuls\", with an additional note about the websites. The price and country are included. The ISBN and OCLC numbers are added. The format is non-projectable medium, carrier type graphic, and the table of contents is indicated.\n",
      "\n",
      "I should also check for any special codes or tags that might be present, like \"With\" and \"Bibliography\" notes. The user included \"Bibliogr. p. 374-375\" and \"Index\" under the notes, which are standard tags. The abstract or source notes are covered under the \"notes\" section. The keywords are part of the \"keywords\" field. The record ends with the library info and cataloging details.\n",
      "\n",
      "I need to make sure that all the information provided is accurately reflected without adding any extra data. The user's input includes all necessary fields, so the generated XML should match exactly what's provided. Finally, double-check the XML structure to ensure it's valid and follows the Unimarc standards.\n",
      "</think>\n",
      "\n",
      "```xml\n",
      "<record><controlfield tag=\"005\">20240410125233.000</controlfield><datafield tag=\"035\" ind1=\" \" ind2=\" \"><subfield code=\"a\">978-2-7540-6581-8</subfield><subfield code=\"b\">Rett</subfield><subfield code=\"c\">fre</subfield><subfield code=\"d\">Rett</subfield></datafield><datafield tag=\"033\" ind1=\" \" ind2=\"0\"><subfield code=\"a\">22,95 EUR</subfield></datafield><datafield tag=\"100\" ind1=\" \" ind2=\" \"><subfield code=\"a\">Comprendre l'autisme pour les nuls</subfield><subfield code=\"b\">9782754065818</subfield></datafield><datafield tag=\"101\" ind1=\" \" ind2=\" \"><subfield code=\"a\">fre</subfield><subfield code=\"b\">fre</subfield><subfield code=\"b\">eng</subfield></datafield><datafield tag=\"109\" ind1=\" \" ind2=\" \"><subfield code=\"a\">www.sudoc.fr/184834244</subfield></datafield><datafield tag=\"130\" ind1=\" \" ind2=\" \"><subfield code=\"a\">SUDOC</subfield><subfield code=\"b\">184834244</subfield></datafield><datafield tag=\"200\" ind1=\" \" ind2=\" \"><subfield code=\"a\">http://www.sudoc.fr/184834244</subfield></datafield><datafield tag=\"245\" ind1=\" \" ind2=\" \"><subfield code=\"6\">a</subfield><subfield code=\"2\">r</subfield></datafield><datafield tag=\"245\" ind1=\" \" ind2=\"1\"><subfield code=\"6\">r</subfield><subfield code=\"2\">r</subfield></datafield><datafield tag=\"264\" ind1=\" \" ind2=\" \"><subfield code=\"a\">index</subfield></datafield><datafield tag=\"264\" ind1=\" \" ind2=\"1\"><subfield code=\"a\">index</subfield></datafield><datafield tag=\"270\" ind1=\" \" ind2=\" \"><subfield code=\"a\">cover</subfield></datafield><datafield tag=\"270\" ind1=\" \" ind2=\" \"><subfield code=\"a\">couverte</subfield></datafield><datafield tag=\"303\" ind1=\" \" ind2=\" \"><subfield code=\"a\">Rett</subfield></datafield><datafield tag=\"303\" ind1=\" \" ind2=\"1\"><subfield code=\"a\">Rett</subfield></datafield><datafield tag=\"343\" ind1=\" \" ind2=\" \"><subfield code=\"a\">Rett</subfield></datafield><datafield tag=\"350\" ind1=\" \" ind2=\" \"><subfield code=\"a\">Rett</subfield></datafield><datafield tag=\"440\" ind1=\" \" ind2=\" \"><subfield code=\"a\">Rett</subfield></datafield><datafield tag=\"440\" ind1=\" \" ind2=\"1\"><subfield code=\"a\">Rett</subfield></datafield><datafield tag=\"540\" ind1=\" \" ind2=\" \"><subfield code=\"a\">Rett</subfield></datafield><datafield tag=\"610\" ind1=\" \" ind2=\" \"><subfield code=\"a\">Rett</subfield></datafield><datafield tag=\"660\" ind1=\" \" ind2=\" \"><subfield code=\"a\">Rett</subfield></datafield><datafield tag=\"700\" ind1=\" \" ind2=\" \"><subfield code=\"a\">Rett</subfield></datafield></record>\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "generated_ids = [\n",
    "   output_ids[len(input_ids):] for input_ids, output_ids in zip(inputs.input_ids, outputs)\n",
    "]\n",
    "print(tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0])\n",
    "response = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d8020ee-4889-4a3c-a278-606944f25880",
   "metadata": {},
   "source": [
    "# Reward functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f6c955c-550b-412b-9723-6f7729a04cef",
   "metadata": {},
   "source": [
    "## utils functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7d53cc64-58bc-457a-8aa8-4729e5934045",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "import re\n",
    "\n",
    "def extract_hash_answer(text: str) -> str | None:\n",
    "    # Use model response structure to find the XML part\n",
    "    if \"</think>\" not in text:\n",
    "        return text\n",
    "    return text.split(\"</think>\")[1].strip()\n",
    "\n",
    "def extract_xml(text: str) -> str | None:\n",
    "    # Use regular expression to find the XML part enclosed in ```xml...```\n",
    "    xml_match = re.search(r'```xml(.*?)```', response, re.DOTALL)\n",
    "    if xml_match:\n",
    "        return xml_match.group(1).strip()\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def extract_field_values(xml_str):\n",
    "    root = ET.fromstring(xml_str)\n",
    "    fields = {}\n",
    "    for df in root.findall(\".//datafield\"):\n",
    "        tag = df.get(\"tag\")\n",
    "        subfields = [sf.text for sf in df.findall(\"subfield\")]\n",
    "        fields[tag] = \" \".join(subfields)\n",
    "    return fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5f9cf5c4-2f15-46c4-b8f1-ae2a497b8e82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```xml\n",
      "<record><controlfield tag=\"005\">20240410182933.000</controlfield><datafield tag=\"035\" ind1=\" \" ind2=\" \"><subfield code=\"a\">(OCoLC)907002543</subfield><subfield code=\"b\">http://www.sudoc.fr/184834244</subfield><subfield code=\"b\">SUDOC</subfield></datafield><datafield tag=\"033\" ind1=\" \" ind2=\" \"><subfield code=\"a\">22,95</subfield><subfield code=\"b\">978-2-7540-6581-8</subfield></datafield><datafield tag=\"100\" ind1=\" \" ind2=\" \"><subfield code=\"a\">Stephen M. Shore</subfield><subfield code=\"b\">http://www.sudoc.fr/184834244</subfield><datafield tag=\"101\" ind1=\" \" ind2=\" \"><subfield code=\"a\">FR</subfield><subfield code=\"b\">fre</subfield><subfield code=\"b\">eng</subfield></datafield><datafield tag=\"101\" ind1=\" \" ind2=\" \"><subfield code=\"a\">22,95</subfield><subfield code=\"b\">978-2-7540-6581-8</subfield></datafield><datafield tag=\"105\" ind1=\" \" ind2=\" \"><subfield code=\"a\">DL</subfield><subfield code=\"b\">2015</subfield><subfield code=\"b\">Y</subfield></datafield><datafield tag=\"106\" ind1=\" \" ind2=\" \"><subfield code=\"a\">235423</subfield></datafield><datafield tag=\"181\" ind1=\" \" ind2=\" \"><subfield code=\"a\">978-2-7540-6581-8</subfield><subfield code=\"b\">fre</subfield><subfield code=\"b\">eng</subfield></datafield><datafield tag=\"181\" ind1=\" \" ind2=\"1\"><subfield code=\"6\">978</subfield><subfield code=\"a\">235423</subfield></datafield><datafield tag=\"182\" ind1=\" \" ind2=\" \"><subfield code=\"6\">275423</subfield></datafield><datafield tag=\"183\" ind1=\" \" ind2=\" \"><subfield code=\"6\">235423</subfield></datafield><datafield tag=\"185\" ind1=\" \" ind2=\" \"><subfield code=\"6\">235423</subfield></datafield><datafield tag=\"200\" ind1=\" \" ind2=\" \"><subfield code=\"a\">First édition</subfield><subfield code=\"b\">Paris</subfield><subfield code=\"b\">Y</subfield></datafield><datafield tag=\"201\" ind1=\" \" ind2=\" \"><subfield code=\"6\">a</subfield><subfield code=\"6\">2015</subfield></datafield><datafield tag=\"201\" ind1=\" \" ind2=\"1\"><subfield code=\"6\">2015</subfield><subfield code=\"6\">Y</subfield></datafield><datafield tag=\"203\" ind1=\" \" ind2=\" \"><subfield code=\"6\">275423</subfield></datafield><datafield tag=\"204\" ind1=\" \" ind2=\" \"><subfield code=\"6\">235423</subfield></datafield><datafield tag=\"205\" ind1=\" \" ind2=\" \"><subfield code=\"6\">235423</subfield></datafield><datafield tag=\"210\" ind1=\" \" ind2=\" \"><subfield code=\"6\">235423</subfield></datafield><datafield tag=\"211\" ind1=\" \" ind2=\" \"><subfield code=\"6\">235423</subfield></datafield><datafield tag=\"212\" ind1=\" \" ind2=\" \"><subfield code=\"6\">235423</subfield></datafield><datafield tag=\"220\" ind1=\" \" ind2=\" \"><subfield code=\"6\">275423</subfield></datafield><datafield tag=\"221\" ind1=\" \" ind2=\" \"><subfield code=\"6\">235423</subfield></datafield><datafield tag=\"222\" ind1=\" \" ind2=\" \"><subfield code=\"6\">235423</subfield></datafield><datafield tag=\"223\" ind1=\" \" ind2=\" \"><subfield code=\"6\">235423</subfield></datafield><datafield tag=\"224\" ind1=\" \" ind2=\" \"><subfield code=\"6\">235423</subfield></datafield><datafield tag=\"225\" ind1=\" \" ind2=\" \"><subfield code=\"6\">235423</subfield></datafield><datafield tag=\"226\" ind1=\" \" ind2=\" \"><subfield code=\"6\">235423</subfield></datafield><datafield tag=\"227\" ind1=\" \" ind2=\" \"><subfield code=\"6\">235423</subfield></datafield><datafield tag=\"228\" ind1=\" \" ind2=\" \"><subfield code=\"6\">235423</subfield></datafield><datafield tag=\"229\" ind1=\" \" ind2=\" \"><subfield code=\"6\">235423</subfield></datafield><datafield tag=\"230\" ind1=\" \" ind2=\" \"><subfield code=\"6\">235423</subfield></datafield></datafield>\n",
      "</record>\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "print(extract_hash_answer(text=response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ff7bf179-7fa4-48c0-8c78-b06dcf90e38b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<record><controlfield tag=\"005\">20240410125233.000</controlfield><datafield tag=\"035\" ind1=\" \" ind2=\" \"><subfield code=\"a\">978-2-7540-6581-8</subfield><subfield code=\"b\">Rett</subfield><subfield code=\"c\">fre</subfield><subfield code=\"d\">Rett</subfield></datafield><datafield tag=\"033\" ind1=\" \" ind2=\"0\"><subfield code=\"a\">22,95 EUR</subfield></datafield><datafield tag=\"100\" ind1=\" \" ind2=\" \"><subfield code=\"a\">Comprendre l'autisme pour les nuls</subfield><subfield code=\"b\">9782754065818</subfield></datafield><datafield tag=\"101\" ind1=\" \" ind2=\" \"><subfield code=\"a\">fre</subfield><subfield code=\"b\">fre</subfield><subfield code=\"b\">eng</subfield></datafield><datafield tag=\"109\" ind1=\" \" ind2=\" \"><subfield code=\"a\">www.sudoc.fr/184834244</subfield></datafield><datafield tag=\"130\" ind1=\" \" ind2=\" \"><subfield code=\"a\">SUDOC</subfield><subfield code=\"b\">184834244</subfield></datafield><datafield tag=\"200\" ind1=\" \" ind2=\" \"><subfield code=\"a\">http://www.sudoc.fr/184834244</subfield></datafield><datafield tag=\"245\" ind1=\" \" ind2=\" \"><subfield code=\"6\">a</subfield><subfield code=\"2\">r</subfield></datafield><datafield tag=\"245\" ind1=\" \" ind2=\"1\"><subfield code=\"6\">r</subfield><subfield code=\"2\">r</subfield></datafield><datafield tag=\"264\" ind1=\" \" ind2=\" \"><subfield code=\"a\">index</subfield></datafield><datafield tag=\"264\" ind1=\" \" ind2=\"1\"><subfield code=\"a\">index</subfield></datafield><datafield tag=\"270\" ind1=\" \" ind2=\" \"><subfield code=\"a\">cover</subfield></datafield><datafield tag=\"270\" ind1=\" \" ind2=\" \"><subfield code=\"a\">couverte</subfield></datafield><datafield tag=\"303\" ind1=\" \" ind2=\" \"><subfield code=\"a\">Rett</subfield></datafield><datafield tag=\"303\" ind1=\" \" ind2=\"1\"><subfield code=\"a\">Rett</subfield></datafield><datafield tag=\"343\" ind1=\" \" ind2=\" \"><subfield code=\"a\">Rett</subfield></datafield><datafield tag=\"350\" ind1=\" \" ind2=\" \"><subfield code=\"a\">Rett</subfield></datafield><datafield tag=\"440\" ind1=\" \" ind2=\" \"><subfield code=\"a\">Rett</subfield></datafield><datafield tag=\"440\" ind1=\" \" ind2=\"1\"><subfield code=\"a\">Rett</subfield></datafield><datafield tag=\"540\" ind1=\" \" ind2=\" \"><subfield code=\"a\">Rett</subfield></datafield><datafield tag=\"610\" ind1=\" \" ind2=\" \"><subfield code=\"a\">Rett</subfield></datafield><datafield tag=\"660\" ind1=\" \" ind2=\" \"><subfield code=\"a\">Rett</subfield></datafield><datafield tag=\"700\" ind1=\" \" ind2=\" \"><subfield code=\"a\">Rett</subfield></datafield></record>\n"
     ]
    }
   ],
   "source": [
    "print(extract_xml(text=response))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5e0c0ec-44c7-4f19-8055-f760b4627cf0",
   "metadata": {},
   "source": [
    "## Test Format-based reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2bcd0252-36d8-4281-8ad3-b7081cf1b1d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_reward(xml_output: str) -> float:\n",
    "    try:\n",
    "        root = ET.fromstring(xml_output)\n",
    "    except ET.ParseError:\n",
    "        return 0.0  # Not even valid XML\n",
    "\n",
    "    required_tags = [\"leader\", \"controlfield\", \"datafield\", \"subfield\"]\n",
    "    has_required_tags = all(root.find(f\".//{tag}\") is not None for tag in required_tags)\n",
    "\n",
    "    if not has_required_tags:\n",
    "        return 0.3  # Barely structured but not fully compliant\n",
    "\n",
    "    # Optionally: integrate XSD/Schematron validation here\n",
    "    return 1.0  # Well-formed and conforms to expected structure\n",
    "\n",
    "def format_reward_2(xml_output: str) -> float:\n",
    "    try:\n",
    "        root = ET.fromstring(xml_output)\n",
    "    except ET.ParseError:\n",
    "        return 0.0\n",
    "\n",
    "    score = 0.2  # Starts above 0 for well-formed but noncompliant XML\n",
    "\n",
    "    if root.find(\".//controlfield\") is not None:\n",
    "        score += 0.1\n",
    "    if root.find(\".//leader\") is not None:\n",
    "        score += 0.1\n",
    "    if root.find(\".//datafield\") is not None:\n",
    "        score += 0.3\n",
    "    if root.find(\".//subfield\") is not None:\n",
    "        score += 0.3\n",
    "\n",
    "    return min(score, 1.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0e9a09fc-3630-42bc-a6dc-2776b54e7239",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3\n",
      "0.9000000000000001\n"
     ]
    }
   ],
   "source": [
    "xml_answer = extract_xml(text=response)\n",
    "print(format_reward(xml_output=xml_answer))\n",
    "print(format_reward_2(xml_output=xml_answer))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6a96315-00f0-4ca5-b286-710546be8425",
   "metadata": {},
   "source": [
    "## Test Accuracy-based reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c94bbef0-8539-47c6-96ac-2df18b8a54d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "xml_answer = extract_xml(text=response)\n",
    "xml_target = \"\"\"<record><controlfield tag=\"005\">20240731164753.000</controlfield><leader> cam0 22 450 </leader><controlfield tag=\"001\">276421795</controlfield><controlfield tag=\"003\">http://www.sudoc.fr/276421795</controlfield><datafield tag=\"035\" ind1=\" \" ind2=\" \"><subfield code=\"a\">(OCoLC)1426782189</subfield></datafield><datafield tag=\"010\" ind1=\" \" ind2=\" \"><subfield code=\"a\">978-2-10-086210-8</subfield><subfield code=\"b\">br.</subfield></datafield><datafield tag=\"073\" ind1=\" \" ind2=\"1\"><subfield code=\"a\">9782100862108</subfield></datafield><datafield tag=\"100\" ind1=\" \" ind2=\" \"><subfield code=\"a\">20240315h20242024m y0frey50 ba</subfield></datafield><datafield tag=\"101\" ind1=\"0\" ind2=\" \"><subfield code=\"a\">fre</subfield><subfield code=\"d\">fre</subfield><subfield code=\"2\">639-2</subfield></datafield><datafield tag=\"105\" ind1=\" \" ind2=\" \"><subfield code=\"a\">ab a 000yy</subfield></datafield><datafield tag=\"106\" ind1=\" \" ind2=\" \"><subfield code=\"a\">r</subfield></datafield><datafield tag=\"181\" ind1=\" \" ind2=\" \"><subfield code=\"6\">z01</subfield><subfield code=\"c\">txt</subfield><subfield code=\"2\">rdacontent</subfield></datafield><datafield tag=\"181\" ind1=\" \" ind2=\"1\"><subfield code=\"6\">z01</subfield><subfield code=\"a\">i#</subfield><subfield code=\"b\">xxxe##</subfield></datafield><datafield tag=\"182\" ind1=\" \" ind2=\" \"><subfield code=\"6\">z01</subfield><subfield code=\"c\">n</subfield><subfield code=\"2\">rdamedia</subfield></datafield><datafield tag=\"182\" ind1=\" \" ind2=\"1\"><subfield code=\"6\">z01</subfield><subfield code=\"a\">n</subfield></datafield><datafield tag=\"183\" ind1=\" \" ind2=\"1\"><subfield code=\"6\">z01</subfield><subfield code=\"a\">nga</subfield><subfield code=\"2\">RDAfrCarrier</subfield></datafield><datafield tag=\"102\" ind1=\" \" ind2=\" \"><subfield code=\"a\">FR</subfield></datafield><datafield tag=\"320\" ind1=\" \" ind2=\" \"><subfield code=\"a\">Biblbiogr. p. 243-250</subfield></datafield><datafield tag=\"200\" ind1=\"1\" ind2=\" \"><subfield code=\"a\">12 clés économiques pour aborder 2030</subfield><subfield code=\"e\">maîtriser les enjeux qui feront le monde de demain</subfield><subfield code=\"f\">BSI Economics</subfield><subfield code=\"g\">[ouvrage coordonné par Victor Lequillerier et Mathieu Obertelli]</subfield></datafield><datafield tag=\"517\" ind1=\"|\" ind2=\" \"><subfield code=\"a\">Douze clés économiques pour aborder deux mille trente</subfield></datafield><datafield tag=\"701\" ind1=\" \" ind2=\"1\"><subfield code=\"3\">242250564</subfield><subfield code=\"a\">Lequillerier</subfield><subfield code=\"b\">Victor</subfield><subfield code=\"4\">651</subfield></datafield><datafield tag=\"701\" ind1=\" \" ind2=\"1\"><subfield code=\"3\">276422082</subfield><subfield code=\"a\">Obertelli</subfield><subfield code=\"b\">Mathieu</subfield><subfield code=\"f\">19..-....</subfield><subfield code=\"4\">651</subfield></datafield><datafield tag=\"710\" ind1=\"0\" ind2=\"2\"><subfield code=\"3\">233994092</subfield><subfield code=\"a\">BSI Economics</subfield><subfield code=\"4\">070</subfield></datafield><datafield tag=\"801\" ind1=\" \" ind2=\"3\"><subfield code=\"a\">FR</subfield><subfield code=\"b\">Abes</subfield><subfield code=\"c\">20240731</subfield><subfield code=\"g\">AFNOR</subfield></datafield><datafield tag=\"214\" ind1=\" \" ind2=\"0\"><subfield code=\"a\">Malakoff</subfield><subfield code=\"c\">Dunod</subfield><subfield code=\"d\">DL 2024</subfield></datafield><datafield tag=\"215\" ind1=\" \" ind2=\" \"><subfield code=\"a\">1 volume (255 pages)</subfield><subfield code=\"c\">graphiques, tableaux, schémas, cartes</subfield><subfield code=\"d\">22 cm</subfield></datafield><datafield tag=\"606\" ind1=\" \" ind2=\" \"><subfield code=\"3\">028209796</subfield><subfield code=\"a\">Économie politique</subfield><subfield code=\"z\">1945-....</subfield><subfield code=\"2\">rameau</subfield></datafield><datafield tag=\"606\" ind1=\" \" ind2=\" \"><subfield code=\"3\">027323161</subfield><subfield code=\"a\">Relations économiques internationales</subfield><subfield code=\"2\">rameau</subfield></datafield><datafield tag=\"606\" ind1=\" \" ind2=\" \"><subfield code=\"3\">027245276</subfield><subfield code=\"a\">Prévision économique</subfield><subfield code=\"2\">rameau</subfield></datafield><datafield tag=\"676\" ind1=\" \" ind2=\" \"><subfield code=\"a\">337</subfield><subfield code=\"v\">23</subfield></datafield><datafield tag=\"676\" ind1=\" \" ind2=\" \"><subfield code=\"a\">330</subfield></datafield><datafield tag=\"314\" ind1=\" \" ind2=\" \"><subfield code=\"a\">Avec la collaboration de Hervé Amourda, Evelyne Banh, Ana Boata, Pierre Bossuet, Cecile Buchholz, Paul Chollet, Alexis Garatti, Charlotte Gardes, Arthur Jurus, Julien Lecumberry, Jérôme Mathis, Rodrigue Mear, Anthony Morlet-Lavidalie, Julien Moussavi, Sandra Nevoux, Ludovic Subran et Maëlle Vaille</subfield></datafield><datafield tag=\"359\" ind1=\"2\" ind2=\" \"><subfield code=\"p\">P.7</subfield><subfield code=\"b\">Introduction</subfield><subfield code=\"p\">P.9</subfield><subfield code=\"b\">1. L'endettement des États européens est-il soutenable ? Quelles sont les solutions ?</subfield><subfield code=\"p\">P.27</subfield><subfield code=\"b\">2. La mainmise de l'inflation va-t-elle disparaître ?</subfield><subfield code=\"p\">P.49</subfield><subfield code=\"b\">3. Quel avenir pour la politique monétaire ?</subfield><subfield code=\"p\">P.71</subfield><subfield code=\"b\">4. Le vieillissement démographique va-t-il raviver ou tuer l'inflation ?</subfield><subfield code=\"p\">P.89</subfield><subfield code=\"b\">5. Économie de guerre au XXIe siècle : pourquoi les États-Unis sont-ils en situation de conflit permanent ?</subfield><subfield code=\"p\">P.107</subfield><subfield code=\"b\">6. La Chine, tout d'un numéro 1 ?</subfield><subfield code=\"p\">P.130</subfield><subfield code=\"b\">7. Comment verdir la finance ?</subfield><subfield code=\"p\">P.148</subfield><subfield code=\"b\">8. La décarbonation de l'économie européenne est-elle utopique ?</subfield><subfield code=\"p\">P.169</subfield><subfield code=\"b\">9. L'économie circulaire est-elle la solution aux défis environnementaux actuels et de demain ?</subfield><subfield code=\"p\">P.188</subfield><subfield code=\"b\">10. 2035 : plein gaz sur l'électrique ?</subfield><subfield code=\"p\">P.204</subfield><subfield code=\"b\">11. Le télétravail : une opportunité pour les territoires ?</subfield><subfield code=\"p\">P.224</subfield><subfield code=\"b\">12. Les cryptomonnaies : bulle spéculative ou révolution financière ?</subfield><subfield code=\"p\">P.243</subfield><subfield code=\"b\">Bibliographie</subfield><subfield code=\"p\">P.251</subfield><subfield code=\"b\">Présentation des auteurs</subfield></datafield><datafield tag=\"330\" ind1=\" \" ind2=\" \"><subfield code=\"a\">Cet ouvrage éclaire 12 questions au coeur de l'actualité, 12 problématiques dont les enjeux sont d'une importance majeure pour notre futur. Fruit du travail d'une nouvelle génération d'économistes, il offre une vision précise de l'état du monde actuel et fournit les clés pour comprendre les enjeux de demain, afin de pouvoir réfléchir en toute connaissance de cause aux moyens d'y faire face. L'endettement des États européens est-il soutenable ? ; La mainmise de l'inflation va-t-elle disparaître ? ; Quel avenir pour la politique monétaire ? ; Le vieillissement démographique va-t-il raviver ou tuer l'inflation ? ; Économie de guerre au XXIe siècle : pourquoi les États-Unis sont-ils en situation de conflit permanent ? ; La Chine, tout d'un numéro 1 ? ; Comment verdir la finance ? ; La décarbonation de l'économie européenne est-elle utopique ? ; L'économie circulaire est-elle la solution aux défis environnementaux actuels et de demain ? ; 2035 : plein gaz sur l'électrique ? ; Le télétravail : une opportunité pour les territoires ? ; Les cryptomonnaies : bulle spéculative ou révolution financière ?</subfield><subfield code=\"2\">4e de couverture</subfield></datafield></record>\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e3c9ba34-c696-48f2-bbb3-8948aacd81f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'035': '978-2-7540-6581-8 Rett fre Rett', '033': '22,95 EUR', '100': \"Comprendre l'autisme pour les nuls 9782754065818\", '101': 'fre fre eng', '109': 'www.sudoc.fr/184834244', '130': 'SUDOC 184834244', '200': 'http://www.sudoc.fr/184834244', '245': 'r r', '264': 'index', '270': 'couverte', '303': 'Rett', '343': 'Rett', '350': 'Rett', '440': 'Rett', '540': 'Rett', '610': 'Rett', '660': 'Rett', '700': 'Rett'}\n"
     ]
    }
   ],
   "source": [
    "print(extract_field_values(xml_answer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "861b1f63-fced-4103-802d-c255375203b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'035': '(OCoLC)1426782189', '010': '978-2-10-086210-8 br.', '073': '9782100862108', '100': '20240315h20242024m y0frey50 ba', '101': 'fre fre 639-2', '105': 'ab a 000yy', '106': 'r', '181': 'z01 i# xxxe##', '182': 'z01 n', '183': 'z01 nga RDAfrCarrier', '102': 'FR', '320': 'Biblbiogr. p. 243-250', '200': '12 clés économiques pour aborder 2030 maîtriser les enjeux qui feront le monde de demain BSI Economics [ouvrage coordonné par Victor Lequillerier et Mathieu Obertelli]', '517': 'Douze clés économiques pour aborder deux mille trente', '701': '276422082 Obertelli Mathieu 19..-.... 651', '710': '233994092 BSI Economics 070', '801': 'FR Abes 20240731 AFNOR', '214': 'Malakoff Dunod DL 2024', '215': '1 volume (255 pages) graphiques, tableaux, schémas, cartes 22 cm', '606': '027245276 Prévision économique rameau', '676': '330', '314': 'Avec la collaboration de Hervé Amourda, Evelyne Banh, Ana Boata, Pierre Bossuet, Cecile Buchholz, Paul Chollet, Alexis Garatti, Charlotte Gardes, Arthur Jurus, Julien Lecumberry, Jérôme Mathis, Rodrigue Mear, Anthony Morlet-Lavidalie, Julien Moussavi, Sandra Nevoux, Ludovic Subran et Maëlle Vaille', '359': \"P.7 Introduction P.9 1. L'endettement des États européens est-il soutenable ? Quelles sont les solutions ? P.27 2. La mainmise de l'inflation va-t-elle disparaître ? P.49 3. Quel avenir pour la politique monétaire ? P.71 4. Le vieillissement démographique va-t-il raviver ou tuer l'inflation ? P.89 5. Économie de guerre au XXIe siècle : pourquoi les États-Unis sont-ils en situation de conflit permanent ? P.107 6. La Chine, tout d'un numéro 1 ? P.130 7. Comment verdir la finance ? P.148 8. La décarbonation de l'économie européenne est-elle utopique ? P.169 9. L'économie circulaire est-elle la solution aux défis environnementaux actuels et de demain ? P.188 10. 2035 : plein gaz sur l'électrique ? P.204 11. Le télétravail : une opportunité pour les territoires ? P.224 12. Les cryptomonnaies : bulle spéculative ou révolution financière ? P.243 Bibliographie P.251 Présentation des auteurs\", '330': \"Cet ouvrage éclaire 12 questions au coeur de l'actualité, 12 problématiques dont les enjeux sont d'une importance majeure pour notre futur. Fruit du travail d'une nouvelle génération d'économistes, il offre une vision précise de l'état du monde actuel et fournit les clés pour comprendre les enjeux de demain, afin de pouvoir réfléchir en toute connaissance de cause aux moyens d'y faire face. L'endettement des États européens est-il soutenable ? ; La mainmise de l'inflation va-t-elle disparaître ? ; Quel avenir pour la politique monétaire ? ; Le vieillissement démographique va-t-il raviver ou tuer l'inflation ? ; Économie de guerre au XXIe siècle : pourquoi les États-Unis sont-ils en situation de conflit permanent ? ; La Chine, tout d'un numéro 1 ? ; Comment verdir la finance ? ; La décarbonation de l'économie européenne est-elle utopique ? ; L'économie circulaire est-elle la solution aux défis environnementaux actuels et de demain ? ; 2035 : plein gaz sur l'électrique ? ; Le télétravail : une opportunité pour les territoires ? ; Les cryptomonnaies : bulle spéculative ou révolution financière ? 4e de couverture\"}\n"
     ]
    }
   ],
   "source": [
    "print(extract_field_values(xml_target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0d5b9c3c-5edd-4e45-971a-160a8fad72f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import difflib\n",
    "\n",
    "def accuracy_reward(generated_xml: str, target_xml: str) -> float:\n",
    "    try:\n",
    "        gen_fields = extract_field_values(generated_xml)\n",
    "        tgt_fields = extract_field_values(target_xml)\n",
    "    except ET.ParseError:\n",
    "        return 0.0\n",
    "\n",
    "    shared_keys = set(gen_fields) & set(tgt_fields)\n",
    "    if not shared_keys:\n",
    "        return 0.0\n",
    "\n",
    "    total_sim = 0\n",
    "    for key in shared_keys:\n",
    "        sim = difflib.SequenceMatcher(None, gen_fields[key], tgt_fields[key]).ratio()\n",
    "        total_sim += sim\n",
    "\n",
    "    return total_sim / len(shared_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "236ca6a2-60b2-4dd8-bfb4-e34ea1a9ba83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.26079277864992145\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_reward(generated_xml=xml_answer, target_xml=xml_target))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "137a26a7-60f0-4bb4-99a9-b2ceee3fe29c",
   "metadata": {},
   "source": [
    "## Test Semantic-based reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5f4b227c-2eba-4a48-aa8b-15fcc4ef4e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_metadata(text: str) -> dict:\n",
    "    # Define the main fields with regular expressions\n",
    "    fields = {\n",
    "        \"Title\": r\"Title:\\s*(.+)\",\n",
    "        \"Subtitle\": r\"(?:s)?title(?:s)?:\\s*(.+)\",\n",
    "        \"Authors\": r\"Author(?:s)?:\\s*(.+)\",\n",
    "        \"Contributors\": r\"With:\\s*(.+)\",\n",
    "        \"Publisher\": r\"Publisher:\\s*(.+)\",\n",
    "        \"Year\": r\"Year:\\s*(.+)\",\n",
    "        \"Edition\": r\"Edition:\\s*(.+)\",\n",
    "        \"Collection/Series\": r\"Collection/Series:\\s*(.+)\",\n",
    "        \"Material description\": r\"Material description:\\s*(.+)\",\n",
    "        \"ISBN\": r\"ISBN:\\s*(.+)\",\n",
    "        \"Price\": r\"Price:\\s*(.+)\",\n",
    "        \"Language\": r\"Language:\\s*(.+)\",\n",
    "        \"Country of publication\": r\"Country of publication:\\s*(.+)\",\n",
    "        \"Notes/Bibliography\": r\"Notes/Bibliography:\\s*(.+)\",\n",
    "        \"Material description\": r\"(?:s)?description:\\s*(.+)\",\n",
    "        \"Abstract/Notes Source\": r\"Abstract/Notes Source:\\s*(.+)\",\n",
    "        \"Source\": r\"Source:\\s*(.+)\",\n",
    "        \"Language Codes\": r\"Language Codes:\\s*(.+)\",\n",
    "        \"Format content\": r\"Format content:\\s*(.+)\",\n",
    "        \"Media type\": r\"Media type:\\s*(.+)\",\n",
    "        \"Carrier type\": r\"Carrier type:\\s*(.+)\",\n",
    "        \"Library info\": r\"Library info:\\s*(.+)\",\n",
    "        \"Control Numbers\": r\"Control Numbers:\\s*(.+)\"\n",
    "    }\n",
    "    \n",
    "    # Initialize the metadata dictionary\n",
    "    metadata = {}\n",
    "\n",
    "    # First, extract the main fields\n",
    "    for field, pattern in fields.items():\n",
    "        match = re.search(pattern, text, re.DOTALL)\n",
    "        if match:\n",
    "            metadata[field] = match.group(1).strip()\n",
    "        else:\n",
    "            metadata[field] = None\n",
    "    \n",
    "    # Parse structured lists: Keywords / Subject Headings\n",
    "    keywords_match = re.search(r\"Keywords / Subject Headings:\\s*(.*?)\\n\\n\", text, re.DOTALL)\n",
    "    if keywords_match:\n",
    "        keywords = [kw.strip(\"- \").strip() for kw in keywords_match.group(1).split(\"\\n\") if kw.strip()]\n",
    "        metadata[\"Keywords / Subject Headings\"] = keywords\n",
    "\n",
    "    # Parse Contributors list\n",
    "    contributors_match = re.search(r\"Contributors:\\s*(.*?)\\n\\n\", text, re.DOTALL)\n",
    "    if contributors_match:\n",
    "        contributors = [c.strip(\"- \").strip() for c in contributors_match.group(1).split(\"\\n\") if c.strip()]\n",
    "        metadata[\"Contributors\"] = contributors\n",
    "\n",
    "    # Parse Control Numbers if exists\n",
    "    if metadata[\"Control Numbers\"]:\n",
    "        control_numbers = {}\n",
    "        for line in metadata[\"Control Numbers\"].split(\"\\n\"):\n",
    "            if \":\" in line:\n",
    "                key, value = line.split(\":\", 1)\n",
    "                control_numbers[key.strip()] = value.strip()\n",
    "        metadata[\"Control Numbers\"] = control_numbers\n",
    "\n",
    "    # Parse Library info if exists\n",
    "    if metadata[\"Library info\"]:\n",
    "        library_info = {}\n",
    "        for line in metadata[\"Library info\"].split(\"\\n\"):\n",
    "            if \":\" in line:\n",
    "                key, value = line.split(\":\", 1)\n",
    "                library_info[key.strip()] = value.strip()\n",
    "        metadata[\"Library info\"] = library_info\n",
    "\n",
    "    return metadata\n",
    "\n",
    "\n",
    "def semantic_field_reward(user_prompt: str, generated_xml: str) -> float:\n",
    "    try:\n",
    "        root = ET.fromstring(generated_xml)\n",
    "    except ET.ParseError:\n",
    "        return 0.0\n",
    "        \n",
    "    metadata = parse_metadata(user_prompt)\n",
    "    score = 0\n",
    "    max_score = 3  # Adjust based on fields you check\n",
    "\n",
    "    # Check title mapping\n",
    "    title = metadata.get(\"Title\")\n",
    "    df_200 = root.find(\".//datafield[@tag='200']\")\n",
    "    if df_200 is not None:\n",
    "        if any(sf.text and title in sf.text for sf in df_200.findall(\"subfield\")):\n",
    "            score += 1\n",
    "\n",
    "    # Check year mapping\n",
    "    year = metadata.get(\"Year\")\n",
    "    if year and generated_xml.find(year) != -1:\n",
    "        score += 1\n",
    "\n",
    "    # Check author mapping\n",
    "    authors = metadata.get(\"Author\")\n",
    "    if authors and any(a.strip() in generated_xml for a in authors.split(\",\")):\n",
    "        score += 1\n",
    "\n",
    "    return score / max_score\n",
    "\n",
    "def semantic_field_reward_2(user_prompt: str, generated_xml: str) -> float:\n",
    "    FIELD_MAPPINGS = {\n",
    "        \"Title\": (\"200\", \"a\"),              # Title → 200$a\n",
    "        \"Subtitle\": (\"200\", \"e\"),           # Subtitle → 200$e\n",
    "        \"Year\": (\"214\", \"d\"),               # Year → 214$d (Publication date)\n",
    "        \"Authors\": (\"700\", \"a\"),            # Authors → 700$a (Main Author)\n",
    "        \"Publisher\": (\"214\", \"c\"),          # Publisher → 214$c\n",
    "        \"ISBN\": (\"010\", \"a\"),               # ISBN → 010$a\n",
    "        \"Language\": (\"101\", \"a\"),           # Language → 101$a\n",
    "        \"Collection/Series\": (\"225\", \"a\"),         # Collection/Series → 225$a\n",
    "        \"Material description\": (\"215\", \"a\"), # Material description → 215$a\n",
    "        \"Price\": (\"010\", \"d\"),              # Price → 010$d\n",
    "        \"Abstract/Notes Source\": (\"330\", \"a\"),           # Abstract → 330$a\n",
    "        \"Country of publication\": (\"102\", \"a\"),            # Country of publication → 102$a\n",
    "        \"Edition\": (\"205\", \"a\"),            # Edition → 205$a\n",
    "        \"Notes\": (\"300\", \"a\"),              # Notes → 300$a\n",
    "        \"Keywords / Subject Headings\": (\"600\", \"a\")            # Keywords → 600$a (Subject Headings)\n",
    "    }\n",
    "    try:\n",
    "        root = ET.fromstring(generated_xml)\n",
    "    except ET.ParseError:\n",
    "        return 0.0\n",
    "    metadata = parse_metadata(user_prompt)\n",
    "    \n",
    "    total_fields = len(FIELD_MAPPINGS)\n",
    "    matched_fields = 0\n",
    "    \n",
    "    for field, (tag, subfield) in FIELD_MAPPINGS.items():\n",
    "        if field not in metadata:\n",
    "            continue\n",
    "        \n",
    "        # Locate the corresponding datafield and subfield in the XML\n",
    "        datafield = root.find(f\".//datafield[@tag='{tag}']/subfield[@code='{subfield}']\")\n",
    "        \n",
    "        if datafield is not None:\n",
    "            # Normalizing for comparison\n",
    "            generated_value = datafield.text.strip().lower()\n",
    "            metadata_value = metadata[field].strip().lower()\n",
    "            \n",
    "            # Exact match or partial similarity\n",
    "            if metadata_value in generated_value or generated_value in metadata_value:\n",
    "                matched_fields += 1\n",
    "\n",
    "    # Reward is proportional to the number of matched fields\n",
    "    reward = matched_fields / total_fields\n",
    "    return round(reward, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ed06e0f6-f93a-4b27-a24c-9f0b96aaec19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "0.2\n"
     ]
    }
   ],
   "source": [
    "print(semantic_field_reward(user_prompt=user_prompt,generated_xml=xml_answer))\n",
    "print(semantic_field_reward_2(user_prompt=user_prompt,generated_xml=xml_answer))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4d35044-f124-487f-ad2d-0afb93d925f5",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "19e9187a-98ec-4190-8244-89b1e3878272",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 100%|██████████| 673/673 [00:00<00:00, 15291.43 examples/s]\n",
      "Map: 100%|██████████| 673/673 [00:00<00:00, 4777.34 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'prompt': [{'content': 'You are an expert in Unimarc/XML bibliographic records encoding.\\nGenerate an XML Unimarc record from the given bibliographic metadata. /think',\n",
       "   'role': 'system'},\n",
       "  {'content': \"Title: Yoga senior  \\nSubtitle: la méthode de Gasquet  \\nAuthor: Dr Bernadette de Gasquet  \\nParticipation: avec la participation du Dr Marie Thirion  \\nAuthor details:  \\n- Bernadette de Gasquet (born 1946)  \\n- Marie Thirion (born 1944), pediatrician  \\n\\nPublisher: Robert Laffont  \\nPlace of publication: Paris  \\nYear: DL 2019 (Legal deposit 2019)  \\n\\nISBN: 978-2-221-24174-5  \\nOther identifier: 9782221241745 (EAN)  \\nOCLC number: 1107377985  \\n\\nLanguage: French (fre)  \\n\\nEdition: Not explicitly stated; appears first edition  \\n\\nMaterial Description:  \\n- 1 volume (250 pages)  \\n- Illustrations, color illustrated cover  \\n- Dimensions: 22 cm  \\n\\nCollection/Series: Réponses  \\n\\nNotes/Bibliographic references: Notes bibliogr.  \\n\\nAbstract/Notes:  \\nLa méthode de Gasquet enfin adaptée aux seniors ! Quelle activité physique pratiquer lorsque, à 50 ans, des fragilités corporelles et des douleurs apparaissent ? Comment prendre soin de soi, garder un corps fonctionnel et source de plaisir ? Spécialiste du périnée, professeure de yoga, reconnue et suivie par des médecins, des sages-femmes, des kinésithérapeutes et des coachs sportifs dans le monde entier, Bernadette de Gasquet adapte dans ce livre sa célèbre méthode aux seniors et propose un travail sur le renforcement musculaire, sans recherche de la performance, à travers des exercices simples. Travail corporel sans douleur et sans risque, discipline au service de l'être humain, le yoga peut être pratiqué à tout âge. En alternant tonification et détente, renforcements et étirements, en associant respiration et action sur les fonctions vitales, on peut garder un corps en pleine forme. Bernadette de Gasquet reprend ici les bases de l'activité physique – postures, respiration, abdominaux – en se concentrant sur les maux des seniors – douleurs articulaires, problèmes de circulation, de constipation, hypertension, troubles respiratoires, rhumatismes... – pour leur donner les clés d'une vie plus saine et du bien-être au quotidien. 200 photos, 15 schémas, des exercices filmés... Yoga senior vous propose de nombreux conseils pratiques et des exercices physiques adaptés pour rester en forme après 50 ans.  \\nSource of the abstract/notes: éditeur  \\n\\nTable of contents: Not provided  \\n\\nKeywords/Subject headings:  \\n- Hatha-yoga (RAMEAU)  \\n- Exercices physiques pour personnes âgées (RAMEAU)  \\n\\nClassification:  \\n- Dewey: 613.710 846  \\n- French national bibliography classification: 610  \\n- Réponses (Paris. 1967) [series] ISSN 0750-7747  \\n\\nCountry of publication: France (FR)  \\n\\nOther information:  \\n- Legal deposit and cataloging codes for French institutions included  \\n- Material type: text, printed book  \\n- Carrier type: volume (nga)\",\n",
       "   'role': 'user'}],\n",
       " 'answer': '<record><controlfield tag=\"005\">20210208123415.000</controlfield><leader> cam0 22        450 </leader><controlfield tag=\"001\">236807005</controlfield><controlfield tag=\"003\">http://www.sudoc.fr/236807005</controlfield><datafield tag=\"035\" ind1=\" \" ind2=\" \"><subfield code=\"a\">(OCoLC)1107377985</subfield></datafield><datafield tag=\"010\" ind1=\" \" ind2=\" \"><subfield code=\"a\">978-2-221-24174-5</subfield><subfield code=\"b\">br.</subfield></datafield><datafield tag=\"073\" ind1=\" \" ind2=\"1\"><subfield code=\"a\">9782221241745</subfield></datafield><datafield tag=\"035\" ind1=\" \" ind2=\" \"><subfield code=\"a\">FRBNF457384730000008</subfield><subfield code=\"z\">FRBNF45738473</subfield></datafield><datafield tag=\"100\" ind1=\" \" ind2=\" \"><subfield code=\"a\">20190703h20192019m  y0frey50      ba</subfield></datafield><datafield tag=\"101\" ind1=\"0\" ind2=\" \"><subfield code=\"a\">fre</subfield><subfield code=\"2\">639-2</subfield></datafield><datafield tag=\"105\" ind1=\" \" ind2=\" \"><subfield code=\"a\">a   ||||000yy</subfield></datafield><datafield tag=\"106\" ind1=\" \" ind2=\" \"><subfield code=\"a\">r</subfield></datafield><datafield tag=\"181\" ind1=\" \" ind2=\" \"><subfield code=\"6\">z01</subfield><subfield code=\"c\">txt</subfield><subfield code=\"2\">rdacontent</subfield></datafield><datafield tag=\"181\" ind1=\" \" ind2=\"1\"><subfield code=\"6\">z01</subfield><subfield code=\"a\">i#</subfield><subfield code=\"b\">xxxe##</subfield></datafield><datafield tag=\"182\" ind1=\" \" ind2=\" \"><subfield code=\"6\">z01</subfield><subfield code=\"c\">n</subfield><subfield code=\"2\">rdamedia</subfield></datafield><datafield tag=\"182\" ind1=\" \" ind2=\"1\"><subfield code=\"6\">z01</subfield><subfield code=\"a\">n</subfield></datafield><datafield tag=\"183\" ind1=\" \" ind2=\"1\"><subfield code=\"6\">z01</subfield><subfield code=\"a\">nga</subfield><subfield code=\"2\">RDAfrCarrier</subfield></datafield><datafield tag=\"102\" ind1=\" \" ind2=\" \"><subfield code=\"a\">FR</subfield></datafield><datafield tag=\"320\" ind1=\" \" ind2=\" \"><subfield code=\"a\">Notes bibliogr.</subfield></datafield><datafield tag=\"200\" ind1=\"1\" ind2=\" \"><subfield code=\"a\">Yoga senior</subfield><subfield code=\"e\">la méthode de Gasquet</subfield><subfield code=\"f\">Dr Bernadette de Gasquet</subfield><subfield code=\"f\">avec la participation du Dr Marie Thirion</subfield></datafield><datafield tag=\"700\" ind1=\" \" ind2=\"1\"><subfield code=\"3\">084278986</subfield><subfield code=\"a\">Gasquet</subfield><subfield code=\"b\">Bernadette de</subfield><subfield code=\"f\">1946-....</subfield><subfield code=\"4\">070</subfield></datafield><datafield tag=\"702\" ind1=\" \" ind2=\"1\"><subfield code=\"3\">028312635</subfield><subfield code=\"a\">Thirion</subfield><subfield code=\"b\">Marie</subfield><subfield code=\"f\">1944-....</subfield><subfield code=\"c\">pédiatre</subfield><subfield code=\"4\">205</subfield></datafield><datafield tag=\"801\" ind1=\" \" ind2=\"3\"><subfield code=\"a\">FR</subfield><subfield code=\"b\">Abes</subfield><subfield code=\"c\">20210208</subfield><subfield code=\"g\">AFNOR</subfield></datafield><datafield tag=\"214\" ind1=\" \" ind2=\"0\"><subfield code=\"a\">Paris</subfield><subfield code=\"c\">Robert Laffont</subfield><subfield code=\"d\">DL 2019</subfield></datafield><datafield tag=\"215\" ind1=\" \" ind2=\" \"><subfield code=\"a\">1 vol. (250 p.)</subfield><subfield code=\"c\">ill., couv. ill. en coul.</subfield><subfield code=\"d\">22 cm</subfield></datafield><datafield tag=\"225\" ind1=\"0\" ind2=\" \"><subfield code=\"a\">Réponses</subfield></datafield><datafield tag=\"410\" ind1=\" \" ind2=\"|\"><subfield code=\"0\">001026399</subfield><subfield code=\"t\">Réponses (Paris. 1967)</subfield><subfield code=\"x\">0750-7747</subfield></datafield><datafield tag=\"606\" ind1=\" \" ind2=\" \"><subfield code=\"3\">027347893</subfield><subfield code=\"a\">Hatha-yoga</subfield><subfield code=\"2\">rameau</subfield></datafield><datafield tag=\"606\" ind1=\" \" ind2=\" \"><subfield code=\"3\">027425541</subfield><subfield code=\"a\">Exercices physiques pour personnes âgées</subfield><subfield code=\"2\">rameau</subfield></datafield><datafield tag=\"676\" ind1=\" \" ind2=\" \"><subfield code=\"a\">613.710 846</subfield><subfield code=\"v\">23</subfield></datafield><datafield tag=\"686\" ind1=\" \" ind2=\" \"><subfield code=\"a\">610</subfield><subfield code=\"2\">Cadre de classement de la Bibliographie nationale française</subfield></datafield><datafield tag=\"801\" ind1=\" \" ind2=\"0\"><subfield code=\"a\">FR</subfield><subfield code=\"b\">FR-751131015</subfield><subfield code=\"c\">20190529</subfield><subfield code=\"g\">AFNOR</subfield><subfield code=\"2\">intermrc</subfield></datafield><datafield tag=\"330\" ind1=\" \" ind2=\" \"><subfield code=\"a\">La méthode de Gasquet enfin adaptée aux seniors ! Quelle activité physique pratiquer lorsque, à 50 ans, des fragilités corporelles et des douleurs apparaissent ? Comment prendre soin de soi, garder un corps fonctionnel et source de plaisir ? Spécialiste du périnée, professeure de yoga, reconnue et suivie par des médecins, des sages-femmes, des kinésithérapeutes et des coachs sportifs dans le monde entier, Bernadette de Gasquet adapte dans ce livre sa célèbre méthode aux seniors et propose un travail sur le renforcement musculaire, sans recherche de la performance, à travers des exercices simples. Travail corporel sans douleur et sans risque, discipline au service de l\\'être humain, le yoga peut être pratiqué à tout âge. En alternant tonification et détente, renforcements et étirements, en associant respiration et action sur les fonctions vitales, on peut garder un corps en pleine forme. Bernadette de Gasquet reprend ici les bases de l\\'activité physique – postures, respiration, abdominaux – en se concentrant sur les maux des seniors – douleurs articulaires, problèmes de circulation, de constipation, hypertension, troubles respiratoires, rhumatismes... – pour leur donner les clés d\\'une vie plus saine et du bien-être au quotidien. 200 photos, 15 schémas, des exercices filmés... Yoga senior vous propose de nombreux conseils pratiques et des exercices physiques adaptés pour rester en forme après 50 ans</subfield><subfield code=\"2\">éditeur</subfield></datafield></record>'}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = load_dataset(\"Geraldine/metadata-to-unimarc-traces\", split=\"train\")\n",
    "\n",
    "SYSTEM_PROMPT = \"\"\"You are an expert in Unimarc/XML bibliographic records encoding.\n",
    "Generate an XML Unimarc record from the given bibliographic metadata. /think\"\"\"\n",
    "\n",
    "def create_conversation(row):\n",
    "    return {\n",
    "        \"prompt\": [\n",
    "            {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
    "            {\"role\": \"user\", \"content\": row[\"metadata\"]},\n",
    "        ],\n",
    "        \"answer\": row[\"unimarc_record\"]\n",
    "    }\n",
    "\n",
    "# Apply the transformation and remove old columns\n",
    "dataset = dataset.map(create_conversation, remove_columns=list(dataset.features.keys()))\n",
    "dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7984dac3-6142-40c6-8818-9bffcce4571e",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "04f1da12-cdb4-41e6-a470-a4dabf8e784f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from trl import GRPOConfig, GRPOTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cb50d794-442a-4756-af4c-a5500227ee5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "import re\n",
    "import difflib\n",
    "\n",
    "def extract_xml(text: str) -> str | None:\n",
    "    # Use regular expression to find the XML part enclosed in ```xml...```\n",
    "    xml_match = re.search(r'```xml(.*?)```', response, re.DOTALL)\n",
    "    if xml_match:\n",
    "        return xml_match.group(1).strip()\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def extract_field_values(xml_str):\n",
    "    root = ET.fromstring(xml_str)\n",
    "    fields = {}\n",
    "    for df in root.findall(\".//datafield\"):\n",
    "        tag = df.get(\"tag\")\n",
    "        subfields = [sf.text for sf in df.findall(\"subfield\")]\n",
    "        fields[tag] = \" \".join(subfields)\n",
    "    return fields\n",
    "\n",
    "def parse_metadata(text: str) -> dict:\n",
    "    # Define the main fields with regular expressions\n",
    "    fields = {\n",
    "        \"Title\": r\"Title:\\s*(.+)\",\n",
    "        \"Subtitle\": r\"(?:s)?title(?:s)?:\\s*(.+)\",\n",
    "        \"Authors\": r\"Author(?:s)?:\\s*(.+)\",\n",
    "        \"Contributors\": r\"With:\\s*(.+)\",\n",
    "        \"Publisher\": r\"Publisher:\\s*(.+)\",\n",
    "        \"Year\": r\"Year:\\s*(.+)\",\n",
    "        \"Edition\": r\"Edition:\\s*(.+)\",\n",
    "        \"Collection/Series\": r\"Collection/Series:\\s*(.+)\",\n",
    "        \"Material description\": r\"Material description:\\s*(.+)\",\n",
    "        \"ISBN\": r\"ISBN:\\s*(.+)\",\n",
    "        \"Price\": r\"Price:\\s*(.+)\",\n",
    "        \"Language\": r\"Language:\\s*(.+)\",\n",
    "        \"Country of publication\": r\"Country of publication:\\s*(.+)\",\n",
    "        \"Notes/Bibliography\": r\"Notes/Bibliography:\\s*(.+)\",\n",
    "        \"Material description\": r\"(?:s)?description:\\s*(.+)\",\n",
    "        \"Abstract/Notes Source\": r\"Abstract/Notes Source:\\s*(.+)\",\n",
    "        \"Source\": r\"Source:\\s*(.+)\",\n",
    "        \"Language Codes\": r\"Language Codes:\\s*(.+)\",\n",
    "        \"Format content\": r\"Format content:\\s*(.+)\",\n",
    "        \"Media type\": r\"Media type:\\s*(.+)\",\n",
    "        \"Carrier type\": r\"Carrier type:\\s*(.+)\",\n",
    "        \"Library info\": r\"Library info:\\s*(.+)\",\n",
    "        \"Control Numbers\": r\"Control Numbers:\\s*(.+)\"\n",
    "    }\n",
    "    \n",
    "    # Initialize the metadata dictionary\n",
    "    metadata = {}\n",
    "\n",
    "    # First, extract the main fields\n",
    "    for field, pattern in fields.items():\n",
    "        match = re.search(pattern, text, re.DOTALL)\n",
    "        if match:\n",
    "            metadata[field] = match.group(1).strip()\n",
    "        else:\n",
    "            metadata[field] = None\n",
    "    \n",
    "    # Parse structured lists: Keywords / Subject Headings\n",
    "    keywords_match = re.search(r\"Keywords / Subject Headings:\\s*(.*?)\\n\\n\", text, re.DOTALL)\n",
    "    if keywords_match:\n",
    "        keywords = [kw.strip(\"- \").strip() for kw in keywords_match.group(1).split(\"\\n\") if kw.strip()]\n",
    "        metadata[\"Keywords / Subject Headings\"] = keywords\n",
    "\n",
    "    # Parse Contributors list\n",
    "    contributors_match = re.search(r\"Contributors:\\s*(.*?)\\n\\n\", text, re.DOTALL)\n",
    "    if contributors_match:\n",
    "        contributors = [c.strip(\"- \").strip() for c in contributors_match.group(1).split(\"\\n\") if c.strip()]\n",
    "        metadata[\"Contributors\"] = contributors\n",
    "\n",
    "    # Parse Control Numbers if exists\n",
    "    if metadata[\"Control Numbers\"]:\n",
    "        control_numbers = {}\n",
    "        for line in metadata[\"Control Numbers\"].split(\"\\n\"):\n",
    "            if \":\" in line:\n",
    "                key, value = line.split(\":\", 1)\n",
    "                control_numbers[key.strip()] = value.strip()\n",
    "        metadata[\"Control Numbers\"] = control_numbers\n",
    "\n",
    "    # Parse Library info if exists\n",
    "    if metadata[\"Library info\"]:\n",
    "        library_info = {}\n",
    "        for line in metadata[\"Library info\"].split(\"\\n\"):\n",
    "            if \":\" in line:\n",
    "                key, value = line.split(\":\", 1)\n",
    "                library_info[key.strip()] = value.strip()\n",
    "        metadata[\"Library info\"] = library_info\n",
    "\n",
    "    return metadata\n",
    "\n",
    "def format_reward_(xml_output: str) -> float:\n",
    "    try:\n",
    "        root = ET.fromstring(xml_output)\n",
    "    except ET.ParseError:\n",
    "        return 0.0\n",
    "\n",
    "    score = 0.2  # Starts above 0 for well-formed but noncompliant XML\n",
    "\n",
    "    if root.find(\".//controlfield\") is not None:\n",
    "        score += 0.1\n",
    "    if root.find(\".//leader\") is not None:\n",
    "        score += 0.1\n",
    "    if root.find(\".//datafield\") is not None:\n",
    "        score += 0.3\n",
    "    if root.find(\".//subfield\") is not None:\n",
    "        score += 0.3\n",
    "\n",
    "    return min(score, 1.0)\n",
    "\n",
    "def format_reward_func(completions) -> list[float]:\n",
    "    responses = [completion[0]['content'] for completion in completions]\n",
    "    extracted_responses = [extract_xml(r) for r in responses]\n",
    "    return [format_reward(r) for r in extracted_responses]\n",
    "        \n",
    "def accuracy_reward(generated_xml: str, target_xml: str) -> float:\n",
    "    try:\n",
    "        gen_fields = extract_field_values(generated_xml)\n",
    "        tgt_fields = extract_field_values(target_xml)\n",
    "    except ET.ParseError:\n",
    "        return 0.0\n",
    "\n",
    "    shared_keys = set(gen_fields) & set(tgt_fields)\n",
    "    if not shared_keys:\n",
    "        return 0.0\n",
    "\n",
    "    total_sim = 0\n",
    "    for key in shared_keys:\n",
    "        sim = difflib.SequenceMatcher(None, gen_fields[key], tgt_fields[key]).ratio()\n",
    "        total_sim += sim\n",
    "\n",
    "    return total_sim / len(shared_keys)\n",
    "\n",
    "def accuracy_reward_func(completions, answer)-> list[float]:\n",
    "    responses = [completion[0]['content'] for completion in completions]\n",
    "    extracted_responses = [extract_xml(r) for r in responses]\n",
    "    return [accuracy_reward(r,a) for r, a in zip(extracted_responses, answer)]\n",
    "\n",
    "def semantic_field_reward(user_prompt: str, generated_xml: str) -> float:\n",
    "    FIELD_MAPPINGS = {\n",
    "        \"Title\": (\"200\", \"a\"),              # Title → 200$a\n",
    "        \"Subtitle\": (\"200\", \"e\"),           # Subtitle → 200$e\n",
    "        \"Year\": (\"214\", \"d\"),               # Year → 214$d (Publication date)\n",
    "        \"Authors\": (\"700\", \"a\"),            # Authors → 700$a (Main Author)\n",
    "        \"Publisher\": (\"214\", \"c\"),          # Publisher → 214$c\n",
    "        \"ISBN\": (\"010\", \"a\"),               # ISBN → 010$a\n",
    "        \"Language\": (\"101\", \"a\"),           # Language → 101$a\n",
    "        \"Collection/Series\": (\"225\", \"a\"),         # Collection/Series → 225$a\n",
    "        \"Material description\": (\"215\", \"a\"), # Material description → 215$a\n",
    "        \"Price\": (\"010\", \"d\"),              # Price → 010$d\n",
    "        \"Abstract/Notes Source\": (\"330\", \"a\"),           # Abstract → 330$a\n",
    "        \"Country of publication\": (\"102\", \"a\"),            # Country of publication → 102$a\n",
    "        \"Edition\": (\"205\", \"a\"),            # Edition → 205$a\n",
    "        \"Notes\": (\"300\", \"a\"),              # Notes → 300$a\n",
    "        \"Keywords / Subject Headings\": (\"600\", \"a\")            # Keywords → 600$a (Subject Headings)\n",
    "    }\n",
    "    try:\n",
    "        root = ET.fromstring(generated_xml)\n",
    "    except ET.ParseError:\n",
    "        return 0.0\n",
    "    metadata = parse_metadata(user_prompt)\n",
    "    \n",
    "    total_fields = len(FIELD_MAPPINGS)\n",
    "    matched_fields = 0\n",
    "    \n",
    "    for field, (tag, subfield) in FIELD_MAPPINGS.items():\n",
    "        if field not in metadata:\n",
    "            continue\n",
    "        \n",
    "        # Locate the corresponding datafield and subfield in the XML\n",
    "        datafield = root.find(f\".//datafield[@tag='{tag}']/subfield[@code='{subfield}']\")\n",
    "        \n",
    "        if datafield is not None:\n",
    "            # Normalizing for comparison\n",
    "            generated_value = datafield.text.strip().lower()\n",
    "            metadata_value = metadata[field].strip().lower()\n",
    "            \n",
    "            # Exact match or partial similarity\n",
    "            if metadata_value in generated_value or generated_value in metadata_value:\n",
    "                matched_fields += 1\n",
    "\n",
    "    # Reward is proportional to the number of matched fields\n",
    "    reward = matched_fields / total_fields\n",
    "    return round(reward, 2)\n",
    "\n",
    "def semantic_field_reward_func(prompts,completions) -> list[float]:\n",
    "    responses = [completion[0]['content'] for completion in completions]\n",
    "    extracted_responses = [extract_xml(r) for r in responses]\n",
    "    prompts = [p[0][-1]['content'] for p in prompts]\n",
    "    return [semantic_field_reward(p,r) for p, r in zip(prompts,extracted_responses)]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c15fdd0a-eb8c-4095-8284-fc58e04350f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir=\"output_unimarc_grpo\"\n",
    "run_name=\"unimarc_grpo_run\"\n",
    "\n",
    "training_args = GRPOConfig(\n",
    "    output_dir=output_dir,\n",
    "    run_name=run_name,\n",
    "    learning_rate=2e-5,                          # Slightly higher LR for smaller dataset\n",
    "    adam_beta1=0.9,\n",
    "    adam_beta2=0.98,                             # Fine-tuned to reduce overshooting\n",
    "    weight_decay=0.01,                           # Reduced weight decay (over-regularization can hurt small datasets)\n",
    "    warmup_ratio=0.2,                            # Increased warmup to allow more stable gradient updates early on\n",
    "    lr_scheduler_type='cosine',\n",
    "    logging_steps=10,                            # Log every 10 steps (less noise, more signal)\n",
    "    bf16=True,                                   # Keep bf16 for memory efficiency\n",
    "    per_device_train_batch_size=2,               # Increased to 2 for faster throughput\n",
    "    gradient_accumulation_steps=8,               # Increased for better gradient stability\n",
    "    num_generations=8,                           # Reduced generations to focus on quality\n",
    "    max_prompt_length=4096,                       # Increased max prompt length for richer context\n",
    "    max_completion_length=4096,                   # Increased to handle larger XML responses\n",
    "    num_train_epochs=3,                          # Increased to 3 epochs for better convergence\n",
    "    save_steps=50,                               # Save more frequently given smaller dataset\n",
    "    max_grad_norm=1.0,                           # Standard value for clipping\n",
    "    log_on_each_node=False,\n",
    "    use_vllm=False,\n",
    "    report_to=\"none\"\n",
    ")\n",
    "\n",
    "trainer = GRPOTrainer(\n",
    "    model=model,\n",
    "    processing_class=tokenizer,\n",
    "    reward_funcs=[\n",
    "        format_reward_func,\n",
    "        accuracy_reward_func,\n",
    "        semantic_field_reward_func,],\n",
    "    args=training_args,\n",
    "    train_dataset=dataset,\n",
    "    #peft_config=peft_config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "726470dc-840f-425d-b13c-09e047743fde",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`generation_config` default values have been modified to match model-specific defaults: {'top_k': 20, 'top_p': 0.95, 'bos_token_id': 151643}. If this is not desired, please set these values explicitly.\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 422.00 MiB. GPU 0 has a total capacity of 14.57 GiB of which 322.75 MiB is free. Process 445065 has 14.25 GiB memory in use. Of the allocated memory 10.34 GiB is allocated by PyTorch, and 3.78 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mOutOfMemoryError\u001b[39m                          Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[35]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/transformers/trainer.py:2245\u001b[39m, in \u001b[36mTrainer.train\u001b[39m\u001b[34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[39m\n\u001b[32m   2243\u001b[39m         hf_hub_utils.enable_progress_bars()\n\u001b[32m   2244\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2245\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2246\u001b[39m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[43m=\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2247\u001b[39m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2248\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2249\u001b[39m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m=\u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2250\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/transformers/trainer.py:2560\u001b[39m, in \u001b[36mTrainer._inner_training_loop\u001b[39m\u001b[34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[39m\n\u001b[32m   2553\u001b[39m context = (\n\u001b[32m   2554\u001b[39m     functools.partial(\u001b[38;5;28mself\u001b[39m.accelerator.no_sync, model=model)\n\u001b[32m   2555\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m i != \u001b[38;5;28mlen\u001b[39m(batch_samples) - \u001b[32m1\u001b[39m\n\u001b[32m   2556\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.accelerator.distributed_type != DistributedType.DEEPSPEED\n\u001b[32m   2557\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m contextlib.nullcontext\n\u001b[32m   2558\u001b[39m )\n\u001b[32m   2559\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m context():\n\u001b[32m-> \u001b[39m\u001b[32m2560\u001b[39m     tr_loss_step = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_items_in_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2562\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m   2563\u001b[39m     args.logging_nan_inf_filter\n\u001b[32m   2564\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_xla_available()\n\u001b[32m   2565\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m (torch.isnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m torch.isinf(tr_loss_step))\n\u001b[32m   2566\u001b[39m ):\n\u001b[32m   2567\u001b[39m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[32m   2568\u001b[39m     tr_loss = tr_loss + tr_loss / (\u001b[32m1\u001b[39m + \u001b[38;5;28mself\u001b[39m.state.global_step - \u001b[38;5;28mself\u001b[39m._globalstep_last_logged)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/transformers/trainer.py:3730\u001b[39m, in \u001b[36mTrainer.training_step\u001b[39m\u001b[34m(self, model, inputs, num_items_in_batch)\u001b[39m\n\u001b[32m   3727\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m.optimizer, \u001b[33m\"\u001b[39m\u001b[33mtrain\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mself\u001b[39m.optimizer.train):\n\u001b[32m   3728\u001b[39m     \u001b[38;5;28mself\u001b[39m.optimizer.train()\n\u001b[32m-> \u001b[39m\u001b[32m3730\u001b[39m inputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_prepare_inputs\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3731\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_sagemaker_mp_enabled():\n\u001b[32m   3732\u001b[39m     loss_mb = smp_forward_backward(model, inputs, \u001b[38;5;28mself\u001b[39m.args.gradient_accumulation_steps)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/trl/extras/profiling.py:87\u001b[39m, in \u001b[36mprofiling_decorator.<locals>.wrapper\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     84\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m     85\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapper\u001b[39m(\u001b[38;5;28mself\u001b[39m, *args, **kwargs):\n\u001b[32m     86\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m profiling_context(\u001b[38;5;28mself\u001b[39m, func.\u001b[34m__name__\u001b[39m):\n\u001b[32m---> \u001b[39m\u001b[32m87\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/trl/trainer/grpo_trainer.py:899\u001b[39m, in \u001b[36mGRPOTrainer._prepare_inputs\u001b[39m\u001b[34m(self, accumulated_local_batch)\u001b[39m\n\u001b[32m    896\u001b[39m generate_every = \u001b[38;5;28mself\u001b[39m.args.gradient_accumulation_steps * \u001b[38;5;28mself\u001b[39m.num_iterations\n\u001b[32m    897\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._step % generate_every == \u001b[32m0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._buffered_inputs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    898\u001b[39m     \u001b[38;5;66;03m# self._buffered_inputs=None can occur when resuming from a checkpoint\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m899\u001b[39m     accumulated_local_batch = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate_and_score_completions\u001b[49m\u001b[43m(\u001b[49m\u001b[43maccumulated_local_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    900\u001b[39m     \u001b[38;5;28mself\u001b[39m._buffered_inputs = split_tensor_dict(\n\u001b[32m    901\u001b[39m         accumulated_local_batch, \u001b[38;5;28mself\u001b[39m.args.gradient_accumulation_steps\n\u001b[32m    902\u001b[39m     )\n\u001b[32m    903\u001b[39m inputs = \u001b[38;5;28mself\u001b[39m._buffered_inputs[\u001b[38;5;28mself\u001b[39m._step % \u001b[38;5;28mself\u001b[39m.args.gradient_accumulation_steps]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/trl/trainer/grpo_trainer.py:974\u001b[39m, in \u001b[36mGRPOTrainer._generate_and_score_completions\u001b[39m\u001b[34m(self, inputs)\u001b[39m\n\u001b[32m    969\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    970\u001b[39m     \u001b[38;5;66;03m# Regular generation path\u001b[39;00m\n\u001b[32m    971\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m unwrap_model_for_generation(\n\u001b[32m    972\u001b[39m         \u001b[38;5;28mself\u001b[39m.model_wrapped, \u001b[38;5;28mself\u001b[39m.accelerator, gather_deepspeed3_params=\u001b[38;5;28mself\u001b[39m.args.ds3_gather_for_generation\n\u001b[32m    973\u001b[39m     ) \u001b[38;5;28;01mas\u001b[39;00m unwrapped_model:\n\u001b[32m--> \u001b[39m\u001b[32m974\u001b[39m         prompt_completion_ids = \u001b[43munwrapped_model\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    975\u001b[39m \u001b[43m            \u001b[49m\u001b[43mprompt_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprompt_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgeneration_config\u001b[49m\n\u001b[32m    976\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    978\u001b[39m     \u001b[38;5;66;03m# Compute prompt length and extract completion ids\u001b[39;00m\n\u001b[32m    979\u001b[39m     prompt_length = prompt_ids.size(\u001b[32m1\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/torch/utils/_contextlib.py:116\u001b[39m, in \u001b[36mcontext_decorator.<locals>.decorate_context\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    113\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m    114\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecorate_context\u001b[39m(*args, **kwargs):\n\u001b[32m    115\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[32m--> \u001b[39m\u001b[32m116\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/transformers/generation/utils.py:2465\u001b[39m, in \u001b[36mGenerationMixin.generate\u001b[39m\u001b[34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, use_model_defaults, **kwargs)\u001b[39m\n\u001b[32m   2457\u001b[39m     input_ids, model_kwargs = \u001b[38;5;28mself\u001b[39m._expand_inputs_for_generation(\n\u001b[32m   2458\u001b[39m         input_ids=input_ids,\n\u001b[32m   2459\u001b[39m         expand_size=generation_config.num_return_sequences,\n\u001b[32m   2460\u001b[39m         is_encoder_decoder=\u001b[38;5;28mself\u001b[39m.config.is_encoder_decoder,\n\u001b[32m   2461\u001b[39m         **model_kwargs,\n\u001b[32m   2462\u001b[39m     )\n\u001b[32m   2464\u001b[39m     \u001b[38;5;66;03m# 12. run sample (it degenerates to greedy search when `generation_config.do_sample=False`)\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2465\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sample\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2466\u001b[39m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2467\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlogits_processor\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprepared_logits_processor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2468\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstopping_criteria\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprepared_stopping_criteria\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2469\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2470\u001b[39m \u001b[43m        \u001b[49m\u001b[43msynced_gpus\u001b[49m\u001b[43m=\u001b[49m\u001b[43msynced_gpus\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2471\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstreamer\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstreamer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2472\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2473\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2475\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m generation_mode \u001b[38;5;129;01min\u001b[39;00m (GenerationMode.BEAM_SAMPLE, GenerationMode.BEAM_SEARCH):\n\u001b[32m   2476\u001b[39m     \u001b[38;5;66;03m# 11. interleave input_ids with `num_beams` additional sequences per batch\u001b[39;00m\n\u001b[32m   2477\u001b[39m     input_ids, model_kwargs = \u001b[38;5;28mself\u001b[39m._expand_inputs_for_generation(\n\u001b[32m   2478\u001b[39m         input_ids=input_ids,\n\u001b[32m   2479\u001b[39m         expand_size=generation_config.num_beams,\n\u001b[32m   2480\u001b[39m         is_encoder_decoder=\u001b[38;5;28mself\u001b[39m.config.is_encoder_decoder,\n\u001b[32m   2481\u001b[39m         **model_kwargs,\n\u001b[32m   2482\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/transformers/generation/utils.py:3434\u001b[39m, in \u001b[36mGenerationMixin._sample\u001b[39m\u001b[34m(self, input_ids, logits_processor, stopping_criteria, generation_config, synced_gpus, streamer, **model_kwargs)\u001b[39m\n\u001b[32m   3432\u001b[39m     is_prefill = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m   3433\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3434\u001b[39m     outputs = \u001b[43mmodel_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m   3436\u001b[39m \u001b[38;5;66;03m# synced_gpus: don't waste resources running the code we don't need; kwargs must be updated before skipping\u001b[39;00m\n\u001b[32m   3437\u001b[39m model_kwargs = \u001b[38;5;28mself\u001b[39m._update_model_kwargs_for_generation(\n\u001b[32m   3438\u001b[39m     outputs,\n\u001b[32m   3439\u001b[39m     model_kwargs,\n\u001b[32m   3440\u001b[39m     is_encoder_decoder=\u001b[38;5;28mself\u001b[39m.config.is_encoder_decoder,\n\u001b[32m   3441\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/accelerate/utils/operations.py:814\u001b[39m, in \u001b[36mconvert_outputs_to_fp32.<locals>.forward\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    813\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(*args, **kwargs):\n\u001b[32m--> \u001b[39m\u001b[32m814\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/accelerate/utils/operations.py:802\u001b[39m, in \u001b[36mConvertOutputsToFp32.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    801\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, *args, **kwargs):\n\u001b[32m--> \u001b[39m\u001b[32m802\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m convert_to_fp32(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/torch/amp/autocast_mode.py:44\u001b[39m, in \u001b[36mautocast_decorator.<locals>.decorate_autocast\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     41\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m     42\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecorate_autocast\u001b[39m(*args, **kwargs):\n\u001b[32m     43\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m autocast_instance:\n\u001b[32m---> \u001b[39m\u001b[32m44\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/transformers/utils/generic.py:965\u001b[39m, in \u001b[36mcan_return_tuple.<locals>.wrapper\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    962\u001b[39m     set_attribute_for_modules(\u001b[38;5;28mself\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m_is_top_level_module\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m    964\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m965\u001b[39m     output = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    966\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m is_requested_to_return_tuple \u001b[38;5;129;01mor\u001b[39;00m (is_configured_to_return_tuple \u001b[38;5;129;01mand\u001b[39;00m is_top_level_module):\n\u001b[32m    967\u001b[39m         output = output.to_tuple()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/transformers/utils/deprecation.py:172\u001b[39m, in \u001b[36mdeprecate_kwarg.<locals>.wrapper.<locals>.wrapped_func\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    168\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m minimum_action \u001b[38;5;129;01min\u001b[39;00m (Action.NOTIFY, Action.NOTIFY_ALWAYS) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torchdynamo_compiling():\n\u001b[32m    169\u001b[39m     \u001b[38;5;66;03m# DeprecationWarning is ignored by default, so we use FutureWarning instead\u001b[39;00m\n\u001b[32m    170\u001b[39m     warnings.warn(message, \u001b[38;5;167;01mFutureWarning\u001b[39;00m, stacklevel=\u001b[32m2\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m172\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/transformers/models/qwen3/modeling_qwen3.py:850\u001b[39m, in \u001b[36mQwen3ForCausalLM.forward\u001b[39m\u001b[34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, cache_position, logits_to_keep, **kwargs)\u001b[39m\n\u001b[32m    845\u001b[39m output_hidden_states = (\n\u001b[32m    846\u001b[39m     output_hidden_states \u001b[38;5;28;01mif\u001b[39;00m output_hidden_states \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m.config.output_hidden_states\n\u001b[32m    847\u001b[39m )\n\u001b[32m    849\u001b[39m \u001b[38;5;66;03m# decoder outputs consists of (dec_features, layer_state, dec_hidden, dec_attn)\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m850\u001b[39m outputs: BaseModelOutputWithPast = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    851\u001b[39m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    852\u001b[39m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    853\u001b[39m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    854\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    855\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    856\u001b[39m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    857\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    858\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    859\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    860\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    861\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    863\u001b[39m hidden_states = outputs.last_hidden_state\n\u001b[32m    864\u001b[39m \u001b[38;5;66;03m# Only compute necessary logits, and do not upcast them to float if we are not computing the loss\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/transformers/utils/generic.py:965\u001b[39m, in \u001b[36mcan_return_tuple.<locals>.wrapper\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    962\u001b[39m     set_attribute_for_modules(\u001b[38;5;28mself\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m_is_top_level_module\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m    964\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m965\u001b[39m     output = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    966\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m is_requested_to_return_tuple \u001b[38;5;129;01mor\u001b[39;00m (is_configured_to_return_tuple \u001b[38;5;129;01mand\u001b[39;00m is_top_level_module):\n\u001b[32m    967\u001b[39m         output = output.to_tuple()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/transformers/models/qwen3/modeling_qwen3.py:576\u001b[39m, in \u001b[36mQwen3Model.forward\u001b[39m\u001b[34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, cache_position, **flash_attn_kwargs)\u001b[39m\n\u001b[32m    564\u001b[39m     layer_outputs = \u001b[38;5;28mself\u001b[39m._gradient_checkpointing_func(\n\u001b[32m    565\u001b[39m         partial(decoder_layer.\u001b[34m__call__\u001b[39m, **flash_attn_kwargs),\n\u001b[32m    566\u001b[39m         hidden_states,\n\u001b[32m   (...)\u001b[39m\u001b[32m    573\u001b[39m         position_embeddings,\n\u001b[32m    574\u001b[39m     )\n\u001b[32m    575\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m576\u001b[39m     layer_outputs = \u001b[43mdecoder_layer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    577\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    578\u001b[39m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcausal_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    579\u001b[39m \u001b[43m        \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    580\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    581\u001b[39m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    582\u001b[39m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    583\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    584\u001b[39m \u001b[43m        \u001b[49m\u001b[43mposition_embeddings\u001b[49m\u001b[43m=\u001b[49m\u001b[43mposition_embeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    585\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mflash_attn_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    586\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    588\u001b[39m hidden_states = layer_outputs[\u001b[32m0\u001b[39m]\n\u001b[32m    590\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m output_attentions:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/transformers/models/qwen3/modeling_qwen3.py:289\u001b[39m, in \u001b[36mQwen3DecoderLayer.forward\u001b[39m\u001b[34m(self, hidden_states, attention_mask, position_ids, past_key_value, output_attentions, use_cache, cache_position, position_embeddings, **kwargs)\u001b[39m\n\u001b[32m    286\u001b[39m hidden_states = \u001b[38;5;28mself\u001b[39m.input_layernorm(hidden_states)\n\u001b[32m    288\u001b[39m \u001b[38;5;66;03m# Self Attention\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m289\u001b[39m hidden_states, self_attn_weights = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mself_attn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    290\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    291\u001b[39m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    292\u001b[39m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    293\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    294\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    295\u001b[39m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    296\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    297\u001b[39m \u001b[43m    \u001b[49m\u001b[43mposition_embeddings\u001b[49m\u001b[43m=\u001b[49m\u001b[43mposition_embeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    298\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    299\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    300\u001b[39m hidden_states = residual + hidden_states\n\u001b[32m    302\u001b[39m \u001b[38;5;66;03m# Fully Connected\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/transformers/models/qwen3/modeling_qwen3.py:239\u001b[39m, in \u001b[36mQwen3Attention.forward\u001b[39m\u001b[34m(self, hidden_states, position_embeddings, attention_mask, past_key_value, cache_position, **kwargs)\u001b[39m\n\u001b[32m    236\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    237\u001b[39m         attention_interface = ALL_ATTENTION_FUNCTIONS[\u001b[38;5;28mself\u001b[39m.config._attn_implementation]\n\u001b[32m--> \u001b[39m\u001b[32m239\u001b[39m attn_output, attn_weights = \u001b[43mattention_interface\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    240\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    241\u001b[39m \u001b[43m    \u001b[49m\u001b[43mquery_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    242\u001b[39m \u001b[43m    \u001b[49m\u001b[43mkey_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    243\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvalue_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    244\u001b[39m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    245\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdropout\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.0\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mattention_dropout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    246\u001b[39m \u001b[43m    \u001b[49m\u001b[43mscaling\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mscaling\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    247\u001b[39m \u001b[43m    \u001b[49m\u001b[43msliding_window\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msliding_window\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# diff with Llama\u001b[39;49;00m\n\u001b[32m    248\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    249\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    251\u001b[39m attn_output = attn_output.reshape(*input_shape, -\u001b[32m1\u001b[39m).contiguous()\n\u001b[32m    252\u001b[39m attn_output = \u001b[38;5;28mself\u001b[39m.o_proj(attn_output)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/transformers/integrations/sdpa_attention.py:54\u001b[39m, in \u001b[36msdpa_attention_forward\u001b[39m\u001b[34m(module, query, key, value, attention_mask, dropout, scaling, is_causal, **kwargs)\u001b[39m\n\u001b[32m     51\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch.jit.is_tracing() \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(is_causal, torch.Tensor):\n\u001b[32m     52\u001b[39m     is_causal = is_causal.item()\n\u001b[32m---> \u001b[39m\u001b[32m54\u001b[39m attn_output = \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mnn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfunctional\u001b[49m\u001b[43m.\u001b[49m\u001b[43mscaled_dot_product_attention\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     55\u001b[39m \u001b[43m    \u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     56\u001b[39m \u001b[43m    \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     57\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     58\u001b[39m \u001b[43m    \u001b[49m\u001b[43mattn_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcausal_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     59\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdropout_p\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdropout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     60\u001b[39m \u001b[43m    \u001b[49m\u001b[43mscale\u001b[49m\u001b[43m=\u001b[49m\u001b[43mscaling\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     61\u001b[39m \u001b[43m    \u001b[49m\u001b[43mis_causal\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_causal\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     62\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     63\u001b[39m attn_output = attn_output.transpose(\u001b[32m1\u001b[39m, \u001b[32m2\u001b[39m).contiguous()\n\u001b[32m     65\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m attn_output, \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[31mOutOfMemoryError\u001b[39m: CUDA out of memory. Tried to allocate 422.00 MiB. GPU 0 has a total capacity of 14.57 GiB of which 322.75 MiB is free. Process 445065 has 14.25 GiB memory in use. Of the allocated memory 10.34 GiB is allocated by PyTorch, and 3.78 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ccfeaf8-6e1b-40f5-a41e-a8330876900d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
