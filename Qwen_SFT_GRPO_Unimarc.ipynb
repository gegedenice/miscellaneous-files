{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "16d969d4-d3a4-4c46-b647-167236c78768",
   "metadata": {},
   "source": [
    "<h3 align=\"center\">Status : <span class=\"badge\"><b>En cours</b></span></h3>\n",
    "\n",
    "<h1 align=\"center\">RL GRPO</h1>\n",
    "\n",
    "---\n",
    "\n",
    "<h1 align=\"center\">Training a small Unimarc reasoner with RL</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "208a0dbc-baee-49c3-9ce6-2522e07c3be6",
   "metadata": {},
   "source": [
    "# Requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1ddac3ec-3e4e-48b8-9a69-4d0fe027dfad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch:\n",
      "PyTorch version is:2.5.1\n",
      "PyTorch is working with CUDA\n",
      "The GPU model is: NVIDIA A100 80GB PCIe\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(\"PyTorch:\")\n",
    "print(\"PyTorch version is:\" + torch.__version__)\n",
    "print(\"PyTorch is working with CUDA\" if torch.cuda.is_available() else \"Error! It is not working correctly\")\n",
    "print(\"The GPU model is: \"+ torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d502c402-8236-4ecb-9654-6e0d7cfa994d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pip in /opt/anaconda3/lib/python3.12/site-packages (24.2)\n",
      "Collecting pip\n",
      "  Downloading pip-25.1.1-py3-none-any.whl.metadata (3.6 kB)\n",
      "Downloading pip-25.1.1-py3-none-any.whl (1.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m31.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pip\n",
      "\u001b[33m  WARNING: The scripts pip, pip3 and pip3.12 are installed in '/home/user/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0mSuccessfully installed pip-25.1.1\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0516e17e-d358-45e2-8ad7-f16c62cd5378",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33m  DEPRECATION: Building 'flash-attn' using the legacy setup.py bdist_wheel mechanism, which will be removed in a future version. pip 25.3 will enforce this behaviour change. A possible replacement is to use the standardized build interface by setting the `--use-pep517` option, (possibly combined with `--no-build-isolation`), or adding a `pyproject.toml` file to the source tree of 'flash-attn'. Discussion can be found at https://github.com/pypa/pip/issues/6334\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m  WARNING: The script huggingface-cli is installed in '/home/user/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m  WARNING: The script datasets-cli is installed in '/home/user/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m  WARNING: The script transformers-cli is installed in '/home/user/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m  WARNING: The scripts accelerate, accelerate-config, accelerate-estimate-memory, accelerate-launch and accelerate-merge-weights are installed in '/home/user/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m  WARNING: The script trl is installed in '/home/user/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m  WARNING: The script tensorboard is installed in '/home/user/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m  WARNING: The scripts import_pb_to_tensorboard, saved_model_cli, tensorboard, tf_upgrade_v2, tflite_convert and toco are installed in '/home/user/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m  WARNING: The script isympy is installed in '/home/user/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install -U --quiet datasets transformers trl huggingface_hub accelerate peft --use-deprecated=legacy-resolver\n",
    "#if A100 or H100 GPU: pip install flash-attn tf-keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec980996-ca3c-4b66-8a88-42200f930e31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'type': 'user',\n",
       " 'id': '63256c1fa3f07c8e168c0d47',\n",
       " 'name': 'Geraldine',\n",
       " 'fullname': 'Géraldine Geoffroy',\n",
       " 'email': 'grldn.geoffroy@gmail.com',\n",
       " 'emailVerified': True,\n",
       " 'canPay': False,\n",
       " 'periodEnd': 1748735999,\n",
       " 'isPro': False,\n",
       " 'avatarUrl': '/avatars/9cb069e5e90930e818ebe69300cd35d8.svg',\n",
       " 'orgs': [{'type': 'org',\n",
       "   'id': '665f255b175693a15893b7a1',\n",
       "   'name': 'discord-community',\n",
       "   'fullname': 'Hugging Face Discord Community',\n",
       "   'email': 'lunarflu@gmail.com',\n",
       "   'canPay': False,\n",
       "   'periodEnd': 1748735999,\n",
       "   'avatarUrl': 'https://cdn-avatars.huggingface.co/v1/production/uploads/6340651b388c3fa40f9a5bc0/j6Vb_hutYuKRcQgMaDTAt.png',\n",
       "   'roleInOrg': 'read',\n",
       "   'isEnterprise': False}],\n",
       " 'auth': {'type': 'access_token',\n",
       "  'accessToken': {'displayName': 'write_hf_token',\n",
       "   'role': 'write',\n",
       "   'createdAt': '2024-11-08T10:49:12.891Z'}}}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from huggingface_hub import login, whoami\n",
    "\n",
    "login(\n",
    "  token=\"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\" # with write permissions\n",
    ")\n",
    "whoami()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07e21012-2850-4403-a395-c70cdc15465e",
   "metadata": {},
   "source": [
    "# Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "add8b2b4-0c14-4582-98ff-30df58a4ed8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8a178c0d-8bea-43c5-b2b1-fec88e470af2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d203cd98921849f299b651ae134bc954",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/7.30k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b119f85eff74c41a49c3cc11f8e5fd2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/2.78M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64bb15757d2c4ad7ac8a4d1135a2e5e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/1.67M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "404a3919ed7940b1988cbb04f67422f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/7.03M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49e5a7b13bbd43138c68660161836bd4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/659 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd01b29e502848a398858f8618df51e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/988M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "257ee799ea5b4bf1bc970feb39c82098",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/242 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_name = \"Qwen/Qwen2.5-0.5B-Instruct\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    torch_dtype=\"auto\",\n",
    "    device_map=\"auto\",\n",
    "    #attn_implementation=\"flash_attention_2\"\n",
    ")\n",
    "model.config.sliding_window = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6db1ceba-0d68-4622-8e50-3a37e482344b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Qwen2ForCausalLM(\n",
       "  (model): Qwen2Model(\n",
       "    (embed_tokens): Embedding(151936, 896)\n",
       "    (layers): ModuleList(\n",
       "      (0-23): 24 x Qwen2DecoderLayer(\n",
       "        (self_attn): Qwen2Attention(\n",
       "          (q_proj): Linear(in_features=896, out_features=896, bias=True)\n",
       "          (k_proj): Linear(in_features=896, out_features=128, bias=True)\n",
       "          (v_proj): Linear(in_features=896, out_features=128, bias=True)\n",
       "          (o_proj): Linear(in_features=896, out_features=896, bias=False)\n",
       "        )\n",
       "        (mlp): Qwen2MLP(\n",
       "          (gate_proj): Linear(in_features=896, out_features=4864, bias=False)\n",
       "          (up_proj): Linear(in_features=896, out_features=4864, bias=False)\n",
       "          (down_proj): Linear(in_features=4864, out_features=896, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): Qwen2RMSNorm((896,), eps=1e-06)\n",
       "        (post_attention_layernorm): Qwen2RMSNorm((896,), eps=1e-06)\n",
       "      )\n",
       "    )\n",
       "    (norm): Qwen2RMSNorm((896,), eps=1e-06)\n",
       "    (rotary_emb): Qwen2RotaryEmbedding()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=896, out_features=151936, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.config.sliding_window = None\n",
    "device = \"cuda\" # for GPU usage or \"cpu\" for CPU usage\n",
    "model = model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bca1192b-9713-4f53-9340-c17d0273e6b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !Important\n",
    "tokenizer.padding_side = \"left\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70fdbedb-cdcf-471b-87d1-980842de7d49",
   "metadata": {},
   "source": [
    "## Inspect tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cea2c081-d317-4090-ab34-2c9fd5d6da83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "151665"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b093e0fa-0034-4024-8b51-b685c53de48c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**EOS**\n",
      "EOS token: <|im_end|>\n",
      "- EOS token id: 151645\n",
      "\n",
      "**PAD**\n",
      "PAD token: <|endoftext|>\n",
      "- PAD token id: 151643\n"
     ]
    }
   ],
   "source": [
    "print(f\"**EOS**\\nEOS token: {tokenizer.eos_token}\\n- EOS token id: {tokenizer.eos_token_id}\\n\\n**PAD**\\nPAD token: {tokenizer.pad_token}\\n- PAD token id: {tokenizer.pad_token_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d1097588-e692-4a37-9253-56eefc10537f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[ 1782, 12884,   374,  6303]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1]], device='cuda:0')}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer(\"the sky is blue\", return_tensors=\"pt\").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a232afe9-f43e-405d-b470-78fa8a0f26c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = tokenizer(\"the sky is blue\", return_tensors=\"pt\").to(device).input_ids[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b85a729e-cee3-4264-82dd-90e0e62e78a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'the sky is blue'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "03458069-d640-43d2-b800-f4c1882b7dd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current chat template: {%- if tools %}\n",
      "    {{- '<|im_start|>system\\n' }}\n",
      "    {%- if messages[0]['role'] == 'system' %}\n",
      "        {{- messages[0]['content'] }}\n",
      "    {%- else %}\n",
      "        {{- 'You are Qwen, created by Alibaba Cloud. You are a helpful assistant.' }}\n",
      "    {%- endif %}\n",
      "    {{- \"\\n\\n# Tools\\n\\nYou may call one or more functions to assist with the user query.\\n\\nYou are provided with function signatures within <tools></tools> XML tags:\\n<tools>\" }}\n",
      "    {%- for tool in tools %}\n",
      "        {{- \"\\n\" }}\n",
      "        {{- tool | tojson }}\n",
      "    {%- endfor %}\n",
      "    {{- \"\\n</tools>\\n\\nFor each function call, return a json object with function name and arguments within <tool_call></tool_call> XML tags:\\n<tool_call>\\n{\\\"name\\\": <function-name>, \\\"arguments\\\": <args-json-object>}\\n</tool_call><|im_end|>\\n\" }}\n",
      "{%- else %}\n",
      "    {%- if messages[0]['role'] == 'system' %}\n",
      "        {{- '<|im_start|>system\\n' + messages[0]['content'] + '<|im_end|>\\n' }}\n",
      "    {%- else %}\n",
      "        {{- '<|im_start|>system\\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\\n' }}\n",
      "    {%- endif %}\n",
      "{%- endif %}\n",
      "{%- for message in messages %}\n",
      "    {%- if (message.role == \"user\") or (message.role == \"system\" and not loop.first) or (message.role == \"assistant\" and not message.tool_calls) %}\n",
      "        {{- '<|im_start|>' + message.role + '\\n' + message.content + '<|im_end|>' + '\\n' }}\n",
      "    {%- elif message.role == \"assistant\" %}\n",
      "        {{- '<|im_start|>' + message.role }}\n",
      "        {%- if message.content %}\n",
      "            {{- '\\n' + message.content }}\n",
      "        {%- endif %}\n",
      "        {%- for tool_call in message.tool_calls %}\n",
      "            {%- if tool_call.function is defined %}\n",
      "                {%- set tool_call = tool_call.function %}\n",
      "            {%- endif %}\n",
      "            {{- '\\n<tool_call>\\n{\"name\": \"' }}\n",
      "            {{- tool_call.name }}\n",
      "            {{- '\", \"arguments\": ' }}\n",
      "            {{- tool_call.arguments | tojson }}\n",
      "            {{- '}\\n</tool_call>' }}\n",
      "        {%- endfor %}\n",
      "        {{- '<|im_end|>\\n' }}\n",
      "    {%- elif message.role == \"tool\" %}\n",
      "        {%- if (loop.index0 == 0) or (messages[loop.index0 - 1].role != \"tool\") %}\n",
      "            {{- '<|im_start|>user' }}\n",
      "        {%- endif %}\n",
      "        {{- '\\n<tool_response>\\n' }}\n",
      "        {{- message.content }}\n",
      "        {{- '\\n</tool_response>' }}\n",
      "        {%- if loop.last or (messages[loop.index0 + 1].role != \"tool\") %}\n",
      "            {{- '<|im_end|>\\n' }}\n",
      "        {%- endif %}\n",
      "    {%- endif %}\n",
      "{%- endfor %}\n",
      "{%- if add_generation_prompt %}\n",
      "    {{- '<|im_start|>assistant\\n' }}\n",
      "{%- endif %}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if hasattr(tokenizer, \"chat_template\"):\n",
    "    print(\"Current chat template:\", tokenizer.chat_template)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "650b9be4-19ca-40cc-97af-56bd0f6f570f",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6daf62b3-b325-42ed-8dee-f4e74c704f3c",
   "metadata": {},
   "source": [
    "### Without applying chat templating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "92e78fa0-e0d2-4382-b738-98663777d509",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"<|im_start|>system: You are a helpful assistant<|im_end|><|im_start|>user: complete this sentence 'the sky is blue and '<|im_end|><|im_start|>assistant: \"\n",
    "inputs = tokenizer(prompt, return_tensors=\"pt\").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8db10eed-0a4c-4ce6-866e-65574ec0b73a",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = model.generate(**inputs,\n",
    "                         max_new_tokens = 20,\n",
    "                         use_cache = True,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f2145d5d-c8cf-4019-802e-62d49ec09230",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|im_start|>system: You are a helpful assistant<|im_end|><|im_start|>user: complete this sentence 'the sky is blue and '<|im_end|><|im_start|>assistant:  the sky is blue and the clouds are white.<|im_end|>\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.decode(outputs[0], skip_special_tokens=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55a0c2d9-0160-41be-9d2e-e3bda819782e",
   "metadata": {},
   "source": [
    "### With applying chat templating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "85afd227-55ec-4845-a617-2f5023d8ffff",
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM_PROMPT_0 = \"\"\"\n",
    "You are an expert in Unimarc/XML bibliographic records.\n",
    "Respond in the following format:\n",
    "<reasoning>\n",
    "...\n",
    "</reasoning>\n",
    "<answer>\n",
    "...\n",
    "</answer>\n",
    "\"\"\"\n",
    "\n",
    "SYSTEM_PROMPT_0_SMALL = \"\"\"\n",
    "You are an expert in Unimarc/XML bibliographic records.\n",
    "Respond in the following format:\n",
    "### Reasoning:...\n",
    "### Answer: ...\n",
    "\"\"\"\n",
    "\n",
    "# source: https://arxiv.org/pdf/2503.19470v1\n",
    "SYSTEM_PROMPT_1 = \"\"\"\n",
    "You are a helpful assistant that can solve the given question step by step. \n",
    "Given a question, you need to first think about the reasoning process in\n",
    "the mind and then provide the answer. The reasoning process and\n",
    "answer are enclosed within <think> </think> and <answer> </answer> tags respectively. \n",
    "For example, <think> This is the reasoning process. </think>\n",
    "<answer> The final answer is \\boxed{answer here}\n",
    "</answer>. In the last part of the answer, the final exact answer is enclosed within \\boxed{}\n",
    "with xml format.\n",
    "\"\"\"\n",
    "\n",
    "SYSTEM_PROMPT_2 = (\n",
    "    \"A conversation between User and Assistant. The user asks a question, and the Assistant solves it. The assistant \"\n",
    "    \"first thinks about the reasoning process in the mind and then provides the user with the answer. The reasoning \"\n",
    "    \"process and answer are enclosed within <think> </think> and <answer> </answer> tags, respectively, i.e., \"\n",
    "    \"<think> reasoning process here </think><answer> answer here </answer>\"\n",
    ")\n",
    "\n",
    "SYSTEM_PROMPT_2_SMALL = \"\"\"\n",
    "You are a helpful assistant expert in Unimarc/XML bibliographic records. \n",
    "Given a question, you need to first think about the reasoning process in the mind and then provide the answer. \n",
    "The reasoning process and answer are separated in distincts paragraphs respectively starting with `### Reasoning:` and `### Answer:`.\n",
    "For example, ### Reasoning: This is the reasoning process. \\n ### Answer: The final exact answer is \\boxed{answer here}. \n",
    "In the last part of the answer, the final exact answer is enclosed within \\boxed{} with XML format.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "user_prompt = \"\"\"\n",
    "Generate a valid Unimarc/XML record from these unstructured informations:\n",
    "Title: Electric vehicle tribology\n",
    "Subtitle: Challenges and opportunities for a sustainable transportation future\n",
    "Author: Leonardo I. Farfan-Cabrera, Ali Erdemir\n",
    "Publisher: Elsevier\n",
    "Year: 2024\n",
    "ISBN: 978-0-443-14074-7\n",
    "Language: English\n",
    "Collection/Series: Elsevier Series on Tribology and Surface Engineering\n",
    "Edition: Not specified\n",
    "Material description: 1 vol. (XI-313 p.), couv. ill. en coul., 23 cm\n",
    "Abstract/Notes: \"Electric vehicle tribology, challenges and opportunities for a sustainable transportation future\" provides practical, comprehensive guidance on a new and increasingly important area of tribology. Building skills from fundamentals to solution design, this book demonstrates the unique tribological techniques essential to the efficient electrification of transport systems. Led by professors with a combined three decades in industry and academia, and collecting insights from experts around the world, this book begins with the essential knowledge regarding both electric vehicles and tribology. After outlining the unique tribological needs of EVs, the book then breaks down the components and hardware required. It provides detailed protocols and methods for the testing and improvement of lubricants and materials as well as a dedicated section on modern lubrication specific to EVs. Throughout, it considers the critical question of sustainable tribology and the long-term sustainable options for lubrication and materials for electric vehicles.\n",
    "Source of the abstract/notes: 4e de couverture\n",
    "Table of contents: Not specified\n",
    "Keywords: Tribologie (technologie), Tribologie (Technologie)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1e6303e7-c98a-44ab-a0a9-6b545df643f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "  {\"role\": \"system\", \"content\": SYSTEM_PROMPT_2_SMALL},\n",
    "  {\"role\": \"user\", \"content\": user_prompt},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6400bc7e-061f-4dc5-a465-d8be980a008f",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer.apply_chat_template(\n",
    "    messages,\n",
    "    return_dict=True,\n",
    "    tokenize = True,\n",
    "    add_generation_prompt = True, # Must add for generation\n",
    "    return_tensors = \"pt\",\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "39395bd2-69eb-4689-8cb6-ffafb1de6e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = model.generate(\n",
    "    **inputs,\n",
    "    max_new_tokens = 2048,\n",
    "    use_cache = True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52e940fb-b2f3-4340-8a86-55c0aacc2877",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(tokenizer.decode(outputs[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c037b7da-39f5-4576-80a3-7267775e0408",
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_ids = [\n",
    "   output_ids[len(input_ids):] for input_ids, output_ids in zip(inputs.input_ids, outputs)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "766efb3a-dc8c-4278-b4be-1174ba8aa78f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Reasoning:\n",
      "\n",
      "To generate a valid Unimarc/XML record, we need to follow these steps:\n",
      "\n",
      "1. **Identify the elements**: We have provided information about the title, subtitle, author, publisher, year, ISBN, language, collection series, edition, material description, abstract notes, source of the abstract/notes, table of contents, and keywords.\n",
      "\n",
      "2. **Determine the structure**: The given text already contains the necessary fields and metadata that can be used to create an Unimarc/XML record. However, we need to ensure that all the fields are correctly formatted and complete.\n",
      "\n",
      "3. **Construct the XML document**:\n",
      "   - Start with the `<unimarc>` tag.\n",
      "   - Use the `<title>` tag to specify the title.\n",
      "   - Follow with the `<subtitle>` tag to include the subtitle.\n",
      "   - Add the author's name using the `<author>` tag.\n",
      "   - Include the publication details such as the publisher, year, ISBN, language, and collection series.\n",
      "   - Mention the edition and material description.\n",
      "   - Provide the abstract notes at the end of the record.\n",
      "   - End with the `<endnote>` tag to list any additional references or notes.\n",
      "\n",
      "4. **Format the fields according to the XML schema**: Ensure that all fields are properly structured and formatted according to the Unimarc XML schema.\n",
      "\n",
      "5. **Ensure the record is valid**: Validate the XML code against the Unimarc XML schema to confirm its correctness.\n",
      "\n",
      "6. **Review and finalize**: Finally, review the XML code to make sure there are no errors and that the content is accurate and complete.\n",
      "\n",
      "### Answer:\n",
      "\n",
      "```xml\n",
      "<?xml version=\"1.0\"?>\n",
      "<unimarc>\n",
      "    <record>\n",
      "        <title>Electric vehicle tribology</title>\n",
      "        <subtitle>Challenges and opportunities for a sustainable transportation future</subtitle>\n",
      "        <author>Lionardo I. Farfan-Cabrera, Ali Erdemir</author>\n",
      "        <publisher>Elsevier</publisher>\n",
      "        <year>2024</year>\n",
      "        <isbn>978-0-443-14074-7</isbn>\n",
      "        <language>English</language>\n",
      "        <collection>Series on Tribology and Surface Engineering</collection>\n",
      "        <edition>N/A</edition>\n",
      "        <material description>1 vol. (XI-313 p.), couv. ill. en coul., 23 cm</material description>\n",
      "        <abstract notes>Electric vehicle tribology, challenges and opportunities for a sustainable transportation future</abstract notes>\n",
      "        <source_of_abstract_notes>4e de couverture</source_of_abstract_notes>\n",
      "        <tableofcontents>\n",
      "            <item>\n",
      "                <title>Essential knowledge regarding both electric vehicles and tribology</title>\n",
      "                <abstract>Building skills from fundamentals to solution design, this book demonstrates the unique tribological techniques essential to the efficient electrification of transport systems.</abstract>\n",
      "                <keywords>Tribology (technologie), Tribology (Technologie)</keywords>\n",
      "            </item>\n",
      "            <!-- Add more items as needed -->\n",
      "        </tableofcontents>\n",
      "    </record>\n",
      "</unimarc>\n",
      "```\n",
      "\n",
      "This XML structure accurately represents the given information in a way that follows the Unimarc XML schema guidelines.\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c09f9a3-8e84-4392-a2c1-eacfe5d26b3d",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e481b67f-1e1f-4ec2-b573-a5a8c61ef24c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset, Dataset\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4ea14964-a96a-400b-a2ac-855241bc2ea4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2de3904b12e94fd2a704cf14678d2966",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/348 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9fe2037c770949b39a87b8df3c6b7a99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00000-of-00001.parquet:   0%|          | 0.00/15.6M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e29c58b98f247a1a264abd59a302343",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/5129 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['ppn', 'question', 'answer'],\n",
       "    num_rows: 5129\n",
       "})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = load_dataset(\"Geraldine/Unimarc-iln050-5k\", split=\"train\")\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5ea468bc-a8f0-4143-8196-f98326934d17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22416c4dc9124beb96c2c3e25441ce9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5129 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['messages'],\n",
       "    num_rows: 5129\n",
       "})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "system_message = \"\"\"You are a helpful assistant expert in Unimarc/XML bibliographic records. Given bibliographic metadata, generate a valid Unimarc XML record.\"\"\"\n",
    "def create_conversation(row):\n",
    "  return {\n",
    "    \"messages\": [\n",
    "      {\"role\": \"system\", \"content\": system_message},\n",
    "      {\"role\": \"user\", \"content\": row[\"question\"]},\n",
    "      {\"role\": \"assistant\", \"content\": row[\"answer\"] + tokenizer.eos_token} # to avoid infinite generation\n",
    "    ]\n",
    "  }\n",
    "\n",
    "dataset = dataset.map(create_conversation, remove_columns=dataset.features, batched=False)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "91ecd306-d1f3-4e07-9976-2463b69b01a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [{'content': 'You are a helpful assistant expert in Unimarc/XML bibliographic records. Given bibliographic metadata, generate a valid Unimarc XML record.',\n",
       "   'role': 'system'},\n",
       "  {'content': 'Title: Les Jeux olympiques de 1892 à 2024\\nSubtitle: une aventure mondiale\\nAuthor: Patrick Clastres\\nAdditional author info: Clastres, Patrick (19..-....)\\nPublisher: Presses universitaires de Rennes\\nPlace of publication: Rennes\\nYear: 2025 (DL 2025)\\nISBN: 978-2-7535-9645-0 (br.)\\nLanguage: French (fre)\\nEdition: Not explicitly stated\\nMaterial description: 1 volume (463 pages); color illustrated cover; 24 cm\\nCollection/Series: Collection \"Histoire\"\\nSeries ISSN: 1255-2364 (Histoire (Rennes))\\nTable of contents: Not provided\\nAbstract/Notes: \\n\"Depuis leur réinvention à Paris et à Athènes à la fin du XIXe siècle, les Jeux olympiques semblent refléter la marche du monde. En fait, ils progressent à leur propre rythme, quadriennal, et ils ne sont jamais qu’un interlude posé dans les interstices des États, des sociétés et des économies. Faire l’histoire de leur aventure mondiale nécessite un préalable : mettre à distance le roman olympique conçu par le CIO. Tout est parti de l’idée messianique imaginée en 1892 par Pierre de Coubertin : contribuer à la paix des nations par la compétition sportive. Pour défendre son idéal contre les ingérences politiques et commerciales, ce jeune aristocrate parisien a théorisé la neutralité de l’« olympisme ». Une contre-société d’échelle mondiale est apparue avec sa capitale et son gouvernement, sa géographie et sa diplomatie, son administration et sa législation. Depuis 130 ans, le CIO bataille contre les fédérations internationales pour imposer son hégémonie. Pour appréhender la diffusion des JO d’Athènes en 1896 jusqu’à Paris en 2024, et décrypter l’olympisation des sociétés voulue par le CIO, une même trame est proposée au lecteur : l’imbrication des enjeux politiques et sportifs, la concurrence des jeux alternatifs, la compétition entre villes candidates, les portraits des présidents successifs du CIO, les cérémonies d’ouverture comme romans nationaux, le programme olympique au prisme des cultures corporelles, le dopage et la corruption, les oppositions à l’organisation des Jeux, la hiérarchie sportive des États, les trajectoires de vie des champions et championnes, les freins et avancées des droits humains dans le sport.\"\\nSource of the abstract/notes: 4e de couverture (back cover)\\nBibliographic references: pages 419-424; includes index\\nKeywords: Olympisme, Jeux olympiques, Histoire\\nClassification: 796(23a)\\nCountry of publication: France (FR)\\nAdditional identifiers: OCLC number (OCoLC)1513823097\\nLibrary info/source: Abes (FR); AFNOR; Sudoc link: http://www.sudoc.fr/284189537',\n",
       "   'role': 'user'},\n",
       "  {'content': '<record><controlfield tag=\"005\">20250424100757.000</controlfield><leader> cam0 22        450 </leader><controlfield tag=\"001\">284189537</controlfield><controlfield tag=\"003\">http://www.sudoc.fr/284189537</controlfield><datafield tag=\"035\" ind1=\" \" ind2=\" \"><subfield code=\"a\">(OCoLC)1513823097</subfield></datafield><datafield tag=\"010\" ind1=\" \" ind2=\" \"><subfield code=\"a\">978-2-7535-9645-0</subfield><subfield code=\"b\">br.</subfield></datafield><datafield tag=\"073\" ind1=\" \" ind2=\"1\"><subfield code=\"a\">9782753596450</subfield></datafield><datafield tag=\"100\" ind1=\" \" ind2=\" \"><subfield code=\"a\">20250408d2025    m  y0frey50      ba</subfield></datafield><datafield tag=\"101\" ind1=\"0\" ind2=\" \"><subfield code=\"a\">fre</subfield><subfield code=\"2\">639-2</subfield></datafield><datafield tag=\"105\" ind1=\" \" ind2=\" \"><subfield code=\"a\">a   a   001yy</subfield></datafield><datafield tag=\"106\" ind1=\" \" ind2=\" \"><subfield code=\"a\">r</subfield></datafield><datafield tag=\"181\" ind1=\" \" ind2=\" \"><subfield code=\"6\">z01</subfield><subfield code=\"c\">txt</subfield><subfield code=\"2\">rdacontent</subfield></datafield><datafield tag=\"181\" ind1=\" \" ind2=\"1\"><subfield code=\"6\">z01</subfield><subfield code=\"a\">i#</subfield><subfield code=\"b\">xxxe##</subfield></datafield><datafield tag=\"182\" ind1=\" \" ind2=\" \"><subfield code=\"6\">z01</subfield><subfield code=\"c\">n</subfield><subfield code=\"2\">rdamedia</subfield></datafield><datafield tag=\"182\" ind1=\" \" ind2=\"1\"><subfield code=\"6\">z01</subfield><subfield code=\"a\">n</subfield></datafield><datafield tag=\"183\" ind1=\" \" ind2=\"1\"><subfield code=\"6\">z01</subfield><subfield code=\"a\">nga</subfield><subfield code=\"2\">RDAfrCarrier</subfield></datafield><datafield tag=\"102\" ind1=\" \" ind2=\" \"><subfield code=\"a\">FR</subfield></datafield><datafield tag=\"320\" ind1=\" \" ind2=\" \"><subfield code=\"a\">Bilbliogr. p. 419-424. Index</subfield></datafield><datafield tag=\"200\" ind1=\"1\" ind2=\" \"><subfield code=\"a\">\\x98Les \\x9cJeux olympiques de 1892 à 2024</subfield><subfield code=\"e\">une aventure mondiale</subfield><subfield code=\"f\">Patrick Clastres</subfield></datafield><datafield tag=\"700\" ind1=\" \" ind2=\"1\"><subfield code=\"3\">080640443</subfield><subfield code=\"a\">Clastres</subfield><subfield code=\"b\">Patrick</subfield><subfield code=\"f\">19..-....</subfield><subfield code=\"4\">070</subfield></datafield><datafield tag=\"801\" ind1=\" \" ind2=\"3\"><subfield code=\"a\">FR</subfield><subfield code=\"b\">Abes</subfield><subfield code=\"c\">20250424</subfield><subfield code=\"g\">AFNOR</subfield></datafield><datafield tag=\"214\" ind1=\" \" ind2=\"0\"><subfield code=\"a\">Rennes</subfield><subfield code=\"c\">Presses universitaires de Rennes</subfield><subfield code=\"d\">DL 2025</subfield></datafield><datafield tag=\"215\" ind1=\" \" ind2=\" \"><subfield code=\"a\">1 vol. (463 p.)</subfield><subfield code=\"c\">couv. ill. en coul.</subfield><subfield code=\"d\">24 cm</subfield></datafield><datafield tag=\"225\" ind1=\"0\" ind2=\" \"><subfield code=\"a\">Collection \"Histoire\"</subfield></datafield><datafield tag=\"410\" ind1=\" \" ind2=\"|\"><subfield code=\"0\">003326195</subfield><subfield code=\"t\">Histoire (Rennes)</subfield><subfield code=\"x\">1255-2364</subfield></datafield><datafield tag=\"606\" ind1=\" \" ind2=\" \"><subfield code=\"3\">027389162</subfield><subfield code=\"a\">Olympisme</subfield><subfield code=\"3\">02726470X</subfield><subfield code=\"x\">Histoire</subfield><subfield code=\"2\">rameau</subfield></datafield><datafield tag=\"606\" ind1=\" \" ind2=\" \"><subfield code=\"3\">027325652</subfield><subfield code=\"a\">Jeux olympiques</subfield><subfield code=\"3\">02726470X</subfield><subfield code=\"x\">Histoire</subfield><subfield code=\"2\">rameau</subfield></datafield><datafield tag=\"676\" ind1=\" \" ind2=\" \"><subfield code=\"a\">796</subfield><subfield code=\"v\">23a</subfield></datafield><datafield tag=\"330\" ind1=\" \" ind2=\" \"><subfield code=\"a\">\"Depuis leur réinvention à Paris et à Athènes à la fin du XIXe siècle, les Jeux olympiques semblent refléter la marche du monde. En fait, ils progressent à leur propre rythme, quadriennal, et ils ne sont jamais qu’un interlude posé dans les interstices des États, des sociétés et des économies. Faire l’histoire de leur aventure mondiale nécessite un préalable : mettre à distance le roman olympique conçu par le CIO. Tout est parti de l’idée messianique imaginée en 1892 par Pierre de Coubertin : contribuer à la paix des nations par la compétition sportive. Pour défendre son idéal contre les ingérences politiques et commerciales, ce jeune aristocrate parisien a théorisé la neutralité de l’« olympisme ». Une contre-société d’échelle mondiale est apparue avec sa capitale et son gouvernement, sa géographie et sa diplomatie, son administration et sa législation. Depuis 130 ans, le CIO bataille contre les fédérations internationales pour imposer son hégémonie. Pour appréhender la diffusion des JO d’Athènes en 1896 jusqu’à Paris en 2024, et décrypter l’olympisation des sociétés voulue par le CIO, une même trame est proposée au lecteur : l’imbrication des enjeux politiques et sportifs, la concurrence des jeux alternatifs, la compétition entre villes candidates, les portraits des présidents successifs du CIO, les cérémonies d’ouverture comme romans nationaux, le programme olympique au prisme des cultures corporelles, le dopage et la corruption, les oppositions à l’organisation des Jeux, la hiérarchie sportive des États, les trajectoires de vie des champions et championnes, les freins et avancées des droits humains dans le sport.\"</subfield><subfield code=\"2\">4e de couverture</subfield></datafield></record><|im_end|>',\n",
       "   'role': 'assistant'}]}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caf4114f-f988-4072-9c53-22b0e8f66d95",
   "metadata": {},
   "source": [
    "# Lora SFT fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dc88791e-c2ce-4b6b-a9ac-bad76166b58e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM, TrainingArguments\n",
    "from trl import SFTTrainer\n",
    "from peft import LoraConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3d642c00-3c85-4de6-80f6-be5544cf3985",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "model\n",
      "model.embed_tokens\n",
      "model.layers\n",
      "model.layers.0\n",
      "model.layers.0.self_attn\n",
      "model.layers.0.self_attn.q_proj\n",
      "model.layers.0.self_attn.k_proj\n",
      "model.layers.0.self_attn.v_proj\n",
      "model.layers.0.self_attn.o_proj\n",
      "model.layers.0.mlp\n",
      "model.layers.0.mlp.gate_proj\n",
      "model.layers.0.mlp.up_proj\n",
      "model.layers.0.mlp.down_proj\n",
      "model.layers.0.mlp.act_fn\n",
      "model.layers.0.input_layernorm\n",
      "model.layers.0.post_attention_layernorm\n",
      "model.layers.1\n",
      "model.layers.1.self_attn\n",
      "model.layers.1.self_attn.q_proj\n",
      "model.layers.1.self_attn.k_proj\n",
      "model.layers.1.self_attn.v_proj\n",
      "model.layers.1.self_attn.o_proj\n",
      "model.layers.1.mlp\n",
      "model.layers.1.mlp.gate_proj\n",
      "model.layers.1.mlp.up_proj\n",
      "model.layers.1.mlp.down_proj\n",
      "model.layers.1.mlp.act_fn\n",
      "model.layers.1.input_layernorm\n",
      "model.layers.1.post_attention_layernorm\n",
      "model.layers.2\n",
      "model.layers.2.self_attn\n",
      "model.layers.2.self_attn.q_proj\n",
      "model.layers.2.self_attn.k_proj\n",
      "model.layers.2.self_attn.v_proj\n",
      "model.layers.2.self_attn.o_proj\n",
      "model.layers.2.mlp\n",
      "model.layers.2.mlp.gate_proj\n",
      "model.layers.2.mlp.up_proj\n",
      "model.layers.2.mlp.down_proj\n",
      "model.layers.2.mlp.act_fn\n",
      "model.layers.2.input_layernorm\n",
      "model.layers.2.post_attention_layernorm\n",
      "model.layers.3\n",
      "model.layers.3.self_attn\n",
      "model.layers.3.self_attn.q_proj\n",
      "model.layers.3.self_attn.k_proj\n",
      "model.layers.3.self_attn.v_proj\n",
      "model.layers.3.self_attn.o_proj\n",
      "model.layers.3.mlp\n",
      "model.layers.3.mlp.gate_proj\n",
      "model.layers.3.mlp.up_proj\n",
      "model.layers.3.mlp.down_proj\n",
      "model.layers.3.mlp.act_fn\n",
      "model.layers.3.input_layernorm\n",
      "model.layers.3.post_attention_layernorm\n",
      "model.layers.4\n",
      "model.layers.4.self_attn\n",
      "model.layers.4.self_attn.q_proj\n",
      "model.layers.4.self_attn.k_proj\n",
      "model.layers.4.self_attn.v_proj\n",
      "model.layers.4.self_attn.o_proj\n",
      "model.layers.4.mlp\n",
      "model.layers.4.mlp.gate_proj\n",
      "model.layers.4.mlp.up_proj\n",
      "model.layers.4.mlp.down_proj\n",
      "model.layers.4.mlp.act_fn\n",
      "model.layers.4.input_layernorm\n",
      "model.layers.4.post_attention_layernorm\n",
      "model.layers.5\n",
      "model.layers.5.self_attn\n",
      "model.layers.5.self_attn.q_proj\n",
      "model.layers.5.self_attn.k_proj\n",
      "model.layers.5.self_attn.v_proj\n",
      "model.layers.5.self_attn.o_proj\n",
      "model.layers.5.mlp\n",
      "model.layers.5.mlp.gate_proj\n",
      "model.layers.5.mlp.up_proj\n",
      "model.layers.5.mlp.down_proj\n",
      "model.layers.5.mlp.act_fn\n",
      "model.layers.5.input_layernorm\n",
      "model.layers.5.post_attention_layernorm\n",
      "model.layers.6\n",
      "model.layers.6.self_attn\n",
      "model.layers.6.self_attn.q_proj\n",
      "model.layers.6.self_attn.k_proj\n",
      "model.layers.6.self_attn.v_proj\n",
      "model.layers.6.self_attn.o_proj\n",
      "model.layers.6.mlp\n",
      "model.layers.6.mlp.gate_proj\n",
      "model.layers.6.mlp.up_proj\n",
      "model.layers.6.mlp.down_proj\n",
      "model.layers.6.mlp.act_fn\n",
      "model.layers.6.input_layernorm\n",
      "model.layers.6.post_attention_layernorm\n",
      "model.layers.7\n",
      "model.layers.7.self_attn\n",
      "model.layers.7.self_attn.q_proj\n",
      "model.layers.7.self_attn.k_proj\n",
      "model.layers.7.self_attn.v_proj\n",
      "model.layers.7.self_attn.o_proj\n",
      "model.layers.7.mlp\n",
      "model.layers.7.mlp.gate_proj\n",
      "model.layers.7.mlp.up_proj\n",
      "model.layers.7.mlp.down_proj\n",
      "model.layers.7.mlp.act_fn\n",
      "model.layers.7.input_layernorm\n",
      "model.layers.7.post_attention_layernorm\n",
      "model.layers.8\n",
      "model.layers.8.self_attn\n",
      "model.layers.8.self_attn.q_proj\n",
      "model.layers.8.self_attn.k_proj\n",
      "model.layers.8.self_attn.v_proj\n",
      "model.layers.8.self_attn.o_proj\n",
      "model.layers.8.mlp\n",
      "model.layers.8.mlp.gate_proj\n",
      "model.layers.8.mlp.up_proj\n",
      "model.layers.8.mlp.down_proj\n",
      "model.layers.8.mlp.act_fn\n",
      "model.layers.8.input_layernorm\n",
      "model.layers.8.post_attention_layernorm\n",
      "model.layers.9\n",
      "model.layers.9.self_attn\n",
      "model.layers.9.self_attn.q_proj\n",
      "model.layers.9.self_attn.k_proj\n",
      "model.layers.9.self_attn.v_proj\n",
      "model.layers.9.self_attn.o_proj\n",
      "model.layers.9.mlp\n",
      "model.layers.9.mlp.gate_proj\n",
      "model.layers.9.mlp.up_proj\n",
      "model.layers.9.mlp.down_proj\n",
      "model.layers.9.mlp.act_fn\n",
      "model.layers.9.input_layernorm\n",
      "model.layers.9.post_attention_layernorm\n",
      "model.layers.10\n",
      "model.layers.10.self_attn\n",
      "model.layers.10.self_attn.q_proj\n",
      "model.layers.10.self_attn.k_proj\n",
      "model.layers.10.self_attn.v_proj\n",
      "model.layers.10.self_attn.o_proj\n",
      "model.layers.10.mlp\n",
      "model.layers.10.mlp.gate_proj\n",
      "model.layers.10.mlp.up_proj\n",
      "model.layers.10.mlp.down_proj\n",
      "model.layers.10.mlp.act_fn\n",
      "model.layers.10.input_layernorm\n",
      "model.layers.10.post_attention_layernorm\n",
      "model.layers.11\n",
      "model.layers.11.self_attn\n",
      "model.layers.11.self_attn.q_proj\n",
      "model.layers.11.self_attn.k_proj\n",
      "model.layers.11.self_attn.v_proj\n",
      "model.layers.11.self_attn.o_proj\n",
      "model.layers.11.mlp\n",
      "model.layers.11.mlp.gate_proj\n",
      "model.layers.11.mlp.up_proj\n",
      "model.layers.11.mlp.down_proj\n",
      "model.layers.11.mlp.act_fn\n",
      "model.layers.11.input_layernorm\n",
      "model.layers.11.post_attention_layernorm\n",
      "model.layers.12\n",
      "model.layers.12.self_attn\n",
      "model.layers.12.self_attn.q_proj\n",
      "model.layers.12.self_attn.k_proj\n",
      "model.layers.12.self_attn.v_proj\n",
      "model.layers.12.self_attn.o_proj\n",
      "model.layers.12.mlp\n",
      "model.layers.12.mlp.gate_proj\n",
      "model.layers.12.mlp.up_proj\n",
      "model.layers.12.mlp.down_proj\n",
      "model.layers.12.mlp.act_fn\n",
      "model.layers.12.input_layernorm\n",
      "model.layers.12.post_attention_layernorm\n",
      "model.layers.13\n",
      "model.layers.13.self_attn\n",
      "model.layers.13.self_attn.q_proj\n",
      "model.layers.13.self_attn.k_proj\n",
      "model.layers.13.self_attn.v_proj\n",
      "model.layers.13.self_attn.o_proj\n",
      "model.layers.13.mlp\n",
      "model.layers.13.mlp.gate_proj\n",
      "model.layers.13.mlp.up_proj\n",
      "model.layers.13.mlp.down_proj\n",
      "model.layers.13.mlp.act_fn\n",
      "model.layers.13.input_layernorm\n",
      "model.layers.13.post_attention_layernorm\n",
      "model.layers.14\n",
      "model.layers.14.self_attn\n",
      "model.layers.14.self_attn.q_proj\n",
      "model.layers.14.self_attn.k_proj\n",
      "model.layers.14.self_attn.v_proj\n",
      "model.layers.14.self_attn.o_proj\n",
      "model.layers.14.mlp\n",
      "model.layers.14.mlp.gate_proj\n",
      "model.layers.14.mlp.up_proj\n",
      "model.layers.14.mlp.down_proj\n",
      "model.layers.14.mlp.act_fn\n",
      "model.layers.14.input_layernorm\n",
      "model.layers.14.post_attention_layernorm\n",
      "model.layers.15\n",
      "model.layers.15.self_attn\n",
      "model.layers.15.self_attn.q_proj\n",
      "model.layers.15.self_attn.k_proj\n",
      "model.layers.15.self_attn.v_proj\n",
      "model.layers.15.self_attn.o_proj\n",
      "model.layers.15.mlp\n",
      "model.layers.15.mlp.gate_proj\n",
      "model.layers.15.mlp.up_proj\n",
      "model.layers.15.mlp.down_proj\n",
      "model.layers.15.mlp.act_fn\n",
      "model.layers.15.input_layernorm\n",
      "model.layers.15.post_attention_layernorm\n",
      "model.layers.16\n",
      "model.layers.16.self_attn\n",
      "model.layers.16.self_attn.q_proj\n",
      "model.layers.16.self_attn.k_proj\n",
      "model.layers.16.self_attn.v_proj\n",
      "model.layers.16.self_attn.o_proj\n",
      "model.layers.16.mlp\n",
      "model.layers.16.mlp.gate_proj\n",
      "model.layers.16.mlp.up_proj\n",
      "model.layers.16.mlp.down_proj\n",
      "model.layers.16.mlp.act_fn\n",
      "model.layers.16.input_layernorm\n",
      "model.layers.16.post_attention_layernorm\n",
      "model.layers.17\n",
      "model.layers.17.self_attn\n",
      "model.layers.17.self_attn.q_proj\n",
      "model.layers.17.self_attn.k_proj\n",
      "model.layers.17.self_attn.v_proj\n",
      "model.layers.17.self_attn.o_proj\n",
      "model.layers.17.mlp\n",
      "model.layers.17.mlp.gate_proj\n",
      "model.layers.17.mlp.up_proj\n",
      "model.layers.17.mlp.down_proj\n",
      "model.layers.17.mlp.act_fn\n",
      "model.layers.17.input_layernorm\n",
      "model.layers.17.post_attention_layernorm\n",
      "model.layers.18\n",
      "model.layers.18.self_attn\n",
      "model.layers.18.self_attn.q_proj\n",
      "model.layers.18.self_attn.k_proj\n",
      "model.layers.18.self_attn.v_proj\n",
      "model.layers.18.self_attn.o_proj\n",
      "model.layers.18.mlp\n",
      "model.layers.18.mlp.gate_proj\n",
      "model.layers.18.mlp.up_proj\n",
      "model.layers.18.mlp.down_proj\n",
      "model.layers.18.mlp.act_fn\n",
      "model.layers.18.input_layernorm\n",
      "model.layers.18.post_attention_layernorm\n",
      "model.layers.19\n",
      "model.layers.19.self_attn\n",
      "model.layers.19.self_attn.q_proj\n",
      "model.layers.19.self_attn.k_proj\n",
      "model.layers.19.self_attn.v_proj\n",
      "model.layers.19.self_attn.o_proj\n",
      "model.layers.19.mlp\n",
      "model.layers.19.mlp.gate_proj\n",
      "model.layers.19.mlp.up_proj\n",
      "model.layers.19.mlp.down_proj\n",
      "model.layers.19.mlp.act_fn\n",
      "model.layers.19.input_layernorm\n",
      "model.layers.19.post_attention_layernorm\n",
      "model.layers.20\n",
      "model.layers.20.self_attn\n",
      "model.layers.20.self_attn.q_proj\n",
      "model.layers.20.self_attn.k_proj\n",
      "model.layers.20.self_attn.v_proj\n",
      "model.layers.20.self_attn.o_proj\n",
      "model.layers.20.mlp\n",
      "model.layers.20.mlp.gate_proj\n",
      "model.layers.20.mlp.up_proj\n",
      "model.layers.20.mlp.down_proj\n",
      "model.layers.20.mlp.act_fn\n",
      "model.layers.20.input_layernorm\n",
      "model.layers.20.post_attention_layernorm\n",
      "model.layers.21\n",
      "model.layers.21.self_attn\n",
      "model.layers.21.self_attn.q_proj\n",
      "model.layers.21.self_attn.k_proj\n",
      "model.layers.21.self_attn.v_proj\n",
      "model.layers.21.self_attn.o_proj\n",
      "model.layers.21.mlp\n",
      "model.layers.21.mlp.gate_proj\n",
      "model.layers.21.mlp.up_proj\n",
      "model.layers.21.mlp.down_proj\n",
      "model.layers.21.mlp.act_fn\n",
      "model.layers.21.input_layernorm\n",
      "model.layers.21.post_attention_layernorm\n",
      "model.layers.22\n",
      "model.layers.22.self_attn\n",
      "model.layers.22.self_attn.q_proj\n",
      "model.layers.22.self_attn.k_proj\n",
      "model.layers.22.self_attn.v_proj\n",
      "model.layers.22.self_attn.o_proj\n",
      "model.layers.22.mlp\n",
      "model.layers.22.mlp.gate_proj\n",
      "model.layers.22.mlp.up_proj\n",
      "model.layers.22.mlp.down_proj\n",
      "model.layers.22.mlp.act_fn\n",
      "model.layers.22.input_layernorm\n",
      "model.layers.22.post_attention_layernorm\n",
      "model.layers.23\n",
      "model.layers.23.self_attn\n",
      "model.layers.23.self_attn.q_proj\n",
      "model.layers.23.self_attn.k_proj\n",
      "model.layers.23.self_attn.v_proj\n",
      "model.layers.23.self_attn.o_proj\n",
      "model.layers.23.mlp\n",
      "model.layers.23.mlp.gate_proj\n",
      "model.layers.23.mlp.up_proj\n",
      "model.layers.23.mlp.down_proj\n",
      "model.layers.23.mlp.act_fn\n",
      "model.layers.23.input_layernorm\n",
      "model.layers.23.post_attention_layernorm\n",
      "model.norm\n",
      "model.rotary_emb\n",
      "lm_head\n"
     ]
    }
   ],
   "source": [
    "for name, module in model.named_modules():\n",
    "    print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85c64bfa-cc45-4b85-ab32-4da49ebb3fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "help(SFTTrainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b8068044-64c7-4b9e-b8d9-d850bfd6a938",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db00e2812a194234b5cb0274583c7da5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Converting train dataset to ChatML:   0%|          | 0/5129 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c935696f7bbb4c8d80f8491398685d71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Applying chat template to train dataset:   0%|          | 0/5129 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c1b622967ca4291a08c5a07e5a74933",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tokenizing train dataset:   0%|          | 0/5129 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0743e0da3a324e16bdbd063549de9a0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Truncating train dataset:   0%|          | 0/5129 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
     ]
    }
   ],
   "source": [
    "# ---- 3. Define LoRA config ----\n",
    "peft_config = LoraConfig(\n",
    "    r=8,\n",
    "    lora_alpha=32,\n",
    "    lora_dropout=0.1,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\",\n",
    "    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\"] # may vary based on model, check with `model.named_modules()` in previous cell\n",
    ")\n",
    "\n",
    "# ---- 4. Training args ----\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./sft_lora_output\",\n",
    "    per_device_train_batch_size=4,\n",
    "    gradient_accumulation_steps=4,\n",
    "    logging_steps=10,\n",
    "    save_strategy=\"epoch\",\n",
    "    num_train_epochs=3,\n",
    "    learning_rate=2e-4,\n",
    "    fp16=True,\n",
    "    report_to=\"none\"\n",
    ")\n",
    "\n",
    "# ---- 5. Launch training ----\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    train_dataset=dataset,\n",
    "    peft_config=peft_config,\n",
    "    args=training_args\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "06d96808-643e-4eb0-a248-47f14700e3fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The input hidden states seems to be silently casted in float32, this might be related to the fact you have upcasted embedding or layer norm layers in float32. We will cast back the input in torch.float16.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='960' max='960' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [960/960 13:33, Epoch 2/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>2.002400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1.695500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1.523800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1.529100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.409200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>1.318200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>1.429800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>1.375600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>1.312200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.321700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>1.385000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>1.366300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>1.321900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>1.283300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1.288300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>1.241700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>1.290200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>1.243300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>1.180400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1.282500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>1.186900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>1.297000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>1.277700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>1.278600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>1.266600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>1.216300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>1.236600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>1.342500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>1.233400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>1.252600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>1.319900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>1.218200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>1.361700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>1.240000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>1.186200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>1.217400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>370</td>\n",
       "      <td>1.212800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>1.174100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>390</td>\n",
       "      <td>1.270600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>1.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>410</td>\n",
       "      <td>1.204900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>1.200900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>430</td>\n",
       "      <td>1.238300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>440</td>\n",
       "      <td>1.241700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>1.198200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>460</td>\n",
       "      <td>1.243600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>470</td>\n",
       "      <td>1.208400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>1.222800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>490</td>\n",
       "      <td>1.164000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>1.188800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>510</td>\n",
       "      <td>1.228200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>520</td>\n",
       "      <td>1.195500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>530</td>\n",
       "      <td>1.232700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>1.185700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>1.241000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>560</td>\n",
       "      <td>1.159500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>570</td>\n",
       "      <td>1.221100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>580</td>\n",
       "      <td>1.206600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>590</td>\n",
       "      <td>1.223000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>1.189400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>610</td>\n",
       "      <td>1.219500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>620</td>\n",
       "      <td>1.183000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>630</td>\n",
       "      <td>1.223100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>640</td>\n",
       "      <td>1.218000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>1.350000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>660</td>\n",
       "      <td>1.182100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>670</td>\n",
       "      <td>1.127200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>680</td>\n",
       "      <td>1.246100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>690</td>\n",
       "      <td>1.199800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>1.181800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>710</td>\n",
       "      <td>1.147700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>720</td>\n",
       "      <td>1.227800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>730</td>\n",
       "      <td>1.184800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>740</td>\n",
       "      <td>1.241400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>1.179800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>760</td>\n",
       "      <td>1.178200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>770</td>\n",
       "      <td>1.207800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>780</td>\n",
       "      <td>1.216600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>790</td>\n",
       "      <td>1.103700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>1.196100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>810</td>\n",
       "      <td>1.190100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>820</td>\n",
       "      <td>1.139800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>830</td>\n",
       "      <td>1.185600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>840</td>\n",
       "      <td>1.197600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>1.160400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>860</td>\n",
       "      <td>1.176000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>870</td>\n",
       "      <td>1.153200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>880</td>\n",
       "      <td>1.210400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>890</td>\n",
       "      <td>1.152400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>1.218800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>910</td>\n",
       "      <td>1.142000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>920</td>\n",
       "      <td>1.141900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>930</td>\n",
       "      <td>1.181400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>940</td>\n",
       "      <td>1.201400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>1.234700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>960</td>\n",
       "      <td>1.178600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=960, training_loss=1.2485659301280976, metrics={'train_runtime': 814.5382, 'train_samples_per_second': 18.89, 'train_steps_per_second': 1.179, 'total_flos': 3.389519634314035e+16, 'train_loss': 1.2485659301280976})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "189f49f3-9a9d-4bfd-b308-d81703bb075a",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d6a9d9ba-a490-4330-8776-48cdaea30556",
   "metadata": {},
   "outputs": [],
   "source": [
    "peft_model_id = \"sft_lora_output\"\n",
    "tr_model_id = \"Qwen/Qwen2.5-0.5B-Instruct\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0b1ac408-e785-4745-a6fa-43b07569ba9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sliding Window Attention is enabled but not implemented for `sdpa`; unexpected results may be encountered.\n"
     ]
    }
   ],
   "source": [
    "from peft import AutoPeftModelForCausalLM, PeftModel\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(tr_model_id, trust_remote_code=True, torch_dtype=torch.float16,\n",
    "     low_cpu_mem_usage=True,)\n",
    "model = PeftModel.from_pretrained(model, peft_model_id)\n",
    "merged_model = model.merge_and_unload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "152ce199-d3cb-440a-88e0-5575828cb9b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8821b23fd8ee486fa0e5957a6d608af6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/988M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/Geraldine/FineQwen2.5-0.5B-Instruct-sft-unimarc/commit/47463a7231c78284a535fe884d57a95c19d97eb3', commit_message='Upload Qwen2ForCausalLM', commit_description='', oid='47463a7231c78284a535fe884d57a95c19d97eb3', pr_url=None, repo_url=RepoUrl('https://huggingface.co/Geraldine/FineQwen2.5-0.5B-Instruct-sft-unimarc', endpoint='https://huggingface.co', repo_type='model', repo_id='Geraldine/FineQwen2.5-0.5B-Instruct-sft-unimarc'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_model.push_to_hub(f\"Geraldine/FineQwen2.5-0.5B-Instruct-sft-unimarc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e9e6a07d-58d1-4a19-8ba4-b636bd0cd4fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d54d912ddffb48ec9c1021463fd44e60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/5.17k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df2640edaf2341ffab6a60a42a2cddc2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/11.4M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/Geraldine/FineQwen2.5-0.5B-Instruct-sft-unimarc/commit/07c7caa385df6907882345c6cf8d415ce8f2ec6c', commit_message='Upload tokenizer', commit_description='', oid='07c7caa385df6907882345c6cf8d415ce8f2ec6c', pr_url=None, repo_url=RepoUrl('https://huggingface.co/Geraldine/FineQwen2.5-0.5B-Instruct-sft-unimarc', endpoint='https://huggingface.co', repo_type='model', repo_id='Geraldine/FineQwen2.5-0.5B-Instruct-sft-unimarc'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(peft_model_id)\n",
    "tokenizer.push_to_hub(f\"Geraldine/FineQwen2.5-0.5B-Instruct-sft-unimarc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6507649c-f75a-467e-8b11-23306a07c468",
   "metadata": {},
   "source": [
    "## Inference with Lora fine-tuned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "07ffa8d4-51bf-4f21-8913-e0ac9c57932d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b5e1f9e17ce44ada2b3f7417c031f4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/7.34k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bfbbd614b35b406485ffa72890fa0b4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/2.78M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84645b1923834989872b02d7ae428542",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/1.67M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f837b19fe0da4f92a157549d53690a77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/11.4M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43e886acafbb4a8ebbf7cba2f959e196",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "added_tokens.json:   0%|          | 0.00/605 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eac6b448f51a49fc95772b27149fc2ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/613 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2374e0462cdb4f1c87cd9c9243bcc13e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/682 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "155a2957db474928a0c4bac08c2f6d83",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/988M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e5fbb526d094bc59036a32419aecc87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/242 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_name = \"Geraldine/FineQwen2.5-0.5B-Instruct-sft-unimarc\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    torch_dtype=\"auto\",\n",
    "    device_map=\"auto\",\n",
    "    attn_implementation=\"flash_attention_2\"\n",
    ")\n",
    "model.config.sliding_window = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "49cb262f-5330-4096-ad5f-dfea4a9258c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Qwen2ForCausalLM(\n",
       "  (model): Qwen2Model(\n",
       "    (embed_tokens): Embedding(151936, 896)\n",
       "    (layers): ModuleList(\n",
       "      (0-23): 24 x Qwen2DecoderLayer(\n",
       "        (self_attn): Qwen2Attention(\n",
       "          (q_proj): Linear(in_features=896, out_features=896, bias=True)\n",
       "          (k_proj): Linear(in_features=896, out_features=128, bias=True)\n",
       "          (v_proj): Linear(in_features=896, out_features=128, bias=True)\n",
       "          (o_proj): Linear(in_features=896, out_features=896, bias=False)\n",
       "        )\n",
       "        (mlp): Qwen2MLP(\n",
       "          (gate_proj): Linear(in_features=896, out_features=4864, bias=False)\n",
       "          (up_proj): Linear(in_features=896, out_features=4864, bias=False)\n",
       "          (down_proj): Linear(in_features=4864, out_features=896, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): Qwen2RMSNorm((896,), eps=1e-06)\n",
       "        (post_attention_layernorm): Qwen2RMSNorm((896,), eps=1e-06)\n",
       "      )\n",
       "    )\n",
       "    (norm): Qwen2RMSNorm((896,), eps=1e-06)\n",
       "    (rotary_emb): Qwen2RotaryEmbedding()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=896, out_features=151936, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.config.sliding_window = None\n",
    "device = \"cuda\" # for GPU usage or \"cpu\" for CPU usage\n",
    "model = model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "31e94c77-00a0-4d74-87df-a46b5d0e4dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"\n",
    "You are a helpful assistant expert in Unimarc/XML bibliographic records.\n",
    "you need to first think about the reasoning process in the mind and then provide the answer. \n",
    "The reasoning process and answer are separated in distincts paragraphs respectively starting with `### Reasoning:` and `### Answer:`.\n",
    "For example, ### Reasoning: This is the reasoning process. \\n ### Answer: The final exact answer is \\boxed{answer here}. \n",
    "In the last part of the answer, the final exact answer is enclosed within \\boxed{} with XML format.\n",
    "\"\"\"\n",
    "\n",
    "user_prompt = \"\"\"Given these bibliographic metadata, generate a valid Unimarc XML record:\n",
    "Title: Les Jeux olympiques de 1892 à 2024\n",
    "Subtitle: une aventure mondiale\n",
    "Author: Patrick Clastres\n",
    "Additional author info: Clastres, Patrick (19..-....)\n",
    "Publisher: Presses universitaires de Rennes\n",
    "Place of publication: Rennes\n",
    "Year: 2025 (DL 2025)\n",
    "ISBN: 978-2-7535-9645-0 (br.)\n",
    "Language: French (fre)\n",
    "Edition: Not explicitly stated\n",
    "Material description: 1 volume (463 pages); color illustrated cover; 24 cm\n",
    "Collection/Series: Collection \"Histoire\"\n",
    "Series ISSN: 1255-2364 (Histoire (Rennes))\n",
    "Table of contents: Not provided\n",
    "Abstract/Notes:\n",
    "\"Depuis leur réinvention à Paris et à Athènes à la fin du XIXe siècle, les Jeux olympiques semblent refléter la marche du monde. En fait, ils progressent à leur propre rythme, quadriennal, et ils ne sont jamais qu’un interlude posé dans les interstices des États, des sociétés et des économies. Faire l’histoire de leur aventure mondiale nécessite un préalable : mettre à distance le roman olympique conçu par le CIO. Tout est parti de l’idée messianique imaginée en 1892 par Pierre de Coubertin : contribuer à la paix des nations par la compétition sportive. Pour défendre son idéal contre les ingérences politiques et commerciales, ce jeune aristocrate parisien a théorisé la neutralité de l’« olympisme ». Une contre-société d’échelle mondiale est apparue avec sa capitale et son gouvernement, sa géographie et sa diplomatie, son administration et sa législation. Depuis 130 ans, le CIO bataille contre les fédérations internationales pour imposer son hégémonie. Pour appréhender la diffusion des JO d’Athènes en 1896 jusqu’à Paris en 2024, et décrypter l’olympisation des sociétés voulue par le CIO, une même trame est proposée au lecteur : l’imbrication des enjeux politiques et sportifs, la concurrence des jeux alternatifs, la compétition entre villes candidates, les portraits des présidents successifs du CIO, les cérémonies d’ouverture comme romans nationaux, le programme olympique au prisme des cultures corporelles, le dopage et la corruption, les oppositions à l’organisation des Jeux, la hiérarchie sportive des États, les trajectoires de vie des champions et championnes, les freins et avancées des droits humains dans le sport.\"\n",
    "Source of the abstract/notes: 4e de couverture (back cover)\n",
    "Bibliographic references: pages 419-424; includes index\n",
    "Keywords: Olympisme, Jeux olympiques, Histoire\n",
    "Classification: 796(23a)\n",
    "Country of publication: France (FR)\n",
    "Additional identifiers: OCLC number (OCoLC)1513823097\n",
    "Library info/source: Abes (FR); AFNOR; Sudoc link: http://www.sudoc.fr/284189537\"\"\"\n",
    "\n",
    "messages = [\n",
    "  {\"role\": \"system\", \"content\": system_prompt},\n",
    "  {\"role\": \"user\", \"content\": user_prompt},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "e3952799-50dd-4942-8045-97562e2a9942",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer.apply_chat_template(\n",
    "    messages,\n",
    "    return_dict=True,\n",
    "    tokenize = True,\n",
    "    add_generation_prompt = True, # Must add for generation\n",
    "    return_tensors = \"pt\",\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "9e073957-a07b-4ab7-8c97-c4cc1c1d6ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = model.generate(\n",
    "    **inputs,\n",
    "    max_new_tokens = 4096,\n",
    "    repetition_penalty=1.2,\n",
    "    eos_token_id=tokenizer.eos_token_id,\n",
    "    use_cache = True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "e06875c6-048b-4a1f-9ac0-a69ff97eb1cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_ids = [\n",
    "   output_ids[len(input_ids):] for input_ids, output_ids in zip(inputs.input_ids, outputs)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "ecf4592d-37bd-4743-ad64-1b2e190f2382",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Reasoning:\n",
      "\n",
      "This bibliography entry describes an electronic book titled \"Les Jeux olympiques de 1892 à 2024\", authored by Patrick Clastres and published under the collection name \"Histoire\". It was released on April 17, 2025, at ISBN 978-2-7535-9645-0.\n",
      "\n",
      "It contains several fields indicating content type and media type details such as text (\"r\"), non-representational form (\"n\") including physical medium (\"m\"). There's also mention of digital file or carrier code (rd).\n",
      "\n",
      "The main subject matter relates specifically to Olympic history from its inception up until present day.\n",
      "\n",
      "### Final note:\n",
      "The complete title structure appears correctly aligned across all elements mentioned for this bibliographic data related to the given cataloguing rules and source codes used.\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d8020ee-4889-4a3c-a278-606944f25880",
   "metadata": {},
   "source": [
    "# Reward functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f6c955c-550b-412b-9723-6f7729a04cef",
   "metadata": {},
   "source": [
    "## utils functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7d53cc64-58bc-457a-8aa8-4729e5934045",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "import re\n",
    "\n",
    "def extract_hash_answer(text: str) -> str | None:\n",
    "    if \"### Answer:\" not in text:\n",
    "        return None\n",
    "    first_split = text.split(\"### Answer:\")[1].strip()\n",
    "    if \"### Explanation:\" not in first_split:\n",
    "        return first_split\n",
    "    else:\n",
    "        return first_split.split(\"### Explanation:\")[0].strip()\n",
    "\n",
    "def extract_xml(text: str) -> str | None:\n",
    "    # Use regular expression to find the XML part enclosed in ```xml...```\n",
    "    xml_match = re.search(r'```xml(.*?)```', response, re.DOTALL)\n",
    "    if xml_match:\n",
    "        return xml_match.group(1).strip()\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def extract_field_values(xml_str):\n",
    "    root = ET.fromstring(xml_str)\n",
    "    fields = {}\n",
    "    for df in root.findall(\".//datafield\"):\n",
    "        tag = df.get(\"tag\")\n",
    "        subfields = [sf.text for sf in df.findall(\"subfield\")]\n",
    "        fields[tag] = \" \".join(subfields)\n",
    "    return fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2f9a80c6-e6a3-454f-b411-265079c766d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example avec previous example\n",
    "response = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5f9cf5c4-2f15-46c4-b8f1-ae2a497b8e82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```xml\n",
      "<?xml version=\"1.0\"?>\n",
      "<record xmlns=\"http://unimarc.org/xml/ns/unimarc\">\n",
      "    <author>\n",
      "        <name>Leonardo I. Farfan-Cabrera, Ali Erdemir</name>\n",
      "    </author>\n",
      "    <publisher>Elsevier</publisher>\n",
      "    <year>2024</year>\n",
      "    <isbn>978-0-443-14074-7</isbn>\n",
      "    <language>English</language>\n",
      "    <collection>\n",
      "        <series>Elsevier Series on Tribology and Surface Engineering</series>\n",
      "    </collection>\n",
      "    <edition>\n",
      "        Not specified\n",
      "    </edition>\n",
      "    <material>\n",
      "        <description>1 vol. (XII-313 p.), couv. ill. en coul., 23 cm</description>\n",
      "    </material>\n",
      "    <abstract>\n",
      "        \"Electric vehicle tribology, challenges and opportunities for a sustainable transportation future\"\n",
      "        provides practical, comprehensive guidance on a new and increasingly important area of tribology. Building skills from fundamentals to solution design, this book demonstrates the unique tribological techniques essential to the efficient electrification of transport systems.\"\n",
      "    </abstract>\n",
      "    <keywords>Tribologie (technologie), Tribologie (Technologie)</keywords>\n",
      "    <tableOfContents/>\n",
      "    <keyword>\n",
      "        Tribologie (technologie)\n",
      "    </keyword>\n",
      "</record>\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "print(extract_hash_answer(text=response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ff7bf179-7fa4-48c0-8c78-b06dcf90e38b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<?xml version=\"1.0\"?>\n",
      "<record xmlns=\"http://unimarc.org/xml/ns/unimarc\">\n",
      "    <author>\n",
      "        <name>Leonardo I. Farfan-Cabrera, Ali Erdemir</name>\n",
      "    </author>\n",
      "    <publisher>Elsevier</publisher>\n",
      "    <year>2024</year>\n",
      "    <isbn>978-0-443-14074-7</isbn>\n",
      "    <language>English</language>\n",
      "    <collection>\n",
      "        <series>Elsevier Series on Tribology and Surface Engineering</series>\n",
      "    </collection>\n",
      "    <edition>\n",
      "        Not specified\n",
      "    </edition>\n",
      "    <material>\n",
      "        <description>1 vol. (XII-313 p.), couv. ill. en coul., 23 cm</description>\n",
      "    </material>\n",
      "    <abstract>\n",
      "        \"Electric vehicle tribology, challenges and opportunities for a sustainable transportation future\"\n",
      "        provides practical, comprehensive guidance on a new and increasingly important area of tribology. Building skills from fundamentals to solution design, this book demonstrates the unique tribological techniques essential to the efficient electrification of transport systems.\"\n",
      "    </abstract>\n",
      "    <keywords>Tribologie (technologie), Tribologie (Technologie)</keywords>\n",
      "    <tableOfContents/>\n",
      "    <keyword>\n",
      "        Tribologie (technologie)\n",
      "    </keyword>\n",
      "</record>\n"
     ]
    }
   ],
   "source": [
    "print(extract_xml(text=response))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5e0c0ec-44c7-4f19-8055-f760b4627cf0",
   "metadata": {},
   "source": [
    "## Format-based reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2bcd0252-36d8-4281-8ad3-b7081cf1b1d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_reward(xml_output: str) -> float:\n",
    "    try:\n",
    "        root = ET.fromstring(xml_output)\n",
    "    except ET.ParseError:\n",
    "        return 0.0  # Not even valid XML\n",
    "\n",
    "    required_tags = [\"leader\", \"controlfield\", \"datafield\"]\n",
    "    has_required_tags = all(root.find(f\".//{tag}\") is not None for tag in required_tags)\n",
    "\n",
    "    if not has_required_tags:\n",
    "        return 0.3  # Barely structured but not fully compliant\n",
    "\n",
    "    # Optionally: integrate XSD/Schematron validation here\n",
    "    return 1.0  # Well-formed and conforms to expected structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0e9a09fc-3630-42bc-a6dc-2776b54e7239",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3\n"
     ]
    }
   ],
   "source": [
    "xml_answer = extract_xml(text=response)\n",
    "print(format_reward(xml_output=xml_answer))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6a96315-00f0-4ca5-b286-710546be8425",
   "metadata": {},
   "source": [
    "## Accuracy-based reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c94bbef0-8539-47c6-96ac-2df18b8a54d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "xml_answer = extract_xml(text=response)\n",
    "xml_target = \"\"\"<record><controlfield tag=\"005\">20240711151255.000</controlfield><leader> nam0 22 450 </leader><controlfield tag=\"001\">279354177</controlfield><controlfield tag=\"003\">http://www.sudoc.fr/279354177</controlfield><datafield tag=\"035\" ind1=\" \" ind2=\" \"><subfield code=\"a\">(OCoLC)1449675800</subfield></datafield><datafield tag=\"010\" ind1=\" \" ind2=\" \"><subfield code=\"a\">978-0-443-14074-7</subfield><subfield code=\"b\">br.</subfield></datafield><datafield tag=\"073\" ind1=\" \" ind2=\"1\"><subfield code=\"a\">9780443140747</subfield></datafield><datafield tag=\"100\" ind1=\" \" ind2=\" \"><subfield code=\"a\">20240711d2024 ||||0frey50 ba</subfield></datafield><datafield tag=\"101\" ind1=\"0\" ind2=\" \"><subfield code=\"a\">eng</subfield><subfield code=\"2\">639-2</subfield></datafield><datafield tag=\"105\" ind1=\" \" ind2=\" \"><subfield code=\"a\">y ||||001yy</subfield></datafield><datafield tag=\"106\" ind1=\" \" ind2=\" \"><subfield code=\"a\">r</subfield></datafield><datafield tag=\"181\" ind1=\" \" ind2=\" \"><subfield code=\"6\">z01</subfield><subfield code=\"c\">txt</subfield><subfield code=\"2\">rdacontent</subfield></datafield><datafield tag=\"181\" ind1=\" \" ind2=\"1\"><subfield code=\"6\">z01</subfield><subfield code=\"a\">i#</subfield><subfield code=\"b\">xxxe##</subfield></datafield><datafield tag=\"182\" ind1=\" \" ind2=\" \"><subfield code=\"6\">z01</subfield><subfield code=\"c\">c</subfield><subfield code=\"2\">rdamedia</subfield></datafield><datafield tag=\"182\" ind1=\" \" ind2=\"1\"><subfield code=\"6\">z01</subfield><subfield code=\"a\">b</subfield></datafield><datafield tag=\"183\" ind1=\" \" ind2=\"1\"><subfield code=\"6\">z01</subfield><subfield code=\"a\">nga</subfield><subfield code=\"2\">RDAfrCarrier</subfield></datafield><datafield tag=\"102\" ind1=\" \" ind2=\" \"><subfield code=\"a\">NL</subfield><subfield code=\"a\">GB</subfield><subfield code=\"a\">US</subfield></datafield><datafield tag=\"200\" ind1=\"0\" ind2=\" \"><subfield code=\"a\">Electric vehicle tribology</subfield><subfield code=\"e\">challenges and opportunities for a sustainable transportation future</subfield><subfield code=\"f\">edited by Leonardo I. Farfan-Cabrera, ... Ali Erdemir, ...</subfield></datafield><datafield tag=\"701\" ind1=\" \" ind2=\"1\"><subfield code=\"3\">279354606</subfield><subfield code=\"a\">Farfan-Cabrera</subfield><subfield code=\"b\">Leonardo Israel</subfield><subfield code=\"4\">340</subfield></datafield><datafield tag=\"701\" ind1=\" \" ind2=\"1\"><subfield code=\"3\">11490314X</subfield><subfield code=\"a\">Erdemir</subfield><subfield code=\"b\">Ali</subfield><subfield code=\"4\">340</subfield></datafield><datafield tag=\"801\" ind1=\" \" ind2=\"3\"><subfield code=\"a\">FR</subfield><subfield code=\"b\">Abes</subfield><subfield code=\"c\">20240711</subfield><subfield code=\"g\">AFNOR</subfield></datafield><datafield tag=\"214\" ind1=\" \" ind2=\"0\"><subfield code=\"a\">Amsterdam</subfield><subfield code=\"c\">Elsevier</subfield><subfield code=\"d\">2024</subfield></datafield><datafield tag=\"215\" ind1=\" \" ind2=\" \"><subfield code=\"a\">1 vol. (XI-313 p.)</subfield><subfield code=\"c\">couv. ill. en coul.</subfield><subfield code=\"d\">23 cm</subfield></datafield><datafield tag=\"225\" ind1=\"0\" ind2=\" \"><subfield code=\"a\">Elsevier Series on Tribology and Surface Engineering</subfield></datafield><datafield tag=\"606\" ind1=\" \" ind2=\" \"><subfield code=\"3\">027720055</subfield><subfield code=\"a\">Tribologie (technologie)</subfield><subfield code=\"2\">rameau</subfield></datafield><datafield tag=\"606\" ind1=\" \" ind2=\" \"><subfield code=\"a\">Tribologie (Technologie)</subfield><subfield code=\"2\">lc</subfield></datafield><datafield tag=\"330\" ind1=\" \" ind2=\" \"><subfield code=\"a\">\"Electric vehicle tribology, challenges and opportunities for a sustainable transportation future\" provides practical, comprehensive guidance on a new and increasingly important aera of tribology. Building skills from fundamentals to solution design, this book demonstrates the unique tribological techniques essential to the efficient electrification of transportt systems. Led by professors with a combined three decades in industry and academia, and collecting insights from experts around the world, this book begins with the essential knowledge regarding both electric vehicles and tribology. After outlining the unique tribological needs of EVs, the book then breaks down the components and hardware required. It provides detailed protocols and methods for the testing and improvement of lubricants and materials as well as a dedicated section on modern lubrication specific to EVs. Throughout, it considers the critical question of sustainable tribology and the long-term sustainable options for lubrication and materials for electric vehicles.</subfield><subfield code=\"2\">4e de couverture</subfield></datafield></record>\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e3c9ba34-c696-48f2-bbb3-8948aacd81f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{}\n"
     ]
    }
   ],
   "source": [
    "print(extract_field_values(xml_answer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "861b1f63-fced-4103-802d-c255375203b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'035': '(OCoLC)1449675800', '010': '978-0-443-14074-7 br.', '073': '9780443140747', '100': '20240711d2024 ||||0frey50 ba', '101': 'eng 639-2', '105': 'y ||||001yy', '106': 'r', '181': 'z01 i# xxxe##', '182': 'z01 b', '183': 'z01 nga RDAfrCarrier', '102': 'NL GB US', '200': 'Electric vehicle tribology challenges and opportunities for a sustainable transportation future edited by Leonardo I. Farfan-Cabrera, ... Ali Erdemir, ...', '701': '11490314X Erdemir Ali 340', '801': 'FR Abes 20240711 AFNOR', '214': 'Amsterdam Elsevier 2024', '215': '1 vol. (XI-313 p.) couv. ill. en coul. 23 cm', '225': 'Elsevier Series on Tribology and Surface Engineering', '606': 'Tribologie (Technologie) lc', '330': '\"Electric vehicle tribology, challenges and opportunities for a sustainable transportation future\" provides practical, comprehensive guidance on a new and increasingly important aera of tribology. Building skills from fundamentals to solution design, this book demonstrates the unique tribological techniques essential to the efficient electrification of transportt systems. Led by professors with a combined three decades in industry and academia, and collecting insights from experts around the world, this book begins with the essential knowledge regarding both electric vehicles and tribology. After outlining the unique tribological needs of EVs, the book then breaks down the components and hardware required. It provides detailed protocols and methods for the testing and improvement of lubricants and materials as well as a dedicated section on modern lubrication specific to EVs. Throughout, it considers the critical question of sustainable tribology and the long-term sustainable options for lubrication and materials for electric vehicles. 4e de couverture'}\n"
     ]
    }
   ],
   "source": [
    "print(extract_field_values(xml_target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0d5b9c3c-5edd-4e45-971a-160a8fad72f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_reward(generated_xml: str, target_xml: str) -> float:\n",
    "    try:\n",
    "        gen_fields = extract_field_values(generated_xml)\n",
    "        tgt_fields = extract_field_values(target_xml)\n",
    "    except ET.ParseError:\n",
    "        return 0.0\n",
    "\n",
    "    shared_keys = set(gen_fields) & set(tgt_fields)\n",
    "    if not shared_keys:\n",
    "        return 0.0\n",
    "\n",
    "    total_sim = 0\n",
    "    for key in shared_keys:\n",
    "        sim = SequenceMatcher(None, gen_fields[key], tgt_fields[key]).ratio()\n",
    "        total_sim += sim\n",
    "\n",
    "    return total_sim / len(shared_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "236ca6a2-60b2-4dd8-bfb4-e34ea1a9ba83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_reward(generated_xml=xml_answer, target_xml=xml_target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63aa9561-fb84-48cd-8980-5e9547a08e35",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
