{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "16d969d4-d3a4-4c46-b647-167236c78768",
   "metadata": {},
   "source": [
    "<h3 align=\"center\">Status : <span class=\"badge\"><b>En cours</b></span></h3>\n",
    "\n",
    "<h1 align=\"center\">RL GRPO</h1>\n",
    "\n",
    "---\n",
    "\n",
    "<h1 align=\"center\">Training a small Unimarc reasoner with RL</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "208a0dbc-baee-49c3-9ce6-2522e07c3be6",
   "metadata": {},
   "source": [
    "# Requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1ddac3ec-3e4e-48b8-9a69-4d0fe027dfad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch:\n",
      "PyTorch version is:2.7.0+cu126\n",
      "PyTorch is working with CUDA\n",
      "The GPU model is: Tesla T4\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(\"PyTorch:\")\n",
    "print(\"PyTorch version is:\" + torch.__version__)\n",
    "print(\"PyTorch is working with CUDA\" if torch.cuda.is_available() else \"Error! It is not working correctly\")\n",
    "print(\"The GPU model is: \"+ torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d502c402-8236-4ecb-9654-6e0d7cfa994d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0516e17e-d358-45e2-8ad7-f16c62cd5378",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U --quiet datasets transformers trl huggingface_hub accelerate peft --use-deprecated=legacy-resolver\n",
    "#tensordock: pip install flash-attn tf-keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ec980996-ca3c-4b66-8a88-42200f930e31",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'type': 'user',\n",
       " 'id': '63256c1fa3f07c8e168c0d47',\n",
       " 'name': 'Geraldine',\n",
       " 'fullname': 'GÃ©raldine Geoffroy',\n",
       " 'email': 'grldn.geoffroy@gmail.com',\n",
       " 'emailVerified': True,\n",
       " 'canPay': False,\n",
       " 'periodEnd': 1748735999,\n",
       " 'isPro': False,\n",
       " 'avatarUrl': '/avatars/9cb069e5e90930e818ebe69300cd35d8.svg',\n",
       " 'orgs': [{'type': 'org',\n",
       "   'id': '665f255b175693a15893b7a1',\n",
       "   'name': 'discord-community',\n",
       "   'fullname': 'Hugging Face Discord Community',\n",
       "   'email': 'lunarflu@gmail.com',\n",
       "   'canPay': False,\n",
       "   'periodEnd': 1748735999,\n",
       "   'avatarUrl': 'https://cdn-avatars.huggingface.co/v1/production/uploads/6340651b388c3fa40f9a5bc0/j6Vb_hutYuKRcQgMaDTAt.png',\n",
       "   'roleInOrg': 'read',\n",
       "   'isEnterprise': False}],\n",
       " 'auth': {'type': 'access_token',\n",
       "  'accessToken': {'displayName': 'write_hf_token',\n",
       "   'role': 'write',\n",
       "   'createdAt': '2024-11-08T10:49:12.891Z'}}}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from huggingface_hub import login, whoami\n",
    "\n",
    "login(\n",
    "  token=\"...\" # with write permissions\n",
    ")\n",
    "whoami()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07e21012-2850-4403-a395-c70cdc15465e",
   "metadata": {},
   "source": [
    "# Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "add8b2b4-0c14-4582-98ff-30df58a4ed8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8a178c0d-8bea-43c5-b2b1-fec88e470af2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sliding Window Attention is enabled but not implemented for `sdpa`; unexpected results may be encountered.\n"
     ]
    }
   ],
   "source": [
    "model_name = \"Qwen/Qwen2.5-0.5B-Instruct\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    torch_dtype=\"auto\",\n",
    "    device_map=\"auto\",\n",
    "    #attn_implementation=\"flash_attention_2\"\n",
    ")\n",
    "model.config.sliding_window = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6db1ceba-0d68-4622-8e50-3a37e482344b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Qwen2ForCausalLM(\n",
       "  (model): Qwen2Model(\n",
       "    (embed_tokens): Embedding(151936, 896)\n",
       "    (layers): ModuleList(\n",
       "      (0-23): 24 x Qwen2DecoderLayer(\n",
       "        (self_attn): Qwen2Attention(\n",
       "          (q_proj): Linear(in_features=896, out_features=896, bias=True)\n",
       "          (k_proj): Linear(in_features=896, out_features=128, bias=True)\n",
       "          (v_proj): Linear(in_features=896, out_features=128, bias=True)\n",
       "          (o_proj): Linear(in_features=896, out_features=896, bias=False)\n",
       "        )\n",
       "        (mlp): Qwen2MLP(\n",
       "          (gate_proj): Linear(in_features=896, out_features=4864, bias=False)\n",
       "          (up_proj): Linear(in_features=896, out_features=4864, bias=False)\n",
       "          (down_proj): Linear(in_features=4864, out_features=896, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): Qwen2RMSNorm((896,), eps=1e-06)\n",
       "        (post_attention_layernorm): Qwen2RMSNorm((896,), eps=1e-06)\n",
       "      )\n",
       "    )\n",
       "    (norm): Qwen2RMSNorm((896,), eps=1e-06)\n",
       "    (rotary_emb): Qwen2RotaryEmbedding()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=896, out_features=151936, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.config.sliding_window = None\n",
    "device = \"cuda\" # for GPU usage or \"cpu\" for CPU usage\n",
    "model = model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bca1192b-9713-4f53-9340-c17d0273e6b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !Important\n",
    "tokenizer.padding_side = \"left\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70fdbedb-cdcf-471b-87d1-980842de7d49",
   "metadata": {},
   "source": [
    "## Inspect tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cea2c081-d317-4090-ab34-2c9fd5d6da83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "151665"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b093e0fa-0034-4024-8b51-b685c53de48c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**EOS**\n",
      "EOS token: <|im_end|>\n",
      "- EOS token id: 151645\n",
      "\n",
      "**PAD**\n",
      "PAD token: <|endoftext|>\n",
      "- PAD token id: 151643\n"
     ]
    }
   ],
   "source": [
    "print(f\"**EOS**\\nEOS token: {tokenizer.eos_token}\\n- EOS token id: {tokenizer.eos_token_id}\\n\\n**PAD**\\nPAD token: {tokenizer.pad_token}\\n- PAD token id: {tokenizer.pad_token_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d1097588-e692-4a37-9253-56eefc10537f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[ 1782, 12884,   374,  6303]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1]], device='cuda:0')}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer(\"the sky is blue\", return_tensors=\"pt\").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a232afe9-f43e-405d-b470-78fa8a0f26c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = tokenizer(\"the sky is blue\", return_tensors=\"pt\").to(device).input_ids[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b85a729e-cee3-4264-82dd-90e0e62e78a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'the sky is blue'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "03458069-d640-43d2-b800-f4c1882b7dd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current chat template: {%- if tools %}\n",
      "    {{- '<|im_start|>system\\n' }}\n",
      "    {%- if messages[0]['role'] == 'system' %}\n",
      "        {{- messages[0]['content'] }}\n",
      "    {%- else %}\n",
      "        {{- 'You are Qwen, created by Alibaba Cloud. You are a helpful assistant.' }}\n",
      "    {%- endif %}\n",
      "    {{- \"\\n\\n# Tools\\n\\nYou may call one or more functions to assist with the user query.\\n\\nYou are provided with function signatures within <tools></tools> XML tags:\\n<tools>\" }}\n",
      "    {%- for tool in tools %}\n",
      "        {{- \"\\n\" }}\n",
      "        {{- tool | tojson }}\n",
      "    {%- endfor %}\n",
      "    {{- \"\\n</tools>\\n\\nFor each function call, return a json object with function name and arguments within <tool_call></tool_call> XML tags:\\n<tool_call>\\n{\\\"name\\\": <function-name>, \\\"arguments\\\": <args-json-object>}\\n</tool_call><|im_end|>\\n\" }}\n",
      "{%- else %}\n",
      "    {%- if messages[0]['role'] == 'system' %}\n",
      "        {{- '<|im_start|>system\\n' + messages[0]['content'] + '<|im_end|>\\n' }}\n",
      "    {%- else %}\n",
      "        {{- '<|im_start|>system\\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\\n' }}\n",
      "    {%- endif %}\n",
      "{%- endif %}\n",
      "{%- for message in messages %}\n",
      "    {%- if (message.role == \"user\") or (message.role == \"system\" and not loop.first) or (message.role == \"assistant\" and not message.tool_calls) %}\n",
      "        {{- '<|im_start|>' + message.role + '\\n' + message.content + '<|im_end|>' + '\\n' }}\n",
      "    {%- elif message.role == \"assistant\" %}\n",
      "        {{- '<|im_start|>' + message.role }}\n",
      "        {%- if message.content %}\n",
      "            {{- '\\n' + message.content }}\n",
      "        {%- endif %}\n",
      "        {%- for tool_call in message.tool_calls %}\n",
      "            {%- if tool_call.function is defined %}\n",
      "                {%- set tool_call = tool_call.function %}\n",
      "            {%- endif %}\n",
      "            {{- '\\n<tool_call>\\n{\"name\": \"' }}\n",
      "            {{- tool_call.name }}\n",
      "            {{- '\", \"arguments\": ' }}\n",
      "            {{- tool_call.arguments | tojson }}\n",
      "            {{- '}\\n</tool_call>' }}\n",
      "        {%- endfor %}\n",
      "        {{- '<|im_end|>\\n' }}\n",
      "    {%- elif message.role == \"tool\" %}\n",
      "        {%- if (loop.index0 == 0) or (messages[loop.index0 - 1].role != \"tool\") %}\n",
      "            {{- '<|im_start|>user' }}\n",
      "        {%- endif %}\n",
      "        {{- '\\n<tool_response>\\n' }}\n",
      "        {{- message.content }}\n",
      "        {{- '\\n</tool_response>' }}\n",
      "        {%- if loop.last or (messages[loop.index0 + 1].role != \"tool\") %}\n",
      "            {{- '<|im_end|>\\n' }}\n",
      "        {%- endif %}\n",
      "    {%- endif %}\n",
      "{%- endfor %}\n",
      "{%- if add_generation_prompt %}\n",
      "    {{- '<|im_start|>assistant\\n' }}\n",
      "{%- endif %}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if hasattr(tokenizer, \"chat_template\"):\n",
    "    print(\"Current chat template:\", tokenizer.chat_template)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "650b9be4-19ca-40cc-97af-56bd0f6f570f",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6daf62b3-b325-42ed-8dee-f4e74c704f3c",
   "metadata": {},
   "source": [
    "### Without applying chat templating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "92e78fa0-e0d2-4382-b738-98663777d509",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"<|im_start|>system: You are a helpful assistant<|im_end|><|im_start|>user: complete this sentence 'the sky is blue and '<|im_end|><|im_start|>assistant: \"\n",
    "inputs = tokenizer(prompt, return_tensors=\"pt\").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8db10eed-0a4c-4ce6-866e-65574ec0b73a",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = model.generate(**inputs,\n",
    "                         max_new_tokens = 20,\n",
    "                         use_cache = True,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f2145d5d-c8cf-4019-802e-62d49ec09230",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|im_start|>system: You are a helpful assistant<|im_end|><|im_start|>user: complete this sentence 'the sky is blue and '<|im_end|><|im_start|>assistant:  the sky is blue and the clouds are white.<|im_end|>\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.decode(outputs[0], skip_special_tokens=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55a0c2d9-0160-41be-9d2e-e3bda819782e",
   "metadata": {},
   "source": [
    "### With applying chat templating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "85afd227-55ec-4845-a617-2f5023d8ffff",
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM_PROMPT_0 = \"\"\"\n",
    "You are an expert in Unimarc/XML bibliographic records.\n",
    "Respond in the following format:\n",
    "<reasoning>\n",
    "...\n",
    "</reasoning>\n",
    "<answer>\n",
    "...\n",
    "</answer>\n",
    "\"\"\"\n",
    "\n",
    "SYSTEM_PROMPT_0_SMALL = \"\"\"\n",
    "You are an expert in Unimarc/XML bibliographic records.\n",
    "Respond in the following format:\n",
    "### Resoaning:...\n",
    "### Answer: ...\n",
    "\"\"\"\n",
    "\n",
    "# source: https://arxiv.org/pdf/2503.19470v1\n",
    "SYSTEM_PROMPT_1 = \"\"\"\n",
    "You are a helpful assistant that can solve the given question step by step. \n",
    "Given a question, you need to first think about the reasoning process in\n",
    "the mind and then provide the answer. The reasoning process and\n",
    "answer are enclosed within <think> </think> and <answer> </answer> tags respectively. \n",
    "For example, <think> This is the reasoning process. </think>\n",
    "<answer> The final answer is \\boxed{answer here}\n",
    "</answer>. In the last part of the answer, the final exact answer is enclosed within \\boxed{}\n",
    "with xml format.\n",
    "\"\"\"\n",
    "\n",
    "SYSTEM_PROMPT_2 = (\n",
    "    \"A conversation between User and Assistant. The user asks a question, and the Assistant solves it. The assistant \"\n",
    "    \"first thinks about the reasoning process in the mind and then provides the user with the answer. The reasoning \"\n",
    "    \"process and answer are enclosed within <think> </think> and <answer> </answer> tags, respectively, i.e., \"\n",
    "    \"<think> reasoning process here </think><answer> answer here </answer>\"\n",
    ")\n",
    "\n",
    "SYSTEM_PROMPT_2_SMALL = \"\"\"\n",
    "You are a helpful assistant expert in Unimarc/XML bibliographic records. \n",
    "Given a question, you need to first think about the reasoning process in the mind and then provide the answer. \n",
    "The reasoning process and answer are separated in distincts paragraphs respectively starting with `### Reasoning:` and `### Answer:`.\n",
    "For example, ### Reasoning: This is the reasoning process. \\n ### Answer: The final exact answer is \\boxed{answer here}. \n",
    "In the last part of the answer, the final exact answer is enclosed within \\boxed{} with XML format.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "user_prompt = \"\"\"\n",
    "Generate a valid Unimarc/XML record from these unstructured informations:\n",
    "Title: Electric vehicle tribology\n",
    "Subtitle: Challenges and opportunities for a sustainable transportation future\n",
    "Author: Leonardo I. Farfan-Cabrera, Ali Erdemir\n",
    "Publisher: Elsevier\n",
    "Year: 2024\n",
    "ISBN: 978-0-443-14074-7\n",
    "Language: English\n",
    "Collection/Series: Elsevier Series on Tribology and Surface Engineering\n",
    "Edition: Not specified\n",
    "Material description: 1 vol. (XI-313 p.), couv. ill. en coul., 23 cm\n",
    "Abstract/Notes: \"Electric vehicle tribology, challenges and opportunities for a sustainable transportation future\" provides practical, comprehensive guidance on a new and increasingly important area of tribology. Building skills from fundamentals to solution design, this book demonstrates the unique tribological techniques essential to the efficient electrification of transport systems. Led by professors with a combined three decades in industry and academia, and collecting insights from experts around the world, this book begins with the essential knowledge regarding both electric vehicles and tribology. After outlining the unique tribological needs of EVs, the book then breaks down the components and hardware required. It provides detailed protocols and methods for the testing and improvement of lubricants and materials as well as a dedicated section on modern lubrication specific to EVs. Throughout, it considers the critical question of sustainable tribology and the long-term sustainable options for lubrication and materials for electric vehicles.\n",
    "Source of the abstract/notes: 4e de couverture\n",
    "Table of contents: Not specified\n",
    "Keywords: Tribologie (technologie), Tribologie (Technologie)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1e6303e7-c98a-44ab-a0a9-6b545df643f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "  {\"role\": \"system\", \"content\": SYSTEM_PROMPT_2_SMALL},\n",
    "  {\"role\": \"user\", \"content\": user_prompt},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6400bc7e-061f-4dc5-a465-d8be980a008f",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer.apply_chat_template(\n",
    "    messages,\n",
    "    return_dict=True,\n",
    "    tokenize = True,\n",
    "    add_generation_prompt = True, # Must add for generation\n",
    "    return_tensors = \"pt\",\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "39395bd2-69eb-4689-8cb6-ffafb1de6e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = model.generate(\n",
    "    **inputs,\n",
    "    max_new_tokens = 2048,\n",
    "    use_cache = True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52e940fb-b2f3-4340-8a86-55c0aacc2877",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(tokenizer.decode(outputs[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c037b7da-39f5-4576-80a3-7267775e0408",
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_ids = [\n",
    "   output_ids[len(input_ids):] for input_ids, output_ids in zip(inputs.input_ids, outputs)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "766efb3a-dc8c-4278-b4be-1174ba8aa78f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Reasoning:\n",
      "\n",
      "To generate a valid Unimarc/XML record, we need to follow these steps:\n",
      "\n",
      "1. **Identify the Document Type**: The document type should be `Book`. Since the title, author, publisher, year, ISBN, language, and collection series are provided, we can infer that the document is likely a book.\n",
      "\n",
      "2. **Extract Title**: From the title \"Electric vehicle tribology\", we can extract the following information:\n",
      "   - Book Title: Electric vehicle tribology\n",
      "   - Author: Leonardo I. Farfan-Cabrera, Ali Erdemir\n",
      "   - Publisher: Elsevier\n",
      "   - Year: 2024\n",
      "   - ISBN: 978-0-443-14074-7\n",
      "   - Language: English\n",
      "\n",
      "3. **Extract Publication Information**: From the publication information \"Elsevier\", we can extract the following details:\n",
      "   - Source: 4e de couverture\n",
      "   - Collection: Elsevier Series on Tribology and Surface Engineering\n",
      "   - Edition: Not specified\n",
      "\n",
      "4. **Extract Abstract/Notes**: The abstract/notes section does not contain any explicit text but suggests that there might be additional information that would form part of the abstract or notes. However, since the question asks for an exact answer, we will focus on extracting the most relevant elements.\n",
      "\n",
      "5. **Extract Content Description**: The content description \"1 vol. (XI-313 p.), couv. ill. en coul., 23 cm\" indicates that the book contains one volume, with each page having an illustration (illus.) and a cover (coul.). This structure is typical for books.\n",
      "\n",
      "6. **Extract Keywords**: Keywords such as \"Tribologie (technologie)\", \"Tribologie (Technologie)\" are present in the abstract.\n",
      "\n",
      "### Answer:\n",
      "\n",
      "#### Book Title: Electric vehicle tribology\n",
      "#### Author: Leonardo I. Farfan-Cabrera, Ali Erdemir\n",
      "#### Publisher: Elsevier\n",
      "#### Year: 2024\n",
      "#### ISBN: 978-0-443-14074-7\n",
      "#### Language: English\n",
      "#### Collection/Series: Elsevier Series on Tribology and Surface Engineering\n",
      "#### Edition: Not specified\n",
      "#### Material description: 1 vol. (XI-313 p.), couv. ill. en coul., 23 cm\n",
      "#### Abstract/Notes: \"Electric vehicle tribology, challenges and opportunities for a sustainable transportation future\" provides practical, comprehensive guidance on a new and increasingly important area of tribology. Building skills from fundamentals to solution design, this book demonstrates the unique tribological techniques essential to the efficient electrification of transport systems. Led by professors with a combined three decades in industry and academia, and collecting insights from experts around the world, this book begins with the essential knowledge regarding both electric vehicles and tribology. After outlining the unique tribological needs of EVs, the book then breaks down the components and hardware required. It provides detailed protocols and methods for the testing and improvement of lubricants and materials as well as a dedicated section on modern lubrication specific to EVs. Throughout, it considers the critical question of sustainable tribology and the long-term sustainable options for lubrication and materials for electric vehicles.\"\n",
      "\n",
      "**Final Exact Answer:** \n",
      "\n",
      "```xml\n",
      "<book>\n",
      "    <title>Electric vehicle tribology</title>\n",
      "    <author>Lionel I. Farfan-Cabrera, Ali Erdemir</author>\n",
      "    <publisher>Elsevier</publisher>\n",
      "    <year>2024</year>\n",
      "    <isbn>978-0-443-14074-7</isbn>\n",
      "    <language>English</language>\n",
      "    <collection>Series on Tribology and Surface Engineering</collection>\n",
      "    <edition>Not specified</edition>\n",
      "    <materialDescription>XII-313 pages, couv. ill. en coul., 23 cm</materialDescription>\n",
      "    <abstract>\n",
      "        \"Electric vehicle tribology, challenges and opportunities for a sustainable transportation future\" provides practical, comprehensive guidance on a new and increasingly important area of tribology. Building skills from fundamentals to solution design, this book demonstrates the unique tribological techniques essential to the efficient electrification of transport systems. Led by professors with a combined three decades in industry and academia, and collecting insights from experts around the world, this book begins with the essential knowledge regarding both electric vehicles and tribology. After outlining the unique tribological needs of EVs, the book then breaks down the components and hardware required. It provides detailed protocols and methods for the testing and improvement of lubricants and materials as well as a dedicated section on modern lubrication specific to EVs. Throughout, it considers the critical question of sustainable tribology and the long-term sustainable options for lubrication and materials for electric vehicles.\"\n",
      "    </abstract>\n",
      "</book>\n",
      "```\n",
      "\n",
      "This response has extracted all the necessary information from the given text to create a valid Unimarc/XML record.\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c09f9a3-8e84-4392-a2c1-eacfe5d26b3d",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e481b67f-1e1f-4ec2-b573-a5a8c61ef24c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset, Dataset\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4ea14964-a96a-400b-a2ac-855241bc2ea4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 100%|ââââââââââ| 5129/5129 [00:00<00:00, 10334.49 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['ppn', 'question', 'answer'],\n",
       "    num_rows: 5129\n",
       "})"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = load_dataset(\"Geraldine/Unimarc-iln050-5k\", split=\"train\")\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5ea468bc-a8f0-4143-8196-f98326934d17",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|ââââââââââ| 5129/5129 [00:01<00:00, 3031.70 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['messages'],\n",
       "    num_rows: 5129\n",
       "})"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "system_message = \"\"\"You are a helpful assistant expert in Unimarc/XML bibliographic records. Given bibliographic metadata, generate a valid Unimarc XML record.\"\"\"\n",
    "def create_conversation(row):\n",
    "  return {\n",
    "    \"messages\": [\n",
    "      {\"role\": \"system\", \"content\": system_message},\n",
    "      {\"role\": \"user\", \"content\": row[\"question\"]},\n",
    "      {\"role\": \"assistant\", \"content\": row[\"answer\"] + tokenizer.eos_token} # to avoid infinite generation\n",
    "    ]\n",
    "  }\n",
    "\n",
    "dataset = dataset.map(create_conversation, remove_columns=dataset.features, batched=False)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "91ecd306-d1f3-4e07-9976-2463b69b01a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [{'content': 'You are a helpful assistant expert in Unimarc/XML bibliographic records. Given bibliographic metadata, generate a valid Unimarc XML record.',\n",
       "   'role': 'system'},\n",
       "  {'content': 'Title: Les Jeux olympiques de 1892 Ã  2024\\nSubtitle: une aventure mondiale\\nAuthor: Patrick Clastres\\nAdditional author info: Clastres, Patrick (19..-....)\\nPublisher: Presses universitaires de Rennes\\nPlace of publication: Rennes\\nYear: 2025 (DL 2025)\\nISBN: 978-2-7535-9645-0 (br.)\\nLanguage: French (fre)\\nEdition: Not explicitly stated\\nMaterial description: 1 volume (463 pages); color illustrated cover; 24 cm\\nCollection/Series: Collection \"Histoire\"\\nSeries ISSN: 1255-2364 (Histoire (Rennes))\\nTable of contents: Not provided\\nAbstract/Notes: \\n\"Depuis leur rÃ©invention Ã  Paris et Ã  AthÃ¨nes Ã  la fin du XIXe siÃ¨cle, les Jeux olympiques semblent reflÃ©ter la marche du monde. En fait, ils progressent Ã  leur propre rythme, quadriennal, et ils ne sont jamais quâun interlude posÃ© dans les interstices des Ãtats, des sociÃ©tÃ©s et des Ã©conomies. Faire lâhistoire de leur aventure mondiale nÃ©cessite un prÃ©alable : mettre Ã  distance le roman olympique conÃ§u par le CIO. Tout est parti de lâidÃ©e messianique imaginÃ©e en 1892 par Pierre de Coubertin : contribuer Ã  la paix des nations par la compÃ©tition sportive. Pour dÃ©fendre son idÃ©al contre les ingÃ©rences politiques et commerciales, ce jeune aristocrate parisien a thÃ©orisÃ© la neutralitÃ© de lâÂ« olympisme Â». Une contre-sociÃ©tÃ© dâÃ©chelle mondiale est apparue avec sa capitale et son gouvernement, sa gÃ©ographie et sa diplomatie, son administration et sa lÃ©gislation. Depuis 130 ans, le CIO bataille contre les fÃ©dÃ©rations internationales pour imposer son hÃ©gÃ©monie. Pour apprÃ©hender la diffusion des JO dâAthÃ¨nes en 1896 jusquâÃ  Paris en 2024, et dÃ©crypter lâolympisation des sociÃ©tÃ©s voulue par le CIO, une mÃªme trame est proposÃ©e au lecteur : lâimbrication des enjeux politiques et sportifs, la concurrence des jeux alternatifs, la compÃ©tition entre villes candidates, les portraits des prÃ©sidents successifs du CIO, les cÃ©rÃ©monies dâouverture comme romans nationaux, le programme olympique au prisme des cultures corporelles, le dopage et la corruption, les oppositions Ã  lâorganisation des Jeux, la hiÃ©rarchie sportive des Ãtats, les trajectoires de vie des champions et championnes, les freins et avancÃ©es des droits humains dans le sport.\"\\nSource of the abstract/notes: 4e de couverture (back cover)\\nBibliographic references: pages 419-424; includes index\\nKeywords: Olympisme, Jeux olympiques, Histoire\\nClassification: 796(23a)\\nCountry of publication: France (FR)\\nAdditional identifiers: OCLC number (OCoLC)1513823097\\nLibrary info/source: Abes (FR); AFNOR; Sudoc link: http://www.sudoc.fr/284189537',\n",
       "   'role': 'user'},\n",
       "  {'content': '<record><controlfield tag=\"005\">20250424100757.000</controlfield><leader> cam0 22        450 </leader><controlfield tag=\"001\">284189537</controlfield><controlfield tag=\"003\">http://www.sudoc.fr/284189537</controlfield><datafield tag=\"035\" ind1=\" \" ind2=\" \"><subfield code=\"a\">(OCoLC)1513823097</subfield></datafield><datafield tag=\"010\" ind1=\" \" ind2=\" \"><subfield code=\"a\">978-2-7535-9645-0</subfield><subfield code=\"b\">br.</subfield></datafield><datafield tag=\"073\" ind1=\" \" ind2=\"1\"><subfield code=\"a\">9782753596450</subfield></datafield><datafield tag=\"100\" ind1=\" \" ind2=\" \"><subfield code=\"a\">20250408d2025    m  y0frey50      ba</subfield></datafield><datafield tag=\"101\" ind1=\"0\" ind2=\" \"><subfield code=\"a\">fre</subfield><subfield code=\"2\">639-2</subfield></datafield><datafield tag=\"105\" ind1=\" \" ind2=\" \"><subfield code=\"a\">a   a   001yy</subfield></datafield><datafield tag=\"106\" ind1=\" \" ind2=\" \"><subfield code=\"a\">r</subfield></datafield><datafield tag=\"181\" ind1=\" \" ind2=\" \"><subfield code=\"6\">z01</subfield><subfield code=\"c\">txt</subfield><subfield code=\"2\">rdacontent</subfield></datafield><datafield tag=\"181\" ind1=\" \" ind2=\"1\"><subfield code=\"6\">z01</subfield><subfield code=\"a\">i#</subfield><subfield code=\"b\">xxxe##</subfield></datafield><datafield tag=\"182\" ind1=\" \" ind2=\" \"><subfield code=\"6\">z01</subfield><subfield code=\"c\">n</subfield><subfield code=\"2\">rdamedia</subfield></datafield><datafield tag=\"182\" ind1=\" \" ind2=\"1\"><subfield code=\"6\">z01</subfield><subfield code=\"a\">n</subfield></datafield><datafield tag=\"183\" ind1=\" \" ind2=\"1\"><subfield code=\"6\">z01</subfield><subfield code=\"a\">nga</subfield><subfield code=\"2\">RDAfrCarrier</subfield></datafield><datafield tag=\"102\" ind1=\" \" ind2=\" \"><subfield code=\"a\">FR</subfield></datafield><datafield tag=\"320\" ind1=\" \" ind2=\" \"><subfield code=\"a\">Bilbliogr. p. 419-424. Index</subfield></datafield><datafield tag=\"200\" ind1=\"1\" ind2=\" \"><subfield code=\"a\">\\x98Les \\x9cJeux olympiques de 1892 Ã  2024</subfield><subfield code=\"e\">une aventure mondiale</subfield><subfield code=\"f\">Patrick Clastres</subfield></datafield><datafield tag=\"700\" ind1=\" \" ind2=\"1\"><subfield code=\"3\">080640443</subfield><subfield code=\"a\">Clastres</subfield><subfield code=\"b\">Patrick</subfield><subfield code=\"f\">19..-....</subfield><subfield code=\"4\">070</subfield></datafield><datafield tag=\"801\" ind1=\" \" ind2=\"3\"><subfield code=\"a\">FR</subfield><subfield code=\"b\">Abes</subfield><subfield code=\"c\">20250424</subfield><subfield code=\"g\">AFNOR</subfield></datafield><datafield tag=\"214\" ind1=\" \" ind2=\"0\"><subfield code=\"a\">Rennes</subfield><subfield code=\"c\">Presses universitaires de Rennes</subfield><subfield code=\"d\">DL 2025</subfield></datafield><datafield tag=\"215\" ind1=\" \" ind2=\" \"><subfield code=\"a\">1 vol. (463 p.)</subfield><subfield code=\"c\">couv. ill. en coul.</subfield><subfield code=\"d\">24 cm</subfield></datafield><datafield tag=\"225\" ind1=\"0\" ind2=\" \"><subfield code=\"a\">Collection \"Histoire\"</subfield></datafield><datafield tag=\"410\" ind1=\" \" ind2=\"|\"><subfield code=\"0\">003326195</subfield><subfield code=\"t\">Histoire (Rennes)</subfield><subfield code=\"x\">1255-2364</subfield></datafield><datafield tag=\"606\" ind1=\" \" ind2=\" \"><subfield code=\"3\">027389162</subfield><subfield code=\"a\">Olympisme</subfield><subfield code=\"3\">02726470X</subfield><subfield code=\"x\">Histoire</subfield><subfield code=\"2\">rameau</subfield></datafield><datafield tag=\"606\" ind1=\" \" ind2=\" \"><subfield code=\"3\">027325652</subfield><subfield code=\"a\">Jeux olympiques</subfield><subfield code=\"3\">02726470X</subfield><subfield code=\"x\">Histoire</subfield><subfield code=\"2\">rameau</subfield></datafield><datafield tag=\"676\" ind1=\" \" ind2=\" \"><subfield code=\"a\">796</subfield><subfield code=\"v\">23a</subfield></datafield><datafield tag=\"330\" ind1=\" \" ind2=\" \"><subfield code=\"a\">\"Depuis leur rÃ©invention Ã  Paris et Ã  AthÃ¨nes Ã  la fin du XIXe siÃ¨cle, les Jeux olympiques semblent reflÃ©ter la marche du monde. En fait, ils progressent Ã  leur propre rythme, quadriennal, et ils ne sont jamais quâun interlude posÃ© dans les interstices des Ãtats, des sociÃ©tÃ©s et des Ã©conomies. Faire lâhistoire de leur aventure mondiale nÃ©cessite un prÃ©alable : mettre Ã  distance le roman olympique conÃ§u par le CIO. Tout est parti de lâidÃ©e messianique imaginÃ©e en 1892 par Pierre de Coubertin : contribuer Ã  la paix des nations par la compÃ©tition sportive. Pour dÃ©fendre son idÃ©al contre les ingÃ©rences politiques et commerciales, ce jeune aristocrate parisien a thÃ©orisÃ© la neutralitÃ© de lâÂ« olympisme Â». Une contre-sociÃ©tÃ© dâÃ©chelle mondiale est apparue avec sa capitale et son gouvernement, sa gÃ©ographie et sa diplomatie, son administration et sa lÃ©gislation. Depuis 130 ans, le CIO bataille contre les fÃ©dÃ©rations internationales pour imposer son hÃ©gÃ©monie. Pour apprÃ©hender la diffusion des JO dâAthÃ¨nes en 1896 jusquâÃ  Paris en 2024, et dÃ©crypter lâolympisation des sociÃ©tÃ©s voulue par le CIO, une mÃªme trame est proposÃ©e au lecteur : lâimbrication des enjeux politiques et sportifs, la concurrence des jeux alternatifs, la compÃ©tition entre villes candidates, les portraits des prÃ©sidents successifs du CIO, les cÃ©rÃ©monies dâouverture comme romans nationaux, le programme olympique au prisme des cultures corporelles, le dopage et la corruption, les oppositions Ã  lâorganisation des Jeux, la hiÃ©rarchie sportive des Ãtats, les trajectoires de vie des champions et championnes, les freins et avancÃ©es des droits humains dans le sport.\"</subfield><subfield code=\"2\">4e de couverture</subfield></datafield></record><|im_end|>',\n",
       "   'role': 'assistant'}]}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caf4114f-f988-4072-9c53-22b0e8f66d95",
   "metadata": {},
   "source": [
    "# Lora SFT fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "dc88791e-c2ce-4b6b-a9ac-bad76166b58e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM, TrainingArguments\n",
    "from trl import SFTTrainer\n",
    "from peft import LoraConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3d642c00-3c85-4de6-80f6-be5544cf3985",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "model\n",
      "model.embed_tokens\n",
      "model.layers\n",
      "model.layers.0\n",
      "model.layers.0.self_attn\n",
      "model.layers.0.self_attn.q_proj\n",
      "model.layers.0.self_attn.k_proj\n",
      "model.layers.0.self_attn.v_proj\n",
      "model.layers.0.self_attn.o_proj\n",
      "model.layers.0.mlp\n",
      "model.layers.0.mlp.gate_proj\n",
      "model.layers.0.mlp.up_proj\n",
      "model.layers.0.mlp.down_proj\n",
      "model.layers.0.mlp.act_fn\n",
      "model.layers.0.input_layernorm\n",
      "model.layers.0.post_attention_layernorm\n",
      "model.layers.1\n",
      "model.layers.1.self_attn\n",
      "model.layers.1.self_attn.q_proj\n",
      "model.layers.1.self_attn.k_proj\n",
      "model.layers.1.self_attn.v_proj\n",
      "model.layers.1.self_attn.o_proj\n",
      "model.layers.1.mlp\n",
      "model.layers.1.mlp.gate_proj\n",
      "model.layers.1.mlp.up_proj\n",
      "model.layers.1.mlp.down_proj\n",
      "model.layers.1.mlp.act_fn\n",
      "model.layers.1.input_layernorm\n",
      "model.layers.1.post_attention_layernorm\n",
      "model.layers.2\n",
      "model.layers.2.self_attn\n",
      "model.layers.2.self_attn.q_proj\n",
      "model.layers.2.self_attn.k_proj\n",
      "model.layers.2.self_attn.v_proj\n",
      "model.layers.2.self_attn.o_proj\n",
      "model.layers.2.mlp\n",
      "model.layers.2.mlp.gate_proj\n",
      "model.layers.2.mlp.up_proj\n",
      "model.layers.2.mlp.down_proj\n",
      "model.layers.2.mlp.act_fn\n",
      "model.layers.2.input_layernorm\n",
      "model.layers.2.post_attention_layernorm\n",
      "model.layers.3\n",
      "model.layers.3.self_attn\n",
      "model.layers.3.self_attn.q_proj\n",
      "model.layers.3.self_attn.k_proj\n",
      "model.layers.3.self_attn.v_proj\n",
      "model.layers.3.self_attn.o_proj\n",
      "model.layers.3.mlp\n",
      "model.layers.3.mlp.gate_proj\n",
      "model.layers.3.mlp.up_proj\n",
      "model.layers.3.mlp.down_proj\n",
      "model.layers.3.mlp.act_fn\n",
      "model.layers.3.input_layernorm\n",
      "model.layers.3.post_attention_layernorm\n",
      "model.layers.4\n",
      "model.layers.4.self_attn\n",
      "model.layers.4.self_attn.q_proj\n",
      "model.layers.4.self_attn.k_proj\n",
      "model.layers.4.self_attn.v_proj\n",
      "model.layers.4.self_attn.o_proj\n",
      "model.layers.4.mlp\n",
      "model.layers.4.mlp.gate_proj\n",
      "model.layers.4.mlp.up_proj\n",
      "model.layers.4.mlp.down_proj\n",
      "model.layers.4.mlp.act_fn\n",
      "model.layers.4.input_layernorm\n",
      "model.layers.4.post_attention_layernorm\n",
      "model.layers.5\n",
      "model.layers.5.self_attn\n",
      "model.layers.5.self_attn.q_proj\n",
      "model.layers.5.self_attn.k_proj\n",
      "model.layers.5.self_attn.v_proj\n",
      "model.layers.5.self_attn.o_proj\n",
      "model.layers.5.mlp\n",
      "model.layers.5.mlp.gate_proj\n",
      "model.layers.5.mlp.up_proj\n",
      "model.layers.5.mlp.down_proj\n",
      "model.layers.5.mlp.act_fn\n",
      "model.layers.5.input_layernorm\n",
      "model.layers.5.post_attention_layernorm\n",
      "model.layers.6\n",
      "model.layers.6.self_attn\n",
      "model.layers.6.self_attn.q_proj\n",
      "model.layers.6.self_attn.k_proj\n",
      "model.layers.6.self_attn.v_proj\n",
      "model.layers.6.self_attn.o_proj\n",
      "model.layers.6.mlp\n",
      "model.layers.6.mlp.gate_proj\n",
      "model.layers.6.mlp.up_proj\n",
      "model.layers.6.mlp.down_proj\n",
      "model.layers.6.mlp.act_fn\n",
      "model.layers.6.input_layernorm\n",
      "model.layers.6.post_attention_layernorm\n",
      "model.layers.7\n",
      "model.layers.7.self_attn\n",
      "model.layers.7.self_attn.q_proj\n",
      "model.layers.7.self_attn.k_proj\n",
      "model.layers.7.self_attn.v_proj\n",
      "model.layers.7.self_attn.o_proj\n",
      "model.layers.7.mlp\n",
      "model.layers.7.mlp.gate_proj\n",
      "model.layers.7.mlp.up_proj\n",
      "model.layers.7.mlp.down_proj\n",
      "model.layers.7.mlp.act_fn\n",
      "model.layers.7.input_layernorm\n",
      "model.layers.7.post_attention_layernorm\n",
      "model.layers.8\n",
      "model.layers.8.self_attn\n",
      "model.layers.8.self_attn.q_proj\n",
      "model.layers.8.self_attn.k_proj\n",
      "model.layers.8.self_attn.v_proj\n",
      "model.layers.8.self_attn.o_proj\n",
      "model.layers.8.mlp\n",
      "model.layers.8.mlp.gate_proj\n",
      "model.layers.8.mlp.up_proj\n",
      "model.layers.8.mlp.down_proj\n",
      "model.layers.8.mlp.act_fn\n",
      "model.layers.8.input_layernorm\n",
      "model.layers.8.post_attention_layernorm\n",
      "model.layers.9\n",
      "model.layers.9.self_attn\n",
      "model.layers.9.self_attn.q_proj\n",
      "model.layers.9.self_attn.k_proj\n",
      "model.layers.9.self_attn.v_proj\n",
      "model.layers.9.self_attn.o_proj\n",
      "model.layers.9.mlp\n",
      "model.layers.9.mlp.gate_proj\n",
      "model.layers.9.mlp.up_proj\n",
      "model.layers.9.mlp.down_proj\n",
      "model.layers.9.mlp.act_fn\n",
      "model.layers.9.input_layernorm\n",
      "model.layers.9.post_attention_layernorm\n",
      "model.layers.10\n",
      "model.layers.10.self_attn\n",
      "model.layers.10.self_attn.q_proj\n",
      "model.layers.10.self_attn.k_proj\n",
      "model.layers.10.self_attn.v_proj\n",
      "model.layers.10.self_attn.o_proj\n",
      "model.layers.10.mlp\n",
      "model.layers.10.mlp.gate_proj\n",
      "model.layers.10.mlp.up_proj\n",
      "model.layers.10.mlp.down_proj\n",
      "model.layers.10.mlp.act_fn\n",
      "model.layers.10.input_layernorm\n",
      "model.layers.10.post_attention_layernorm\n",
      "model.layers.11\n",
      "model.layers.11.self_attn\n",
      "model.layers.11.self_attn.q_proj\n",
      "model.layers.11.self_attn.k_proj\n",
      "model.layers.11.self_attn.v_proj\n",
      "model.layers.11.self_attn.o_proj\n",
      "model.layers.11.mlp\n",
      "model.layers.11.mlp.gate_proj\n",
      "model.layers.11.mlp.up_proj\n",
      "model.layers.11.mlp.down_proj\n",
      "model.layers.11.mlp.act_fn\n",
      "model.layers.11.input_layernorm\n",
      "model.layers.11.post_attention_layernorm\n",
      "model.layers.12\n",
      "model.layers.12.self_attn\n",
      "model.layers.12.self_attn.q_proj\n",
      "model.layers.12.self_attn.k_proj\n",
      "model.layers.12.self_attn.v_proj\n",
      "model.layers.12.self_attn.o_proj\n",
      "model.layers.12.mlp\n",
      "model.layers.12.mlp.gate_proj\n",
      "model.layers.12.mlp.up_proj\n",
      "model.layers.12.mlp.down_proj\n",
      "model.layers.12.mlp.act_fn\n",
      "model.layers.12.input_layernorm\n",
      "model.layers.12.post_attention_layernorm\n",
      "model.layers.13\n",
      "model.layers.13.self_attn\n",
      "model.layers.13.self_attn.q_proj\n",
      "model.layers.13.self_attn.k_proj\n",
      "model.layers.13.self_attn.v_proj\n",
      "model.layers.13.self_attn.o_proj\n",
      "model.layers.13.mlp\n",
      "model.layers.13.mlp.gate_proj\n",
      "model.layers.13.mlp.up_proj\n",
      "model.layers.13.mlp.down_proj\n",
      "model.layers.13.mlp.act_fn\n",
      "model.layers.13.input_layernorm\n",
      "model.layers.13.post_attention_layernorm\n",
      "model.layers.14\n",
      "model.layers.14.self_attn\n",
      "model.layers.14.self_attn.q_proj\n",
      "model.layers.14.self_attn.k_proj\n",
      "model.layers.14.self_attn.v_proj\n",
      "model.layers.14.self_attn.o_proj\n",
      "model.layers.14.mlp\n",
      "model.layers.14.mlp.gate_proj\n",
      "model.layers.14.mlp.up_proj\n",
      "model.layers.14.mlp.down_proj\n",
      "model.layers.14.mlp.act_fn\n",
      "model.layers.14.input_layernorm\n",
      "model.layers.14.post_attention_layernorm\n",
      "model.layers.15\n",
      "model.layers.15.self_attn\n",
      "model.layers.15.self_attn.q_proj\n",
      "model.layers.15.self_attn.k_proj\n",
      "model.layers.15.self_attn.v_proj\n",
      "model.layers.15.self_attn.o_proj\n",
      "model.layers.15.mlp\n",
      "model.layers.15.mlp.gate_proj\n",
      "model.layers.15.mlp.up_proj\n",
      "model.layers.15.mlp.down_proj\n",
      "model.layers.15.mlp.act_fn\n",
      "model.layers.15.input_layernorm\n",
      "model.layers.15.post_attention_layernorm\n",
      "model.layers.16\n",
      "model.layers.16.self_attn\n",
      "model.layers.16.self_attn.q_proj\n",
      "model.layers.16.self_attn.k_proj\n",
      "model.layers.16.self_attn.v_proj\n",
      "model.layers.16.self_attn.o_proj\n",
      "model.layers.16.mlp\n",
      "model.layers.16.mlp.gate_proj\n",
      "model.layers.16.mlp.up_proj\n",
      "model.layers.16.mlp.down_proj\n",
      "model.layers.16.mlp.act_fn\n",
      "model.layers.16.input_layernorm\n",
      "model.layers.16.post_attention_layernorm\n",
      "model.layers.17\n",
      "model.layers.17.self_attn\n",
      "model.layers.17.self_attn.q_proj\n",
      "model.layers.17.self_attn.k_proj\n",
      "model.layers.17.self_attn.v_proj\n",
      "model.layers.17.self_attn.o_proj\n",
      "model.layers.17.mlp\n",
      "model.layers.17.mlp.gate_proj\n",
      "model.layers.17.mlp.up_proj\n",
      "model.layers.17.mlp.down_proj\n",
      "model.layers.17.mlp.act_fn\n",
      "model.layers.17.input_layernorm\n",
      "model.layers.17.post_attention_layernorm\n",
      "model.layers.18\n",
      "model.layers.18.self_attn\n",
      "model.layers.18.self_attn.q_proj\n",
      "model.layers.18.self_attn.k_proj\n",
      "model.layers.18.self_attn.v_proj\n",
      "model.layers.18.self_attn.o_proj\n",
      "model.layers.18.mlp\n",
      "model.layers.18.mlp.gate_proj\n",
      "model.layers.18.mlp.up_proj\n",
      "model.layers.18.mlp.down_proj\n",
      "model.layers.18.mlp.act_fn\n",
      "model.layers.18.input_layernorm\n",
      "model.layers.18.post_attention_layernorm\n",
      "model.layers.19\n",
      "model.layers.19.self_attn\n",
      "model.layers.19.self_attn.q_proj\n",
      "model.layers.19.self_attn.k_proj\n",
      "model.layers.19.self_attn.v_proj\n",
      "model.layers.19.self_attn.o_proj\n",
      "model.layers.19.mlp\n",
      "model.layers.19.mlp.gate_proj\n",
      "model.layers.19.mlp.up_proj\n",
      "model.layers.19.mlp.down_proj\n",
      "model.layers.19.mlp.act_fn\n",
      "model.layers.19.input_layernorm\n",
      "model.layers.19.post_attention_layernorm\n",
      "model.layers.20\n",
      "model.layers.20.self_attn\n",
      "model.layers.20.self_attn.q_proj\n",
      "model.layers.20.self_attn.k_proj\n",
      "model.layers.20.self_attn.v_proj\n",
      "model.layers.20.self_attn.o_proj\n",
      "model.layers.20.mlp\n",
      "model.layers.20.mlp.gate_proj\n",
      "model.layers.20.mlp.up_proj\n",
      "model.layers.20.mlp.down_proj\n",
      "model.layers.20.mlp.act_fn\n",
      "model.layers.20.input_layernorm\n",
      "model.layers.20.post_attention_layernorm\n",
      "model.layers.21\n",
      "model.layers.21.self_attn\n",
      "model.layers.21.self_attn.q_proj\n",
      "model.layers.21.self_attn.k_proj\n",
      "model.layers.21.self_attn.v_proj\n",
      "model.layers.21.self_attn.o_proj\n",
      "model.layers.21.mlp\n",
      "model.layers.21.mlp.gate_proj\n",
      "model.layers.21.mlp.up_proj\n",
      "model.layers.21.mlp.down_proj\n",
      "model.layers.21.mlp.act_fn\n",
      "model.layers.21.input_layernorm\n",
      "model.layers.21.post_attention_layernorm\n",
      "model.layers.22\n",
      "model.layers.22.self_attn\n",
      "model.layers.22.self_attn.q_proj\n",
      "model.layers.22.self_attn.k_proj\n",
      "model.layers.22.self_attn.v_proj\n",
      "model.layers.22.self_attn.o_proj\n",
      "model.layers.22.mlp\n",
      "model.layers.22.mlp.gate_proj\n",
      "model.layers.22.mlp.up_proj\n",
      "model.layers.22.mlp.down_proj\n",
      "model.layers.22.mlp.act_fn\n",
      "model.layers.22.input_layernorm\n",
      "model.layers.22.post_attention_layernorm\n",
      "model.layers.23\n",
      "model.layers.23.self_attn\n",
      "model.layers.23.self_attn.q_proj\n",
      "model.layers.23.self_attn.k_proj\n",
      "model.layers.23.self_attn.v_proj\n",
      "model.layers.23.self_attn.o_proj\n",
      "model.layers.23.mlp\n",
      "model.layers.23.mlp.gate_proj\n",
      "model.layers.23.mlp.up_proj\n",
      "model.layers.23.mlp.down_proj\n",
      "model.layers.23.mlp.act_fn\n",
      "model.layers.23.input_layernorm\n",
      "model.layers.23.post_attention_layernorm\n",
      "model.norm\n",
      "model.rotary_emb\n",
      "lm_head\n"
     ]
    }
   ],
   "source": [
    "for name, module in model.named_modules():\n",
    "    print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85c64bfa-cc45-4b85-ab32-4da49ebb3fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "help(SFTTrainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b8068044-64c7-4b9e-b8d9-d850bfd6a938",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/site-packages/peft/mapping_func.py:73: UserWarning: You are trying to modify a model with PEFT for a second time. If you want to reload the model with a different config, make sure to call `.unload()` before.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/site-packages/peft/tuners/tuners_utils.py:167: UserWarning: Already found a `peft_config` attribute in the model. This will lead to having multiple adapters in the model. Make sure to know what you are doing!\n",
      "  warnings.warn(\n",
      "Applying chat template to train dataset: 100%|ââââââââââ| 5129/5129 [00:02<00:00, 1745.09 examples/s]\n",
      "Tokenizing train dataset: 100%|ââââââââââ| 5129/5129 [02:34<00:00, 33.12 examples/s]\n",
      "Truncating train dataset: 100%|ââââââââââ| 5129/5129 [00:02<00:00, 1934.43 examples/s]\n",
      "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
     ]
    }
   ],
   "source": [
    "# ---- 3. Define LoRA config ----\n",
    "peft_config = LoraConfig(\n",
    "    r=8,\n",
    "    lora_alpha=32,\n",
    "    lora_dropout=0.1,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\",\n",
    "    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\"] # may vary based on model, check with `model.named_modules()` in previous cell\n",
    ")\n",
    "\n",
    "# ---- 4. Training args ----\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./sft_lora_output\",\n",
    "    per_device_train_batch_size=4,\n",
    "    gradient_accumulation_steps=4,\n",
    "    logging_steps=10,\n",
    "    save_strategy=\"epoch\",\n",
    "    num_train_epochs=3,\n",
    "    learning_rate=2e-4,\n",
    "    fp16=True,\n",
    "    report_to=\"none\"\n",
    ")\n",
    "\n",
    "# ---- 5. Launch training ----\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    train_dataset=dataset,\n",
    "    peft_config=peft_config,\n",
    "    args=training_args\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "06d96808-643e-4eb0-a248-47f14700e3fd",
   "metadata": {},
   "outputs": [
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 2.32 GiB. GPU 0 has a total capacity of 14.57 GiB of which 292.75 MiB is free. Process 3526258 has 14.28 GiB memory in use. Of the allocated memory 11.58 GiB is allocated by PyTorch, and 2.56 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mOutOfMemoryError\u001b[39m                          Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[32]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/transformers/trainer.py:2245\u001b[39m, in \u001b[36mTrainer.train\u001b[39m\u001b[34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[39m\n\u001b[32m   2243\u001b[39m         hf_hub_utils.enable_progress_bars()\n\u001b[32m   2244\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2245\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2246\u001b[39m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[43m=\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2247\u001b[39m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2248\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2249\u001b[39m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m=\u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2250\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/transformers/trainer.py:2560\u001b[39m, in \u001b[36mTrainer._inner_training_loop\u001b[39m\u001b[34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[39m\n\u001b[32m   2553\u001b[39m context = (\n\u001b[32m   2554\u001b[39m     functools.partial(\u001b[38;5;28mself\u001b[39m.accelerator.no_sync, model=model)\n\u001b[32m   2555\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m i != \u001b[38;5;28mlen\u001b[39m(batch_samples) - \u001b[32m1\u001b[39m\n\u001b[32m   2556\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.accelerator.distributed_type != DistributedType.DEEPSPEED\n\u001b[32m   2557\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m contextlib.nullcontext\n\u001b[32m   2558\u001b[39m )\n\u001b[32m   2559\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m context():\n\u001b[32m-> \u001b[39m\u001b[32m2560\u001b[39m     tr_loss_step = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_items_in_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2562\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m   2563\u001b[39m     args.logging_nan_inf_filter\n\u001b[32m   2564\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_xla_available()\n\u001b[32m   2565\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m (torch.isnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m torch.isinf(tr_loss_step))\n\u001b[32m   2566\u001b[39m ):\n\u001b[32m   2567\u001b[39m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[32m   2568\u001b[39m     tr_loss = tr_loss + tr_loss / (\u001b[32m1\u001b[39m + \u001b[38;5;28mself\u001b[39m.state.global_step - \u001b[38;5;28mself\u001b[39m._globalstep_last_logged)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/transformers/trainer.py:3736\u001b[39m, in \u001b[36mTrainer.training_step\u001b[39m\u001b[34m(self, model, inputs, num_items_in_batch)\u001b[39m\n\u001b[32m   3733\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m loss_mb.reduce_mean().detach().to(\u001b[38;5;28mself\u001b[39m.args.device)\n\u001b[32m   3735\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m.compute_loss_context_manager():\n\u001b[32m-> \u001b[39m\u001b[32m3736\u001b[39m     loss = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcompute_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_items_in_batch\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_items_in_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3738\u001b[39m \u001b[38;5;28;01mdel\u001b[39;00m inputs\n\u001b[32m   3739\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m   3740\u001b[39m     \u001b[38;5;28mself\u001b[39m.args.torch_empty_cache_steps \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   3741\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.state.global_step % \u001b[38;5;28mself\u001b[39m.args.torch_empty_cache_steps == \u001b[32m0\u001b[39m\n\u001b[32m   3742\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/trl/trainer/sft_trainer.py:672\u001b[39m, in \u001b[36mSFTTrainer.compute_loss\u001b[39m\u001b[34m(self, model, inputs, return_outputs, num_items_in_batch)\u001b[39m\n\u001b[32m    670\u001b[39m \u001b[38;5;66;03m# Compute token accuracy if we have labels and if the model is not using Liger (no logits)\u001b[39;00m\n\u001b[32m    671\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mlabels\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m inputs \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.args.use_liger_kernel:\n\u001b[32m--> \u001b[39m\u001b[32m672\u001b[39m     shift_logits = \u001b[43moutputs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlogits\u001b[49m\u001b[43m[\u001b[49m\u001b[43m.\u001b[49m\u001b[43m.\u001b[49m\u001b[43m.\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m-\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcontiguous\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    673\u001b[39m     shift_labels = inputs[\u001b[33m\"\u001b[39m\u001b[33mlabels\u001b[39m\u001b[33m\"\u001b[39m][..., \u001b[32m1\u001b[39m:].contiguous()\n\u001b[32m    675\u001b[39m     \u001b[38;5;66;03m# Get predictions\u001b[39;00m\n",
      "\u001b[31mOutOfMemoryError\u001b[39m: CUDA out of memory. Tried to allocate 2.32 GiB. GPU 0 has a total capacity of 14.57 GiB of which 292.75 MiB is free. Process 3526258 has 14.28 GiB memory in use. Of the allocated memory 11.58 GiB is allocated by PyTorch, and 2.56 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "189f49f3-9a9d-4bfd-b308-d81703bb075a",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d6a9d9ba-a490-4330-8776-48cdaea30556",
   "metadata": {},
   "outputs": [],
   "source": [
    "peft_model_id = \"sft_lora_output\"\n",
    "tr_model_id = \"Qwen/Qwen2.5-0.5B-Instruct\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0b1ac408-e785-4745-a6fa-43b07569ba9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import AutoPeftModelForCausalLM, PeftModel\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(tr_model_id, trust_remote_code=True, torch_dtype=torch.float16,\n",
    "     low_cpu_mem_usage=True,)\n",
    "model = PeftModel.from_pretrained(model, peft_model_id)\n",
    "merged_model = model.merge_and_unload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "152ce199-d3cb-440a-88e0-5575828cb9b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "model.safetensors: 100%|ââââââââââ| 988M/988M [00:52<00:00, 18.8MB/s] \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/Geraldine/FineQwen2.5-0.5B-Instruct-sft-unimarc/commit/4bb9dfb8545d1dc0db42e35a8222c3f92022d08f', commit_message='Upload Qwen2ForCausalLM', commit_description='', oid='4bb9dfb8545d1dc0db42e35a8222c3f92022d08f', pr_url=None, repo_url=RepoUrl('https://huggingface.co/Geraldine/FineQwen2.5-0.5B-Instruct-sft-unimarc', endpoint='https://huggingface.co', repo_type='model', repo_id='Geraldine/FineQwen2.5-0.5B-Instruct-sft-unimarc'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_model.push_to_hub(f\"Geraldine/FineQwen2.5-0.5B-Instruct-sft-unimarc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e9e6a07d-58d1-4a19-8ba4-b636bd0cd4fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tokenizer.json: 100%|ââââââââââ| 11.4M/11.4M [00:00<00:00, 25.0MB/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/Geraldine/FineQwen2.5-0.5B-Instruct-sft-unimarc/commit/9165c226214411fc1714214a4681f425d8ee742e', commit_message='Upload tokenizer', commit_description='', oid='9165c226214411fc1714214a4681f425d8ee742e', pr_url=None, repo_url=RepoUrl('https://huggingface.co/Geraldine/FineQwen2.5-0.5B-Instruct-sft-unimarc', endpoint='https://huggingface.co', repo_type='model', repo_id='Geraldine/FineQwen2.5-0.5B-Instruct-sft-unimarc'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(peft_model_id)\n",
    "tokenizer.push_to_hub(f\"Geraldine/FineQwen2.5-0.5B-Instruct-sft-unimarc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6507649c-f75a-467e-8b11-23306a07c468",
   "metadata": {},
   "source": [
    "## Inference with Lora fine-tuned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "07ffa8d4-51bf-4f21-8913-e0ac9c57932d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"Geraldine/FineQwen2.5-0.5B-Instruct-sft-unimarc\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    torch_dtype=\"auto\",\n",
    "    device_map=\"auto\",\n",
    "    #attn_implementation=\"flash_attention_2\"\n",
    ")\n",
    "model.config.sliding_window = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "49cb262f-5330-4096-ad5f-dfea4a9258c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Qwen2ForCausalLM(\n",
       "  (model): Qwen2Model(\n",
       "    (embed_tokens): Embedding(151936, 896)\n",
       "    (layers): ModuleList(\n",
       "      (0-23): 24 x Qwen2DecoderLayer(\n",
       "        (self_attn): Qwen2Attention(\n",
       "          (q_proj): Linear(in_features=896, out_features=896, bias=True)\n",
       "          (k_proj): Linear(in_features=896, out_features=128, bias=True)\n",
       "          (v_proj): Linear(in_features=896, out_features=128, bias=True)\n",
       "          (o_proj): Linear(in_features=896, out_features=896, bias=False)\n",
       "        )\n",
       "        (mlp): Qwen2MLP(\n",
       "          (gate_proj): Linear(in_features=896, out_features=4864, bias=False)\n",
       "          (up_proj): Linear(in_features=896, out_features=4864, bias=False)\n",
       "          (down_proj): Linear(in_features=4864, out_features=896, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): Qwen2RMSNorm((896,), eps=1e-06)\n",
       "        (post_attention_layernorm): Qwen2RMSNorm((896,), eps=1e-06)\n",
       "      )\n",
       "    )\n",
       "    (norm): Qwen2RMSNorm((896,), eps=1e-06)\n",
       "    (rotary_emb): Qwen2RotaryEmbedding()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=896, out_features=151936, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.config.sliding_window = None\n",
    "device = \"cuda\" # for GPU usage or \"cpu\" for CPU usage\n",
    "model = model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "31e94c77-00a0-4d74-87df-a46b5d0e4dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "  {\"role\": \"system\", \"content\": SYSTEM_PROMPT_0_SMALL},\n",
    "  {\"role\": \"user\", \"content\": user_prompt},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e3952799-50dd-4942-8045-97562e2a9942",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer.apply_chat_template(\n",
    "    messages,\n",
    "    return_dict=True,\n",
    "    tokenize = True,\n",
    "    add_generation_prompt = True, # Must add for generation\n",
    "    return_tensors = \"pt\",\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9e073957-a07b-4ab7-8c97-c4cc1c1d6ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = model.generate(\n",
    "    **inputs,\n",
    "    max_new_tokens = 4096,\n",
    "    repetition_penalty=1.2,\n",
    "    use_cache = True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e06875c6-048b-4a1f-9ac0-a69ff97eb1cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_ids = [\n",
    "   output_ids[len(input_ids):] for input_ids, output_ids in zip(inputs.input_ids, outputs)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ecf4592d-37bd-4743-ad64-1b2e190f2382",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<record><controlfield tag=\"005\">20250314162408.000</controlfield><leader> cam0 22        450 </leader><controlfield tag=\"001\">27698450X</controlfield><controlfield tag=\"003\">http://www.sudoc.fr/27698450X</controlfield><datafield tag=\"035\" ind1=\" \" ind2=\" \"><subfield code=\"a\">(OCoLC)1423210952</subfield></datafield><datafield tag=\"010\" ind1=\" \" ind2=\" \"><subfield code=\"a\">978-0-443-14074-7</subfield><subfield code=\"b\">br.</subfield></datafield><datafield tag=\"073\" ind1=\" \" ind2=\"1\"><subfield code=\"a\">9780443140747</subfield></datafield><datafield tag=\"100\" ind1=\" \" ind2=\" \"><subfield code=\"a\">20240411h20242024k  y0frey50      ba</subfield></datafield><datafield tag=\"101\" ind1=\"0\" ind2=\" \"><subfield code=\"a\">eng</subfield><subfield code=\"d\">eng</subfield><subfield code=\"f\">eng</subfield><subfield code=\"g\">eng</subfield><subfield code=\"h\">eng</subfield><subfield code=\"i\">eng</subfield><subfield code=\"n\">eng</subfield><subfield code=\"z\">eng</subfield></datafield><datafield tag=\"105\" ind1=\" \" ind2=\" \"><subfield code=\"a\">a   ||||001yy</subfield></datafield><datafield tag=\"106\" ind1=\" \" ind2=\" \"><subfield code=\"a\">r</subfield></datafield><datafield tag=\"181\" ind1=\" \" ind2=\" \"><subfield code=\"6\">z01</subfield><subfield code=\"c\">txt</subfield><subfield code=\"2\">639-2</subfield></datafield><datafield tag=\"182\" ind1=\" \" ind2=\" \"><subfield code=\"6\">z01</subfield><subfield code=\"a\">i#</subfield><subfield code=\"b\">xxxe##</subfield></datafield><datafield tag=\"183\" ind1=\" \" ind2=\" \"><subfield code=\"6\">z01</subfield><subfield code=\"c\">n</subfield><subfield code=\"2\">639-2</subfield></datafield><datafield tag=\"184\" ind1=\" \" ind2=\"1\"><subfield code=\"6\">z01</subfield><subfield code=\"a\">x</subfield><subfield code=\"b\"> \".nocode.\".</subfield></datafield><datafield tag=\"184\" ind1=\" \" ind2=\"1\"><subfield code=\"6\">z02</subfield><subfield code=\"a\">x</subfield><subfield code=\"b\">b##</subfield></datafield><datafield tag=\"184\" ind1=\" \" ind2=\"1\"><subfield code=\"6\">z03</subfield><subfield code=\"a\">x</subfield><subfield code=\"b\">b</subfield></datafield><datafield tag=\"184\" ind1=\" \" ind2=\"1\"><subfield code=\"6\">z05</subfield><subfield code=\"a\">x</subfield><subfield code=\"b\">b</subfield><subfield code=\"c\"> .</subfield></datafield><datafield tag=\"184\" ind1=\" \" ind2=\"1\"><subfield code=\"6\">z06</subfield><subfield code=\"a\">x</subfield><subfield code=\"b\">b</subfield><subfield code=\"b\">e</subfield></datafield><datafield tag=\"184\" ind1=\" \" ind2=\"1\"><subfield code=\"6\">z07</subfield><subfield code=\"a\">x</subfield><subfield code=\"b\">b</subfield><subfield code=\"b\">e</subfield><subfield code=\"c\"> .</subfield></datafield><datafield tag=\"184\" ind1=\" \" ind2=\"1\"><subfield code=\"6\">z08</subfield><subfield code=\"a\">x</subfield><subfield code=\"b\">b</subfield><subfield code=\"b\">e</subfield><subfield code=\"b\">e</subfield></datafield><datafield tag=\"184\" ind1=\" \" ind2=\"1\"><subfield code=\"6\">z09</subfield><subfield code=\"a\">x</subfield><subfield code=\"b\">b</subfield><subfield code=\"b\">e</subfield><subfield code=\"b\">e</subfield><subfield code=\"c\"> .</subfield></datafield><datafield tag=\"184\" ind1=\" \" ind2=\"1\"><subfield code=\"6\">z10</subfield><subfield code=\"a\">x</subfield><subfield code=\"b\">b</subfield><subfield code=\"b\">e</subfield><subfield code=\"b\">e</subfield><subfield code=\"b\">e</subfield><subfield code=\"c\"> .</subfield></datafield><datafield tag=\"184\" ind1=\" \" ind2=\"1\"><subfield code=\"6\">z11</subfield><subfield code=\"a\">x</subfield><subfield code=\"b\">b</subfield><subfield code=\"b\">e</subfield><subfield code=\"b\">e</subfield><subfield code=\"b\">e</subfield><subfield code=\"b\">e</subfield><subfield code=\"c\"> .</subfield></datafield><datafield tag=\"184\" ind1=\" \" ind2=\"1\"><subfield code=\"6\">z12</subfield><subfield code=\"a\">x</subfield><subfield code=\"b\">b</subfield><subfield code=\"b\">e</subfield><subfield code=\"b\">e</subfield><subfield code=\"b\">e</subfield><subfield code=\"b\">e</subfield><subfield code=\"c\"> .</subfield></datafield><datafield tag=\"184\" ind1=\" \" ind2=\"1\"><subfield code=\"6\">z13</subfield><subfield code=\"a\">x</subfield><subfield code=\"b\">b</subfield><subfield code=\"b\">e</subfield><subfield code=\"b\">e</subfield><subfield code=\"b\">e</subfield><subfield code=\"b\">e</subfield><subfield code=\"b\">e</subfield><subfield code=\"b\">b\">e</subfield><subfield code=\"b\">e</subfield><subfield code=\"c\"> .</subfield></datafield><datafield tag=\"184\" ind1=\" \" ind2=\"1\"><subfield code=\"6\">z14</subfield><subfield code=\"a\">x</subfield><subfield code=\"b\">b</subfield><subfield code=\"b\">e</subfield><subfield code=\"b\">e</subfield><subfield code=\"b\">e</subfield><subfield code=\"b\">e</subfield><subfield code=\"b\">e</subfield><subfield code=\"b\">e</subfield><subfield code=\"b\">e</subfield><subfield code=\"b\">b\">b</subfield><subfield code=\"c\"> .</subfield></datafield><datafield tag=\"184\" ind1=\" \" ind2=\"1\"><subfield code=\"6\">z15</subfield><subfield code=\"a\">x</subfield><subfield code=\"b\">b</subfield><subfield code=\"b\">e</subfield><subfield code=\"b\">e</subfield><subfield code=\"b\">e</subfield><subfield code=\"b\">e</subfield><subfield code=\"b\">e</subfield><subfield code=\"b\">e</subfield><subfield code=\"b\">e</subfield><subfield code=\"b\">e</subfield><subfield code=\"b\">e</subfield><subfield code=\"b\">b\">b</subfield><subfield code=\"b\">b</subfield><subfield code=\"c\"> .</subfield></datafield><datafield tag=\"102\" ind1=\" \" ind2=\" \"><subfield code=\"a\">28081060Y</subfield></datafield><datafield tag=\"1013\" ind1=\" \" ind2=\" \"><subfield code=\"a\">en</subfield><subfield code=\"b\">eng</subfield><subfield code=\"f\">eng</subfield><subfield code=\"z\">eng</subfield><subfield code=\"t\">eng</subfield><subfield code=\"j\">eng</subfield><subfield code=\"m\">eng</subfield><subfield code=\"d\">eng</subfield></datafield><datafield tag=\"101\" ind1=\"0\" ind2=\" \"><subfield code=\"a\">GB</subfield><subfield code=\"b\">Belgium</subfield><subfield code=\"b\">DLE</subfield><subfield code=\"c\">DL</subfield><subfield code=\"d\">000</subfield><subfield code=\"f\">GB</subfield><subfield code=\"g\">NL</subfield><subfield code=\"h\">DL</subfield><subfield code=\"i\">DL</subfield><subfield code=\"j\">FR</subfield><subfield code=\"s\">FR</subfield><subfield code=\"u\">NL</subfield><subfield code=\"v\">000</subfield><subfield code=\"y\">000</subfield><subfield code=\"z\">000</subfield></datafield><datafield tag=\"200\" ind1=\" \" ind2=\" \"><subfield code=\"a\">27698450X</subfield><subfield code=\"b\">titre</subfield><subfield code=\"b\">E. I. Farfan-Cabrera et al.</subfield><subfield code=\"b\">le 2024-04-11</subfield><subfield code=\"b\">2e Ã©dition</subfield><subfield code=\"c\">[Paris] [2024]</subfield><subfield code=\"f\">ouvrage</subfield><subfield code=\"g\">byl. d. r.</subfield><subfield code=\"d\">fr.</subfield><subfield code=\"e\">[Ã©p.] d. e.</subfield><subfield code=\"e\">20240411h20242024k  y0frey50      ba</subfield></datafield><datafield tag=\"700\" ind1=\" \" ind2=\"1\"><subfield code=\"a\">27698450X</subfield><subfield code=\"b\">titres</subfield><subfield code=\"b\">par</subfield><subfield code=\"b\">le</subfield><subfield code=\"b\">2e</subfield><subfield code=\"b\">Ã©dition</subfield><subfield code=\"b\">Paris</subfield><subfield code=\"b\">[2024]</subfield><subfield code=\"b\">2e</subfield><subfield code=\"b\">edition</subfield><subfield code=\"b\">Rennes</subfield><subfield code=\"b\">[2024]</subfield><subfield code=\"b\">D. L.</subfield><subfield code=\"b\">DL</subfield><subfield code=\"b\">FR</subfield><subfield code=\"b\">FR</subfield><subfield code=\"b\">DL</subfield><subfield code=\"b\">000</subfield><subfield code=\"b\">000</subfield><subfield code=\"b\">000</subfield><subfield code=\"b\">000</subfield><subfield code=\"b\">000</subfield><subfield code=\"b\">000</subfield><subfield code=\"b\">000</subfield><subfield code=\"b\">000</subfield><subfield code=\"b\">000</subfield><subfield code=\"b\">000</subfield><subfield code=\"b\">000</subfield><subfield code=\"b\">000</subfield><subfield code=\"b\">000</subfield><subfield code=\"b\">000</subfield><subfield code=\"b\">000</subfield><subfield code=\"b\">000</subfield><subfield code=\"b\">000</subfield><subfield code=\"b\">000</subfield><subfield code=\"b\">000</subfield><subfield code=\"b\">000</subfield><subfield code=\"b\">000</subfield><subfield code=\"b\">000</subfield><subfield code=\"b\">000</subfield><subfield code=\"b\">000</subfield><subfield code=\"b\">000</subfield><subfield code=\"b\">000</subfield><subfield code=\"b\">000</subfield><subfield code=\"b\">000</subfield><subfield code=\"b\">000</subfield><subfield code=\"b\">000</subfield><subfield code=\"b\">000</subfield><subfield code=\"b\">000</subfield><subfield code=\"b\">000</subfield><subfield code=\"b\">000</subfield><subfield code=\"b\">000</subfield><subfield code=\"b\">000</subfield><subfield code=\"b\">000</subfield><subfield code=\"b\">000</subfield><subfield code=\"b\">000</subfield><subfield code=\"b\">000</subfield><subfield code=\"b\">000</subfield><subfield code=\"b\">000</subfield><subfield code=\"b\">000</subfield><subfield code=\"b\">000</subfield><subfield code=\"b\">000</subfield><subfield code=\"b\">000</subfield><subfield code=\"b\">000</subfield><subfield code=\"b\">000</subfield><subfield code=\"b\">000</subfield><subfield code=\"b\">000</subfield><subfield code=\"b\">000</subfield><subfield code=\"b\">000</subfield><subfield code=\"b\">000</subfield><subfield code=\"b\">000</subfield><subfield code=\"b\">000</subfield><subfield code=\"b\">000</subfield><subfield code=\"b\">000</subfield><subfield code=\"b\">000</subfield><subfield code=\"b\">000</subfield><subfield code=\"b\">000</subfield><subfield code=\"b\">000</subfield><subfield code=\"b\">000</subfield><subfield code=\"b\">000</subfield><subfield code=\"b\">000</subfield><subfield code=\"b\">000</subfield><subfield code=\"b\">000</subfield><subfield code=\"b\">000</subfield><subfield code=\"b\">000</subfield><subfield code=\"b\">000</subfield><subfield code=\"b\">000</subfield><subfield code=\"b\">000</subfield><subfield code=\"b\">000</subfield><subfield code=\"b\">000</subfield><subfield code=\"b\">000</subfield><subfield code=\"b\">000</subfield><subfield code=\"b\">000</subfield><subfield code=\"b\">000</subfield><subfield code=\"b\">000</subfield><subfield code=\"b\">000</subfield><subfield code=\"b\">000</subfield><subfield code=\"b\">000</subfield><subfield code=\"b\">000</subfield><subfield code=\"b\">000</subfield><subfield code=\"b\">000</subfield><subfield code=\"b\">000</subfield><subfield code=\"b\">000</subfield><subfield code=\"b\">000</subfield><subfield code=\"b\">000</subfield><subfield code=\"b\">000</subfield><subfield code=\"b\">000</subfield><subfield code=\"b\">000</subfield><subfield code=\"b\">000</subfield><subfield code=\"b\">000</subfield><subfield code=\"b\">000</subfield><subfield code=\"b\">000</subfield><subfield code=\"b\">000</subfield><subfield code=\"b\">000</subfield><subfield code=\"b\">000</subfield><subfield code=\"b\">000</subfield><subfield code=\"b\">000</subfield><subfield code=\"b\">000</subfield><sub\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d8020ee-4889-4a3c-a278-606944f25880",
   "metadata": {},
   "source": [
    "# Reward functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f6c955c-550b-412b-9723-6f7729a04cef",
   "metadata": {},
   "source": [
    "## utils functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7d53cc64-58bc-457a-8aa8-4729e5934045",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "import re\n",
    "\n",
    "def extract_hash_answer(text: str) -> str | None:\n",
    "    if \"### Answer:\" not in text:\n",
    "        return None\n",
    "    first_split = text.split(\"### Answer:\")[1].strip()\n",
    "    if \"### Explanation:\" not in first_split:\n",
    "        return first_split\n",
    "    else:\n",
    "        return first_split.split(\"### Explanation:\")[0].strip()\n",
    "\n",
    "def extract_xml(text: str) -> str | None:\n",
    "    # Use regular expression to find the XML part enclosed in ```xml...```\n",
    "    xml_match = re.search(r'```xml(.*?)```', response, re.DOTALL)\n",
    "    if xml_match:\n",
    "        return xml_match.group(1).strip()\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def extract_field_values(xml_str):\n",
    "    root = ET.fromstring(xml_str)\n",
    "    fields = {}\n",
    "    for df in root.findall(\".//datafield\"):\n",
    "        tag = df.get(\"tag\")\n",
    "        subfields = [sf.text for sf in df.findall(\"subfield\")]\n",
    "        fields[tag] = \" \".join(subfields)\n",
    "    return fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2f9a80c6-e6a3-454f-b411-265079c766d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example avec previous example\n",
    "response = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5f9cf5c4-2f15-46c4-b8f1-ae2a497b8e82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```xml\n",
      "<?xml version=\"1.0\"?>\n",
      "<record xmlns=\"http://unimarc.org/xml/ns/unimarc\">\n",
      "    <author>\n",
      "        <name>Leonardo I. Farfan-Cabrera, Ali Erdemir</name>\n",
      "    </author>\n",
      "    <publisher>Elsevier</publisher>\n",
      "    <year>2024</year>\n",
      "    <isbn>978-0-443-14074-7</isbn>\n",
      "    <language>English</language>\n",
      "    <collection>\n",
      "        <series>Elsevier Series on Tribology and Surface Engineering</series>\n",
      "    </collection>\n",
      "    <edition>\n",
      "        Not specified\n",
      "    </edition>\n",
      "    <material>\n",
      "        <description>1 vol. (XII-313 p.), couv. ill. en coul., 23 cm</description>\n",
      "    </material>\n",
      "    <abstract>\n",
      "        \"Electric vehicle tribology, challenges and opportunities for a sustainable transportation future\"\n",
      "        provides practical, comprehensive guidance on a new and increasingly important area of tribology. Building skills from fundamentals to solution design, this book demonstrates the unique tribological techniques essential to the efficient electrification of transport systems.\"\n",
      "    </abstract>\n",
      "    <keywords>Tribologie (technologie), Tribologie (Technologie)</keywords>\n",
      "    <tableOfContents/>\n",
      "    <keyword>\n",
      "        Tribologie (technologie)\n",
      "    </keyword>\n",
      "</record>\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "print(extract_hash_answer(text=response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ff7bf179-7fa4-48c0-8c78-b06dcf90e38b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<?xml version=\"1.0\"?>\n",
      "<record xmlns=\"http://unimarc.org/xml/ns/unimarc\">\n",
      "    <author>\n",
      "        <name>Leonardo I. Farfan-Cabrera, Ali Erdemir</name>\n",
      "    </author>\n",
      "    <publisher>Elsevier</publisher>\n",
      "    <year>2024</year>\n",
      "    <isbn>978-0-443-14074-7</isbn>\n",
      "    <language>English</language>\n",
      "    <collection>\n",
      "        <series>Elsevier Series on Tribology and Surface Engineering</series>\n",
      "    </collection>\n",
      "    <edition>\n",
      "        Not specified\n",
      "    </edition>\n",
      "    <material>\n",
      "        <description>1 vol. (XII-313 p.), couv. ill. en coul., 23 cm</description>\n",
      "    </material>\n",
      "    <abstract>\n",
      "        \"Electric vehicle tribology, challenges and opportunities for a sustainable transportation future\"\n",
      "        provides practical, comprehensive guidance on a new and increasingly important area of tribology. Building skills from fundamentals to solution design, this book demonstrates the unique tribological techniques essential to the efficient electrification of transport systems.\"\n",
      "    </abstract>\n",
      "    <keywords>Tribologie (technologie), Tribologie (Technologie)</keywords>\n",
      "    <tableOfContents/>\n",
      "    <keyword>\n",
      "        Tribologie (technologie)\n",
      "    </keyword>\n",
      "</record>\n"
     ]
    }
   ],
   "source": [
    "print(extract_xml(text=response))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5e0c0ec-44c7-4f19-8055-f760b4627cf0",
   "metadata": {},
   "source": [
    "## Format-based reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2bcd0252-36d8-4281-8ad3-b7081cf1b1d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_reward(xml_output: str) -> float:\n",
    "    try:\n",
    "        root = ET.fromstring(xml_output)\n",
    "    except ET.ParseError:\n",
    "        return 0.0  # Not even valid XML\n",
    "\n",
    "    required_tags = [\"leader\", \"controlfield\", \"datafield\"]\n",
    "    has_required_tags = all(root.find(f\".//{tag}\") is not None for tag in required_tags)\n",
    "\n",
    "    if not has_required_tags:\n",
    "        return 0.3  # Barely structured but not fully compliant\n",
    "\n",
    "    # Optionally: integrate XSD/Schematron validation here\n",
    "    return 1.0  # Well-formed and conforms to expected structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0e9a09fc-3630-42bc-a6dc-2776b54e7239",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3\n"
     ]
    }
   ],
   "source": [
    "xml_answer = extract_xml(text=response)\n",
    "print(format_reward(xml_output=xml_answer))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6a96315-00f0-4ca5-b286-710546be8425",
   "metadata": {},
   "source": [
    "## Accuracy-based reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c94bbef0-8539-47c6-96ac-2df18b8a54d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "xml_answer = extract_xml(text=response)\n",
    "xml_target = \"\"\"<record><controlfield tag=\"005\">20240711151255.000</controlfield><leader> nam0 22 450 </leader><controlfield tag=\"001\">279354177</controlfield><controlfield tag=\"003\">http://www.sudoc.fr/279354177</controlfield><datafield tag=\"035\" ind1=\" \" ind2=\" \"><subfield code=\"a\">(OCoLC)1449675800</subfield></datafield><datafield tag=\"010\" ind1=\" \" ind2=\" \"><subfield code=\"a\">978-0-443-14074-7</subfield><subfield code=\"b\">br.</subfield></datafield><datafield tag=\"073\" ind1=\" \" ind2=\"1\"><subfield code=\"a\">9780443140747</subfield></datafield><datafield tag=\"100\" ind1=\" \" ind2=\" \"><subfield code=\"a\">20240711d2024 ||||0frey50 ba</subfield></datafield><datafield tag=\"101\" ind1=\"0\" ind2=\" \"><subfield code=\"a\">eng</subfield><subfield code=\"2\">639-2</subfield></datafield><datafield tag=\"105\" ind1=\" \" ind2=\" \"><subfield code=\"a\">y ||||001yy</subfield></datafield><datafield tag=\"106\" ind1=\" \" ind2=\" \"><subfield code=\"a\">r</subfield></datafield><datafield tag=\"181\" ind1=\" \" ind2=\" \"><subfield code=\"6\">z01</subfield><subfield code=\"c\">txt</subfield><subfield code=\"2\">rdacontent</subfield></datafield><datafield tag=\"181\" ind1=\" \" ind2=\"1\"><subfield code=\"6\">z01</subfield><subfield code=\"a\">i#</subfield><subfield code=\"b\">xxxe##</subfield></datafield><datafield tag=\"182\" ind1=\" \" ind2=\" \"><subfield code=\"6\">z01</subfield><subfield code=\"c\">c</subfield><subfield code=\"2\">rdamedia</subfield></datafield><datafield tag=\"182\" ind1=\" \" ind2=\"1\"><subfield code=\"6\">z01</subfield><subfield code=\"a\">b</subfield></datafield><datafield tag=\"183\" ind1=\" \" ind2=\"1\"><subfield code=\"6\">z01</subfield><subfield code=\"a\">nga</subfield><subfield code=\"2\">RDAfrCarrier</subfield></datafield><datafield tag=\"102\" ind1=\" \" ind2=\" \"><subfield code=\"a\">NL</subfield><subfield code=\"a\">GB</subfield><subfield code=\"a\">US</subfield></datafield><datafield tag=\"200\" ind1=\"0\" ind2=\" \"><subfield code=\"a\">Electric vehicle tribology</subfield><subfield code=\"e\">challenges and opportunities for a sustainable transportation future</subfield><subfield code=\"f\">edited by Leonardo I. Farfan-Cabrera, ... Ali Erdemir, ...</subfield></datafield><datafield tag=\"701\" ind1=\" \" ind2=\"1\"><subfield code=\"3\">279354606</subfield><subfield code=\"a\">Farfan-Cabrera</subfield><subfield code=\"b\">Leonardo Israel</subfield><subfield code=\"4\">340</subfield></datafield><datafield tag=\"701\" ind1=\" \" ind2=\"1\"><subfield code=\"3\">11490314X</subfield><subfield code=\"a\">Erdemir</subfield><subfield code=\"b\">Ali</subfield><subfield code=\"4\">340</subfield></datafield><datafield tag=\"801\" ind1=\" \" ind2=\"3\"><subfield code=\"a\">FR</subfield><subfield code=\"b\">Abes</subfield><subfield code=\"c\">20240711</subfield><subfield code=\"g\">AFNOR</subfield></datafield><datafield tag=\"214\" ind1=\" \" ind2=\"0\"><subfield code=\"a\">Amsterdam</subfield><subfield code=\"c\">Elsevier</subfield><subfield code=\"d\">2024</subfield></datafield><datafield tag=\"215\" ind1=\" \" ind2=\" \"><subfield code=\"a\">1 vol. (XI-313 p.)</subfield><subfield code=\"c\">couv. ill. en coul.</subfield><subfield code=\"d\">23 cm</subfield></datafield><datafield tag=\"225\" ind1=\"0\" ind2=\" \"><subfield code=\"a\">Elsevier Series on Tribology and Surface Engineering</subfield></datafield><datafield tag=\"606\" ind1=\" \" ind2=\" \"><subfield code=\"3\">027720055</subfield><subfield code=\"a\">Tribologie (technologie)</subfield><subfield code=\"2\">rameau</subfield></datafield><datafield tag=\"606\" ind1=\" \" ind2=\" \"><subfield code=\"a\">Tribologie (Technologie)</subfield><subfield code=\"2\">lc</subfield></datafield><datafield tag=\"330\" ind1=\" \" ind2=\" \"><subfield code=\"a\">\"Electric vehicle tribology, challenges and opportunities for a sustainable transportation future\" provides practical, comprehensive guidance on a new and increasingly important aera of tribology. Building skills from fundamentals to solution design, this book demonstrates the unique tribological techniques essential to the efficient electrification of transportt systems. Led by professors with a combined three decades in industry and academia, and collecting insights from experts around the world, this book begins with the essential knowledge regarding both electric vehicles and tribology. After outlining the unique tribological needs of EVs, the book then breaks down the components and hardware required. It provides detailed protocols and methods for the testing and improvement of lubricants and materials as well as a dedicated section on modern lubrication specific to EVs. Throughout, it considers the critical question of sustainable tribology and the long-term sustainable options for lubrication and materials for electric vehicles.</subfield><subfield code=\"2\">4e de couverture</subfield></datafield></record>\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e3c9ba34-c696-48f2-bbb3-8948aacd81f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{}\n"
     ]
    }
   ],
   "source": [
    "print(extract_field_values(xml_answer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "861b1f63-fced-4103-802d-c255375203b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'035': '(OCoLC)1449675800', '010': '978-0-443-14074-7 br.', '073': '9780443140747', '100': '20240711d2024 ||||0frey50 ba', '101': 'eng 639-2', '105': 'y ||||001yy', '106': 'r', '181': 'z01 i# xxxe##', '182': 'z01 b', '183': 'z01 nga RDAfrCarrier', '102': 'NL GB US', '200': 'Electric vehicle tribology challenges and opportunities for a sustainable transportation future edited by Leonardo I. Farfan-Cabrera, ... Ali Erdemir, ...', '701': '11490314X Erdemir Ali 340', '801': 'FR Abes 20240711 AFNOR', '214': 'Amsterdam Elsevier 2024', '215': '1 vol. (XI-313 p.) couv. ill. en coul. 23 cm', '225': 'Elsevier Series on Tribology and Surface Engineering', '606': 'Tribologie (Technologie) lc', '330': '\"Electric vehicle tribology, challenges and opportunities for a sustainable transportation future\" provides practical, comprehensive guidance on a new and increasingly important aera of tribology. Building skills from fundamentals to solution design, this book demonstrates the unique tribological techniques essential to the efficient electrification of transportt systems. Led by professors with a combined three decades in industry and academia, and collecting insights from experts around the world, this book begins with the essential knowledge regarding both electric vehicles and tribology. After outlining the unique tribological needs of EVs, the book then breaks down the components and hardware required. It provides detailed protocols and methods for the testing and improvement of lubricants and materials as well as a dedicated section on modern lubrication specific to EVs. Throughout, it considers the critical question of sustainable tribology and the long-term sustainable options for lubrication and materials for electric vehicles. 4e de couverture'}\n"
     ]
    }
   ],
   "source": [
    "print(extract_field_values(xml_target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0d5b9c3c-5edd-4e45-971a-160a8fad72f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_reward(generated_xml: str, target_xml: str) -> float:\n",
    "    try:\n",
    "        gen_fields = extract_field_values(generated_xml)\n",
    "        tgt_fields = extract_field_values(target_xml)\n",
    "    except ET.ParseError:\n",
    "        return 0.0\n",
    "\n",
    "    shared_keys = set(gen_fields) & set(tgt_fields)\n",
    "    if not shared_keys:\n",
    "        return 0.0\n",
    "\n",
    "    total_sim = 0\n",
    "    for key in shared_keys:\n",
    "        sim = SequenceMatcher(None, gen_fields[key], tgt_fields[key]).ratio()\n",
    "        total_sim += sim\n",
    "\n",
    "    return total_sim / len(shared_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "236ca6a2-60b2-4dd8-bfb4-e34ea1a9ba83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_reward(generated_xml=xml_answer, target_xml=xml_target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63aa9561-fb84-48cd-8980-5e9547a08e35",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
