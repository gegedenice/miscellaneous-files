{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c39404ea-61a4-4a54-a340-8f9509d6a4f3",
   "metadata": {},
   "source": [
    "# Unsloth SFT\n",
    "\n",
    "*https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/Qwen3_(14B)-Reasoning-Conversational.ipynb#scrollTo=QmUBVEnvCDJv*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4062975-0066-49ee-82c2-4f8b15a18088",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U --quiet ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "77b2c6d7-f7e5-4a92-ad6c-0a8eeda3f1e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "import os\n",
    "if \"COLAB_\" not in \"\".join(os.environ.keys()):\n",
    "    !pip install unsloth\n",
    "else:\n",
    "    # Do this only in Colab notebooks! Otherwise use pip install unsloth\n",
    "    !pip install --no-deps bitsandbytes accelerate xformers==0.0.29.post3 peft trl==0.15.2 triton cut_cross_entropy unsloth_zoo\n",
    "    !pip install sentencepiece protobuf datasets huggingface_hub hf_transfer\n",
    "    !pip install --no-deps unsloth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "882a24a8-63bd-47df-8cc4-236dbdb432d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
      "ðŸ¦¥ Unsloth Zoo will now patch everything to make training faster!\n",
      "INFO 05-13 09:27:24 [importing.py:53] Triton module has been replaced with a placeholder.\n",
      "INFO 05-13 09:27:24 [__init__.py:239] Automatically detected platform cuda.\n"
     ]
    }
   ],
   "source": [
    "from unsloth import FastLanguageModel\n",
    "import torch\n",
    "from transformers import DataCollatorForLanguageModeling, TrainerCallback, DataCollatorForLanguageModeling\n",
    "import pandas as pd\n",
    "from datasets import Dataset, load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2f0f3099-b3fc-4743-a5a8-ea8c9a0704c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "\n",
    "# Save the original function\n",
    "_original_cpu_count = multiprocessing.cpu_count\n",
    "\n",
    "# Override it to return 1\n",
    "def _patched_cpu_count():\n",
    "    return 1\n",
    "\n",
    "# Apply the patch\n",
    "multiprocessing.cpu_count = _patched_cpu_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "df35c799-520c-4943-93dc-7fad6bdf7b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "del model\n",
    "del tokenizer\n",
    "#del trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "3532237d-1202-4e09-b92f-84cdd569c70a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "67a0f55f-71e4-48df-826d-361c82643b35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth 2025.5.1: Fast Qwen3 patching. Transformers: 4.51.3. vLLM: 0.8.5.post1.\n",
      "   \\\\   /|    NVIDIA A2. Num GPUs = 1. Max memory: 14.529 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.6.0+cu124. CUDA: 8.6. CUDA Toolkit: 12.4. Triton: 3.2.0\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.29.post2. FA2 = False]\n",
      " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8967bf76caec4ad2b1135562e5a3efb8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/576M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bec00fa807604ad6ae192d7f447d718d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/242 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aad32f03c3dc426b819edf3bad5df3ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/10.3k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c4182614d3f412f9e46d4571ca0c0c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/2.78M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9aa33261cec4041ae1881239c17424b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/1.67M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31074071f0224a3cb336d5fcb1861d31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "added_tokens.json:   0%|          | 0.00/707 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6cae06fca61a46deab45499ef2dd6c65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/614 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68a0356acbfd4e16be8ee18f8b83b48c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/11.4M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "544b3aa44f894c62b1390b125e048033",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "chat_template.jinja:   0%|          | 0.00/4.67k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name = \"Qwen/Qwen3-0.6B\",\n",
    "    #model_name = \"unsloth/Llama-3.2-3B-Instruct\",\n",
    "    max_seq_length = 4096,   # Context length - can be longer, but uses more memory\n",
    "    load_in_4bit = True,     # 4bit uses much less memory\n",
    "    load_in_8bit = False,    # A bit more accurate, uses 2x memory\n",
    "    full_finetuning = False, # We have full finetuning now!\n",
    "    # token = \"hf_...\",      # use one if using gated models\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8a0f03ce-0131-4766-a223-81884a33751f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Qwen3ForCausalLM(\n",
       "  (model): Qwen3Model(\n",
       "    (embed_tokens): Embedding(151936, 1024, padding_idx=151654)\n",
       "    (layers): ModuleList(\n",
       "      (0): Qwen3DecoderLayer(\n",
       "        (self_attn): Qwen3Attention(\n",
       "          (q_proj): Linear(in_features=1024, out_features=2048, bias=False)\n",
       "          (k_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (v_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (o_proj): Linear(in_features=2048, out_features=1024, bias=False)\n",
       "          (q_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
       "          (k_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
       "          (rotary_emb): LlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): Qwen3MLP(\n",
       "          (gate_proj): Linear4bit(in_features=1024, out_features=3072, bias=False)\n",
       "          (up_proj): Linear4bit(in_features=1024, out_features=3072, bias=False)\n",
       "          (down_proj): Linear4bit(in_features=3072, out_features=1024, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): Qwen3RMSNorm((1024,), eps=1e-06)\n",
       "        (post_attention_layernorm): Qwen3RMSNorm((1024,), eps=1e-06)\n",
       "      )\n",
       "      (1): Qwen3DecoderLayer(\n",
       "        (self_attn): Qwen3Attention(\n",
       "          (q_proj): Linear4bit(in_features=1024, out_features=2048, bias=False)\n",
       "          (k_proj): Linear4bit(in_features=1024, out_features=1024, bias=False)\n",
       "          (v_proj): Linear4bit(in_features=1024, out_features=1024, bias=False)\n",
       "          (o_proj): Linear4bit(in_features=2048, out_features=1024, bias=False)\n",
       "          (q_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
       "          (k_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
       "          (rotary_emb): LlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): Qwen3MLP(\n",
       "          (gate_proj): Linear4bit(in_features=1024, out_features=3072, bias=False)\n",
       "          (up_proj): Linear4bit(in_features=1024, out_features=3072, bias=False)\n",
       "          (down_proj): Linear4bit(in_features=3072, out_features=1024, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): Qwen3RMSNorm((1024,), eps=1e-06)\n",
       "        (post_attention_layernorm): Qwen3RMSNorm((1024,), eps=1e-06)\n",
       "      )\n",
       "      (2): Qwen3DecoderLayer(\n",
       "        (self_attn): Qwen3Attention(\n",
       "          (q_proj): Linear4bit(in_features=1024, out_features=2048, bias=False)\n",
       "          (k_proj): Linear4bit(in_features=1024, out_features=1024, bias=False)\n",
       "          (v_proj): Linear4bit(in_features=1024, out_features=1024, bias=False)\n",
       "          (o_proj): Linear4bit(in_features=2048, out_features=1024, bias=False)\n",
       "          (q_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
       "          (k_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
       "          (rotary_emb): LlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): Qwen3MLP(\n",
       "          (gate_proj): Linear(in_features=1024, out_features=3072, bias=False)\n",
       "          (up_proj): Linear(in_features=1024, out_features=3072, bias=False)\n",
       "          (down_proj): Linear(in_features=3072, out_features=1024, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): Qwen3RMSNorm((1024,), eps=1e-06)\n",
       "        (post_attention_layernorm): Qwen3RMSNorm((1024,), eps=1e-06)\n",
       "      )\n",
       "      (3-23): 21 x Qwen3DecoderLayer(\n",
       "        (self_attn): Qwen3Attention(\n",
       "          (q_proj): Linear4bit(in_features=1024, out_features=2048, bias=False)\n",
       "          (k_proj): Linear4bit(in_features=1024, out_features=1024, bias=False)\n",
       "          (v_proj): Linear4bit(in_features=1024, out_features=1024, bias=False)\n",
       "          (o_proj): Linear4bit(in_features=2048, out_features=1024, bias=False)\n",
       "          (q_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
       "          (k_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
       "          (rotary_emb): LlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): Qwen3MLP(\n",
       "          (gate_proj): Linear4bit(in_features=1024, out_features=3072, bias=False)\n",
       "          (up_proj): Linear4bit(in_features=1024, out_features=3072, bias=False)\n",
       "          (down_proj): Linear4bit(in_features=3072, out_features=1024, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): Qwen3RMSNorm((1024,), eps=1e-06)\n",
       "        (post_attention_layernorm): Qwen3RMSNorm((1024,), eps=1e-06)\n",
       "      )\n",
       "      (24): Qwen3DecoderLayer(\n",
       "        (self_attn): Qwen3Attention(\n",
       "          (q_proj): Linear(in_features=1024, out_features=2048, bias=False)\n",
       "          (k_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (v_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (o_proj): Linear(in_features=2048, out_features=1024, bias=False)\n",
       "          (q_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
       "          (k_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
       "          (rotary_emb): LlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): Qwen3MLP(\n",
       "          (gate_proj): Linear4bit(in_features=1024, out_features=3072, bias=False)\n",
       "          (up_proj): Linear4bit(in_features=1024, out_features=3072, bias=False)\n",
       "          (down_proj): Linear4bit(in_features=3072, out_features=1024, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): Qwen3RMSNorm((1024,), eps=1e-06)\n",
       "        (post_attention_layernorm): Qwen3RMSNorm((1024,), eps=1e-06)\n",
       "      )\n",
       "      (25-26): 2 x Qwen3DecoderLayer(\n",
       "        (self_attn): Qwen3Attention(\n",
       "          (q_proj): Linear4bit(in_features=1024, out_features=2048, bias=False)\n",
       "          (k_proj): Linear4bit(in_features=1024, out_features=1024, bias=False)\n",
       "          (v_proj): Linear4bit(in_features=1024, out_features=1024, bias=False)\n",
       "          (o_proj): Linear4bit(in_features=2048, out_features=1024, bias=False)\n",
       "          (q_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
       "          (k_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
       "          (rotary_emb): LlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): Qwen3MLP(\n",
       "          (gate_proj): Linear4bit(in_features=1024, out_features=3072, bias=False)\n",
       "          (up_proj): Linear4bit(in_features=1024, out_features=3072, bias=False)\n",
       "          (down_proj): Linear4bit(in_features=3072, out_features=1024, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): Qwen3RMSNorm((1024,), eps=1e-06)\n",
       "        (post_attention_layernorm): Qwen3RMSNorm((1024,), eps=1e-06)\n",
       "      )\n",
       "      (27): Qwen3DecoderLayer(\n",
       "        (self_attn): Qwen3Attention(\n",
       "          (q_proj): Linear4bit(in_features=1024, out_features=2048, bias=False)\n",
       "          (k_proj): Linear4bit(in_features=1024, out_features=1024, bias=False)\n",
       "          (v_proj): Linear4bit(in_features=1024, out_features=1024, bias=False)\n",
       "          (o_proj): Linear4bit(in_features=2048, out_features=1024, bias=False)\n",
       "          (q_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
       "          (k_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
       "          (rotary_emb): LlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): Qwen3MLP(\n",
       "          (gate_proj): Linear4bit(in_features=1024, out_features=3072, bias=False)\n",
       "          (up_proj): Linear(in_features=1024, out_features=3072, bias=False)\n",
       "          (down_proj): Linear4bit(in_features=3072, out_features=1024, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): Qwen3RMSNorm((1024,), eps=1e-06)\n",
       "        (post_attention_layernorm): Qwen3RMSNorm((1024,), eps=1e-06)\n",
       "      )\n",
       "    )\n",
       "    (norm): Qwen3RMSNorm((1024,), eps=1e-06)\n",
       "    (rotary_emb): LlamaRotaryEmbedding()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=1024, out_features=151936, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# !Important\n",
    "tokenizer.padding_side = \"right\"\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f654f864-c976-48bc-844d-48f3b69b0455",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<think>\n",
      "Okay, let me start by understanding what the user is asking. They want to convert the provided metadata into UNIMARC XML. First, I need to parse the information from the given text. The metadata includes the title, subtitle, author, publisher, place of publication, year, edition, material description, ISBN, other identifiers, language, country, collection/series, bibliography, abstract/notes, keywords, and URL.\n",
      "\n",
      "Now, I remember that UNIMARC XML follows a specific structure. The first part is the root element, then there's a series of elements. The title should be a <title> element. The subtitle is in <subtitle> and needs to be enclosed in <title> tags. The author and publisher are in <author> and <publisher>, respectively.\n",
      "\n",
      "The material description includes the volume information: 1 vol. (207 p.), colors, illustrations, size. The ISBN is in <isbn> and the other identifiers are also in <other_identifier>. The language is French, and the country is France. The collection/series is not specified, so maybe a <collection> element with the series name. The bibliography is in <bibliography> with p. [200-204], glossary, index.\n",
      "\n",
      "The abstract/notes are in <abstract> and the URL is in <url>. The keywords are in <keywords> and the cataloguing agencies are in <cataloguing_agencies>. \n",
      "\n",
      "I need to make sure that all the elements are properly nested and that the XML is valid. Also, check for any special characters or formatting that need to be handled, like the <title> and <subtitle> tags. Finally, ensure that the XML is correctly formatted with proper XML tags and structure.\n",
      "</think>\n",
      "\n",
      "```xml\n",
      "<unimarc xmlns=\"http://www.unimarc.org/2001/UNIMARC-1.1.1/\">\n",
      "  <title>Agro-visualisation</title>\n",
      "  <subtitle>Enjeux et dÃ©fis de l'agriculture expliquÃ©s en 100 infographies</subtitle>\n",
      "  <author>Benjamin Nowak (1988-....)</author>\n",
      "  <publisher>Dunod</publisher>\n",
      "  <place>Malakoff</place>\n",
      "  <year>2024</year>\n",
      "  <edition>Non explicitement</edition>\n",
      "  <material_description>\n",
      "    <volume>1</volume>\n",
      "    <pages>207</pages>\n",
      "    <cover>illustrÃ©e</cover>\n",
      "    <illustrations>illustrÃ©es</illustrations>\n",
      "    <dimensions>17 Ã— 24 cm</dimensions>\n",
      "  </material_description>\n",
      "  <isbn>978-2-10-086178-1</isbn>\n",
      "  <other_identifier>\n",
      "    <oCoLC>1423791488</oCoLC>\n",
      "    <ISBN>9782100861781</ISBN>\n",
      "    <FRBNF474231740000008</FRBNF474231740000008>\n",
      "  </other_identifier>\n",
      "  <language>French (fre)</language>\n",
      "  <country_of_publication>FR (France)</country_of_publication>\n",
      "  <collection_series>Non spÃ©cifiÃ©</collection_series>\n",
      "  <bibliography>\n",
      "    <bibliography>\n",
      "      <bibliography_entry>\n",
      "        <bibliography_page>\n",
      "          <bibliography_page_number>200</bibliography_page_number>\n",
      "          <bibliography_page_number>204</bibliography_page_number>\n",
      "        </bibliography_page>\n",
      "        <glossary>glossaire</glossary>\n",
      "        <index>index</index>\n",
      "      </bibliography_entry>\n",
      "    </bibliography>\n",
      "  </bibliography>\n",
      "  <abstract/notes>\n",
      "    <abstract/notes>\n",
      "      <title>Titre</title>\n",
      "      <note>Texte</note>\n",
      "    </abstract/notes>\n",
      "  </abstract/notes>\n",
      "  <keywords>\n",
      "    <keywords>\n",
      "      <keyword>Agronomie</keyword>\n",
      "      <keyword>Agriculture â€” Aspect Ã©conomique</keyword>\n",
      "      <keyword>Tableaux, graphiques, etc.</keyword>\n",
      "    </keywords>\n",
      "  </keywords>\n",
      "  <url>\n",
      "    <url>\n",
      "      <url>http://catalogue.bnf.fr/ark:/12148/cb474231743</url>\n",
      "    </url>\n",
      "  </url>\n",
      "  <cataloguing_agencies>\n",
      "    <cataloguing_agencies>\n",
      "      <agency>FR-751131015</agency>\n",
      "      <agency>Abes</agency>\n",
      "      <agency>AFNOR</agency>\n",
      "    </cataloguing_agencies>\n",
      "  </cataloguing_agencies>\n",
      "</unimarc>\n",
      "```<|im_end|>\n"
     ]
    }
   ],
   "source": [
    "user_metadata = \"\"\"\n",
    "Title: MÃ©mo visuel d'agronomie\n",
    "Subtitle: enjeux et dÃ©fis de l'agriculture expliquÃ©s en 100 infographies\n",
    "Author: Benjamin Nowak (1988-....)\n",
    "Publisher: Dunod\n",
    "Place of publication: Malakoff\n",
    "Year: DL 2024 (likely 2024)\n",
    "Edition: Not explicitly stated\n",
    "Material description: 1 vol. (207 p.); couverture illustrÃ©e en couleurs, illustrations en couleurs; 17 Ã— 24 cm\n",
    "ISBN: 978-2-10-086178-1\n",
    "Other identifier: (OCoLC)1423791488; 9782100861781; FRBNF474231740000008\n",
    "Language: French (fre)\n",
    "Country of publication: FR (France)\n",
    "Collection/Series: Not specified\n",
    "Bibliographic references: Bibliography p. [200-204]. Glossaire. Index\n",
    "Abstract/Notes: Cet ouvrage prÃ©sente, sous une forme visuelle et synthÃ©tique, les notions indispensables Ã  tout Ã©tudiant dÃ©couvrant l'agronomie. Ã€ travers 100 infographies en couleurs, il leur permettra de s'initier aux enjeux Ã©conomiques, scientifiques et environnementaux qui fonderont l'ensemble de leur cursus. Les plus : - 100 data visualisations commentÃ©es, pour une initiation synthÃ©tique Ã  une science complexe. - Un panorama allant des dÃ©buts de l'agriculture aux enjeux de l'agronomie de demain. - Un chapitre permettant de s'initier Ã  l'analyse des donnÃ©es et Ã  la conception des infographies scientifiques.\n",
    "Source of abstract/notes: Ã©diteur\n",
    "Keywords/Subjects:\n",
    "- Agronomie (RAMEAU)\n",
    "- Agriculture â€” Aspect Ã©conomique (RAMEAU)\n",
    "- Tableaux, graphiques, etc. (RAMEAU)\n",
    "URL: http://catalogue.bnf.fr/ark:/12148/cb474231743\n",
    "Cataloguing agencies: FR-751131015, Abes, AFNOR\n",
    "Additional notes: Data fields indicate content as textual (txt), media as nonprojected media (n), carrier as unmediated (nga) per RDA codes indicated.\n",
    "\"\"\"\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are an expert bibliographic cataloger assistant. Convert metadata to UNIMARC/XML format.\"},\n",
    "    {\"role\": \"user\", \"content\": f\"Please convert this metadata to UNIMARC/XML:\\n{user_metadata}\"}\n",
    "]\n",
    "text = tokenizer.apply_chat_template(\n",
    "    messages,\n",
    "    tokenize = False,\n",
    "    add_generation_prompt = True, # Must add for generation\n",
    "    enable_thinking = True\n",
    ")\n",
    "\n",
    "from transformers import TextStreamer\n",
    "_ = model.generate(\n",
    "    **tokenizer(text, return_tensors = \"pt\").to(\"cuda\"),\n",
    "    max_new_tokens = 4096, # Increase for longer outputs!\n",
    "    temperature = 0.6, top_p = 0.95, top_k = 20, # For thinking\n",
    "    streamer = TextStreamer(tokenizer, skip_prompt = True),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "f7939fa2-c9eb-45c8-b7cf-569a0772d892",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = tokenizer.decode(_[0], skip_special_tokens=False)\n",
    "format_reward(extract_xml(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8d95c335-1a04-4460-8e55-a57858346d96",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth 2025.5.1 patched 28 layers with 28 QKV layers, 28 O layers and 28 MLP layers.\n"
     ]
    }
   ],
   "source": [
    "model = FastLanguageModel.get_peft_model(\n",
    "    model,\n",
    "    r = 32,           # Choose any number > 0! Suggested 8, 16, 32, 64, 128\n",
    "    target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
    "                      \"gate_proj\", \"up_proj\", \"down_proj\",],\n",
    "    lora_alpha = 32,  # Best to choose alpha = rank or rank*2\n",
    "    lora_dropout = 0, # Supports any, but = 0 is optimized\n",
    "    bias = \"none\",    # Supports any, but = \"none\" is optimized\n",
    "    # [NEW] \"unsloth\" uses 30% less VRAM, fits 2x larger batch sizes!\n",
    "    use_gradient_checkpointing = \"unsloth\", # True or \"unsloth\" for very long context\n",
    "    random_state = 3407,\n",
    "    use_rslora = False,   # We support rank stabilized LoRA\n",
    "    loftq_config = None,  # And LoftQ\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f49b8071-e10c-471e-a3c3-2facc4f1a059",
   "metadata": {},
   "source": [
    "## Tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d49381e-ba1b-4c5a-8f7d-7123c9d8160a",
   "metadata": {},
   "source": [
    "## Data prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7f417fad-f50a-4792-a1c0-4e9c9d561cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "reasoning_dataset = load_dataset(\"Geraldine/metadata-to-unimarc-traces\", split=\"train\")\n",
    "xml_dataset = load_dataset(\"Geraldine/Unimarc-iln050-5k\", split=\"train\")\n",
    "xml_dataset = xml_dataset.select(range(200))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "425fede6-4b17-4954-8dd0-223ba7297290",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['ppn', 'metadata', 'unimarc_record', 'reasoning'],\n",
       "    num_rows: 673\n",
       "})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reasoning_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5abbf570-3b14-49cf-bd4e-9ba68ba0d0a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['ppn', 'question', 'answer'],\n",
       "    num_rows: 200\n",
       "})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xml_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aa389ee2-b49d-4647-a179-a172e45f89ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['index', 'text'],\n",
       "    num_rows: 873\n",
       "})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "system_prompt = \"You are an expert bibliographic cataloger specializing in UNIMARC format\"\n",
    "\n",
    "def chat_templating_func(dataset):\n",
    "    return tokenizer.apply_chat_template(\n",
    "        dataset[\"messages\"],\n",
    "        tokenize = False,\n",
    "    )\n",
    "\n",
    "def create_reasoning_conversation(row):\n",
    "  return {\n",
    "    \"messages\": [\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": f\"Please convert this metadata to UNIMARC/XML:\\n{row['metadata']}\"},\n",
    "            {\"role\": \"assistant\", \"content\": f\"<think>\\n{row['reasoning']}\\n</think>\\n\\n{row['unimarc_record']}\"}\n",
    "        ]\n",
    "  }\n",
    "reasoning_dataset = reasoning_dataset.map(create_reasoning_conversation, remove_columns=reasoning_dataset.features, batched=False)\n",
    "reasoning_conv = chat_templating_func(reasoning_dataset)\n",
    "\n",
    "def create_xml_conversation(row):\n",
    "  return {\n",
    "    \"messages\": [\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": f\"Please convert this metadata to UNIMARC/XML:\\n{row['question']}\"},\n",
    "            {\"role\": \"assistant\", \"content\": f\"<think>\\n\\n</think>\\n\\n{row['answer']}\"}\n",
    "        ]\n",
    "  }\n",
    "xml_dataset = xml_dataset.map(create_xml_conversation, remove_columns=xml_dataset.features, batched=False)\n",
    "xml_conv = chat_templating_func(xml_dataset)\n",
    "\n",
    "data = pd.concat([\n",
    "    pd.Series(reasoning_conv),\n",
    "    pd.Series(xml_conv)\n",
    "])\n",
    "data.name = \"text\"\n",
    "combined_dataset = Dataset.from_pandas(pd.DataFrame(data).reset_index())\n",
    "combined_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b1932637-83ff-4b5f-bc42-970e252fd174",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<|im_start|>system\\nYou are an expert bibliographic cataloger specializing in UNIMARC format<|im_end|>\\n<|im_start|>user\\nPlease convert this metadata to UNIMARC/XML:\\nTitle: Yoga senior  \\nSubtitle: la mÃ©thode de Gasquet  \\nAuthor: Dr Bernadette de Gasquet  \\nParticipation: avec la participation du Dr Marie Thirion  \\nAuthor details:  \\n- Bernadette de Gasquet (born 1946)  \\n- Marie Thirion (born 1944), pediatrician  \\n\\nPublisher: Robert Laffont  \\nPlace of publication: Paris  \\nYear: DL 2019 (Legal deposit 2019)  \\n\\nISBN: 978-2-221-24174-5  \\nOther identifier: 9782221241745 (EAN)  \\nOCLC number: 1107377985  \\n\\nLanguage: French (fre)  \\n\\nEdition: Not explicitly stated; appears first edition  \\n\\nMaterial Description:  \\n- 1 volume (250 pages)  \\n- Illustrations, color illustrated cover  \\n- Dimensions: 22 cm  \\n\\nCollection/Series: RÃ©ponses  \\n\\nNotes/Bibliographic references: Notes bibliogr.  \\n\\nAbstract/Notes:  \\nLa mÃ©thode de Gasquet enfin adaptÃ©e aux seniors ! Quelle activitÃ© physique pratiquer lorsque, Ã  50 ans, des fragilitÃ©s corporelles et des douleurs apparaissent ? Comment prendre soin de soi, garder un corps fonctionnel et source de plaisir ? SpÃ©cialiste du pÃ©rinÃ©e, professeure de yoga, reconnue et suivie par des mÃ©decins, des sages-femmes, des kinÃ©sithÃ©rapeutes et des coachs sportifs dans le monde entier, Bernadette de Gasquet adapte dans ce livre sa cÃ©lÃ¨bre mÃ©thode aux seniors et propose un travail sur le renforcement musculaire, sans recherche de la performance, Ã  travers des exercices simples. Travail corporel sans douleur et sans risque, discipline au service de l\\'Ãªtre humain, le yoga peut Ãªtre pratiquÃ© Ã  tout Ã¢ge. En alternant tonification et dÃ©tente, renforcements et Ã©tirements, en associant respiration et action sur les fonctions vitales, on peut garder un corps en pleine forme. Bernadette de Gasquet reprend ici les bases de l\\'activitÃ© physique â€“ postures, respiration, abdominaux â€“ en se concentrant sur les maux des seniors â€“ douleurs articulaires, problÃ¨mes de circulation, de constipation, hypertension, troubles respiratoires, rhumatismes... â€“ pour leur donner les clÃ©s d\\'une vie plus saine et du bien-Ãªtre au quotidien. 200 photos, 15 schÃ©mas, des exercices filmÃ©s... Yoga senior vous propose de nombreux conseils pratiques et des exercices physiques adaptÃ©s pour rester en forme aprÃ¨s 50 ans.  \\nSource of the abstract/notes: Ã©diteur  \\n\\nTable of contents: Not provided  \\n\\nKeywords/Subject headings:  \\n- Hatha-yoga (RAMEAU)  \\n- Exercices physiques pour personnes Ã¢gÃ©es (RAMEAU)  \\n\\nClassification:  \\n- Dewey: 613.710 846  \\n- French national bibliography classification: 610  \\n- RÃ©ponses (Paris. 1967) [series] ISSN 0750-7747  \\n\\nCountry of publication: France (FR)  \\n\\nOther information:  \\n- Legal deposit and cataloging codes for French institutions included  \\n- Material type: text, printed book  \\n- Carrier type: volume (nga)<|im_end|>\\n<|im_start|>assistant\\n<think>\\nTo transform the provided bibliographical metadata into the given UNIMARC/XML record, proceed step-by-step, field by field, as follows:\\n\\n1. **Control fields** (these are often generated/managed by the cataloguing system):\\n\\n   - `<controlfield tag=\"001\">` â€” Record identifier: `236807005` (not present in metadata; assigned by system)\\n   - `<controlfield tag=\"003\">` â€” Control number identifier (URI source): `http://www.sudoc.fr/236807005`\\n   - `<controlfield tag=\"005\">` â€” Date and time of record processing: `20210208123415.000` (recording timestamp)\\n   - `<controlfield tag=\"035\">` â€” Various system identifiers:\\n     - `(OCoLC)1107377985` from OCLC number metadata\\n     - `FRBNF...` codes from French national bibliographic authority (not explicitly given but part of cataloguing)\\n   - `<controlfield tag=\"010\">` â€” International Standard Book Number with binding type: `978-2-221-24174-5` and a binding subfield `$b`: `br.` (brochÃ© = paperback)\\n   - `<controlfield tag=\"073\">` â€” EAN (European article number) from \"Other identifier\": `9782221241745`\\n\\n2. **Leader**\\n\\n   - Encodes record status, type, bibliographic level, encoding level, etc. (`cam0 22        450`) - typically system generated.\\n\\n3. **010 field** (ISBN with binding):\\n\\n   - Maps ISBN to `<datafield tag=\"010\"><subfield code=\"a\">978-2-221-24174-5</subfield><subfield code=\"b\">br.</subfield></datafield>`\\n   - Binding \"br.\" corresponds to paperback (derived or cataloguer\\'s addition).\\n\\n4. **073 field** (EAN):\\n\\n   - `<datafield tag=\"073\"><subfield code=\"a\">9782221241745</subfield></datafield>`  \\n   - From \"Other identifier\" (EAN in metadata).\\n\\n5. **035 field** (other system numbers):\\n\\n   - OCLC: `(OCoLC)1107377985`\\n   - Other French identifiers (cataloguing institution codes), e.g. `FRBNF...`  \\n   - These are authority/control numbers for integration between systems.\\n\\n6. **100 field** â€” Date and activity code (special code field for cataloguing date/level):\\n\\n   - `<datafield tag=\"100\"><subfield code=\"a\">20190703h20192019m  y0frey50      ba</subfield>`  \\n   - This is a coded field indicating cataloguing dates or activity; this comes from cataloguing process and legal deposit year.  \\n   - The year 2019 comes from \"DL 2019\" (Deposited Legal year 2019).\\n\\n7. **101 field** â€” Language of the item:\\n\\n   - `<datafield tag=\"101\" ind1=\"0\"><subfield code=\"a\">fre</subfield><subfield code=\"2\">639-2</subfield></datafield>`  \\n   - From metadata language \"French (fre)\".\\n\\n8. **105, 106 fields** â€” Related to material form and genre:\\n\\n   - `<datafield tag=\"105\"><subfield code=\"a\">a   ||||000yy</subfield></datafield>`  \\n   - `<datafield tag=\"106\"><subfield code=\"a\">r</subfield></datafield>`\\n   - \\'a\\' = text, \\'r\\' indicates genre/form type (e.g., normal printed book).  \\n   - These are based on \"Material type: text, printed book\" from metadata.\\n\\n9. **181, 182, 183 fields** â€” Content, Media, and Carrier types (RDA):\\n\\n   - `<datafield tag=\"181\"><subfield code=\"c\">txt</subfield><subfield code=\"2\">rdacontent</subfield></datafield>`: Content type = text.\\n   - `<datafield tag=\"182\"><subfield code=\"c\">n</subfield><subfield code=\"2\">rdamedia</subfield></datafield>`: Media type (unmediated).\\n   - `<datafield tag=\"183\"><subfield code=\"a\">nga</subfield><subfield code=\"2\">RDAfrCarrier</subfield></datafield>`: Carrier type = volume (nga).\\n   - These correspond to the metadata fields \"Material type: text, printed book\" and \"Carrier type: volume (nga)\".\\n\\n10. **102 field** â€” Place of publication country code:\\n\\n    - `<datafield tag=\"102\"><subfield code=\"a\">FR</subfield></datafield>`\\n    - From \"Country of publication: France (FR)\".\\n\\n11. **320 field** â€” Notes on bibliography:\\n\\n    - `<datafield tag=\"320\"><subfield code=\"a\">Notes bibliogr.</subfield></datafield>`\\n    - From metadata \"Notes bibliogr.\" under Notes/Bibliographic references.\\n\\n12. **200 field** â€” Title and statement of responsibility:\\n\\n    - `<datafield tag=\"200\" ind1=\"1\" ind2=\" \">`\\n      - `<subfield code=\"a\">Yoga senior</subfield>` -- maps Title\\n      - `<subfield code=\"e\">la mÃ©thode de Gasquet</subfield>` -- maps Subtitle\\n      - `<subfield code=\"f\">Dr Bernadette de Gasquet</subfield>` -- maps Author (statement of responsibility)\\n      - `<subfield code=\"f\">avec la participation du Dr Marie Thirion</subfield>` -- maps Participation statement\\n    - So:\\n      - 200$a = Title\\n      - 200$e = Subtitle\\n      - 200$f = Author(s) / participation statement\\n\\n13. **700 field** â€” Main personal author details:\\n\\n    - `<datafield tag=\"700\" ind1=\" \" ind2=\"1\">`\\n      - `<subfield code=\"3\">084278986</subfield>` â€” Local control number or authority key\\n      - `<subfield code=\"a\">Gasquet</subfield>` â€” family name\\n      - `<subfield code=\"b\">Bernadette de</subfield>` â€” given names\\n      - `<subfield code=\"f\">1946-....</subfield>` â€” dates of birth (metadata: born 1946)\\n      - `<subfield code=\"4\">070</subfield>` â€” relator code for author (UNIMARC relators, \\'070\\' = author)\\n    - From Author details metadata for Bernadette de Gasquet\\n    - Note: The names are split into family and given according to French conventions and authority data.\\n\\n14. **702 field** â€” Secondary personal contributor details (participant):\\n\\n    - `<datafield tag=\"702\" ind1=\" \" ind2=\"1\">`\\n      - `<subfield code=\"3\">028312635</subfield>` â€” local control number\\n      - `<subfield code=\"a\">Thirion</subfield>` â€” family name\\n      - `<subfield code=\"b\">Marie</subfield>` â€” given name\\n      - `<subfield code=\"f\">1944-....</subfield>` â€” birth year\\n      - `<subfield code=\"c\">pÃ©diatre</subfield>` â€” profession (from metadata \"pediatrician\")\\n      - `<subfield code=\"4\">205</subfield>` â€” relator code for contributor function (\\'205\\' = collaborator)\\n    - Matches \"avec la participation du Dr Marie Thirion\" and author\\'s birth details + profession.\\n\\n15. **801 fields** â€” Cataloguing source and date(s):\\n\\n    - Two 801 fields with different subfields showing cataloguing institution, date, and processing. E.g.:\\n      - `<datafield tag=\"801\" ind1=\" \" ind2=\"3\">`\\n      - `<datafield tag=\"801\" ind1=\" \" ind2=\"0\">`\\n    - From cataloguing administrative metadata, not in source but typical.\\n\\n16. **214 field** â€” Imprint information (Publication):\\n\\n    - `<datafield tag=\"214\" ind1=\" \" ind2=\"0\">`\\n      - `<subfield code=\"a\">Paris</subfield>` â€” place of publication (metadata: Paris)\\n      - `<subfield code=\"c\">Robert Laffont</subfield>` â€” publisher\\n      - `<subfield code=\"d\">DL 2019</subfield>` â€” date, legal deposit year (DL 2019)\\n    - Maps directly from metadata imprint data.\\n\\n17. **215 field** â€” Physical description:\\n\\n    - `<datafield tag=\"215\" ind1=\" \" ind2=\" \">`\\n      - `<subfield code=\"a\">1 vol. (250 p.)</subfield>` â€” volume and pages\\n      - `<subfield code=\"c\">ill., couv. ill. en coul.</subfield>` â€” includes illustrations and cover in color (from \"Illustrations, color illustrated cover\")\\n      - `<subfield code=\"d\">22 cm</subfield>` â€” physical size\\n    - Direct mapping from metadata \"Material description\".\\n\\n18. **225 and 410 fields** â€” Series or Collection:\\n\\n    - `<datafield tag=\"225\" ind1=\"0\" ind2=\" \">`\\n      - `<subfield code=\"a\">RÃ©ponses</subfield>`\\n    - `<datafield tag=\"410\" ind1=\" \" ind2=\"|\">`\\n      - `<subfield code=\"0\">001026399</subfield>` â€” series identifier (from catalogue\\'s own authority files)\\n      - `<subfield code=\"t\">RÃ©ponses (Paris. 1967)</subfield>` â€” series title with place and founding year\\n      - `<subfield code=\"x\">0750-7747</subfield>` â€” ISSN for the series\\n    - From metadata \"Collection/Series: RÃ©ponses\" and ISSN 0750-7747\\n\\n19. **606 fields** â€” Subject headings:\\n\\n    - Two fields for RAMEAU subjects:\\n      - `<datafield tag=\"606\"><subfield code=\"3\">027347893</subfield><subfield code=\"a\">Hatha-yoga</subfield><subfield code=\"2\">rameau</subfield></datafield>`\\n      - `<datafield tag=\"606\"><subfield code=\"3\">027425541</subfield><subfield code=\"a\">Exercices physiques pour personnes Ã¢gÃ©es</subfield><subfield code=\"2\">rameau</subfield></datafield>`\\n    - Map from keywords/subject headings with authority source \"RAMEAU\".\\n\\n20. **676 and 686 fields** â€” Classification schemes:\\n\\n    - `<datafield tag=\"676\"><subfield code=\"a\">613.710 846</subfield><subfield code=\"v\">23</subfield></datafield>`\\n      - 613.710 is Dewey number, 846 possibly language or variant, 23 is DDC edition.\\n    - `<datafield tag=\"686\"><subfield code=\"a\">610</subfield><subfield code=\"2\">Cadre de classement de la Bibliographie nationale franÃ§aise</subfield></datafield>`\\n      - The French national bibliography classification number 610\\n\\n21. **330 field** â€” Summary / Abstract:\\n\\n    - `<datafield tag=\"330\"><subfield code=\"a\">[full abstract text]</subfield><subfield code=\"2\">Ã©diteur</subfield></datafield>`\\n    - The long abstract text from metadata \"Abstract/Notes\" with the source \"Ã©diteur\" (publisher).\\n\\n---\\n\\n### Summary Table of key mappings:\\n\\n| Metadata element                  | UNIMARC tag and subfield      | Note                                      |\\n|---------------------------------|-------------------------------|-------------------------------------------|\\n| Title                           | 200$a                         | Main title                               |\\n| Subtitle                        | 200$e                         | Subtitle                                 |\\n| Author (main)                   | 200$f, 700$a(b)(f)            | Statement of responsibility and author info with dates |\\n| Participant                    | 200$f, 702$a(b)(f)(c)         | Statement and contributor info with profession  |\\n| ISBN                           | 010$a                        | ISBN number                              |\\n| Binding                        | 010$b                        | Binding type (\\'br.\\' for paperback)       |\\n| EAN                            | 073$a                        | EAN other identifier                     |\\n| OCLC number                    | 035$a                        | System control number                     |\\n| Language                       | 101$a                        | lang code \\'fre\\'                          |\\n| Place of publication           | 214$a                        | Place of publication                     |\\n| Publisher                     | 214$c                        | Publisher                               |\\n| Date of publication (legal deposit) | 214$d                    | Date (DL 2019)                          |\\n| Physical description (volumes, pages) | 215$a                 | Number of volumes and pages              |\\n| Physical description (illustrations) | 215$c                  | Illustrations and cover details           |\\n| Physical description (dimensions) | 215$d                      | Size in cm                              |\\n| Series                        | 225$a                         | Series name                            |\\n| Series info (Series identifier, title, ISSN) | 410$0 410$t 410$x | Series authority and ISSN info          |\\n| Subjects (RAMEAU terms)        | 606$a and 606$2               | Subject headings with authority code    |\\n| Dewey / French classification | 676$a (DDC), 686$a (FNB classification) | Classification schemes                |\\n| Notes bibliogr.               | 320$a                        | Bibliographic notes                      |\\n| Abstract                      | 330$a and 330$2               | Abstract and its source (publisher)      |\\n| Material type and carrier info | 105, 106, 181, 182, 183       | Content, media, carrier codes             |\\n| Place of publication country   | 102$a                        | Country code                            |\\n| Authority and control numbers  | 035, 100 etc.                  | IDs and cataloguing system info          |\\n| Cataloguing data and source    | 801                           | Cataloguing institution, date            |\\n\\n---\\n\\n### Additional notes:\\n\\n- Some fields (controlfields 001, 003, 005, 035, 100, 801) are system-generated and come from cataloguing process and integration with national and international systems.\\n- Relator codes `$4` in 700/702 fields correspond to the role of the person (author or contributor), respectively 070 and 205.\\n- The authors\\' names are split by family name and given name parts according to authority records.\\n- Professional designation (pÃ©diatre) is placed in 702$c.\\n- Binding type \"br.\" (brochÃ©) is deduced from material (typical for paperbacks).\\n- The \"DL 2019\" is copied literally into 214$d noting the legal deposit date.\\n- Language code is \"fre\" per ISO 639-2.\\n- Abstract is very long and fully included in 330$a with subfield $2 indicating its source.\\n- ISBN appears twice: as 010$a/b (ISBN + binding type) and 073$a (EAN without hyphens).\\n- The dimensions, volume count, number of pages, and illustration details are composed in 215.\\n- The series information includes both 225 (series title) and 410 (series authority control number, titles, ISSN).\\n- Subject headings use RAMEAU authority code in $2.\\n\\n---\\n\\nThis stepwise mapping explains how each piece of your metadata is encoded into UNIMARC XML fields and subfields as presented in the example record.\\n</think>\\n\\n<record><controlfield tag=\"005\">20210208123415.000</controlfield><leader> cam0 22        450 </leader><controlfield tag=\"001\">236807005</controlfield><controlfield tag=\"003\">http://www.sudoc.fr/236807005</controlfield><datafield tag=\"035\" ind1=\" \" ind2=\" \"><subfield code=\"a\">(OCoLC)1107377985</subfield></datafield><datafield tag=\"010\" ind1=\" \" ind2=\" \"><subfield code=\"a\">978-2-221-24174-5</subfield><subfield code=\"b\">br.</subfield></datafield><datafield tag=\"073\" ind1=\" \" ind2=\"1\"><subfield code=\"a\">9782221241745</subfield></datafield><datafield tag=\"035\" ind1=\" \" ind2=\" \"><subfield code=\"a\">FRBNF457384730000008</subfield><subfield code=\"z\">FRBNF45738473</subfield></datafield><datafield tag=\"100\" ind1=\" \" ind2=\" \"><subfield code=\"a\">20190703h20192019m  y0frey50      ba</subfield></datafield><datafield tag=\"101\" ind1=\"0\" ind2=\" \"><subfield code=\"a\">fre</subfield><subfield code=\"2\">639-2</subfield></datafield><datafield tag=\"105\" ind1=\" \" ind2=\" \"><subfield code=\"a\">a   ||||000yy</subfield></datafield><datafield tag=\"106\" ind1=\" \" ind2=\" \"><subfield code=\"a\">r</subfield></datafield><datafield tag=\"181\" ind1=\" \" ind2=\" \"><subfield code=\"6\">z01</subfield><subfield code=\"c\">txt</subfield><subfield code=\"2\">rdacontent</subfield></datafield><datafield tag=\"181\" ind1=\" \" ind2=\"1\"><subfield code=\"6\">z01</subfield><subfield code=\"a\">i#</subfield><subfield code=\"b\">xxxe##</subfield></datafield><datafield tag=\"182\" ind1=\" \" ind2=\" \"><subfield code=\"6\">z01</subfield><subfield code=\"c\">n</subfield><subfield code=\"2\">rdamedia</subfield></datafield><datafield tag=\"182\" ind1=\" \" ind2=\"1\"><subfield code=\"6\">z01</subfield><subfield code=\"a\">n</subfield></datafield><datafield tag=\"183\" ind1=\" \" ind2=\"1\"><subfield code=\"6\">z01</subfield><subfield code=\"a\">nga</subfield><subfield code=\"2\">RDAfrCarrier</subfield></datafield><datafield tag=\"102\" ind1=\" \" ind2=\" \"><subfield code=\"a\">FR</subfield></datafield><datafield tag=\"320\" ind1=\" \" ind2=\" \"><subfield code=\"a\">Notes bibliogr.</subfield></datafield><datafield tag=\"200\" ind1=\"1\" ind2=\" \"><subfield code=\"a\">Yoga senior</subfield><subfield code=\"e\">la mÃ©thode de Gasquet</subfield><subfield code=\"f\">Dr Bernadette de Gasquet</subfield><subfield code=\"f\">avec la participation du Dr Marie Thirion</subfield></datafield><datafield tag=\"700\" ind1=\" \" ind2=\"1\"><subfield code=\"3\">084278986</subfield><subfield code=\"a\">Gasquet</subfield><subfield code=\"b\">Bernadette de</subfield><subfield code=\"f\">1946-....</subfield><subfield code=\"4\">070</subfield></datafield><datafield tag=\"702\" ind1=\" \" ind2=\"1\"><subfield code=\"3\">028312635</subfield><subfield code=\"a\">Thirion</subfield><subfield code=\"b\">Marie</subfield><subfield code=\"f\">1944-....</subfield><subfield code=\"c\">pÃ©diatre</subfield><subfield code=\"4\">205</subfield></datafield><datafield tag=\"801\" ind1=\" \" ind2=\"3\"><subfield code=\"a\">FR</subfield><subfield code=\"b\">Abes</subfield><subfield code=\"c\">20210208</subfield><subfield code=\"g\">AFNOR</subfield></datafield><datafield tag=\"214\" ind1=\" \" ind2=\"0\"><subfield code=\"a\">Paris</subfield><subfield code=\"c\">Robert Laffont</subfield><subfield code=\"d\">DL 2019</subfield></datafield><datafield tag=\"215\" ind1=\" \" ind2=\" \"><subfield code=\"a\">1 vol. (250 p.)</subfield><subfield code=\"c\">ill., couv. ill. en coul.</subfield><subfield code=\"d\">22 cm</subfield></datafield><datafield tag=\"225\" ind1=\"0\" ind2=\" \"><subfield code=\"a\">RÃ©ponses</subfield></datafield><datafield tag=\"410\" ind1=\" \" ind2=\"|\"><subfield code=\"0\">001026399</subfield><subfield code=\"t\">RÃ©ponses (Paris. 1967)</subfield><subfield code=\"x\">0750-7747</subfield></datafield><datafield tag=\"606\" ind1=\" \" ind2=\" \"><subfield code=\"3\">027347893</subfield><subfield code=\"a\">Hatha-yoga</subfield><subfield code=\"2\">rameau</subfield></datafield><datafield tag=\"606\" ind1=\" \" ind2=\" \"><subfield code=\"3\">027425541</subfield><subfield code=\"a\">Exercices physiques pour personnes Ã¢gÃ©es</subfield><subfield code=\"2\">rameau</subfield></datafield><datafield tag=\"676\" ind1=\" \" ind2=\" \"><subfield code=\"a\">613.710 846</subfield><subfield code=\"v\">23</subfield></datafield><datafield tag=\"686\" ind1=\" \" ind2=\" \"><subfield code=\"a\">610</subfield><subfield code=\"2\">Cadre de classement de la Bibliographie nationale franÃ§aise</subfield></datafield><datafield tag=\"801\" ind1=\" \" ind2=\"0\"><subfield code=\"a\">FR</subfield><subfield code=\"b\">FR-751131015</subfield><subfield code=\"c\">20190529</subfield><subfield code=\"g\">AFNOR</subfield><subfield code=\"2\">intermrc</subfield></datafield><datafield tag=\"330\" ind1=\" \" ind2=\" \"><subfield code=\"a\">La mÃ©thode de Gasquet enfin adaptÃ©e aux seniors ! Quelle activitÃ© physique pratiquer lorsque, Ã  50 ans, des fragilitÃ©s corporelles et des douleurs apparaissent ? Comment prendre soin de soi, garder un corps fonctionnel et source de plaisir ? SpÃ©cialiste du pÃ©rinÃ©e, professeure de yoga, reconnue et suivie par des mÃ©decins, des sages-femmes, des kinÃ©sithÃ©rapeutes et des coachs sportifs dans le monde entier, Bernadette de Gasquet adapte dans ce livre sa cÃ©lÃ¨bre mÃ©thode aux seniors et propose un travail sur le renforcement musculaire, sans recherche de la performance, Ã  travers des exercices simples. Travail corporel sans douleur et sans risque, discipline au service de l\\'Ãªtre humain, le yoga peut Ãªtre pratiquÃ© Ã  tout Ã¢ge. En alternant tonification et dÃ©tente, renforcements et Ã©tirements, en associant respiration et action sur les fonctions vitales, on peut garder un corps en pleine forme. Bernadette de Gasquet reprend ici les bases de l\\'activitÃ© physique â€“ postures, respiration, abdominaux â€“ en se concentrant sur les maux des seniors â€“ douleurs articulaires, problÃ¨mes de circulation, de constipation, hypertension, troubles respiratoires, rhumatismes... â€“ pour leur donner les clÃ©s d\\'une vie plus saine et du bien-Ãªtre au quotidien. 200 photos, 15 schÃ©mas, des exercices filmÃ©s... Yoga senior vous propose de nombreux conseils pratiques et des exercices physiques adaptÃ©s pour rester en forme aprÃ¨s 50 ans</subfield><subfield code=\"2\">Ã©diteur</subfield></datafield></record><|im_end|>\\n'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_dataset[0][\"text\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca142fbd-2ccd-40b5-9750-61bd89047afc",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2d985541-765a-460c-a827-8a3a62163dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset\n",
    "train_size = int(len(combined_dataset) * 0.9)\n",
    "train_dataset = combined_dataset.select(range(train_size))\n",
    "eval_dataset = combined_dataset.select(range(train_size, len(combined_dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5742e969-e02f-4a03-89a4-a25ce5dcd08f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth: Tokenizing [\"text\"] (num_proc=104): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 785/785 [00:40<00:00, 19.31 examples/s]\n",
      "num_proc must be <= 88. Reducing num_proc to 88 for dataset of size 88.\n",
      "Unsloth: Tokenizing [\"text\"] (num_proc=88):  27%|â–ˆâ–ˆâ–‹       | 24/88 [00:11<00:27,  2.30 examples/s]"
     ]
    }
   ],
   "source": [
    "from trl import SFTTrainer, SFTConfig\n",
    "trainer = SFTTrainer(\n",
    "    model = model,\n",
    "    tokenizer = tokenizer,\n",
    "    train_dataset = train_dataset,\n",
    "    eval_dataset = eval_dataset,\n",
    "    args = SFTConfig(\n",
    "        dataset_text_field = \"text\",\n",
    "        per_device_train_batch_size = 2,\n",
    "        gradient_accumulation_steps = 4, # Use GA to mimic batch size!\n",
    "        warmup_steps = 5,\n",
    "        # num_train_epochs = 1, # Set this for 1 full training run.\n",
    "        max_steps = 30,\n",
    "        learning_rate = 2e-4, # Reduce to 2e-5 for long training runs\n",
    "        logging_steps = 1,\n",
    "        optim = \"adamw_8bit\",\n",
    "        weight_decay = 0.01,\n",
    "        lr_scheduler_type = \"linear\",\n",
    "        seed = 3407,\n",
    "        report_to = \"none\", # Use this for WandB etc\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b0ab40bb-56f9-4fde-aebe-e241208b88a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n",
      "   \\\\   /|    Num examples = 873 | Num Epochs = 1 | Total steps = 30\n",
      "O^O/ \\_/ \\    Batch size per device = 2 | Gradient accumulation steps = 4\n",
      "\\        /    Data Parallel GPUs = 1 | Total batch size (2 x 4 x 1) = 8\n",
      " \"-____-\"     Trainable parameters = 20,185,088/6,000,000,000 (0.34% trained)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsloth: Will smartly offload gradients to save VRAM!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='30' max='30' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [30/30 08:29, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.585700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.585300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.492200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.496300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.456100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1.371700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1.500300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1.404000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>1.344200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.288800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>1.334800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>1.181300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>1.222100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>1.319900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>1.172900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>1.221200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>1.200100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>1.243300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>1.257200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1.366700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>1.119300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>1.190100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>1.099900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>1.209700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>1.250500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>1.112000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>1.184500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>1.135700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>1.247300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1.267200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer_stats = trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68d42907-7512-4112-82e0-6fae56e4369f",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_metadata = \"\"\"\n",
    "Title: La dynastie des Ming\n",
    "Author: Jean-Pierre Duteil\n",
    "Editor/Director: sous la direction de Jean Heuclin\n",
    "Author details:\n",
    "- Duteil, Jean-Pierre (1952-...)\n",
    "- Heuclin, Jean (1949-...), historien\n",
    "Edition: Nouvelle Ã©dition\n",
    "Publisher: Ellipses\n",
    "Place of publication: Paris\n",
    "Year: 2024\n",
    "ISBN: 978-2-340-08969-3 (note: also 9782340089693)\n",
    "Language: French\n",
    "Country of publication: France\n",
    "Physical description: 1 volume (287 pages), includes cartes, plans, cover illustrated in color, 18 cm\n",
    "Bibliography: Bibliogr. p. 279-286\n",
    "Abstract/Notes:\n",
    "Les Ming, une dynastie brillante dominÃ©e par les Han installÃ©s Ã  PÃ©kin Ã  lâ€™Ã©poque du Quattrocento et de la Renaissance en Europe ; les deux civilisations devaient se rencontrer par une expansion maritime similaire, une dÃ©couverte inquiÃ¨te et remplie des mystÃ¨res orientaux. Le fondateur Hongwu (1368-1398) Ã  lâ€™instar de notre Henri IV, tournant le dos Ã  lâ€™influence nomade mongole, Ã©tablit une sociÃ©tÃ© rurale autosuffisante dont lâ€™essor des productions cÃ©rÃ©aliÃ¨res alimenta toute une Ã©conomie marchande et urbaine. Des projets grandioses virent le jour comme le Grand Canal, la Grande Muraille ou la CitÃ© interdite avec une puissante marine et une armÃ©e de mÃ©tier. Tout un systÃ¨me administratif de fonctionnaires recrutÃ©s par concours sur leurs mÃ©rites accompagne une remarquable crÃ©ation littÃ©raire, calligraphique et artistique facilitÃ©e par lâ€™impression de livres. Cette magnifique construction tomba progressivement sous lâ€™emprise sclÃ©rosante de ces mÃªmes Â« lettrÃ©s Â» trop empreints dâ€™un confucianisme qui rÃ©sistait mal Ã  la critique de la politique gouvernementale et au comportement extravagant des empereurs. Des rÃ©voltes se firent jour durant le dernier siÃ¨cle de la dynastie marquÃ©e par une succession de catastrophes naturelles et dâ€™Ã©pidÃ©mies qui ruinÃ¨rent lâ€™une des pÃ©riodes les plus riches de lâ€™histoire de lâ€™Empire du Milieu.\n",
    "Source of the abstract/notes: 4e de couverture (back cover)\n",
    "Subject/Keywords:\n",
    "- Chine\n",
    "- Dynastie des Ming (1368-1644)\n",
    "Classification: 951.02 (subject classification)\n",
    "Publication history note: Paru prÃ©cÃ©demment en 2016\n",
    "Additional edition note: La 1Ã¨re Ã©dition de ce livre a Ã©tÃ© publiÃ©e en grand format en 2016 dans la collection \"Biographies et mythes historiques\" dirigÃ©e par StÃ©phane Curveiller\n",
    "Collection/Series: Collection \"Biographies et mythes historiques\" (inferred from note about first edition)\n",
    "\"\"\"\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": system_prompt},\n",
    "    {\"role\": \"user\", \"content\": f\"Please convert this metadata to UNIMARC/XML:\\n{user_metadata}\"},\n",
    "]\n",
    "text = tokenizer.apply_chat_template(\n",
    "    messages,\n",
    "    tokenize = False,\n",
    "    add_generation_prompt = True, # Must add for generation\n",
    "    enable_thinking = True\n",
    ")\n",
    "\n",
    "from transformers import TextStreamer\n",
    "_ = model.generate(\n",
    "    **tokenizer(text, return_tensors = \"pt\").to(\"cuda\"),\n",
    "    max_new_tokens = 4096, # Increase for longer outputs!\n",
    "    temperature = 0.6, top_p = 0.95, top_k = 20, # For thinking\n",
    "    streamer = TextStreamer(tokenizer, skip_prompt = True),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf43e8ca-efc7-4a4c-8292-de1dea6a70ab",
   "metadata": {},
   "source": [
    "# Unsloth GRPO\n",
    "\n",
    "*https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/Phi_4_(14B)-GRPO.ipynb#scrollTo=DkIvEkIIkEyB*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "371781c4-3035-4568-9f6b-d8abc010e69c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U --quiet fuzzywuzzy unsloth vllm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d9a37f51-5e39-4315-921d-e58085c20982",
   "metadata": {},
   "outputs": [],
   "source": [
    "del trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4044d7ae-ab63-4b98-a53b-1b3af9e23ac1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsloth: Switching from Unsloth dynamic quant to normal quant since\n",
      "we do not yet support fast inference for unsloth/qwen3-0.6b-unsloth-bnb-4bit\n",
      "==((====))==  Unsloth 2025.5.1: Fast Qwen3 patching. Transformers: 4.51.3. vLLM: 0.8.5.post1.\n",
      "   \\\\   /|    NVIDIA A2. Num GPUs = 1. Max memory: 14.529 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.6.0+cu124. CUDA: 8.6. CUDA Toolkit: 12.4. Triton: 3.2.0\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.29.post2. FA2 = False]\n",
      " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n",
      "Unsloth: Your GPU cannot handle sequence lengths of 256 due to limited GPU memory.\n",
      "Unsloth: Your GPU can only handle approximately the maximum sequence length of 256.\n",
      "Unsloth: vLLM loading unsloth/qwen3-0.6b-bnb-4bit with actual GPU utilization = 3.0%\n",
      "Unsloth: Your GPU has CUDA compute capability 8.6 with VRAM = 14.53 GB.\n",
      "Unsloth: Using conservativeness = 1.0. Chunked prefill tokens = 256. Num Sequences = 128.\n",
      "Unsloth: vLLM's KV Cache can use up to 0.0 GB. Also swap space = 6 GB.\n",
      "INFO 05-13 13:18:25 [config.py:717] This model supports multiple tasks: {'embed', 'generate', 'classify', 'score', 'reward'}. Defaulting to 'generate'.\n",
      "INFO 05-13 13:18:25 [config.py:2003] Chunked prefill is enabled with max_num_batched_tokens=256.\n",
      "Unsloth: vLLM Bitsandbytes config using kwargs = {'load_in_8bit': False, 'load_in_4bit': True, 'bnb_4bit_compute_dtype': 'bfloat16', 'bnb_4bit_quant_storage': 'uint8', 'bnb_4bit_quant_type': 'nf4', 'bnb_4bit_use_double_quant': True, 'llm_int8_enable_fp32_cpu_offload': False, 'llm_int8_has_fp16_weight': False, 'llm_int8_skip_modules': ['lm_head', 'multi_modal_projector', 'merger', 'modality_projection'], 'llm_int8_threshold': 6.0}\n",
      "INFO 05-13 13:18:27 [core.py:58] Initializing a V1 LLM engine (v0.8.5.post1) with config: model='unsloth/qwen3-0.6b-bnb-4bit', speculative_config=None, tokenizer='unsloth/qwen3-0.6b-bnb-4bit', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=256, download_dir=None, load_format=LoadFormat.BITSANDBYTES, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=bitsandbytes, enforce_eager=False, kv_cache_dtype=auto,  device_config=cuda:0, decoding_config=DecodingConfig(guided_decoding_backend='auto', reasoning_backend=None), observability_config=ObservabilityConfig(show_hidden_metrics=False, otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=unsloth/qwen3-0.6b-bnb-4bit, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=True, chunked_prefill_enabled=True, use_async_output_proc=True, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={\"level\":3,\"custom_ops\":[\"none\"],\"splitting_ops\":[\"vllm.unified_attention\",\"vllm.unified_attention_with_output\"],\"use_inductor\":true,\"compile_sizes\":[],\"use_cudagraph\":true,\"cudagraph_num_of_warmups\":1,\"cudagraph_capture_sizes\":[256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],\"max_capture_size\":256}\n",
      "WARNING 05-13 13:18:27 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7f11f610ce90>\n",
      "WARNING 05-13 13:18:28 [topk_topp_sampler.py:69] FlashInfer is not available. Falling back to the PyTorch-native implementation of top-p & top-k sampling. For the best performance, please install FlashInfer.\n",
      "INFO 05-13 13:18:28 [gpu_model_runner.py:1329] Starting to load model unsloth/qwen3-0.6b-bnb-4bit...\n",
      "INFO 05-13 13:18:28 [loader.py:1187] Loading weights with BitsAndBytes quantization. May take a while ...\n",
      "INFO 05-13 13:18:28 [weight_utils.py:265] Using model weights format ['*.safetensors']\n",
      "INFO 05-13 13:18:29 [weight_utils.py:315] No model.safetensors.index.json found in remote.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]\n",
      "Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsloth: Retrying vLLM to process 96 sequences and 256 tokens in tandem.\n",
      "Error:\n",
      "CUDA out of memory. Tried to allocate 304.00 MiB. GPU 0 has a total capacity of 14.53 GiB of which 174.00 MiB is free. Process 3968688 has 14.35 GiB memory in use. Of the allocated memory 13.11 GiB is allocated by PyTorch, with 37.88 MiB allocated in private pools (e.g., CUDA Graphs), and 64.60 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "INFO 05-13 13:18:33 [config.py:717] This model supports multiple tasks: {'embed', 'generate', 'classify', 'score', 'reward'}. Defaulting to 'generate'.\n",
      "INFO 05-13 13:18:33 [config.py:2003] Chunked prefill is enabled with max_num_batched_tokens=256.\n",
      "Unsloth: vLLM Bitsandbytes config using kwargs = {'load_in_8bit': False, 'load_in_4bit': True, 'bnb_4bit_compute_dtype': 'bfloat16', 'bnb_4bit_quant_storage': 'uint8', 'bnb_4bit_quant_type': 'nf4', 'bnb_4bit_use_double_quant': True, 'llm_int8_enable_fp32_cpu_offload': False, 'llm_int8_has_fp16_weight': False, 'llm_int8_skip_modules': ['lm_head', 'multi_modal_projector', 'merger', 'modality_projection'], 'llm_int8_threshold': 6.0}\n",
      "INFO 05-13 13:18:35 [core.py:58] Initializing a V1 LLM engine (v0.8.5.post1) with config: model='unsloth/qwen3-0.6b-bnb-4bit', speculative_config=None, tokenizer='unsloth/qwen3-0.6b-bnb-4bit', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=256, download_dir=None, load_format=LoadFormat.BITSANDBYTES, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=bitsandbytes, enforce_eager=False, kv_cache_dtype=auto,  device_config=cuda:0, decoding_config=DecodingConfig(guided_decoding_backend='auto', reasoning_backend=None), observability_config=ObservabilityConfig(show_hidden_metrics=False, otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=unsloth/qwen3-0.6b-bnb-4bit, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=True, chunked_prefill_enabled=True, use_async_output_proc=True, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={\"level\":3,\"custom_ops\":[\"none\"],\"splitting_ops\":[\"vllm.unified_attention\",\"vllm.unified_attention_with_output\"],\"use_inductor\":true,\"compile_sizes\":[],\"use_cudagraph\":true,\"cudagraph_num_of_warmups\":1,\"cudagraph_capture_sizes\":[256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],\"max_capture_size\":256}\n",
      "WARNING 05-13 13:18:35 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7f11f55f18b0>\n",
      "WARNING 05-13 13:18:36 [topk_topp_sampler.py:69] FlashInfer is not available. Falling back to the PyTorch-native implementation of top-p & top-k sampling. For the best performance, please install FlashInfer.\n",
      "INFO 05-13 13:18:36 [gpu_model_runner.py:1329] Starting to load model unsloth/qwen3-0.6b-bnb-4bit...\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 304.00 MiB. GPU 0 has a total capacity of 14.53 GiB of which 174.00 MiB is free. Process 3968688 has 14.35 GiB memory in use. Of the allocated memory 13.11 GiB is allocated by PyTorch, with 37.88 MiB allocated in private pools (e.g., CUDA Graphs), and 64.60 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mOutOfMemoryError\u001b[39m                          Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/unsloth_zoo/vllm_utils.py:1141\u001b[39m, in \u001b[36mload_vllm\u001b[39m\u001b[34m(model_name, config, gpu_memory_utilization, max_seq_length, dtype, training, float8_kv_cache, random_state, enable_lora, max_lora_rank, max_loras, use_async, use_engine, disable_log_stats, enforce_eager, enable_prefix_caching, compilation_config, conservativeness, max_logprobs, use_bitsandbytes, return_args)\u001b[39m\n\u001b[32m   1140\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1141\u001b[39m     llm = \u001b[43mLLM\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mengine_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1142\u001b[39m \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/vllm/utils.py:1161\u001b[39m, in \u001b[36mdeprecate_args.<locals>.wrapper.<locals>.inner\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m   1156\u001b[39m         warnings.warn(\n\u001b[32m   1157\u001b[39m             \u001b[38;5;167;01mDeprecationWarning\u001b[39;00m(msg),\n\u001b[32m   1158\u001b[39m             stacklevel=\u001b[32m3\u001b[39m,  \u001b[38;5;66;03m# The inner function takes up one level\u001b[39;00m\n\u001b[32m   1159\u001b[39m         )\n\u001b[32m-> \u001b[39m\u001b[32m1161\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/vllm/entrypoints/llm.py:247\u001b[39m, in \u001b[36mLLM.__init__\u001b[39m\u001b[34m(self, model, tokenizer, tokenizer_mode, skip_tokenizer_init, trust_remote_code, allowed_local_media_path, tensor_parallel_size, dtype, quantization, revision, tokenizer_revision, seed, gpu_memory_utilization, swap_space, cpu_offload_gb, enforce_eager, max_seq_len_to_capture, disable_custom_all_reduce, disable_async_output_proc, hf_token, hf_overrides, mm_processor_kwargs, task, override_pooler_config, compilation_config, **kwargs)\u001b[39m\n\u001b[32m    246\u001b[39m \u001b[38;5;66;03m# Create the Engine (autoselects V0 vs V1)\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m247\u001b[39m \u001b[38;5;28mself\u001b[39m.llm_engine = \u001b[43mLLMEngine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_engine_args\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    248\u001b[39m \u001b[43m    \u001b[49m\u001b[43mengine_args\u001b[49m\u001b[43m=\u001b[49m\u001b[43mengine_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43musage_context\u001b[49m\u001b[43m=\u001b[49m\u001b[43mUsageContext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mLLM_CLASS\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    249\u001b[39m \u001b[38;5;28mself\u001b[39m.engine_class = \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m.llm_engine)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/vllm/engine/llm_engine.py:510\u001b[39m, in \u001b[36mLLMEngine.from_engine_args\u001b[39m\u001b[34m(cls, engine_args, usage_context, stat_loggers)\u001b[39m\n\u001b[32m    508\u001b[39m     engine_cls = V1LLMEngine\n\u001b[32m--> \u001b[39m\u001b[32m510\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mengine_cls\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_vllm_config\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    511\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvllm_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvllm_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    512\u001b[39m \u001b[43m    \u001b[49m\u001b[43musage_context\u001b[49m\u001b[43m=\u001b[49m\u001b[43musage_context\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    513\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstat_loggers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstat_loggers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    514\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdisable_log_stats\u001b[49m\u001b[43m=\u001b[49m\u001b[43mengine_args\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdisable_log_stats\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    515\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/vllm/v1/engine/llm_engine.py:112\u001b[39m, in \u001b[36mLLMEngine.from_vllm_config\u001b[39m\u001b[34m(cls, vllm_config, usage_context, stat_loggers, disable_log_stats)\u001b[39m\n\u001b[32m    104\u001b[39m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[32m    105\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfrom_vllm_config\u001b[39m(\n\u001b[32m    106\u001b[39m     \u001b[38;5;28mcls\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    110\u001b[39m     disable_log_stats: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    111\u001b[39m ) -> \u001b[33m\"\u001b[39m\u001b[33mLLMEngine\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m112\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mvllm_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvllm_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    113\u001b[39m \u001b[43m               \u001b[49m\u001b[43mexecutor_class\u001b[49m\u001b[43m=\u001b[49m\u001b[43mExecutor\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_class\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvllm_config\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    114\u001b[39m \u001b[43m               \u001b[49m\u001b[43mlog_stats\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdisable_log_stats\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    115\u001b[39m \u001b[43m               \u001b[49m\u001b[43musage_context\u001b[49m\u001b[43m=\u001b[49m\u001b[43musage_context\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    116\u001b[39m \u001b[43m               \u001b[49m\u001b[43mstat_loggers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstat_loggers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    117\u001b[39m \u001b[43m               \u001b[49m\u001b[43mmultiprocess_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43menvs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mVLLM_ENABLE_V1_MULTIPROCESSING\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/vllm/v1/engine/llm_engine.py:92\u001b[39m, in \u001b[36mLLMEngine.__init__\u001b[39m\u001b[34m(self, vllm_config, executor_class, log_stats, usage_context, stat_loggers, mm_registry, use_cached_outputs, multiprocess_mode)\u001b[39m\n\u001b[32m     91\u001b[39m \u001b[38;5;66;03m# EngineCore (gets EngineCoreRequests and gives EngineCoreOutputs)\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m92\u001b[39m \u001b[38;5;28mself\u001b[39m.engine_core = \u001b[43mEngineCoreClient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmake_client\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     93\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmultiprocess_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmultiprocess_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     94\u001b[39m \u001b[43m    \u001b[49m\u001b[43masyncio_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     95\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvllm_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvllm_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     96\u001b[39m \u001b[43m    \u001b[49m\u001b[43mexecutor_class\u001b[49m\u001b[43m=\u001b[49m\u001b[43mexecutor_class\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     97\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlog_stats\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# FIXME: implement\u001b[39;49;00m\n\u001b[32m     98\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    100\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m multiprocess_mode:\n\u001b[32m    101\u001b[39m     \u001b[38;5;66;03m# for v0 compatibility\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/vllm/v1/engine/core_client.py:75\u001b[39m, in \u001b[36mEngineCoreClient.make_client\u001b[39m\u001b[34m(multiprocess_mode, asyncio_mode, vllm_config, executor_class, log_stats)\u001b[39m\n\u001b[32m     73\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m SyncMPClient(vllm_config, executor_class, log_stats)\n\u001b[32m---> \u001b[39m\u001b[32m75\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mInprocClient\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvllm_config\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexecutor_class\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog_stats\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/vllm/v1/engine/core_client.py:198\u001b[39m, in \u001b[36mInprocClient.__init__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    197\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, *args, **kwargs):\n\u001b[32m--> \u001b[39m\u001b[32m198\u001b[39m     \u001b[38;5;28mself\u001b[39m.engine_core = \u001b[43mEngineCore\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/vllm/v1/engine/core.py:64\u001b[39m, in \u001b[36mEngineCore.__init__\u001b[39m\u001b[34m(self, vllm_config, executor_class, log_stats, executor_fail_callback)\u001b[39m\n\u001b[32m     63\u001b[39m \u001b[38;5;66;03m# Setup Model.\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m64\u001b[39m \u001b[38;5;28mself\u001b[39m.model_executor = \u001b[43mexecutor_class\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvllm_config\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     65\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m executor_fail_callback \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/vllm/executor/executor_base.py:52\u001b[39m, in \u001b[36mExecutorBase.__init__\u001b[39m\u001b[34m(self, vllm_config)\u001b[39m\n\u001b[32m     51\u001b[39m \u001b[38;5;28mself\u001b[39m.observability_config = vllm_config.observability_config\n\u001b[32m---> \u001b[39m\u001b[32m52\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_init_executor\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     53\u001b[39m \u001b[38;5;28mself\u001b[39m.is_sleeping = \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/vllm/executor/uniproc_executor.py:47\u001b[39m, in \u001b[36mUniProcExecutor._init_executor\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     46\u001b[39m \u001b[38;5;28mself\u001b[39m.collective_rpc(\u001b[33m\"\u001b[39m\u001b[33minit_device\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m47\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcollective_rpc\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mload_model\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/vllm/executor/uniproc_executor.py:56\u001b[39m, in \u001b[36mUniProcExecutor.collective_rpc\u001b[39m\u001b[34m(self, method, timeout, args, kwargs)\u001b[39m\n\u001b[32m     55\u001b[39m     kwargs = {}\n\u001b[32m---> \u001b[39m\u001b[32m56\u001b[39m answer = \u001b[43mrun_method\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdriver_worker\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     57\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m [answer]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/vllm/utils.py:2456\u001b[39m, in \u001b[36mrun_method\u001b[39m\u001b[34m(obj, method, args, kwargs)\u001b[39m\n\u001b[32m   2455\u001b[39m     func = partial(method, obj)  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2456\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py:162\u001b[39m, in \u001b[36mWorker.load_model\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    161\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m context:\n\u001b[32m--> \u001b[39m\u001b[32m162\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel_runner\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py:1332\u001b[39m, in \u001b[36mGPUModelRunner.load_model\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1331\u001b[39m time_before_load = time.perf_counter()\n\u001b[32m-> \u001b[39m\u001b[32m1332\u001b[39m \u001b[38;5;28mself\u001b[39m.model = \u001b[43mget_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvllm_config\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mvllm_config\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1333\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.lora_config:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/vllm/model_executor/model_loader/__init__.py:14\u001b[39m, in \u001b[36mget_model\u001b[39m\u001b[34m(vllm_config)\u001b[39m\n\u001b[32m     13\u001b[39m loader = get_model_loader(vllm_config.load_config)\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mloader\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvllm_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvllm_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/vllm/model_executor/model_loader/loader.py:1310\u001b[39m, in \u001b[36mBitsAndBytesModelLoader.load_model\u001b[39m\u001b[34m(self, vllm_config)\u001b[39m\n\u001b[32m   1309\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.device(device_config.device):\n\u001b[32m-> \u001b[39m\u001b[32m1310\u001b[39m     model = \u001b[43m_initialize_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvllm_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvllm_config\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1312\u001b[39m     \u001b[38;5;28mself\u001b[39m._load_weights(model_config, model)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/vllm/model_executor/model_loader/loader.py:133\u001b[39m, in \u001b[36m_initialize_model\u001b[39m\u001b[34m(vllm_config, prefix, model_class)\u001b[39m\n\u001b[32m    132\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m set_current_vllm_config(vllm_config, check_compile=\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[32m--> \u001b[39m\u001b[32m133\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel_class\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvllm_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvllm_config\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprefix\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprefix\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    135\u001b[39m msg = (\u001b[33m\"\u001b[39m\u001b[33mvLLM model class should accept `vllm_config` and `prefix` as \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    136\u001b[39m        \u001b[33m\"\u001b[39m\u001b[33minput arguments. Possibly you have an old-style model class\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    137\u001b[39m        \u001b[33m\"\u001b[39m\u001b[33m registered from out of tree and it is used for new vLLM version. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    138\u001b[39m        \u001b[33m\"\u001b[39m\u001b[33mCheck https://docs.vllm.ai/en/latest/design/arch_overview.html \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    139\u001b[39m        \u001b[33m\"\u001b[39m\u001b[33mfor the design and update the model class accordingly.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py:269\u001b[39m, in \u001b[36mQwen3ForCausalLM.__init__\u001b[39m\u001b[34m(self, vllm_config, prefix)\u001b[39m\n\u001b[32m    268\u001b[39m \u001b[38;5;28mself\u001b[39m.quant_config = quant_config\n\u001b[32m--> \u001b[39m\u001b[32m269\u001b[39m \u001b[38;5;28mself\u001b[39m.model = \u001b[43mQwen3Model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvllm_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvllm_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    270\u001b[39m \u001b[43m                        \u001b[49m\u001b[43mprefix\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmaybe_prefix\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprefix\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodel\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    272\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m get_pp_group().is_last_rank:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/vllm/compilation/decorators.py:151\u001b[39m, in \u001b[36m_support_torch_compile.<locals>.__init__\u001b[39m\u001b[34m(self, vllm_config, prefix, **kwargs)\u001b[39m\n\u001b[32m    150\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, *, vllm_config: VllmConfig, prefix: \u001b[38;5;28mstr\u001b[39m = \u001b[33m'\u001b[39m\u001b[33m'\u001b[39m, **kwargs):\n\u001b[32m--> \u001b[39m\u001b[32m151\u001b[39m     \u001b[43mold_init\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvllm_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvllm_config\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprefix\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprefix\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    152\u001b[39m     \u001b[38;5;28mself\u001b[39m.vllm_config = vllm_config\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py:241\u001b[39m, in \u001b[36mQwen3Model.__init__\u001b[39m\u001b[34m(self, vllm_config, prefix)\u001b[39m\n\u001b[32m    240\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, *, vllm_config: VllmConfig, prefix: \u001b[38;5;28mstr\u001b[39m = \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m241\u001b[39m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mvllm_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvllm_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    242\u001b[39m \u001b[43m                     \u001b[49m\u001b[43mprefix\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprefix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    243\u001b[39m \u001b[43m                     \u001b[49m\u001b[43mdecoder_layer_type\u001b[49m\u001b[43m=\u001b[49m\u001b[43mQwen3DecoderLayer\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/vllm/compilation/decorators.py:151\u001b[39m, in \u001b[36m_support_torch_compile.<locals>.__init__\u001b[39m\u001b[34m(self, vllm_config, prefix, **kwargs)\u001b[39m\n\u001b[32m    150\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, *, vllm_config: VllmConfig, prefix: \u001b[38;5;28mstr\u001b[39m = \u001b[33m'\u001b[39m\u001b[33m'\u001b[39m, **kwargs):\n\u001b[32m--> \u001b[39m\u001b[32m151\u001b[39m     \u001b[43mold_init\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvllm_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvllm_config\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprefix\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprefix\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    152\u001b[39m     \u001b[38;5;28mself\u001b[39m.vllm_config = vllm_config\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py:294\u001b[39m, in \u001b[36mQwen2Model.__init__\u001b[39m\u001b[34m(self, vllm_config, prefix, decoder_layer_type)\u001b[39m\n\u001b[32m    292\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m get_pp_group().is_first_rank \u001b[38;5;129;01mor\u001b[39;00m (config.tie_word_embeddings\n\u001b[32m    293\u001b[39m                                     \u001b[38;5;129;01mand\u001b[39;00m get_pp_group().is_last_rank):\n\u001b[32m--> \u001b[39m\u001b[32m294\u001b[39m     \u001b[38;5;28mself\u001b[39m.embed_tokens = \u001b[43mVocabParallelEmbedding\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    295\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvocab_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    296\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhidden_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    297\u001b[39m \u001b[43m        \u001b[49m\u001b[43mquant_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mquant_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    298\u001b[39m \u001b[43m        \u001b[49m\u001b[43mprefix\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mprefix\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m.embed_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    299\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    300\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/vllm/model_executor/layers/vocab_parallel_embedding.py:264\u001b[39m, in \u001b[36mVocabParallelEmbedding.__init__\u001b[39m\u001b[34m(self, num_embeddings, embedding_dim, params_dtype, org_num_embeddings, padding_size, quant_config, prefix)\u001b[39m\n\u001b[32m    260\u001b[39m \u001b[38;5;28mself\u001b[39m.num_added_embeddings_per_partition = (\n\u001b[32m    261\u001b[39m     \u001b[38;5;28mself\u001b[39m.shard_indices.added_vocab_end_index -\n\u001b[32m    262\u001b[39m     \u001b[38;5;28mself\u001b[39m.shard_indices.added_vocab_start_index)\n\u001b[32m--> \u001b[39m\u001b[32m264\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mquant_method\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate_weights\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    265\u001b[39m \u001b[43m                                 \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43membedding_dim\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    266\u001b[39m \u001b[43m                                 \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mnum_embeddings_per_partition\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    267\u001b[39m \u001b[43m                                 \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43membedding_dim\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    268\u001b[39m \u001b[43m                                 \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mnum_embeddings_padded\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    269\u001b[39m \u001b[43m                                 \u001b[49m\u001b[43mparams_dtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparams_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    270\u001b[39m \u001b[43m                                 \u001b[49m\u001b[43mweight_loader\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight_loader\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/vllm/model_executor/layers/vocab_parallel_embedding.py:32\u001b[39m, in \u001b[36mUnquantizedEmbeddingMethod.create_weights\u001b[39m\u001b[34m(self, layer, input_size_per_partition, output_partition_sizes, input_size, output_size, params_dtype, **extra_weight_attrs)\u001b[39m\n\u001b[32m     31\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Create weights for embedding layer.\"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m32\u001b[39m weight = Parameter(\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mempty\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43msum\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput_partition_sizes\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     33\u001b[39m \u001b[43m                               \u001b[49m\u001b[43minput_size_per_partition\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     34\u001b[39m \u001b[43m                               \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparams_dtype\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[32m     35\u001b[39m                    requires_grad=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m     36\u001b[39m set_weight_attrs(weight, {\u001b[33m\"\u001b[39m\u001b[33minput_dim\u001b[39m\u001b[33m\"\u001b[39m: \u001b[32m1\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33moutput_dim\u001b[39m\u001b[33m\"\u001b[39m: \u001b[32m0\u001b[39m})\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/torch/utils/_device.py:104\u001b[39m, in \u001b[36mDeviceContext.__torch_function__\u001b[39m\u001b[34m(self, func, types, args, kwargs)\u001b[39m\n\u001b[32m    103\u001b[39m     kwargs[\u001b[33m'\u001b[39m\u001b[33mdevice\u001b[39m\u001b[33m'\u001b[39m] = \u001b[38;5;28mself\u001b[39m.device\n\u001b[32m--> \u001b[39m\u001b[32m104\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mOutOfMemoryError\u001b[39m: CUDA out of memory. Tried to allocate 304.00 MiB. GPU 0 has a total capacity of 14.53 GiB of which 174.00 MiB is free. Process 3968688 has 14.35 GiB memory in use. Of the allocated memory 13.11 GiB is allocated by PyTorch, with 37.88 MiB allocated in private pools (e.g., CUDA Graphs), and 64.60 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[23]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      3\u001b[39m max_seq_length = \u001b[32m4096\u001b[39m \u001b[38;5;66;03m# Can increase for longer reasoning traces\u001b[39;00m\n\u001b[32m      4\u001b[39m lora_rank = \u001b[32m16\u001b[39m \u001b[38;5;66;03m# Larger rank = smarter, but slower\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m model, tokenizer = \u001b[43mFastLanguageModel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mQwen/Qwen3-0.6B\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m#model_name = \"unsloth/Llama-3.2-3B-Instruct\",\u001b[39;49;00m\n\u001b[32m     10\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_seq_length\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_seq_length\u001b[49m\u001b[43m,\u001b[49m\u001b[43m   \u001b[49m\u001b[38;5;66;43;03m# Context length - can be longer, but uses more memory\u001b[39;49;00m\n\u001b[32m     11\u001b[39m \u001b[43m    \u001b[49m\u001b[43mload_in_4bit\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m     \u001b[49m\u001b[38;5;66;43;03m# 4bit uses much less memory\u001b[39;49;00m\n\u001b[32m     12\u001b[39m \u001b[43m    \u001b[49m\u001b[43mload_in_8bit\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# A bit more accurate, uses 2x memory\u001b[39;49;00m\n\u001b[32m     13\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfast_inference\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# Enable vLLM fast inference\u001b[39;49;00m\n\u001b[32m     14\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_lora_rank\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mlora_rank\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     15\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgpu_memory_utilization\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0.7\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m      \u001b[49m\u001b[38;5;66;43;03m# use one if using gated models\u001b[39;49;00m\n\u001b[32m     16\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     18\u001b[39m model = FastLanguageModel.get_peft_model(\n\u001b[32m     19\u001b[39m     model,\n\u001b[32m     20\u001b[39m     r = lora_rank, \u001b[38;5;66;03m# Choose any number > 0 ! Suggested 8, 16, 32, 64, 128\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     25\u001b[39m     random_state = \u001b[32m3407\u001b[39m,\n\u001b[32m     26\u001b[39m )\n\u001b[32m     28\u001b[39m \u001b[38;5;66;03m# !Important\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/unsloth/models/loader.py:376\u001b[39m, in \u001b[36mFastLanguageModel.from_pretrained\u001b[39m\u001b[34m(model_name, max_seq_length, dtype, load_in_4bit, load_in_8bit, full_finetuning, token, device_map, rope_scaling, fix_tokenizer, trust_remote_code, use_gradient_checkpointing, resize_model_vocab, revision, use_exact_model_name, fast_inference, gpu_memory_utilization, float8_kv_cache, random_state, max_lora_rank, disable_log_stats, *args, **kwargs)\u001b[39m\n\u001b[32m    373\u001b[39m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[32m    374\u001b[39m \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m376\u001b[39m model, tokenizer = \u001b[43mdispatch_model\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    377\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m        \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    378\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_seq_length\u001b[49m\u001b[43m    \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_seq_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    379\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m             \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43m_get_dtype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    380\u001b[39m \u001b[43m    \u001b[49m\u001b[43mload_in_4bit\u001b[49m\u001b[43m      \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mload_in_4bit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    381\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m             \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    382\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[43m        \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    383\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrope_scaling\u001b[49m\u001b[43m      \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mrope_scaling\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    384\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfix_tokenizer\u001b[49m\u001b[43m     \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mfix_tokenizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    385\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel_patcher\u001b[49m\u001b[43m     \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mdispatch_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    386\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtokenizer_name\u001b[49m\u001b[43m    \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mtokenizer_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    387\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    388\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m          \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mis_peft\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    389\u001b[39m \n\u001b[32m    390\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfast_inference\u001b[49m\u001b[43m    \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mfast_inference\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    391\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgpu_memory_utilization\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mgpu_memory_utilization\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    392\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfloat8_kv_cache\u001b[49m\u001b[43m   \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mfloat8_kv_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    393\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[43m      \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    394\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_lora_rank\u001b[49m\u001b[43m     \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_lora_rank\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    395\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdisable_log_stats\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mdisable_log_stats\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    396\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    397\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    399\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m resize_model_vocab \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    400\u001b[39m     model.resize_token_embeddings(resize_model_vocab)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/unsloth/models/qwen3.py:419\u001b[39m, in \u001b[36mFastQwen3Model.from_pretrained\u001b[39m\u001b[34m(model_name, max_seq_length, dtype, load_in_4bit, token, device_map, rope_scaling, fix_tokenizer, model_patcher, tokenizer_name, trust_remote_code, **kwargs)\u001b[39m\n\u001b[32m    404\u001b[39m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[32m    405\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfrom_pretrained\u001b[39m(  \u001b[38;5;66;03m#TODO: Change after release\u001b[39;00m\n\u001b[32m    406\u001b[39m     model_name        = \u001b[33m\"\u001b[39m\u001b[33mQwen/Qwen3-7B\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    417\u001b[39m     **kwargs,\n\u001b[32m    418\u001b[39m ):\n\u001b[32m--> \u001b[39m\u001b[32m419\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mFastLlamaModel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    420\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m        \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    421\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmax_seq_length\u001b[49m\u001b[43m    \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_seq_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    422\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m             \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    423\u001b[39m \u001b[43m        \u001b[49m\u001b[43mload_in_4bit\u001b[49m\u001b[43m      \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mload_in_4bit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    424\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m             \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    425\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[43m        \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    426\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrope_scaling\u001b[49m\u001b[43m      \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mrope_scaling\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    427\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfix_tokenizer\u001b[49m\u001b[43m     \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mfix_tokenizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    428\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel_patcher\u001b[49m\u001b[43m     \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mFastQwen3Model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    429\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtokenizer_name\u001b[49m\u001b[43m    \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mtokenizer_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    430\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    431\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    432\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/unsloth/models/llama.py:1827\u001b[39m, in \u001b[36mFastLlamaModel.from_pretrained\u001b[39m\u001b[34m(model_name, max_seq_length, dtype, load_in_4bit, token, device_map, rope_scaling, fix_tokenizer, model_patcher, tokenizer_name, trust_remote_code, fast_inference, gpu_memory_utilization, float8_kv_cache, random_state, max_lora_rank, disable_log_stats, **kwargs)\u001b[39m\n\u001b[32m   1824\u001b[39m \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[32m   1826\u001b[39m \u001b[38;5;66;03m# Load vLLM first\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1827\u001b[39m llm = \u001b[43mload_vllm\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mload_vllm_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1829\u001b[39m \u001b[38;5;66;03m# Convert to HF format\u001b[39;00m\n\u001b[32m   1830\u001b[39m _, quant_state_dict = get_vllm_state_dict(llm, config = model_config)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/unsloth_zoo/vllm_utils.py:1153\u001b[39m, in \u001b[36mload_vllm\u001b[39m\u001b[34m(model_name, config, gpu_memory_utilization, max_seq_length, dtype, training, float8_kv_cache, random_state, enable_lora, max_lora_rank, max_loras, use_async, use_engine, disable_log_stats, enforce_eager, enable_prefix_caching, compilation_config, conservativeness, max_logprobs, use_bitsandbytes, return_args)\u001b[39m\n\u001b[32m   1151\u001b[39m error = \u001b[38;5;28mstr\u001b[39m(error)\n\u001b[32m   1152\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m trials >= \u001b[32m2\u001b[39m:\n\u001b[32m-> \u001b[39m\u001b[32m1153\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(error)\n\u001b[32m   1155\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mgpu_memory_utilization\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m error \u001b[38;5;129;01mor\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mmemory\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m error:\n\u001b[32m   1156\u001b[39m     approx_max_num_seqs = \u001b[38;5;28mint\u001b[39m(approx_max_num_seqs * \u001b[32m0.75\u001b[39m)\n",
      "\u001b[31mRuntimeError\u001b[39m: CUDA out of memory. Tried to allocate 304.00 MiB. GPU 0 has a total capacity of 14.53 GiB of which 174.00 MiB is free. Process 3968688 has 14.35 GiB memory in use. Of the allocated memory 13.11 GiB is allocated by PyTorch, with 37.88 MiB allocated in private pools (e.g., CUDA Graphs), and 64.60 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "from unsloth import FastLanguageModel, is_bfloat16_supported\n",
    "import torch\n",
    "max_seq_length = 4096 # Can increase for longer reasoning traces\n",
    "lora_rank = 16 # Larger rank = smarter, but slower\n",
    "\n",
    "\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name = \"Qwen/Qwen3-0.6B\",\n",
    "    #model_name = \"unsloth/Llama-3.2-3B-Instruct\",\n",
    "    max_seq_length = max_seq_length,   # Context length - can be longer, but uses more memory\n",
    "    load_in_4bit = True,     # 4bit uses much less memory\n",
    "    load_in_8bit = False,    # A bit more accurate, uses 2x memory\n",
    "    fast_inference = True, # Enable vLLM fast inference\n",
    "    max_lora_rank = lora_rank,\n",
    "    gpu_memory_utilization = 0.7,      # use one if using gated models\n",
    ")\n",
    "\n",
    "model = FastLanguageModel.get_peft_model(\n",
    "    model,\n",
    "    r = lora_rank, # Choose any number > 0 ! Suggested 8, 16, 32, 64, 128\n",
    "    target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
    "                      \"gate_proj\", \"up_proj\", \"down_proj\",],\n",
    "    lora_alpha = lora_rank,\n",
    "    use_gradient_checkpointing = \"unsloth\", # Enable long context finetuning\n",
    "    random_state = 3407,\n",
    ")\n",
    "\n",
    "# !Important\n",
    "tokenizer.padding_side = \"right\"\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "46354133-c24d-40eb-87a4-19730fc61dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "import re\n",
    "import difflib\n",
    "from fuzzywuzzy import fuzz\n",
    "from inflection import singularize\n",
    "\n",
    "def extract_hash_answer(text: str) -> str | None:\n",
    "    # Use model response structure to find the XML part\n",
    "    if \"</think>\" not in text:\n",
    "        return text\n",
    "    return text.split(\"</think>\")[1].strip()\n",
    "\n",
    "def extract_xml(text: str) -> str | None:\n",
    "    # Use regular expression to find the XML part enclosed in ```xml...```\n",
    "    xml_match = re.search(r'```xml(.*?)```', text, re.DOTALL)\n",
    "    if xml_match:\n",
    "        return xml_match.group(1).strip()\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def extract_field_values(xml_str):\n",
    "    root = ET.fromstring(xml_str)\n",
    "    fields = {}\n",
    "    for df in root.findall(\".//datafield\"):\n",
    "        tag = df.get(\"tag\")\n",
    "        subfields = [sf.text for sf in df.findall(\"subfield\")]\n",
    "        fields[tag] = \" \".join(subfields)\n",
    "    return fields\n",
    "\n",
    "def parse_metadata(user_input: str) -> dict:\n",
    "    \"\"\"\n",
    "    Parses textual bibliographic data into a dictionary.\n",
    "    \"\"\"\n",
    "    metadata = {}\n",
    "    lines = user_input.strip().split('\\n')\n",
    "    for line in lines:\n",
    "        if \":\" in line:\n",
    "            key, value = line.split(\":\", 1)\n",
    "            metadata[key.strip()] = value.strip()\n",
    "    return metadata\n",
    "\n",
    "def format_reward(xml_output: str) -> float:\n",
    "    if xml_output is None:\n",
    "        return 0.0\n",
    "    try:\n",
    "        root = ET.fromstring(xml_output)\n",
    "    except ET.ParseError:\n",
    "        return 0.0\n",
    "\n",
    "    score = 0.2  # Starts above 0 for well-formed but noncompliant XML\n",
    "\n",
    "    if root.find(\".//controlfield\") is not None:\n",
    "        score += 0.1\n",
    "    if root.find(\".//leader\") is not None:\n",
    "        score += 0.1\n",
    "    if root.find(\".//datafield\") is not None:\n",
    "        score += 0.3\n",
    "    if root.find(\".//subfield\") is not None:\n",
    "        score += 0.3\n",
    "\n",
    "    return min(score, 1.0)\n",
    "\n",
    "def accuracy_reward(generated_xml: str, target_xml: str) -> float:\n",
    "    if generated_xml is None or target_xml is None:\n",
    "        return 0.0\n",
    "    try:\n",
    "        gen_fields = extract_field_values(generated_xml)\n",
    "        tgt_fields = extract_field_values(target_xml)\n",
    "    except ET.ParseError:\n",
    "        return 0.0\n",
    "\n",
    "    shared_keys = set(gen_fields) & set(tgt_fields)\n",
    "    if not shared_keys:\n",
    "        return 0.0\n",
    "\n",
    "    total_sim = 0\n",
    "    for key in shared_keys:\n",
    "        sim = difflib.SequenceMatcher(None, gen_fields[key], tgt_fields[key]).ratio()\n",
    "        total_sim += sim\n",
    "\n",
    "    return total_sim / len(shared_keys)\n",
    "\n",
    "def semantic_field_reward(user_prompt: str, generated_xml: str) -> float:\n",
    "    if generated_xml is None or user_prompt is None:\n",
    "        return 0.0\n",
    "    FIELD_MAPPINGS = {\n",
    "        \"Title\": (\"200\", \"a\"),              # Title â†’ 200$a\n",
    "        \"Subtitle\": (\"200\", \"e\"),           # Subtitle â†’ 200$e\n",
    "        \"Year\": (\"214\", \"d\"),               # Year â†’ 214$d (Publication date)\n",
    "        \"Authors\": (\"700\", \"a\"),            # Authors â†’ 700$a (Main Author)\n",
    "        \"Publisher\": (\"214\", \"c\"),          # Publisher â†’ 214$c\n",
    "        \"ISBN\": (\"010\", \"a\"),               # ISBN â†’ 010$a\n",
    "        \"Language\": (\"101\", \"a\"),           # Language â†’ 101$a\n",
    "        \"Collection/Series\": (\"225\", \"a\"),         # Collection/Series â†’ 225$a\n",
    "        \"Material description\": (\"215\", \"a\"), # Material description â†’ 215$a\n",
    "        \"Price\": (\"010\", \"d\"),              # Price â†’ 010$d\n",
    "        \"Abstract/Notes Source\": (\"330\", \"a\"),           # Abstract â†’ 330$a\n",
    "        \"Country of publication\": (\"102\", \"a\"),            # Country of publication â†’ 102$a\n",
    "        \"Edition\": (\"205\", \"a\"),            # Edition â†’ 205$a\n",
    "        \"Notes\": (\"300\", \"a\"),              # Notes â†’ 300$a\n",
    "        \"Keywords / Subject Headings\": (\"600\", \"a\")            # Keywords â†’ 600$a (Subject Headings)\n",
    "    }\n",
    "    try:\n",
    "        root = ET.fromstring(generated_xml)\n",
    "    except ET.ParseError:\n",
    "        return 0.0\n",
    "        metadata = parse_metadata(user_prompt)\n",
    "    total_possible_matches = len(FIELD_MAPPINGS)\n",
    "    successful_matches = 0\n",
    "\n",
    "    for input_field, input_value in metadata.items():\n",
    "        best_match_score = 0\n",
    "        best_matched_unimarc = None\n",
    "\n",
    "        for unimarc_field_label, (tag, subfield) in FIELD_MAPPINGS.items():\n",
    "            similarity_score = fuzz.partial_ratio(input_field.lower(), unimarc_field_label.lower())\n",
    "            if similarity_score > best_match_score and similarity_score > 80: # Adjust threshold\n",
    "                best_match_score = similarity_score\n",
    "                best_matched_unimarc = (tag, subfield)\n",
    "\n",
    "        if best_matched_unimarc:\n",
    "            tag, subfield = best_matched_unimarc\n",
    "            datafield = root.find(f\".//datafield[@tag='{tag}']/subfield[@code='{subfield}']\")\n",
    "            if datafield is not None:\n",
    "                generated_value = datafield.text.strip().lower()\n",
    "                metadata_value = input_value.strip().lower()\n",
    "                if metadata_value in generated_value or generated_value in metadata_value:\n",
    "                    successful_matches += 1\n",
    "\n",
    "    reward = successful_matches / total_possible_matches if total_possible_matches > 0 else 0.0\n",
    "    return round(reward, 2)\n",
    "\n",
    "def format_reward_func(completions, **kwargs) -> list[float]:\n",
    "    rewards = []\n",
    "    for completion in completions:\n",
    "        response = completion[0]['content']\n",
    "        extracted_xml = extract_xml(response)  # Now returns a single XML string or None\n",
    "        rewards.append(format_reward(extracted_xml))\n",
    "    return rewards\n",
    "\n",
    "def accuracy_reward_func(completions, answer, **kwargs) -> list[float]:\n",
    "    rewards = []\n",
    "    for completion, target in zip(completions, answer):\n",
    "        response = completion[0]['content']\n",
    "        extracted_xml = extract_xml(response)  # Returns the first XML string or None\n",
    "        rewards.append(accuracy_reward(extracted_xml, target))\n",
    "    return rewards\n",
    "\n",
    "def semantic_field_reward_func(prompts, completions, **kwargs) -> list[float]:\n",
    "    rewards = []\n",
    "    for prompt_group, completion in zip(prompts, completions):\n",
    "        # Assuming your prompt is the last turn in the conversation history\n",
    "        user_prompt = prompt_group[-1]['content']\n",
    "        response = completion[0]['content']\n",
    "        extracted_xml = extract_xml(response)\n",
    "\n",
    "        if extracted_xml:\n",
    "            reward = semantic_field_reward(user_prompt, extracted_xml)\n",
    "            rewards.append(reward)\n",
    "        else:\n",
    "            rewards.append(0.0)\n",
    "    return rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cf95abe0-7939-490e-b5f0-ce71aa983b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset, Dataset\n",
    "\n",
    "def get_dataset(split = \"train\") -> Dataset:\n",
    "    data = load_dataset(\"Geraldine/metadata-to-unimarc-traces\", split=split)\n",
    "    data = data.map(lambda x: { # type: ignore\n",
    "        'prompt': [\n",
    "            {'role': 'system', 'content': \"You are an expert bibliographic cataloger assistant. Convert metadata to UNIMARC/XML format\"},\n",
    "            {'role': 'user', 'content': f\"Please convert this metadata to UNIMARC/XML:\\n{x['metadata']}\"}\n",
    "        ],\n",
    "        'answer': x['unimarc_record']\n",
    "    }) # type: ignore\n",
    "    return data # type: ignore\n",
    "dataset = get_dataset()\n",
    "dataset = dataset.select(range(50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "179a9471-d776-488f-a7f4-4e3f96076036",
   "metadata": {},
   "outputs": [],
   "source": [
    "#del trainer\n",
    "import torch\n",
    "torch.cuda.empty_cache() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "af6075b3-8743-4f9a-94ab-7cde09eaf2bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsloth: We now expect `per_device_train_batch_size` to be a multiple of `num_generations`.\n",
      "We will change the batch size of 1 to the `num_generations` of 6\n"
     ]
    }
   ],
   "source": [
    "from trl import GRPOConfig, GRPOTrainer\n",
    "training_args = GRPOConfig(\n",
    "    use_vllm = True, # use vLLM for fast inference!\n",
    "    learning_rate = 5e-6,\n",
    "    adam_beta1 = 0.9,\n",
    "    adam_beta2 = 0.99,\n",
    "    weight_decay = 0.1,\n",
    "    warmup_ratio = 0.1,\n",
    "    lr_scheduler_type = \"cosine\",\n",
    "    optim = \"paged_adamw_8bit\",\n",
    "    logging_steps = 1,\n",
    "    bf16 = is_bfloat16_supported(),\n",
    "    fp16 = not is_bfloat16_supported(),\n",
    "    per_device_train_batch_size = 1,\n",
    "    gradient_accumulation_steps = 1, # Increase to 4 for smoother training\n",
    "    num_generations = 6, # Decrease if out of memory\n",
    "    max_prompt_length = 2048,\n",
    "    max_completion_length = max_seq_length,\n",
    "    # num_train_epochs = 1, # Set to 1 for a full training run\n",
    "    max_steps = 100,\n",
    "    save_steps = 250,\n",
    "    max_grad_norm = 0.1,\n",
    "    report_to = \"none\", # Can use Weights & Biases\n",
    "    output_dir = \"outputs\",\n",
    "    do_sample=True,\n",
    "    top_p=0.9,\n",
    "    top_k=50,\n",
    "    repetition_penalty=1.2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f5de87d8-d87a-4f70-bc7a-8f6e9f421398",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n",
      "   \\\\   /|    Num examples = 50 | Num Epochs = 2 | Total steps = 100\n",
      "O^O/ \\_/ \\    Batch size per device = 6 | Gradient accumulation steps = 1\n",
      "\\        /    Data Parallel GPUs = 1 | Total batch size (6 x 1 x 1) = 6\n",
      " \"-____-\"     Trainable parameters = 10,092,544/6,000,000,000 (0.17% trained)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='10' max='100' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 10/100 08:11 < 1:32:08, 0.02 it/s, Epoch 0.18/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>reward</th>\n",
       "      <th>reward_std</th>\n",
       "      <th>completion_length</th>\n",
       "      <th>kl</th>\n",
       "      <th>rewards / format_reward_func_2</th>\n",
       "      <th>rewards / accuracy_reward_func_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.081650</td>\n",
       "      <td>1135.166748</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.103280</td>\n",
       "      <td>1047.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>910.833374</td>\n",
       "      <td>0.000601</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.103280</td>\n",
       "      <td>1121.666748</td>\n",
       "      <td>0.000582</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.103280</td>\n",
       "      <td>826.666687</td>\n",
       "      <td>0.000587</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.109545</td>\n",
       "      <td>1367.666748</td>\n",
       "      <td>0.000631</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.109545</td>\n",
       "      <td>1199.500000</td>\n",
       "      <td>0.000710</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1319.333374</td>\n",
       "      <td>0.000568</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 1.12 GiB. GPU 0 has a total capacity of 14.53 GiB of which 638.00 MiB is free. Process 3968688 has 13.89 GiB memory in use. Of the allocated memory 12.60 GiB is allocated by PyTorch, with 37.88 MiB allocated in private pools (e.g., CUDA Graphs), and 115.35 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mOutOfMemoryError\u001b[39m                          Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 11\u001b[39m\n\u001b[32m      1\u001b[39m trainer = GRPOTrainer(\n\u001b[32m      2\u001b[39m     model = model,\n\u001b[32m      3\u001b[39m     processing_class = tokenizer,\n\u001b[32m   (...)\u001b[39m\u001b[32m      9\u001b[39m     train_dataset = dataset,\n\u001b[32m     10\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/transformers/trainer.py:2245\u001b[39m, in \u001b[36mTrainer.train\u001b[39m\u001b[34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[39m\n\u001b[32m   2243\u001b[39m         hf_hub_utils.enable_progress_bars()\n\u001b[32m   2244\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2245\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2246\u001b[39m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[43m=\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2247\u001b[39m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2248\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2249\u001b[39m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m=\u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2250\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<string>:314\u001b[39m, in \u001b[36m_fast_inner_training_loop\u001b[39m\u001b[34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<string>:31\u001b[39m, in \u001b[36m_unsloth_training_step\u001b[39m\u001b[34m(self, model, inputs, num_items_in_batch)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/work/unsloth_compiled_cache/UnslothGRPOTrainer.py:1132\u001b[39m, in \u001b[36m_UnslothGRPOTrainer.compute_loss\u001b[39m\u001b[34m(self, model, inputs, return_outputs, num_items_in_batch)\u001b[39m\n\u001b[32m   1128\u001b[39m     loss, completion_length, mean_kl = grpo_compute_loss_slow(\n\u001b[32m   1129\u001b[39m         ref_per_token_logps, per_token_logps, input_ids, completion_mask, \u001b[38;5;28mself\u001b[39m.beta, advantages,\n\u001b[32m   1130\u001b[39m     )\n\u001b[32m   1131\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1132\u001b[39m     loss, completion_length, mean_kl = \u001b[43mgrpo_accumulated_loss\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1133\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_input_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogits_to_keep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompletion_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madvantages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1134\u001b[39m \u001b[43m        \u001b[49m\u001b[43mn_chunks\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43margs\u001b[49m\u001b[43m.\u001b[49m\u001b[43munsloth_num_chunks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1135\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1137\u001b[39m \u001b[38;5;66;03m# Log the metrics\u001b[39;00m\n\u001b[32m   1138\u001b[39m \u001b[38;5;66;03m# completion_length = self.accelerator.gather_for_metrics(completion_mask.sum(1)).float().mean().item()\u001b[39;00m\n\u001b[32m   1139\u001b[39m \n\u001b[32m   1140\u001b[39m \u001b[38;5;66;03m# mean_kl = ((per_token_kl * completion_mask).sum(dim=1) / completion_mask.sum(dim=1)).mean()\u001b[39;00m\n\u001b[32m   1141\u001b[39m \u001b[38;5;66;03m# self._metrics[\"kl\"].append(self.accelerator.gather_for_metrics(mean_kl).mean().item())\u001b[39;00m\n\u001b[32m   1143\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mtrain\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._metrics:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/work/unsloth_compiled_cache/UnslothGRPOTrainer.py:194\u001b[39m, in \u001b[36mgrpo_accumulated_loss\u001b[39m\u001b[34m(trainer, input_ids, logits_to_keep, completion_mask, advantages, n_chunks)\u001b[39m\n\u001b[32m    192\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.amp.autocast(device_type = \u001b[33m\"\u001b[39m\u001b[33mcuda\u001b[39m\u001b[33m\"\u001b[39m, dtype = mixed_dtype):\n\u001b[32m    193\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m torch.inference_mode(), trainer.accelerator.unwrap_model(trainer.model, keep_fp32_wrapper = \u001b[38;5;28;01mFalse\u001b[39;00m).disable_adapter():\n\u001b[32m--> \u001b[39m\u001b[32m194\u001b[39m         old_hidden_states = \u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogits_to_keep\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogits_to_keep\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m.logits\n\u001b[32m    195\u001b[39m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[32m    197\u001b[39m     new_hidden_states = trainer.model(input_ids = input_ids, logits_to_keep = logits_to_keep + \u001b[32m1\u001b[39m).logits\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/unsloth/models/llama.py:1207\u001b[39m, in \u001b[36mPeftModelForCausalLM_fast_forward\u001b[39m\u001b[34m(self, input_ids, causal_mask, attention_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict, task_ids, num_logits_to_keep, logits_to_keep, **kwargs)\u001b[39m\n\u001b[32m   1191\u001b[39m \u001b[38;5;129m@torch\u001b[39m._disable_dynamo\n\u001b[32m   1192\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mPeftModelForCausalLM_fast_forward\u001b[39m(\n\u001b[32m   1193\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1205\u001b[39m     **kwargs,\n\u001b[32m   1206\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1207\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbase_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1208\u001b[39m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1209\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcausal_mask\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mcausal_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1210\u001b[39m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1211\u001b[39m \u001b[43m        \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1212\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1213\u001b[39m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1214\u001b[39m \u001b[43m        \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1215\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1216\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnum_logits_to_keep\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_logits_to_keep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1217\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlogits_to_keep\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogits_to_keep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1218\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1219\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/peft/tuners/tuners_utils.py:193\u001b[39m, in \u001b[36mBaseTuner.forward\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    192\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, *args: Any, **kwargs: Any):\n\u001b[32m--> \u001b[39m\u001b[32m193\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/unsloth/models/llama.py:1050\u001b[39m, in \u001b[36mCausalLM_fast_forward.<locals>._CausalLM_fast_forward\u001b[39m\u001b[34m(self, input_ids, causal_mask, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict, num_logits_to_keep, logits_to_keep, *args, **kwargs)\u001b[39m\n\u001b[32m   1048\u001b[39m     \u001b[38;5;66;03m# decoder outputs consists of (dec_features, layer_state, dec_hidden, dec_attn)\u001b[39;00m\n\u001b[32m   1049\u001b[39m     \u001b[38;5;28mself\u001b[39m.model._has_no_labels = labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1050\u001b[39m     outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1051\u001b[39m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1052\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcausal_mask\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mcausal_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1053\u001b[39m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1054\u001b[39m \u001b[43m        \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1055\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1056\u001b[39m \u001b[43m        \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1057\u001b[39m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1058\u001b[39m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1059\u001b[39m \u001b[43m        \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1060\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1061\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1062\u001b[39m \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[32m   1063\u001b[39m hidden_states = outputs[\u001b[32m0\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/unsloth/models/llama.py:859\u001b[39m, in \u001b[36mLlamaModel_fast_forward\u001b[39m\u001b[34m(self, input_ids, causal_mask, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict, *args, **kwargs)\u001b[39m\n\u001b[32m    857\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m custom_forward\n\u001b[32m    858\u001b[39m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m859\u001b[39m     layer_outputs = \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mutils\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcheckpoint\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcheckpoint\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    860\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcreate_custom_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdecoder_layer\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    861\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    862\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    863\u001b[39m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    864\u001b[39m \u001b[43m        \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    865\u001b[39m \u001b[43m        \u001b[49m\u001b[43muse_reentrant\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    866\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpreserve_rng_state\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    867\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    868\u001b[39m     hidden_states = layer_outputs[\u001b[32m0\u001b[39m]\n\u001b[32m    870\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/torch/_compile.py:32\u001b[39m, in \u001b[36m_disable_dynamo.<locals>.inner\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     29\u001b[39m     disable_fn = torch._dynamo.disable(fn, recursive)\n\u001b[32m     30\u001b[39m     fn.__dynamo_disable = disable_fn\n\u001b[32m---> \u001b[39m\u001b[32m32\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdisable_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py:745\u001b[39m, in \u001b[36mDisableContext.__call__.<locals>._fn\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    741\u001b[39m prior_skip_guard_eval_unsafe = set_skip_guard_eval_unsafe(\n\u001b[32m    742\u001b[39m     _is_skip_guard_eval_unsafe_stance()\n\u001b[32m    743\u001b[39m )\n\u001b[32m    744\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m745\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    746\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    747\u001b[39m     _maybe_set_eval_frame(prior)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/unsloth_zoo/gradient_checkpointing.py:747\u001b[39m, in \u001b[36munsloth_checkpoint\u001b[39m\u001b[34m(function, use_reentrant, context_fn, determinism_check, debug, *args, **kwargs)\u001b[39m\n\u001b[32m    742\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m context_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m noop_context_fn \u001b[38;5;129;01mor\u001b[39;00m debug \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[32m    743\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    744\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mPassing `context_fn` or `debug` is only supported when \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    745\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33muse_reentrant=False.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    746\u001b[39m         )\n\u001b[32m--> \u001b[39m\u001b[32m747\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mUnslothCheckpointFunction\u001b[49m\u001b[43m.\u001b[49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreserve\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    748\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    749\u001b[39m     gen = _checkpoint_without_reentrant_generator(\n\u001b[32m    750\u001b[39m         function, preserve, context_fn, determinism_check, debug, *args, **kwargs\n\u001b[32m    751\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/torch/autograd/function.py:575\u001b[39m, in \u001b[36mFunction.apply\u001b[39m\u001b[34m(cls, *args, **kwargs)\u001b[39m\n\u001b[32m    572\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch._C._are_functorch_transforms_active():\n\u001b[32m    573\u001b[39m     \u001b[38;5;66;03m# See NOTE: [functorch vjp and autograd interaction]\u001b[39;00m\n\u001b[32m    574\u001b[39m     args = _functorch.utils.unwrap_dead_wrappers(args)\n\u001b[32m--> \u001b[39m\u001b[32m575\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m    577\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_setup_ctx_defined:\n\u001b[32m    578\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m    579\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mIn order to use an autograd.Function with functorch transforms \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    580\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m(vmap, grad, jvp, jacrev, ...), it must override the setup_context \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    581\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mstaticmethod. For more details, please see \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    582\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mhttps://pytorch.org/docs/main/notes/extending.func.html\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    583\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/unsloth_zoo/gradient_checkpointing.py:463\u001b[39m, in \u001b[36mUnslothCheckpointFunction.forward\u001b[39m\u001b[34m(ctx, run_function, preserve_rng_state, *args)\u001b[39m\n\u001b[32m    460\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m ctx._requires_gradient: ctx.save_for_backward(*tensor_inputs)\n\u001b[32m    462\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n\u001b[32m--> \u001b[39m\u001b[32m463\u001b[39m     outputs = \u001b[43mrun_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    465\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m use_gpu_buffer: MAIN_STREAM.wait_stream(EXTRA_STREAM)\n\u001b[32m    466\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/unsloth/models/llama.py:856\u001b[39m, in \u001b[36mLlamaModel_fast_forward.<locals>.create_custom_forward.<locals>.custom_forward\u001b[39m\u001b[34m(*inputs)\u001b[39m\n\u001b[32m    855\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcustom_forward\u001b[39m(*inputs):\n\u001b[32m--> \u001b[39m\u001b[32m856\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding_mask\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mposition_embeddings\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mposition_embeddings\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/unsloth/models/llama.py:560\u001b[39m, in \u001b[36mLlamaDecoderLayer_fast_forward\u001b[39m\u001b[34m(self, hidden_states, causal_mask, attention_mask, position_ids, past_key_value, output_attentions, use_cache, padding_mask, position_embeddings, *args, **kwargs)\u001b[39m\n\u001b[32m    558\u001b[39m     residual = hidden_states\n\u001b[32m    559\u001b[39m     hidden_states = fast_rms_layernorm(\u001b[38;5;28mself\u001b[39m.post_attention_layernorm, hidden_states)\n\u001b[32m--> \u001b[39m\u001b[32m560\u001b[39m     hidden_states = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmlp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    561\u001b[39m     hidden_states = residual + hidden_states\n\u001b[32m    562\u001b[39m \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/unsloth/kernels/fast_lora.py:181\u001b[39m, in \u001b[36mapply_lora_mlp_swiglu\u001b[39m\u001b[34m(self, X, inplace)\u001b[39m\n\u001b[32m    179\u001b[39m upW,     upW_quant,   upA,   upB,   upS = get_lora_parameters(\u001b[38;5;28mself\u001b[39m.  up_proj)\n\u001b[32m    180\u001b[39m downW, downW_quant, downA, downB, downS = get_lora_parameters(\u001b[38;5;28mself\u001b[39m.down_proj)\n\u001b[32m--> \u001b[39m\u001b[32m181\u001b[39m out = \u001b[43mLoRA_MLP\u001b[49m\u001b[43m.\u001b[49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    182\u001b[39m \u001b[43m                     \u001b[49m\u001b[43mgateW\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgateW_quant\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgateA\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgateB\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgateS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    183\u001b[39m \u001b[43m                     \u001b[49m\u001b[43mupW\u001b[49m\u001b[43m,\u001b[49m\u001b[43m     \u001b[49m\u001b[43mupW_quant\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mupA\u001b[49m\u001b[43m,\u001b[49m\u001b[43m   \u001b[49m\u001b[43mupB\u001b[49m\u001b[43m,\u001b[49m\u001b[43m   \u001b[49m\u001b[43mupS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    184\u001b[39m \u001b[43m                     \u001b[49m\u001b[43mdownW\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdownW_quant\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdownA\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdownB\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdownS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    185\u001b[39m \u001b[43m                     \u001b[49m\u001b[43mswiglu_fg_kernel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mswiglu_DWf_DW_dfg_kernel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    186\u001b[39m \u001b[43m                     \u001b[49m\u001b[43minplace\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    187\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/torch/autograd/function.py:575\u001b[39m, in \u001b[36mFunction.apply\u001b[39m\u001b[34m(cls, *args, **kwargs)\u001b[39m\n\u001b[32m    572\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch._C._are_functorch_transforms_active():\n\u001b[32m    573\u001b[39m     \u001b[38;5;66;03m# See NOTE: [functorch vjp and autograd interaction]\u001b[39;00m\n\u001b[32m    574\u001b[39m     args = _functorch.utils.unwrap_dead_wrappers(args)\n\u001b[32m--> \u001b[39m\u001b[32m575\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m    577\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_setup_ctx_defined:\n\u001b[32m    578\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m    579\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mIn order to use an autograd.Function with functorch transforms \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    580\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m(vmap, grad, jvp, jacrev, ...), it must override the setup_context \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    581\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mstaticmethod. For more details, please see \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    582\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mhttps://pytorch.org/docs/main/notes/extending.func.html\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    583\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/torch/amp/autocast_mode.py:503\u001b[39m, in \u001b[36mcustom_fwd.<locals>.decorate_fwd\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    501\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m cast_inputs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    502\u001b[39m     args[\u001b[32m0\u001b[39m]._fwd_used_autocast = torch.is_autocast_enabled(device_type)\n\u001b[32m--> \u001b[39m\u001b[32m503\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfwd\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    504\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    505\u001b[39m     autocast_context = torch.is_autocast_enabled(device_type)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/unsloth/kernels/fast_lora.py:77\u001b[39m, in \u001b[36mLoRA_MLP.forward\u001b[39m\u001b[34m(ctx, X, gateW, gateW_quant, gateA, gateB, gateS, upW, upW_quant, upA, upB, upS, downW, downW_quant, downA, downB, downS, _forward_function, _backward_function, inplace)\u001b[39m\n\u001b[32m     75\u001b[39m e = matmul_lora(X, gateW, gateW_quant, gateA, gateB, gateS)\n\u001b[32m     76\u001b[39m g = matmul_lora(X,   upW,   upW_quant,   upA,   upB,   upS)\n\u001b[32m---> \u001b[39m\u001b[32m77\u001b[39m h = \u001b[43m_forward_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     78\u001b[39m i = matmul_lora(h, downW, downW_quant, downA, downB, downS)\n\u001b[32m     80\u001b[39m ctx.custom_saved_tensors = (\n\u001b[32m     81\u001b[39m     gateW, gateW_quant, gateS,\n\u001b[32m     82\u001b[39m     upW, upW_quant, upS,\n\u001b[32m     83\u001b[39m     downW, downW_quant, downS,\n\u001b[32m     84\u001b[39m     _backward_function,\n\u001b[32m     85\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/unsloth/kernels/swiglu.py:44\u001b[39m, in \u001b[36mswiglu_fg_kernel\u001b[39m\u001b[34m(e, g)\u001b[39m\n\u001b[32m     42\u001b[39m batch, seq_len, hd = e.shape\n\u001b[32m     43\u001b[39m n_elements = e.numel()\n\u001b[32m---> \u001b[39m\u001b[32m44\u001b[39m h = \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mempty\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseq_len\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhd\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43me\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43me\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     45\u001b[39m grid = \u001b[38;5;28;01mlambda\u001b[39;00m meta: (triton.cdiv(n_elements, meta[\u001b[33m'\u001b[39m\u001b[33mBLOCK_SIZE\u001b[39m\u001b[33m'\u001b[39m]),)\n\u001b[32m     46\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch_cuda_device(e.device):\n",
      "\u001b[31mOutOfMemoryError\u001b[39m: CUDA out of memory. Tried to allocate 1.12 GiB. GPU 0 has a total capacity of 14.53 GiB of which 638.00 MiB is free. Process 3968688 has 13.89 GiB memory in use. Of the allocated memory 12.60 GiB is allocated by PyTorch, with 37.88 MiB allocated in private pools (e.g., CUDA Graphs), and 115.35 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "trainer = GRPOTrainer(\n",
    "    model = model,\n",
    "    processing_class = tokenizer,\n",
    "    reward_funcs = [\n",
    "        format_reward_func,\n",
    "        accuracy_reward_func,\n",
    "        semantic_field_reward_func\n",
    "    ],\n",
    "    args = training_args,\n",
    "    train_dataset = dataset,\n",
    ")\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "93de6fc6-6980-4451-8c95-299bd9a3ecc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extracted_responses = ['<!--\\nUNIMARC XML format for \"Au nom des requins\" (French) - 2022 by Actes Sud\\n--> \\n\\n<notes>\\n  <dedication> DÃ©dicace de l\\'auteur </dedication>\\n  <statement> Includes bibliography and bibliographical notes. </statement>\\n  <collection> \\n    <title>Mondes sauvages</title> \\n    <subtitle>pour une nouvelle alliance</subtitle>\\n  </collection>\\n  <collection/series>\\n  </collection>\\n  <bibs>\\n    <bibliographique>\\n      <note> Buteur: 289 </note>\\n      <note> 4e de couv. </note>\\n    </bibs>\\n  </bibs>\\n  <identifier>\\n    <identifierType>isbn</identifierType>\\n    <identifierValue>978-2-330-16034-0</identifierValue>\\n  </identifier>\\n  <identifier>\\n    <identifierType>oclc</identifierType>\\n    <identifierValue>1304465969</identifierValue>\\n  </identifier>\\n  <identifier>\\n    <identifierType>issn</identifierType>\\n    <identifierValue>2558-2682</identifierValue>\\n  </identifier>\\n  <bibsNote>\\n    <note> Notes bibliographiques </note>\\n  </bibsNote>\\n  <keywords>\\n    <keyword>Requins </keyword>\\n    <keyword>Requins / Comportement animal </keyword>\\n    <keyword>Ã‰thologie </keyword>\\n    <keyword>Relations homme-animal </keyword>\\n  </keywords>\\n</notes>\\n\\n<identifier>\\n  <identifierType>isbn</identifierType>\\n  <identifierValue>978-2330160340</identifierValue>\\n</identifier>\\n\\n<material>\\n  <materialCategory>text </materialCategory>\\n  <materialLevel>txt </materialLevel>\\n  <materialNote> media: non-projectable </materialNote>\\n</material>', '<unimarc>\\n  <title>Nom des requins</title>\\n  <author>\\n    <author>\\n      <name>FranÃ§ois Sarano</name>\\n    </author>\\n  </title>\\n  <publisher>\\n    <publisher>Actes Sud</publisher>\\n  </publisher>\\n  <preface>\\n    <preface>\\n      <name>Sandra Bessudo</name>\\n    </preface>\\n  </preface>\\n  <illustrations>\\n    <illustration>\\n      <image>\\n        <title>Marion Sarano</title>\\n        <author>\\n          <name>Marion Sarano</name>\\n        </author>\\n      </image>\\n    </illustration>\\n  </illustrations>\\n  <illustrations>\\n    <illustration>\\n      <title>Map</title>\\n      <author>\\n        <name>1</name>\\n      </author>\\n    </illustration>\\n  </illustrations>\\n  <publisher>\\n    <publisher>Arles</publisher>\\n  </publisher>\\n  <edition>\\n    <title>DL 2022</title>\\n  </edition>\\n  <price>\\n    <price>21 EUR</price>\\n  </price>\\n  <language>\\n    <language>French</language>\\n  </language>\\n  <country_ofPublication>\\n    <country>France</country>\\n  </country_ofPublication>\\n  <collection>\\n    <digitalCollection>\\n      <title>Mondes sauvages</title>\\n      <description>pour une nouvelle alliance</description>\\n    </digitalCollection>\\n  </collection>\\n  <physicalDescription>\\n    <physicalDescription>\\n      <title>1 volume</title>\\n      <pageCount>291</pageCount>\\n      <height>22 cm</height>\\n      <illustrations>\\n        <illustration>\\n          <title>Illustrations</title>\\n          <author>\\n            <name>Marion Sarano</name>\\n          </author>\\n        </illustration>\\n        <title>Map</title>\\n        <author>\\n          <title>1</title>\\n        </author>\\n      </illustrations>\\n    </physicalDescription>\\n  </physicalDescription>\\n  <bibliographicNotes>\\n    <bibliographicNotes>\\n      <bibliographicNote>[[289]]</bibliographicNote>\\n      <note>Bibliography</note>\\n      <note>Notes bibliographiques</note>\\n    </bibliographicNotes>\\n  </bibliographicNotes>\\n  <dedication>\\n    <dedication>De l\\'auteur</dedication>\\n  </dedication>\\n  <subject>\\n    <subject>\\n      <subject>\\n        <title>Requins</title>\\n      </subject>\\n    </subject>\\n  </subject>\\n  <contributors>\\n    <contributor>\\n      <contributor>\\n        <name>FranÃ§ois Sarano</name>\\n      </contributor>\\n    </contributor>\\n    <contributor>\\n      <contributor>\\n        <name>Marion Sarano</name>\\n      </contributor>\\n    </contributor>\\n    <contributor>\\n      <contributor>\\n        <name>Sandra Bessudo</name>\\n      </contributor>\\n    </contributor>\\n  </contributors>\\n  <additionalIdentifiers>\\n    <additionalIdentifier>\\n      <identifier>OCLC number:1304465969</identifier>\\n    </additionalIdentifier>\\n    <additionalIdentifier>\\n      <identifier> ISSN related to series \"Mondes sauvages\":2558-2682</identifier>\\n    </additionalIdentifier>\\n    <additionalIdentifier>\\n      <identifier>Other identifier: 9782330160340</identifier>\\n    </additionalIdentifier>\\n  </additionalIdentifiers>\\n  <materialType>\\n    <materialType>\\n      <title>text</title>\\n      <medium>\\n        <title>media</title>\\n        <description>non-projectable</description>\\n      </medium>\\n    </materialType>\\n  </materialType>\\n  <sourceDatabase>\\n    <sourceDatabase>\\n      <title>Sudoc</title>\\n    </sourceDatabase>\\n  </sourceDatabase>\\n  <catalogingAgency>\\n    <catalogingAgency>\\n      <title>AFNOR</title>\\n    </catalogingAgency>\\n  </catalogingAgency>\\n  <recordCreationDate>\\n    <recordCreationDate>2023-04-12</recordCreationDate>\\n  </recordCreationDate>\\n  <note>\\n    <note>\\n      <note>Bibliographic</note>\\n      <note>Part of the collection \"Mondes sauvages\"</note>\\n      <note>Includes bibliography...</note>\\n    </note>\\n    <note>Bibliographique</note>\\n    <note>Dedication</note>\\n    <note>Abstract/Description</note>\\n    <note>4e de couv.</note>\\n  </note>\\n</unimarc>', \"<unimarc:bookInfo>\\n  <title>Avant-Garde des Requins</title>\\n  <author>FranÃ§ois Sarano</author>\\n  <author>Sandra Bessudo</author>\\n  <collectionSeries>Mondes sauvages;</collectionSeries>\\n  <publisher>Actes Sud</publisher>\\n  <place>Arles</place>\\n  <date>2022</date>\\n  <edition>DL 2022</edition>\\n  <isbnNumber>978-2330160340</isbnNumber>\\n  <price>21 EUR</price>\\n  <language>French</language>\\n  <country>France</country>\\n  <collection>Sudoc</collection>\\n</unimarc:bookInfo>\\n\\n<unimarc:abstract>\\n  <text>\\n    <description>20 mÃ¨tres de profondeur. L'eau bleue sombre est peuplÃ©e de plancton. Face Ã  moi, Lady Mystery, une Ã©norme femelle requin blanc, soeur des Â« Dents de la mer Â» : 5,5 mÃ¨tres, une tonne et demie. Puissance extrÃªme que rien ne peut arrÃªter. Scientifique, je ne me laisse pas distraire : je consigne profondeur, heure, sexe et taille. Et soudain, Ã  quelques mÃ¨tres de l'Å“il qui me fixe, je rÃ©alise le dÃ©risoire de ces informations, si rÃ©ductrices qu'elles trahissent la crÃ©ature indomptÃ©e que je cherche Ã  connaÃ®tre. Comment raconter cette Ã©lÃ©gance sauvage ? Comment traduire ce que ses sens, profondÃ©ment diffÃ©rents des nÃ´tres, lui disent de cette rencontre et de l'ocÃ©an qui nous entoure ? Je me coule contre son flanc. Nous nageons Ã©paule contre nageoire. La distance qui nous sÃ©pare ne se mesure pas en centimÃ¨tre, elle se mesure en confiance rÃ©ciproque. Minute d'Ã©ternitÃ©. Nous ne faisons qu'un corps. Je suis en paix. Rencontre authentique, sans calcul, qui procure la joie profonde de communier avec la vie.</description>\\n  </text>\\n</unimarc:abstract>\\n\\n<unimarc:note>\\n  <bibliography><p><strong>Bibliographique</strong>:</p><ul><li><strong>289</strong> pages</li></ul><ul><li><strong>Notes bibliographiques</strong>:</li><ul><li><strong>[[4e de couv.]]</strong></li></ul></p>\\n</unimarc:note>\\n\\n<unimarc:author>\\n  <authorItem>\\n    <author>FranÃ§ois Sarano</authorItem>\\n    <attribut> born: 1954 </attribut>\\n  </authorItem>\\n  <authorItem>\\n    <author>Marion Sarano</authorItem>\\n    <attribut> born: 1988 </attribut>\\n  </authorItem>\\n  <authorItem>\\n    <author>Sandra Bessudo</authorItem>\\n    <attribut> born: 1969 </attribut>\\n  </authorItem>\\n</unimarc:author>\\n</unimarc:bookInfo>\", \"<unimarc:metadata>\\n  <title>Amour des requins</title>\\n  <author>FranÃ§ois Sarano</author>\\n  <preface>Sandra Bessudo</preface>\\n  <illustrations>Marion Sarano (original illustrations)</illustrations>\\n  <publisher>Actes Sud</publisher>\\n  <place>Arles</place>\\n  <year>2022</year>\\n  <edition>DL 2022</edition>\\n  <isbn>978-2330160340</isbn>\\n  <price>21 EUR</price>\\n  <language>French</language>\\n  <country>France</country>\\n  <collection/series>Mondes sauvages; subtitle: pour une nouvelle alliance</collection/series>\\n  <physical description>1 volume (291 pages); illustrations, 1 map, color illustrated cover; 22 cm</physical description>\\n  <bibliography>Includes bibliography and bibliographical notes</bibliography>\\n  <dedication>DÃ©dicace de l'auteur</dedication>\\n  <keywords>Requins (Sharks)</keywords>\\n  <contributrices>\\n    <contributeur> FranÃ§ois Sarano</contributeur>\\n    <contributeur> Marion Sarano</contributeur>\\n    <contributeur> Sandra Bessudo</contributeur>\\n  </contributrices>\\n  <additional identifiers>\\n    <oclc>1304465969</oclc>\\n    <issn>2558-2682</issn>\\n    <other identifier>9782330160340</other identifier>\\n  </additional identifiers>\\n  <material type>text (rdacontent: txt), media: non-projectable (n)</material type>\\n  <source database>Sudoc (French union catalogue)</source database>\\n  <cataloging agency>AFNOR (French Association for Standardization)</cataloging agency>\\n  <record creation date>2023-04-12</record creation date>\\n</unimarc:metadata>\", None, '<unimarc xmlns=\"http://unims.marca-iso.org/v3.24.0\">\\n  <series>\\n    <collection>\\n      <title>Marine Fishes</title>\\n      <description>\\n        Louis de la CourriÃ¨re, cible ; collection Â« Mondes sauvages Â», sub-titres : Â« Pour une nouvelle alliance Â».\\n      </description>\\n      <series-number>2</series-number>\\n      <edition>2022</edition>\\n      <publication>\\n        <publisher>Actes Sud</publisher>\\n        <publication>Arles</publication>\\n        <year>2022</year>\\n        <edition>DL 2022</edition>\\n        <isbn>978-2-330-16034-0</isbn>\\n        <price>21 EUR</price>\\n        <language>French</language>\\n        <country>France</country>\\n      </publication>\\n    </collection>\\n  </series>\\n  <contributors>\\n    <contributor>\\n      <author> FranÃ§ois Sarano </author>\\n      <birth>1954</birth>\\n      <language>French</language>\\n    </contributor>\\n    <contributor>\\n      <author> Sandra Bessudo </author>\\n      <birth>1969</birth>\\n    </contributor>\\n    <contributor>\\n      <illustrator> Marion Sarano </illustrator>\\n      <birth>1988</birth>\\n    </contributor>\\n  </contributors>\\n  <abstract>\\n    <note> 4e de couv. </note>\\n    <title>\\n      \"Vingt mÃ¨tres de profondeur. L\\'eau bleu sombre est peuplÃ©e de plancton. Face Ã  moi, Lady Mystery, une Ã©norme femelle requin blanc, soeur des Â« Dents de la mer Â» : 5,5 mÃ¨tres, une tonne et demie. Puissance extrÃªme que rien ne peut arrÃªter. Scientifique, je ne me laisse pas distraire : je consigne profondeur, heure, sexe et taille. Et soudain, Ã  quelques mÃ¨tres de lâ€™Å“il qui me fixe, je rÃ©alise le dÃ©risoire de ces informations, si rÃ©ductrices quâ€™elles trahissent la crÃ©ature indomptÃ©e que je cherche Ã  connaÃ®tre. Comment raconter cette Ã©lÃ©gance sauvage ? Comment traduire ce que ses sens, profondÃ©ment diffÃ©rents des nÃ´tres, lui disent de cette rencontre et de lâ€™ocÃ©an qui nous entoure ? Je me coule contre son flanc. Nous nageons Ã©paule contre nageoire. La distance qui nous sÃ©pare ne se mesure pas en centimÃ¨tre, elle se mesure en confiance rÃ©ciproque. Minute dâ€™Ã©ternitÃ©. Nous ne faisons quâ€™un corps. Je suis en paix. Rencontre authentique, sans calcul, qui procure la joie profonde de communier avec la vie.\" </title>\\n  </abstract>\\n  <keywords>\\n    <keyword>Requins</keyword>\\n    <keyword>Requins / Comportement animal (animal behavior)</keyword>\\n    <keyword>Ã‰thologie</keyword>\\n    <keyword>Relations homme-animal</keyword>\\n  </keywords>\\n</unimarc>'][5]\n",
    "format_reward_func_2(extracted_responses)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff038af7-ca98-4728-baf5-785d89603e34",
   "metadata": {},
   "source": [
    "## Archives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f9fd6ea2-c439-4920-9b30-4db658472038",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example 0 has reasoning marker: True\n",
      "Example 0 preserved reasoning after tokenization: True\n",
      "Structure check for example 0:\n",
      "  Line 0: I'll convert this metadata to UNIMARC/XML.\n",
      "  Line 1: \n",
      "  Line 2: Reasoning process:To transform the provided biblio...\n",
      "  Line 3: \n",
      "  Line 4: 1. **Control fields** (these are often generated/m...\n",
      "  Line 5: \n",
      "  Line 6:    - `<controlfield tag=\"001\">` â€” Record identifie...\n",
      "  Line 7:    - `<controlfield tag=\"003\">` â€” Control number i...\n",
      "  Line 8:    - `<controlfield tag=\"005\">` â€” Date and time of...\n",
      "  Line 9:    - `<controlfield tag=\"035\">` â€” Various system i...\n",
      "  ...\n",
      "\n",
      "Example 1 has reasoning marker: True\n",
      "Example 1 preserved reasoning after tokenization: True\n",
      "Structure check for example 1:\n",
      "  Line 0: I'll convert this metadata to UNIMARC/XML.\n",
      "  Line 1: \n",
      "  Line 2: Reasoning process:Let's analyze the transformation...\n",
      "  Line 3: \n",
      "  Line 4: 1. **Title and subtitle**\n",
      "  Line 5:    - Metadata:\n",
      "  Line 6:      - Title: \"MÃ©mo visuel d'agronomie\"\n",
      "  Line 7:      - Subtitle: \"enjeux et dÃ©fis de l'agriculture...\n",
      "  Line 8:    - XML:\n",
      "  Line 9:      - `<datafield tag=\"200\" ind1=\"1\" ind2=\" \">`\n",
      "  ...\n",
      "\n",
      "Example 2 has reasoning marker: True\n",
      "Example 2 preserved reasoning after tokenization: True\n",
      "Structure check for example 2:\n",
      "  Line 0: I'll convert this metadata to UNIMARC/XML.\n",
      "  Line 1: \n",
      "  Line 2: Reasoning process:To transform the provided biblio...\n",
      "  Line 3: \n",
      "  Line 4: ---\n",
      "  Line 5: \n",
      "  Line 6: ### 1. Control Fields\n",
      "  Line 7: - **005 (Date/time of latest transaction)**\n",
      "  Line 8:   - Not directly from metadata: Timestamp when rec...\n",
      "  Line 9:   - Example value: `<controlfield tag=\"005\">202503...\n",
      "  ...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def check_tokenization(dataset, tokenizer, num_samples=3):\n",
    "    for i in range(min(num_samples, len(dataset))):\n",
    "        # Get example\n",
    "        example = dataset[i]\n",
    "        \n",
    "        # Extract assistant message\n",
    "        assistant_msg = [msg[\"content\"] for msg in example[\"messages\"] if msg[\"role\"] == \"assistant\"][0]\n",
    "        \n",
    "        # Check if reasoning markers appear\n",
    "        reasoning_marker_present = \"Reasoning process:\" in assistant_msg\n",
    "        print(f\"Example {i} has reasoning marker: {reasoning_marker_present}\")\n",
    "        \n",
    "        # Tokenize and decode to check preservation\n",
    "        tokens = tokenizer.encode(assistant_msg)\n",
    "        decoded = tokenizer.decode(tokens)\n",
    "        \n",
    "        # Check if markers survived tokenization\n",
    "        reasoning_preserved = \"Reasoning process:\" in decoded\n",
    "        print(f\"Example {i} preserved reasoning after tokenization: {reasoning_preserved}\")\n",
    "        \n",
    "        # Print the structure\n",
    "        print(f\"Structure check for example {i}:\")\n",
    "        lines = decoded.split(\"\\n\")\n",
    "        for j, line in enumerate(lines[:10]):  # First 10 lines\n",
    "            print(f\"  Line {j}: {line[:50]}...\" if len(line) > 50 else f\"  Line {j}: {line}\")\n",
    "        print(\"  ...\\n\")\n",
    "\n",
    "# Run the check\n",
    "check_tokenization(reasoning_dataset, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7fdc967f-17a6-40c6-811a-9244bb79dbba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a custom data collator that logs what it's doing\n",
    "class DebugCompletionCollator:\n",
    "    def __init__(self, tokenizer, debug_samples=3):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.debug_samples = debug_samples\n",
    "        self.samples_seen = 0\n",
    "        \n",
    "    def __call__(self, examples):\n",
    "        # Convert the examples to a batch\n",
    "        batch = self.tokenizer.pad(examples, return_tensors=\"pt\")\n",
    "        \n",
    "        # Find the assistant token position\n",
    "        assistant_token_id = self.tokenizer.encode(\"<|assistant|>\", add_special_tokens=False)[-1]\n",
    "        # For debugging - if assistant token isn't found, try others\n",
    "        if assistant_token_id not in batch[\"input_ids\"][0]:\n",
    "            possible_tokens = [\"<|assistant|>\",\"<assistant>\", \"[assistant]\", \"assistant:\", \"assistant\\n\",\"ASSISTANT:\"]\n",
    "            for token in possible_tokens:\n",
    "                try:\n",
    "                    assistant_token_id = self.tokenizer.encode(token, add_special_tokens=False)[-1]\n",
    "                    if assistant_token_id in batch[\"input_ids\"][0]:\n",
    "                        print(f\"Found alternative assistant token: {token}\")\n",
    "                        break\n",
    "                except:\n",
    "                    continue\n",
    "        \n",
    "        # Initialize labels with -100 (ignore in loss)\n",
    "        batch[\"labels\"] = batch[\"input_ids\"].clone()\n",
    "        \n",
    "        # For each sequence in the batch\n",
    "        for i, input_seq in enumerate(batch[\"input_ids\"]):\n",
    "            # Try to find assistant token\n",
    "            assistant_pos = -1\n",
    "            for pos in range(len(input_seq)):\n",
    "                if input_seq[pos] == assistant_token_id:\n",
    "                    assistant_pos = pos\n",
    "                    break\n",
    "            \n",
    "            # If we found the assistant token\n",
    "            if assistant_pos >= 0:\n",
    "                # Mask tokens before assistant (set to -100)\n",
    "                batch[\"labels\"][i, :assistant_pos+1] = -100\n",
    "            else:\n",
    "                # If no assistant token found, warn and use heuristic\n",
    "                if self.samples_seen < self.debug_samples:\n",
    "                    print(f\"Warning: No assistant token found in sequence {i}!\")\n",
    "                    decoded = self.tokenizer.decode(input_seq)\n",
    "                    print(f\"Sample tokens: {decoded[:100]}...\")\n",
    "                \n",
    "                # Fallback: assume the first half is prompt, second half is completion\n",
    "                midpoint = len(input_seq) // 2\n",
    "                batch[\"labels\"][i, :midpoint] = -100\n",
    "            \n",
    "            # Debug information for the first few samples\n",
    "            if self.samples_seen < self.debug_samples:\n",
    "                # Count how many tokens contribute to the loss\n",
    "                active_tokens = (batch[\"labels\"][i] != -100).sum().item()\n",
    "                total_tokens = len(input_seq)\n",
    "                \n",
    "                print(f\"Sample {self.samples_seen}: {active_tokens}/{total_tokens} tokens used for training\")\n",
    "                \n",
    "                # Decode a snippet of what's being trained on\n",
    "                if assistant_pos >= 0:\n",
    "                    train_text = self.tokenizer.decode(input_seq[assistant_pos+1:])\n",
    "                    print(f\"Training on: {train_text[:100]}...\")\n",
    "                    \n",
    "                    # Check if reasoning tags are in the training portion\n",
    "                    if \"<think>\" in train_text or \"Reasoning\" in train_text:\n",
    "                        print(\"âœ“ Reasoning traces found in training portion\")\n",
    "                    else:\n",
    "                        print(\"âœ— No reasoning traces found in training portion!\")\n",
    "                \n",
    "                self.samples_seen += 1\n",
    "        \n",
    "        return batch\n",
    "\n",
    "# Instead of using Unsloth's default collator, use our debug collator\n",
    "data_collator = DebugCompletionCollator(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8dbcf376-aa99-411c-94b7-5179d1785c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a callback to periodically check what's being generated during training\n",
    "class ReasoningMonitorCallback(TrainerCallback):\n",
    "    def __init__(self, tokenizer, eval_dataset, check_every=500):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.eval_dataset = eval_dataset\n",
    "        self.check_every = check_every\n",
    "        \n",
    "    def on_step_end(self, args, state, control, **kwargs):\n",
    "        if state.global_step % self.check_every == 0:\n",
    "            model = kwargs.get(\"model\")\n",
    "            \n",
    "            # Select a sample\n",
    "            sample_idx = state.global_step % len(self.eval_dataset)\n",
    "            sample = self.eval_dataset[sample_idx]\n",
    "            \n",
    "            # Create input prompt\n",
    "            #system = [msg[\"content\"] for msg in sample[\"messages\"] if msg[\"role\"] == \"system\"][0]\n",
    "            #user = [msg[\"content\"] for msg in sample[\"messages\"] if msg[\"role\"] == \"user\"][0]\n",
    "            \n",
    "            #prompt = f\"<|system|>\\n{system}\\n<|user|>\\n{user}\\n<|assistant|>\\n\"\n",
    "            prompt = sample[\"text\"].split(\"assistant\\n\")[0]\n",
    "            inputs = self.tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
    "            \n",
    "            # Generate output\n",
    "            with torch.no_grad():\n",
    "                outputs = model.generate(\n",
    "                    **inputs,\n",
    "                    max_new_tokens=512,\n",
    "                    temperature=0.7,\n",
    "                    do_sample=True\n",
    "                )\n",
    "            \n",
    "            # Decode output\n",
    "            generated = self.tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "            assistant_part = generated.split(\"<|assistant|>\\n\")[-1]\n",
    "            \n",
    "            # Check for reasoning\n",
    "            has_reasoning = (\n",
    "                \"Reasoning process:\" in assistant_part or\n",
    "                \"reasoning:\" in assistant_part.lower() or\n",
    "                \"step by step:\" in assistant_part.lower()\n",
    "            )\n",
    "            \n",
    "            print(f\"\\nStep {state.global_step} generation check:\")\n",
    "            print(f\"Has reasoning: {'âœ“' if has_reasoning else 'âœ—'}\")\n",
    "            print(f\"Generated (truncated):\\n{assistant_part[:300]}...\\n\")\n",
    "\n",
    "reasoning_monitor = ReasoningMonitorCallback(\n",
    "    tokenizer=tokenizer,\n",
    "    eval_dataset=eval_dataset,\n",
    "    check_every=5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b791367e-e5f6-4f67-8a94-bf734a86c7c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth: Tokenizing [\"text\"]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:00<00:00, 280.53 examples/s]\n",
      "Unsloth: Tokenizing [\"text\"]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 49.16 examples/s]\n"
     ]
    }
   ],
   "source": [
    "from trl import SFTTrainer, SFTConfig\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model = model,\n",
    "    tokenizer = tokenizer,\n",
    "    train_dataset = train_dataset,\n",
    "    eval_dataset = eval_dataset,\n",
    "    data_collator=DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False),\n",
    "    label_names=[\"labels\"],\n",
    "    args = SFTConfig(\n",
    "        dataset_text_field = \"text\",\n",
    "        per_device_train_batch_size = 1,\n",
    "        gradient_accumulation_steps = 1, # Use GA to mimic batch size!\n",
    "        warmup_steps = 5,\n",
    "        num_train_epochs = 1, # Set this for 1 full training run.\n",
    "        max_steps = 30,\n",
    "        learning_rate = 2e-4, # Reduce to 2e-5 for long training runs\n",
    "        logging_steps = 1,\n",
    "        optim = \"adamw_8bit\",\n",
    "        weight_decay = 0.01,\n",
    "        lr_scheduler_type = \"linear\",\n",
    "        #seed = 3407,\n",
    "        report_to = \"none\", # Use this for WandB etc\n",
    "    ),\n",
    ")\n",
    "trainer.add_callback(reasoning_monitor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b45e5935-dbc1-4b61-9e85-953560760a1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n",
      "   \\\\   /|    Num examples = 18 | Num Epochs = 2 | Total steps = 30\n",
      "O^O/ \\_/ \\    Batch size per device = 1 | Gradient accumulation steps = 1\n",
      "\\        /    Data Parallel GPUs = 1 | Total batch size (1 x 1 x 1) = 1\n",
      " \"-____-\"     Trainable parameters = 4,325,376/5,000,000,000 (0.09% trained)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='30' max='30' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [30/30 01:49, Epoch 1/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.240900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.612500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2.645000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2.589500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>2.571700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>2.609700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>2.701700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>2.288800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>1.740700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>2.413100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>2.451500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>2.491200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>2.105100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>2.279000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>2.387100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>1.915600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>2.084900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>1.959000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>1.941800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1.919200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>2.216200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>2.241600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>2.138100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>2.078900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>1.951900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>2.071000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>2.058500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>2.126000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>2.211300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1.399500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 5 generation check:\n",
      "Has reasoning: âœ“\n",
      "Generated (truncated):\n",
      "system\n",
      "You are an expert bibliographic cataloger specializing in UNIMARC format. \n",
      "Please first thinks about the reasoning process in the mind and then provides the user with the answer.\n",
      "\n",
      "Reasoning process: [YOUR REASONING STEPS HERE]\n",
      "Final UNIMARC/XML record: [THE RESULTING UNIAMRC/XML RECORD HERE]\n",
      "...\n",
      "\n",
      "\n",
      "Step 10 generation check:\n",
      "Has reasoning: âœ“\n",
      "Generated (truncated):\n",
      "system\n",
      "You are an expert bibliographic cataloger specializing in UNIMARC format. \n",
      "Please first thinks about the reasoning process in the mind and then provides the user with the answer.\n",
      "\n",
      "Reasoning process: [YOUR REASONING STEPS HERE]\n",
      "Final UNIMARC/XML record: [THE RESULTING UNIAMRC/XML RECORD HERE]\n",
      "...\n",
      "\n",
      "\n",
      "Step 15 generation check:\n",
      "Has reasoning: âœ“\n",
      "Generated (truncated):\n",
      "system\n",
      "You are an expert bibliographic cataloger specializing in UNIMARC format. \n",
      "Please first thinks about the reasoning process in the mind and then provides the user with the answer.\n",
      "\n",
      "Reasoning process: [YOUR REASONING STEPS HERE]\n",
      "Final UNIMARC/XML record: [THE RESULTING UNIAMRC/XML RECORD HERE]\n",
      "...\n",
      "\n",
      "\n",
      "Step 20 generation check:\n",
      "Has reasoning: âœ“\n",
      "Generated (truncated):\n",
      "system\n",
      "You are an expert bibliographic cataloger specializing in UNIMARC format. \n",
      "Please first thinks about the reasoning process in the mind and then provides the user with the answer.\n",
      "\n",
      "Reasoning process: [YOUR REASONING STEPS HERE]\n",
      "Final UNIMARC/XML record: [THE RESULTING UNIAMRC/XML RECORD HERE]\n",
      "...\n",
      "\n",
      "\n",
      "Step 25 generation check:\n",
      "Has reasoning: âœ“\n",
      "Generated (truncated):\n",
      "system\n",
      "You are an expert bibliographic cataloger specializing in UNIMARC format. \n",
      "Please first thinks about the reasoning process in the mind and then provides the user with the answer.\n",
      "\n",
      "Reasoning process: [YOUR REASONING STEPS HERE]\n",
      "Final UNIMARC/XML record: [THE RESULTING UNIAMRC/XML RECORD HERE]\n",
      "...\n",
      "\n",
      "\n",
      "Step 30 generation check:\n",
      "Has reasoning: âœ“\n",
      "Generated (truncated):\n",
      "system\n",
      "You are an expert bibliographic cataloger specializing in UNIMARC format. \n",
      "Please first thinks about the reasoning process in the mind and then provides the user with the answer.\n",
      "\n",
      "Reasoning process: [YOUR REASONING STEPS HERE]\n",
      "Final UNIMARC/XML record: [THE RESULTING UNIAMRC/XML RECORD HERE]\n",
      "...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trainer_stats = trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9492a437-e0c8-4056-a964-b88fdcc1b38c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User's response matches the provided information. Here is the final UNIMARC/XML record:\n",
      "\n",
      "```\n",
      "<?xml version=\"1.0\"?>\n",
      "<record xmlns=\"http://www.umi.edu/xml/ns/uniamc-xml-format 2.0#\" version=\"4\">\n",
      "    <metadata>\n",
      "        <identifier identifierTarget=\"_dcid01\" scheme=\"http://purl.org/dc/elements/1.1/id\"/>\n",
      "        <identifier identifierTarget=\"_id01\" scheme=\"http://purl.org/dc/elements/1.1/description\"/>\n",
      "        <identifier identifierTarget=\"_acmid01\" scheme=\"http://purl.org/ukpl/acmid\"/>\n",
      "        <identifier identifierTarget=\"_isbn01\" scheme=\"https://bibliothÃ¨ques.univ-amonthe.fr/zbw/nom/isbn/9782340089693\"/>\n",
      "        <identifier identifierTarget=\"_source01\" scheme=\"urn:iadsc:unimaubiblio:unamarc\"/>\n",
      "        <identifier identifierTarget=\"_author01\" scheme=\"http://purl.org/auth/identifier/author\"/>\n",
      "        <identifier identifierTarget=\"_editor01\" scheme=\"http://purl.org/auth/identifier/editor\"/>\n",
      "        <identifier identifierTarget=\"_publisher01\" scheme=\"http://purl.org/auth/identifier/publisher\"/>\n",
      "        <identifier identifierTarget=\"_edition01\" scheme=\"http://purl.org/ukpl/acmid/162910\"/>\n",
      "        <identifier identifierTarget=\"_language01\" scheme=\"http://purl.org/ukpl/langauge\"/>\n",
      "        <identifier identifierTarget=\"_country01\" scheme=\"http://purl.org/ukpl/country\"/>\n",
      "        <identifier identifierTarget=\"_publisher01\" scheme=\"http://purl.org/ukpl/acmid/162910\"/>\n",
      "        <identifier identifierTarget=\"_series01\" scheme=\"http://purl.org/ukpl/acmid\"/>\n",
      "        <identifier identifierTarget=\"_publication01\" scheme=\"http://purl.org/ukpl/acmid\"/>\n",
      "        <identifier identifierTarget=\"_price01\" scheme=\"http://purl.org/ukpl/acmid\"/>\n",
      "        <identifier identifierTarget=\"_subject01\" scheme=\"http://purl.org/ukpl/subj\"/>\n",
      "        <identifier identifierTarget=\"_subject01\" scheme=\"http://purl.org/ukpl/subj/005\"/>\n",
      "        <identifier identifierTarget=\"_abstract01\" scheme=\"http://purl.org/ukpl/subj/005\"/>\n",
      "        <identifier identifierTarget=\"_notes01\" scheme=\"http://purl.org/ukpl/notes\"/>\n",
      "        <identifier identifierTarget=\"_notes01\" scheme=\"http://purl.org/ukpl/notes/005\"/>\n",
      "        <identifier identifierTarget=\"_keywords01\" scheme=\"http://purl.org/ukpl/keyword\"/>\n",
      "        <identifier identifierTarget=\"_notes01\" scheme=\"http://purl.org/ukpl/notes/005\"/>\n",
      "        <identifier identifierTarget=\"_price01\" scheme=\"http://purl.org/ukpl/acmid\"/>\n",
      "        <identifier identifierTarget=\"_abstract01\" scheme=\"http://purl.org/ukpl/subj\"/>\n",
      "        <identifier identifierTarget=\"_abstract01\" scheme=\"http://purl.org/ukpl/subj/005\"/>\n",
      "        <identifier identifierTarget=\"_notes01\" scheme=\"http://purl.org/ukpl/notes\"/>\n",
      "        <identifier identifierTarget=\"_abstract01\" scheme=\"http://purl.org/ukpl/subj\"/>\n",
      "        <identifier identifierTarget=\"_abstract01\" scheme=\"http://purl.org/ukpl/subj/005\"/>\n",
      "        <identifier identifierTarget=\"_notes01\" scheme=\"http://purl.org/ukpl/notes\"/>\n",
      "        <identifier identifierTarget=\"_abstract01\" scheme=\"http://purl.org/ukpl/subj\"/>\n",
      "        <identifier identifierTarget=\"_abstract01\" scheme=\"http://purl.org/ukpl/subj/005\"/>\n",
      "        <identifier identifierTarget=\"_notes01\" scheme=\"http://purl.org/ukpl/notes\"/>\n",
      "        <identifier identifierTarget=\"_abstract01\" scheme=\"http://purl.org/ukpl/subj\"/>\n",
      "        <identifier identifierTarget=\"_abstract01\" scheme=\"http://purl.org/ukpl/subj/005\"/>\n",
      "        <identifier identifierTarget=\"_abstract01\" scheme=\"http://purl.org/ukpl/subj\"/>\n",
      "        <identifier identifierTarget=\"_abstract01\" scheme=\"http://purl.org/ukpl/subj\"/>\n",
      "        <identifier identifierTarget=\"_abstract01\" scheme=\"http://purl.org/ukpl/subj\"/>\n",
      "        <identifier identifierTarget=\"_abstract01\" scheme=\"http://purl.org/ukpl/subj\"/>\n",
      "        <identifier identifierTarget=\"_abstract01\" scheme=\"http://purl.org/ukpl/subj\"/>\n",
      "        <identifier identifierTarget=\"_abstract01\" scheme=\"http://purl.org/ukpl/subj\"/>\n",
      "        <identifier identifierTarget=\"_abstract01\" scheme=\"http://purl.org/ukpl/subj\"/>\n",
      "        <identifier identifierTarget=\"_abstract01\" scheme=\"http://purl.org/ukpl/subj\"/>\n",
      "        <identifier identifierTarget=\"_abstract01\" scheme=\"http://purl.org/ukpl/subj\"/>\n",
      "        <identifier identifierTarget=\"_abstract01\" scheme=\"http://purl.org/ukpl/subj\"/>\n",
      "        <identifier identifierTarget=\"_abstract01\" scheme=\"http://purl.org/ukpl/subj\"/>\n",
      "        <identifier identifierTarget=\"_abstract01\" scheme=\"http://purl.org/ukpl/subj\"/>\n",
      "        <identifier identifierTarget=\"_abstract01\" scheme=\"http://purl.org/ukpl/subj\"/>\n",
      "        <identifier identifierTarget=\"_abstract01\" scheme=\"http://purl.org/ukpl/subj\"/>\n",
      "        <identifier identifierTarget=\"_abstract01\" scheme=\"http://purl.org/ukpl/subj\"/>\n",
      "        <identifier identifierTarget=\"_abstract01\" scheme=\"http://purl.org/ukpl/subj\"/>\n",
      "        <identifier identifierTarget=\"_abstract01\" scheme=\"http://purl.org/ukpl/subj\"/>\n",
      "        <identifier identifierTarget=\"_abstract01\" scheme=\"http://purl.org/ukpl/subj\"/>\n",
      "        <identifier identifierTarget=\"_abstract01\" scheme=\"http://purl.org/ukpl/subj\"/>\n",
      "        <identifier identifierTarget=\"_abstract01\" scheme=\"http://purl.org/ukpl/subj\"/>\n",
      "        <identifier identifierTarget=\"_abstract01\" scheme=\"http://purl.org/ukpl/subj\"/>\n",
      "        <identifier identifierTarget=\"_abstract01\" scheme=\"http://purl.org/ukpl/subj\"/>\n",
      "        <identifier identifierTarget=\"_abstract01\" scheme=\"http://purl.org/ukpl/subj\"/>\n",
      "        <identifier identifierTarget=\"_abstract01\" scheme=\"http://purl.org/ukpl/subj\"/>\n",
      "        <identifier identifierTarget=\"_abstract01\" scheme=\"http://purl.org/ukpl/subj\"/>\n",
      "        <identifier identifierTarget=\"_abstract01\" scheme=\"http://purl.org/ukpl/subj\"/>\n",
      "        <identifier identifierTarget=\"_abstract01\" scheme=\"http://purl.org/ukpl/subj\"/>\n",
      "        <identifier identifierTarget=\"_abstract01\" scheme=\"http://purl.org/ukpl/subj\"/>\n",
      "        <identifier identifierTarget=\"_abstract01\" scheme=\"http://purl.org/ukpl/subj\"/>\n",
      "        <identifier identifierTarget=\"_abstract01\" scheme=\"http://purl.org/ukpl/subj\"/>\n",
      "        <identifier identifierTarget=\"_abstract01\" scheme=\"http://purl.org/ukpl/subj\"/>\n",
      "        <identifier identifierTarget=\"_abstract01\" scheme=\"http://purl.org/ukpl/subj\"/>\n",
      "        <identifier identifierTarget=\"_abstract01\" scheme=\"http://purl.org/ukpl/subj\"/>\n",
      "        <identifier identifierTarget=\"_abstract01\" scheme=\"http://purl.org/ukpl/subj\"/>\n",
      "        <identifier identifierTarget=\"_abstract01\" scheme=\"http://purl.org/ukpl/subj\"/>\n",
      "        <identifier identifierTarget=\"_abstract01\" scheme=\"http://purl.org/ukpl/subj\"/>\n",
      "        <identifier identifierTarget=\"_abstract01\" scheme=\"http://purl.org/ukpl/subj\"/>\n",
      "        <identifier identifierTarget=\"_abstract01\" scheme=\"http://purl.org/ukpl/subj\"/>\n",
      "        <identifier identifierTarget=\"_abstract01\" scheme=\"http://purl.org/ukpl/subj\"/>\n",
      "        <identifier identifierTarget=\"_abstract01\" scheme=\"http://purl.org/ukpl/subj\"/>\n",
      "        <identifier identifierTarget=\"_abstract01\" scheme=\"http://purl.org/ukpl/subj\"/>\n",
      "        <identifier identifierTarget=\"_abstract01\" scheme=\"http://purl.org/ukpl/subj\"/>\n",
      "        <identifier identifierTarget=\"_abstract01\" scheme=\"http://purl.org/ukpl/subj\"/>\n",
      "        <identifier identifierTarget=\"_abstract01\" scheme=\"http://purl.org/ukpl/subj\"/>\n",
      "        <identifier identifierTarget=\"_abstract01\" scheme=\"http://purl.org/ukpl/subj\"/>\n",
      "        <identifier identifierTarget=\"_abstract01\" scheme=\"http://purl.org/ukpl/subj\"/>\n",
      "        <identifier identifierTarget=\"_abstract01\" scheme=\"http://purl.org/ukpl/subj\"/>\n",
      "        <identifier identifierTarget=\"_abstract01\" scheme=\"http://purl.org/ukpl/subj\"/>\n",
      "        <identifier identifierTarget=\"_abstract01\" scheme=\"http://purl.org/ukpl/subj\"/>\n",
      "        <identifier identifierTarget=\"_abstract01\" scheme=\"http://purl.org/ukpl/subj\"/>\n",
      "        <identifier identifierTarget=\"_abstract01\" scheme=\"http://purl.org/ukpl/subj\"/>\n",
      "        <identifier identifierTarget=\"_abstract01\" scheme=\"http://purl.org/ukpl/subj\"/>\n",
      "        <identifier identifierTarget=\"_abstract01\" scheme=\"http://purl.org/ukpl/subj\"/>\n",
      "        <identifier identifierTarget=\"_abstract01\" scheme=\"http://purl.org/ukpl/subj\"/>\n",
      "        <identifier identifierTarget=\"_abstract01\" scheme=\"http://purl.org/ukpl/subj\"/>\n",
      "        <identifier identifierTarget=\"_abstract01\" scheme=\"http://purl.org/ukpl/subj\"/>\n",
      "        <identifier identifierTarget=\"_abstract01\" scheme=\"http://purl.org/ukpl/subj\"/>\n",
      "        <identifier identifierTarget=\"_abstract01\" scheme=\"http://purl.org/ukpl/subj\"/>\n",
      "        <identifier identifierTarget=\"_abstract01\" scheme=\"http://purl.org/ukpl/subj\"/>\n",
      "        <identifier identifierTarget=\"_abstract01\" scheme=\"http://purl.org/ukpl/subj\"/>\n",
      "        <identifier identifierTarget=\"_abstract01\" scheme=\"http://purl.org/ukpl/subj\"/>\n",
      "        <identifier identifierTarget=\"_abstract01\" scheme=\"http://purl.org/ukpl/subj\"/>\n",
      "        <identifier identifierTarget=\"_abstract01\" scheme=\"http://purl.org/ukpl/subj\"/>\n",
      "        <identifier identifierTarget=\"_abstract01\" scheme=\"http://purl.org/ukpl/subj\"/>\n",
      "        <identifier identifierTarget=\"_abstract01\" scheme=\"http://purl.org/ukpl/subj\"/>\n",
      "        <identifier identifierTarget=\"_abstract01\" scheme=\"http://purl.org/ukpl/subj\"/>\n",
      "        <identifier identifierTarget=\"_abstract01\" scheme=\"http://purl.org/ukpl/subj\"/>\n",
      "        <identifier identifierTarget=\"_abstract01\" scheme=\"http://purl.org/ukpl/subj\"/>\n",
      "        <identifier identifierTarget=\"_abstract01\" scheme=\"http://purl.org/ukpl/subj\"/>\n",
      "        <identifier identifierTarget=\"_abstract01\" "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[22]\u001b[39m\u001b[32m, line 41\u001b[39m\n\u001b[32m     33\u001b[39m text = tokenizer.apply_chat_template(\n\u001b[32m     34\u001b[39m     messages,\n\u001b[32m     35\u001b[39m     tokenize = \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m     36\u001b[39m     add_generation_prompt = \u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;66;03m# Must add for generation\u001b[39;00m\n\u001b[32m     37\u001b[39m     \u001b[38;5;66;03m#enable_thinking = False, # Disable thinking\u001b[39;00m\n\u001b[32m     38\u001b[39m )\n\u001b[32m     40\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtransformers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m TextStreamer\n\u001b[32m---> \u001b[39m\u001b[32m41\u001b[39m _ = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     42\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_tensors\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpt\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcuda\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     43\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_new_tokens\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m4096\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# Increase for longer outputs!\u001b[39;49;00m\n\u001b[32m     44\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0.6\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0.95\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_k\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m20\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# For thinking\u001b[39;49;00m\n\u001b[32m     45\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstreamer\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mTextStreamer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskip_prompt\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     46\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/peft/peft_model.py:1875\u001b[39m, in \u001b[36mPeftModelForCausalLM.generate\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1873\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._enable_peft_forward_hooks(*args, **kwargs):\n\u001b[32m   1874\u001b[39m         kwargs = {k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m kwargs.items() \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.special_peft_forward_args}\n\u001b[32m-> \u001b[39m\u001b[32m1875\u001b[39m         outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbase_model\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1876\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1877\u001b[39m     outputs = \u001b[38;5;28mself\u001b[39m.base_model.generate(**kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/unsloth/models/llama.py:1581\u001b[39m, in \u001b[36munsloth_fast_generate\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1579\u001b[39m \u001b[38;5;66;03m# Mixed precision autocast\u001b[39;00m\n\u001b[32m   1580\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.inference_mode(), torch.autocast(device_type = \u001b[33m\"\u001b[39m\u001b[33mcuda\u001b[39m\u001b[33m\"\u001b[39m, dtype = dtype):\n\u001b[32m-> \u001b[39m\u001b[32m1581\u001b[39m     output = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_old_generate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1582\u001b[39m \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[32m   1584\u001b[39m \u001b[38;5;66;03m# Return accelerate back\u001b[39;00m\n\u001b[32m   1585\u001b[39m \u001b[38;5;66;03m# if accelerate_new_send_to_device is not None:\u001b[39;00m\n\u001b[32m   1586\u001b[39m \u001b[38;5;66;03m#     accelerate.utils.operations.send_to_device = accelerate_old_send_to_device\u001b[39;00m\n\u001b[32m   1587\u001b[39m \u001b[38;5;66;03m# pass\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/torch/utils/_contextlib.py:116\u001b[39m, in \u001b[36mcontext_decorator.<locals>.decorate_context\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    113\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m    114\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecorate_context\u001b[39m(*args, **kwargs):\n\u001b[32m    115\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[32m--> \u001b[39m\u001b[32m116\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/transformers/generation/utils.py:2465\u001b[39m, in \u001b[36mGenerationMixin.generate\u001b[39m\u001b[34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, use_model_defaults, **kwargs)\u001b[39m\n\u001b[32m   2457\u001b[39m     input_ids, model_kwargs = \u001b[38;5;28mself\u001b[39m._expand_inputs_for_generation(\n\u001b[32m   2458\u001b[39m         input_ids=input_ids,\n\u001b[32m   2459\u001b[39m         expand_size=generation_config.num_return_sequences,\n\u001b[32m   2460\u001b[39m         is_encoder_decoder=\u001b[38;5;28mself\u001b[39m.config.is_encoder_decoder,\n\u001b[32m   2461\u001b[39m         **model_kwargs,\n\u001b[32m   2462\u001b[39m     )\n\u001b[32m   2464\u001b[39m     \u001b[38;5;66;03m# 12. run sample (it degenerates to greedy search when `generation_config.do_sample=False`)\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2465\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sample\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2466\u001b[39m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2467\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlogits_processor\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprepared_logits_processor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2468\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstopping_criteria\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprepared_stopping_criteria\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2469\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2470\u001b[39m \u001b[43m        \u001b[49m\u001b[43msynced_gpus\u001b[49m\u001b[43m=\u001b[49m\u001b[43msynced_gpus\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2471\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstreamer\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstreamer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2472\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2473\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2475\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m generation_mode \u001b[38;5;129;01min\u001b[39;00m (GenerationMode.BEAM_SAMPLE, GenerationMode.BEAM_SEARCH):\n\u001b[32m   2476\u001b[39m     \u001b[38;5;66;03m# 11. interleave input_ids with `num_beams` additional sequences per batch\u001b[39;00m\n\u001b[32m   2477\u001b[39m     input_ids, model_kwargs = \u001b[38;5;28mself\u001b[39m._expand_inputs_for_generation(\n\u001b[32m   2478\u001b[39m         input_ids=input_ids,\n\u001b[32m   2479\u001b[39m         expand_size=generation_config.num_beams,\n\u001b[32m   2480\u001b[39m         is_encoder_decoder=\u001b[38;5;28mself\u001b[39m.config.is_encoder_decoder,\n\u001b[32m   2481\u001b[39m         **model_kwargs,\n\u001b[32m   2482\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/transformers/generation/utils.py:3434\u001b[39m, in \u001b[36mGenerationMixin._sample\u001b[39m\u001b[34m(self, input_ids, logits_processor, stopping_criteria, generation_config, synced_gpus, streamer, **model_kwargs)\u001b[39m\n\u001b[32m   3432\u001b[39m     is_prefill = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m   3433\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3434\u001b[39m     outputs = \u001b[43mmodel_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m   3436\u001b[39m \u001b[38;5;66;03m# synced_gpus: don't waste resources running the code we don't need; kwargs must be updated before skipping\u001b[39;00m\n\u001b[32m   3437\u001b[39m model_kwargs = \u001b[38;5;28mself\u001b[39m._update_model_kwargs_for_generation(\n\u001b[32m   3438\u001b[39m     outputs,\n\u001b[32m   3439\u001b[39m     model_kwargs,\n\u001b[32m   3440\u001b[39m     is_encoder_decoder=\u001b[38;5;28mself\u001b[39m.config.is_encoder_decoder,\n\u001b[32m   3441\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/unsloth/models/llama.py:1033\u001b[39m, in \u001b[36mCausalLM_fast_forward.<locals>._CausalLM_fast_forward\u001b[39m\u001b[34m(self, input_ids, causal_mask, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict, num_logits_to_keep, logits_to_keep, *args, **kwargs)\u001b[39m\n\u001b[32m   1015\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_CausalLM_fast_forward\u001b[39m(\n\u001b[32m   1016\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1017\u001b[39m     input_ids: torch.LongTensor = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1030\u001b[39m     *args, **kwargs,\n\u001b[32m   1031\u001b[39m ) -> Union[Tuple, CausalLMOutputWithPast]:\n\u001b[32m   1032\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m past_key_values \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1033\u001b[39m         outputs = \u001b[43mfast_forward_inference\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1034\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1035\u001b[39m \u001b[43m            \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1036\u001b[39m \u001b[43m            \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1037\u001b[39m \u001b[43m            \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1038\u001b[39m \u001b[43m            \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1039\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1040\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1041\u001b[39m         causal_mask = xformers.attn_bias.LowerTriangularMask() \u001b[38;5;28;01mif\u001b[39;00m HAS_XFORMERS \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/unsloth/models/llama.py:966\u001b[39m, in \u001b[36m_LlamaModel_fast_forward_inference.<locals>.LlamaModel_fast_forward_inference_custom\u001b[39m\u001b[34m(self, input_ids, past_key_values, position_ids, attention_mask)\u001b[39m\n\u001b[32m    958\u001b[39m residual.copy_(X) \u001b[38;5;66;03m# residual = X\u001b[39;00m\n\u001b[32m    959\u001b[39m X = fast_rms_layernorm_inference(\n\u001b[32m    960\u001b[39m     decoder_layer.input_layernorm,\n\u001b[32m    961\u001b[39m     X,\n\u001b[32m   (...)\u001b[39m\u001b[32m    964\u001b[39m     variance = variance,\n\u001b[32m    965\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m966\u001b[39m X, present_key_value = \u001b[43mattention_fast_forward_inference\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    967\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdecoder_layer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mself_attn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    968\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    969\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    970\u001b[39m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    971\u001b[39m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    972\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdo_prefill\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mhasattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdecoder_layer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mself_attn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpaged_attention\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    973\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    974\u001b[39m X += residual\n\u001b[32m    976\u001b[39m residual.copy_(X) \u001b[38;5;66;03m# residual = X\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/unsloth/models/llama.py:277\u001b[39m, in \u001b[36mLlamaAttention_fast_forward_inference\u001b[39m\u001b[34m(self, hidden_states, past_key_value, position_ids, do_prefill, attention_mask)\u001b[39m\n\u001b[32m    275\u001b[39m     A = torch_matmul(Qn, Knn.transpose(\u001b[32m2\u001b[39m, \u001b[32m3\u001b[39m), out = \u001b[38;5;28mself\u001b[39m.attention[:,:,:,:cached_len])\n\u001b[32m    276\u001b[39m     \u001b[38;5;66;03m# if attention_mask is not None: A += attention_mask # Must add attention_mask for batched\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m277\u001b[39m     A[:] = \u001b[43mtorch_nn_functional_softmax\u001b[49m\u001b[43m(\u001b[49m\u001b[43mA\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43m-\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfloat32\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;66;03m#.to(A.dtype)\u001b[39;00m\n\u001b[32m    278\u001b[39m     A = torch_matmul(A, Vnn, out = Qn)\n\u001b[32m    279\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/torch/nn/functional.py:2142\u001b[39m, in \u001b[36msoftmax\u001b[39m\u001b[34m(input, dim, _stacklevel, dtype)\u001b[39m\n\u001b[32m   2140\u001b[39m     ret = \u001b[38;5;28minput\u001b[39m.softmax(dim)\n\u001b[32m   2141\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2142\u001b[39m     ret = \u001b[38;5;28;43minput\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msoftmax\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2143\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m ret\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "user_metadata = \"\"\"\n",
    "Title: La dynastie des Ming\n",
    "Author: Jean-Pierre Duteil\n",
    "Editor/Director: sous la direction de Jean Heuclin\n",
    "Author details:\n",
    "- Duteil, Jean-Pierre (1952-...)\n",
    "- Heuclin, Jean (1949-...), historien\n",
    "Edition: Nouvelle Ã©dition\n",
    "Publisher: Ellipses\n",
    "Place of publication: Paris\n",
    "Year: 2024\n",
    "ISBN: 978-2-340-08969-3 (note: also 9782340089693)\n",
    "Language: French\n",
    "Country of publication: France\n",
    "Physical description: 1 volume (287 pages), includes cartes, plans, cover illustrated in color, 18 cm\n",
    "Bibliography: Bibliogr. p. 279-286\n",
    "Abstract/Notes:\n",
    "Les Ming, une dynastie brillante dominÃ©e par les Han installÃ©s Ã  PÃ©kin Ã  lâ€™Ã©poque du Quattrocento et de la Renaissance en Europe ; les deux civilisations devaient se rencontrer par une expansion maritime similaire, une dÃ©couverte inquiÃ¨te et remplie des mystÃ¨res orientaux. Le fondateur Hongwu (1368-1398) Ã  lâ€™instar de notre Henri IV, tournant le dos Ã  lâ€™influence nomade mongole, Ã©tablit une sociÃ©tÃ© rurale autosuffisante dont lâ€™essor des productions cÃ©rÃ©aliÃ¨res alimenta toute une Ã©conomie marchande et urbaine. Des projets grandioses virent le jour comme le Grand Canal, la Grande Muraille ou la CitÃ© interdite avec une puissante marine et une armÃ©e de mÃ©tier. Tout un systÃ¨me administratif de fonctionnaires recrutÃ©s par concours sur leurs mÃ©rites accompagne une remarquable crÃ©ation littÃ©raire, calligraphique et artistique facilitÃ©e par lâ€™impression de livres. Cette magnifique construction tomba progressivement sous lâ€™emprise sclÃ©rosante de ces mÃªmes Â« lettrÃ©s Â» trop empreints dâ€™un confucianisme qui rÃ©sistait mal Ã  la critique de la politique gouvernementale et au comportement extravagant des empereurs. Des rÃ©voltes se firent jour durant le dernier siÃ¨cle de la dynastie marquÃ©e par une succession de catastrophes naturelles et dâ€™Ã©pidÃ©mies qui ruinÃ¨rent lâ€™une des pÃ©riodes les plus riches de lâ€™histoire de lâ€™Empire du Milieu.\n",
    "Source of the abstract/notes: 4e de couverture (back cover)\n",
    "Subject/Keywords:\n",
    "- Chine\n",
    "- Dynastie des Ming (1368-1644)\n",
    "Classification: 951.02 (subject classification)\n",
    "Publication history note: Paru prÃ©cÃ©demment en 2016\n",
    "Additional edition note: La 1Ã¨re Ã©dition de ce livre a Ã©tÃ© publiÃ©e en grand format en 2016 dans la collection \"Biographies et mythes historiques\" dirigÃ©e par StÃ©phane Curveiller\n",
    "Collection/Series: Collection \"Biographies et mythes historiques\" (inferred from note about first edition)\n",
    "\"\"\"\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": system_prompt},\n",
    "    {\"role\" : \"user\", \"content\" : user_metadata}\n",
    "]\n",
    "text = tokenizer.apply_chat_template(\n",
    "    messages,\n",
    "    tokenize = False,\n",
    "    add_generation_prompt = True, # Must add for generation\n",
    "    #enable_thinking = False, # Disable thinking\n",
    ")\n",
    "\n",
    "from transformers import TextStreamer\n",
    "_ = model.generate(\n",
    "    **tokenizer(text, return_tensors = \"pt\").to(\"cuda\"),\n",
    "    max_new_tokens = 4096, # Increase for longer outputs!\n",
    "    temperature = 0.6, top_p = 0.95, top_k = 20, # For thinking\n",
    "    streamer = TextStreamer(tokenizer, skip_prompt = True),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2a1ead0-d4d1-4eb3-a176-44d698ff3060",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
